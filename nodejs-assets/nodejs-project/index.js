#! /usr/bin/env node
(function prelude(content, deps, entry) {
  var cache = {}

  function load(file) {
    var d = deps[file]
    if (cache[file]) return cache[file].exports
    if (!d) return require(file)
    var fn = content[d[0]] //the actual module
    var module = (cache[file] = {
      exports: {},
      parent: file !== entry,
      require: require
    })
    cache[file] = module
    var resolved = require('path').resolve(__dirname, file)
    var dirname = require('path').dirname(resolved)
    fn.call(
      module.exports,
      function(m) {
        if (!d[1][m]) return require(m)
        else return load(d[1][m])
      },
      module,
      module.exports,
      dirname,
      resolved
    )
    return cache[file].exports
  }

  return load(entry)
})({
"+1U1cNlSvfoFauoKg7QIMQYA6dPbPgxZIt+oQQlZlvA=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "abaco",
    "abbaglio",
    "abbinato",
    "abete",
    "abisso",
    "abolire",
    "abrasivo",
    "abrogato",
    "accadere",
    "accenno",
    "accusato",
    "acetone",
    "achille",
    "acido",
    "acqua",
    "acre",
    "acrilico",
    "acrobata",
    "acuto",
    "adagio",
    "addebito",
    "addome",
    "adeguato",
    "aderire",
    "adipe",
    "adottare",
    "adulare",
    "affabile",
    "affetto",
    "affisso",
    "affranto",
    "aforisma",
    "afoso",
    "africano",
    "agave",
    "agente",
    "agevole",
    "aggancio",
    "agire",
    "agitare",
    "agonismo",
    "agricolo",
    "agrumeto",
    "aguzzo",
    "alabarda",
    "alato",
    "albatro",
    "alberato",
    "albo",
    "albume",
    "alce",
    "alcolico",
    "alettone",
    "alfa",
    "algebra",
    "aliante",
    "alibi",
    "alimento",
    "allagato",
    "allegro",
    "allievo",
    "allodola",
    "allusivo",
    "almeno",
    "alogeno",
    "alpaca",
    "alpestre",
    "altalena",
    "alterno",
    "alticcio",
    "altrove",
    "alunno",
    "alveolo",
    "alzare",
    "amalgama",
    "amanita",
    "amarena",
    "ambito",
    "ambrato",
    "ameba",
    "america",
    "ametista",
    "amico",
    "ammasso",
    "ammenda",
    "ammirare",
    "ammonito",
    "amore",
    "ampio",
    "ampliare",
    "amuleto",
    "anacardo",
    "anagrafe",
    "analista",
    "anarchia",
    "anatra",
    "anca",
    "ancella",
    "ancora",
    "andare",
    "andrea",
    "anello",
    "angelo",
    "angolare",
    "angusto",
    "anima",
    "annegare",
    "annidato",
    "anno",
    "annuncio",
    "anonimo",
    "anticipo",
    "anzi",
    "apatico",
    "apertura",
    "apode",
    "apparire",
    "appetito",
    "appoggio",
    "approdo",
    "appunto",
    "aprile",
    "arabica",
    "arachide",
    "aragosta",
    "araldica",
    "arancio",
    "aratura",
    "arazzo",
    "arbitro",
    "archivio",
    "ardito",
    "arenile",
    "argento",
    "argine",
    "arguto",
    "aria",
    "armonia",
    "arnese",
    "arredato",
    "arringa",
    "arrosto",
    "arsenico",
    "arso",
    "artefice",
    "arzillo",
    "asciutto",
    "ascolto",
    "asepsi",
    "asettico",
    "asfalto",
    "asino",
    "asola",
    "aspirato",
    "aspro",
    "assaggio",
    "asse",
    "assoluto",
    "assurdo",
    "asta",
    "astenuto",
    "astice",
    "astratto",
    "atavico",
    "ateismo",
    "atomico",
    "atono",
    "attesa",
    "attivare",
    "attorno",
    "attrito",
    "attuale",
    "ausilio",
    "austria",
    "autista",
    "autonomo",
    "autunno",
    "avanzato",
    "avere",
    "avvenire",
    "avviso",
    "avvolgere",
    "azione",
    "azoto",
    "azzimo",
    "azzurro",
    "babele",
    "baccano",
    "bacino",
    "baco",
    "badessa",
    "badilata",
    "bagnato",
    "baita",
    "balcone",
    "baldo",
    "balena",
    "ballata",
    "balzano",
    "bambino",
    "bandire",
    "baraonda",
    "barbaro",
    "barca",
    "baritono",
    "barlume",
    "barocco",
    "basilico",
    "basso",
    "batosta",
    "battuto",
    "baule",
    "bava",
    "bavosa",
    "becco",
    "beffa",
    "belgio",
    "belva",
    "benda",
    "benevole",
    "benigno",
    "benzina",
    "bere",
    "berlina",
    "beta",
    "bibita",
    "bici",
    "bidone",
    "bifido",
    "biga",
    "bilancia",
    "bimbo",
    "binocolo",
    "biologo",
    "bipede",
    "bipolare",
    "birbante",
    "birra",
    "biscotto",
    "bisesto",
    "bisnonno",
    "bisonte",
    "bisturi",
    "bizzarro",
    "blando",
    "blatta",
    "bollito",
    "bonifico",
    "bordo",
    "bosco",
    "botanico",
    "bottino",
    "bozzolo",
    "braccio",
    "bradipo",
    "brama",
    "branca",
    "bravura",
    "bretella",
    "brevetto",
    "brezza",
    "briglia",
    "brillante",
    "brindare",
    "broccolo",
    "brodo",
    "bronzina",
    "brullo",
    "bruno",
    "bubbone",
    "buca",
    "budino",
    "buffone",
    "buio",
    "bulbo",
    "buono",
    "burlone",
    "burrasca",
    "bussola",
    "busta",
    "cadetto",
    "caduco",
    "calamaro",
    "calcolo",
    "calesse",
    "calibro",
    "calmo",
    "caloria",
    "cambusa",
    "camerata",
    "camicia",
    "cammino",
    "camola",
    "campale",
    "canapa",
    "candela",
    "cane",
    "canino",
    "canotto",
    "cantina",
    "capace",
    "capello",
    "capitolo",
    "capogiro",
    "cappero",
    "capra",
    "capsula",
    "carapace",
    "carcassa",
    "cardo",
    "carisma",
    "carovana",
    "carretto",
    "cartolina",
    "casaccio",
    "cascata",
    "caserma",
    "caso",
    "cassone",
    "castello",
    "casuale",
    "catasta",
    "catena",
    "catrame",
    "cauto",
    "cavillo",
    "cedibile",
    "cedrata",
    "cefalo",
    "celebre",
    "cellulare",
    "cena",
    "cenone",
    "centesimo",
    "ceramica",
    "cercare",
    "certo",
    "cerume",
    "cervello",
    "cesoia",
    "cespo",
    "ceto",
    "chela",
    "chiaro",
    "chicca",
    "chiedere",
    "chimera",
    "china",
    "chirurgo",
    "chitarra",
    "ciao",
    "ciclismo",
    "cifrare",
    "cigno",
    "cilindro",
    "ciottolo",
    "circa",
    "cirrosi",
    "citrico",
    "cittadino",
    "ciuffo",
    "civetta",
    "civile",
    "classico",
    "clinica",
    "cloro",
    "cocco",
    "codardo",
    "codice",
    "coerente",
    "cognome",
    "collare",
    "colmato",
    "colore",
    "colposo",
    "coltivato",
    "colza",
    "coma",
    "cometa",
    "commando",
    "comodo",
    "computer",
    "comune",
    "conciso",
    "condurre",
    "conferma",
    "congelare",
    "coniuge",
    "connesso",
    "conoscere",
    "consumo",
    "continuo",
    "convegno",
    "coperto",
    "copione",
    "coppia",
    "copricapo",
    "corazza",
    "cordata",
    "coricato",
    "cornice",
    "corolla",
    "corpo",
    "corredo",
    "corsia",
    "cortese",
    "cosmico",
    "costante",
    "cottura",
    "covato",
    "cratere",
    "cravatta",
    "creato",
    "credere",
    "cremoso",
    "crescita",
    "creta",
    "criceto",
    "crinale",
    "crisi",
    "critico",
    "croce",
    "cronaca",
    "crostata",
    "cruciale",
    "crusca",
    "cucire",
    "cuculo",
    "cugino",
    "cullato",
    "cupola",
    "curatore",
    "cursore",
    "curvo",
    "cuscino",
    "custode",
    "dado",
    "daino",
    "dalmata",
    "damerino",
    "daniela",
    "dannoso",
    "danzare",
    "datato",
    "davanti",
    "davvero",
    "debutto",
    "decennio",
    "deciso",
    "declino",
    "decollo",
    "decreto",
    "dedicato",
    "definito",
    "deforme",
    "degno",
    "delegare",
    "delfino",
    "delirio",
    "delta",
    "demenza",
    "denotato",
    "dentro",
    "deposito",
    "derapata",
    "derivare",
    "deroga",
    "descritto",
    "deserto",
    "desiderio",
    "desumere",
    "detersivo",
    "devoto",
    "diametro",
    "dicembre",
    "diedro",
    "difeso",
    "diffuso",
    "digerire",
    "digitale",
    "diluvio",
    "dinamico",
    "dinnanzi",
    "dipinto",
    "diploma",
    "dipolo",
    "diradare",
    "dire",
    "dirotto",
    "dirupo",
    "disagio",
    "discreto",
    "disfare",
    "disgelo",
    "disposto",
    "distanza",
    "disumano",
    "dito",
    "divano",
    "divelto",
    "dividere",
    "divorato",
    "doblone",
    "docente",
    "doganale",
    "dogma",
    "dolce",
    "domato",
    "domenica",
    "dominare",
    "dondolo",
    "dono",
    "dormire",
    "dote",
    "dottore",
    "dovuto",
    "dozzina",
    "drago",
    "druido",
    "dubbio",
    "dubitare",
    "ducale",
    "duna",
    "duomo",
    "duplice",
    "duraturo",
    "ebano",
    "eccesso",
    "ecco",
    "eclissi",
    "economia",
    "edera",
    "edicola",
    "edile",
    "editoria",
    "educare",
    "egemonia",
    "egli",
    "egoismo",
    "egregio",
    "elaborato",
    "elargire",
    "elegante",
    "elencato",
    "eletto",
    "elevare",
    "elfico",
    "elica",
    "elmo",
    "elsa",
    "eluso",
    "emanato",
    "emblema",
    "emesso",
    "emiro",
    "emotivo",
    "emozione",
    "empirico",
    "emulo",
    "endemico",
    "enduro",
    "energia",
    "enfasi",
    "enoteca",
    "entrare",
    "enzima",
    "epatite",
    "epilogo",
    "episodio",
    "epocale",
    "eppure",
    "equatore",
    "erario",
    "erba",
    "erboso",
    "erede",
    "eremita",
    "erigere",
    "ermetico",
    "eroe",
    "erosivo",
    "errante",
    "esagono",
    "esame",
    "esanime",
    "esaudire",
    "esca",
    "esempio",
    "esercito",
    "esibito",
    "esigente",
    "esistere",
    "esito",
    "esofago",
    "esortato",
    "esoso",
    "espanso",
    "espresso",
    "essenza",
    "esso",
    "esteso",
    "estimare",
    "estonia",
    "estroso",
    "esultare",
    "etilico",
    "etnico",
    "etrusco",
    "etto",
    "euclideo",
    "europa",
    "evaso",
    "evidenza",
    "evitato",
    "evoluto",
    "evviva",
    "fabbrica",
    "faccenda",
    "fachiro",
    "falco",
    "famiglia",
    "fanale",
    "fanfara",
    "fango",
    "fantasma",
    "fare",
    "farfalla",
    "farinoso",
    "farmaco",
    "fascia",
    "fastoso",
    "fasullo",
    "faticare",
    "fato",
    "favoloso",
    "febbre",
    "fecola",
    "fede",
    "fegato",
    "felpa",
    "feltro",
    "femmina",
    "fendere",
    "fenomeno",
    "fermento",
    "ferro",
    "fertile",
    "fessura",
    "festivo",
    "fetta",
    "feudo",
    "fiaba",
    "fiducia",
    "fifa",
    "figurato",
    "filo",
    "finanza",
    "finestra",
    "finire",
    "fiore",
    "fiscale",
    "fisico",
    "fiume",
    "flacone",
    "flamenco",
    "flebo",
    "flemma",
    "florido",
    "fluente",
    "fluoro",
    "fobico",
    "focaccia",
    "focoso",
    "foderato",
    "foglio",
    "folata",
    "folclore",
    "folgore",
    "fondente",
    "fonetico",
    "fonia",
    "fontana",
    "forbito",
    "forchetta",
    "foresta",
    "formica",
    "fornaio",
    "foro",
    "fortezza",
    "forzare",
    "fosfato",
    "fosso",
    "fracasso",
    "frana",
    "frassino",
    "fratello",
    "freccetta",
    "frenata",
    "fresco",
    "frigo",
    "frollino",
    "fronde",
    "frugale",
    "frutta",
    "fucilata",
    "fucsia",
    "fuggente",
    "fulmine",
    "fulvo",
    "fumante",
    "fumetto",
    "fumoso",
    "fune",
    "funzione",
    "fuoco",
    "furbo",
    "furgone",
    "furore",
    "fuso",
    "futile",
    "gabbiano",
    "gaffe",
    "galateo",
    "gallina",
    "galoppo",
    "gambero",
    "gamma",
    "garanzia",
    "garbo",
    "garofano",
    "garzone",
    "gasdotto",
    "gasolio",
    "gastrico",
    "gatto",
    "gaudio",
    "gazebo",
    "gazzella",
    "geco",
    "gelatina",
    "gelso",
    "gemello",
    "gemmato",
    "gene",
    "genitore",
    "gennaio",
    "genotipo",
    "gergo",
    "ghepardo",
    "ghiaccio",
    "ghisa",
    "giallo",
    "gilda",
    "ginepro",
    "giocare",
    "gioiello",
    "giorno",
    "giove",
    "girato",
    "girone",
    "gittata",
    "giudizio",
    "giurato",
    "giusto",
    "globulo",
    "glutine",
    "gnomo",
    "gobba",
    "golf",
    "gomito",
    "gommone",
    "gonfio",
    "gonna",
    "governo",
    "gracile",
    "grado",
    "grafico",
    "grammo",
    "grande",
    "grattare",
    "gravoso",
    "grazia",
    "greca",
    "gregge",
    "grifone",
    "grigio",
    "grinza",
    "grotta",
    "gruppo",
    "guadagno",
    "guaio",
    "guanto",
    "guardare",
    "gufo",
    "guidare",
    "ibernato",
    "icona",
    "identico",
    "idillio",
    "idolo",
    "idra",
    "idrico",
    "idrogeno",
    "igiene",
    "ignaro",
    "ignorato",
    "ilare",
    "illeso",
    "illogico",
    "illudere",
    "imballo",
    "imbevuto",
    "imbocco",
    "imbuto",
    "immane",
    "immerso",
    "immolato",
    "impacco",
    "impeto",
    "impiego",
    "importo",
    "impronta",
    "inalare",
    "inarcare",
    "inattivo",
    "incanto",
    "incendio",
    "inchino",
    "incisivo",
    "incluso",
    "incontro",
    "incrocio",
    "incubo",
    "indagine",
    "india",
    "indole",
    "inedito",
    "infatti",
    "infilare",
    "inflitto",
    "ingaggio",
    "ingegno",
    "inglese",
    "ingordo",
    "ingrosso",
    "innesco",
    "inodore",
    "inoltrare",
    "inondato",
    "insano",
    "insetto",
    "insieme",
    "insonnia",
    "insulina",
    "intasato",
    "intero",
    "intonaco",
    "intuito",
    "inumidire",
    "invalido",
    "invece",
    "invito",
    "iperbole",
    "ipnotico",
    "ipotesi",
    "ippica",
    "iride",
    "irlanda",
    "ironico",
    "irrigato",
    "irrorare",
    "isolato",
    "isotopo",
    "isterico",
    "istituto",
    "istrice",
    "italia",
    "iterare",
    "labbro",
    "labirinto",
    "lacca",
    "lacerato",
    "lacrima",
    "lacuna",
    "laddove",
    "lago",
    "lampo",
    "lancetta",
    "lanterna",
    "lardoso",
    "larga",
    "laringe",
    "lastra",
    "latenza",
    "latino",
    "lattuga",
    "lavagna",
    "lavoro",
    "legale",
    "leggero",
    "lembo",
    "lentezza",
    "lenza",
    "leone",
    "lepre",
    "lesivo",
    "lessato",
    "lesto",
    "letterale",
    "leva",
    "levigato",
    "libero",
    "lido",
    "lievito",
    "lilla",
    "limatura",
    "limitare",
    "limpido",
    "lineare",
    "lingua",
    "liquido",
    "lira",
    "lirica",
    "lisca",
    "lite",
    "litigio",
    "livrea",
    "locanda",
    "lode",
    "logica",
    "lombare",
    "londra",
    "longevo",
    "loquace",
    "lorenzo",
    "loto",
    "lotteria",
    "luce",
    "lucidato",
    "lumaca",
    "luminoso",
    "lungo",
    "lupo",
    "luppolo",
    "lusinga",
    "lusso",
    "lutto",
    "macabro",
    "macchina",
    "macero",
    "macinato",
    "madama",
    "magico",
    "maglia",
    "magnete",
    "magro",
    "maiolica",
    "malafede",
    "malgrado",
    "malinteso",
    "malsano",
    "malto",
    "malumore",
    "mana",
    "mancia",
    "mandorla",
    "mangiare",
    "manifesto",
    "mannaro",
    "manovra",
    "mansarda",
    "mantide",
    "manubrio",
    "mappa",
    "maratona",
    "marcire",
    "maretta",
    "marmo",
    "marsupio",
    "maschera",
    "massaia",
    "mastino",
    "materasso",
    "matricola",
    "mattone",
    "maturo",
    "mazurca",
    "meandro",
    "meccanico",
    "mecenate",
    "medesimo",
    "meditare",
    "mega",
    "melassa",
    "melis",
    "melodia",
    "meninge",
    "meno",
    "mensola",
    "mercurio",
    "merenda",
    "merlo",
    "meschino",
    "mese",
    "messere",
    "mestolo",
    "metallo",
    "metodo",
    "mettere",
    "miagolare",
    "mica",
    "micelio",
    "michele",
    "microbo",
    "midollo",
    "miele",
    "migliore",
    "milano",
    "milite",
    "mimosa",
    "minerale",
    "mini",
    "minore",
    "mirino",
    "mirtillo",
    "miscela",
    "missiva",
    "misto",
    "misurare",
    "mitezza",
    "mitigare",
    "mitra",
    "mittente",
    "mnemonico",
    "modello",
    "modifica",
    "modulo",
    "mogano",
    "mogio",
    "mole",
    "molosso",
    "monastero",
    "monco",
    "mondina",
    "monetario",
    "monile",
    "monotono",
    "monsone",
    "montato",
    "monviso",
    "mora",
    "mordere",
    "morsicato",
    "mostro",
    "motivato",
    "motosega",
    "motto",
    "movenza",
    "movimento",
    "mozzo",
    "mucca",
    "mucosa",
    "muffa",
    "mughetto",
    "mugnaio",
    "mulatto",
    "mulinello",
    "multiplo",
    "mummia",
    "munto",
    "muovere",
    "murale",
    "musa",
    "muscolo",
    "musica",
    "mutevole",
    "muto",
    "nababbo",
    "nafta",
    "nanometro",
    "narciso",
    "narice",
    "narrato",
    "nascere",
    "nastrare",
    "naturale",
    "nautica",
    "naviglio",
    "nebulosa",
    "necrosi",
    "negativo",
    "negozio",
    "nemmeno",
    "neofita",
    "neretto",
    "nervo",
    "nessuno",
    "nettuno",
    "neutrale",
    "neve",
    "nevrotico",
    "nicchia",
    "ninfa",
    "nitido",
    "nobile",
    "nocivo",
    "nodo",
    "nome",
    "nomina",
    "nordico",
    "normale",
    "norvegese",
    "nostrano",
    "notare",
    "notizia",
    "notturno",
    "novella",
    "nucleo",
    "nulla",
    "numero",
    "nuovo",
    "nutrire",
    "nuvola",
    "nuziale",
    "oasi",
    "obbedire",
    "obbligo",
    "obelisco",
    "oblio",
    "obolo",
    "obsoleto",
    "occasione",
    "occhio",
    "occidente",
    "occorrere",
    "occultare",
    "ocra",
    "oculato",
    "odierno",
    "odorare",
    "offerta",
    "offrire",
    "offuscato",
    "oggetto",
    "oggi",
    "ognuno",
    "olandese",
    "olfatto",
    "oliato",
    "oliva",
    "ologramma",
    "oltre",
    "omaggio",
    "ombelico",
    "ombra",
    "omega",
    "omissione",
    "ondoso",
    "onere",
    "onice",
    "onnivoro",
    "onorevole",
    "onta",
    "operato",
    "opinione",
    "opposto",
    "oracolo",
    "orafo",
    "ordine",
    "orecchino",
    "orefice",
    "orfano",
    "organico",
    "origine",
    "orizzonte",
    "orma",
    "ormeggio",
    "ornativo",
    "orologio",
    "orrendo",
    "orribile",
    "ortensia",
    "ortica",
    "orzata",
    "orzo",
    "osare",
    "oscurare",
    "osmosi",
    "ospedale",
    "ospite",
    "ossa",
    "ossidare",
    "ostacolo",
    "oste",
    "otite",
    "otre",
    "ottagono",
    "ottimo",
    "ottobre",
    "ovale",
    "ovest",
    "ovino",
    "oviparo",
    "ovocito",
    "ovunque",
    "ovviare",
    "ozio",
    "pacchetto",
    "pace",
    "pacifico",
    "padella",
    "padrone",
    "paese",
    "paga",
    "pagina",
    "palazzina",
    "palesare",
    "pallido",
    "palo",
    "palude",
    "pandoro",
    "pannello",
    "paolo",
    "paonazzo",
    "paprica",
    "parabola",
    "parcella",
    "parere",
    "pargolo",
    "pari",
    "parlato",
    "parola",
    "partire",
    "parvenza",
    "parziale",
    "passivo",
    "pasticca",
    "patacca",
    "patologia",
    "pattume",
    "pavone",
    "peccato",
    "pedalare",
    "pedonale",
    "peggio",
    "peloso",
    "penare",
    "pendice",
    "penisola",
    "pennuto",
    "penombra",
    "pensare",
    "pentola",
    "pepe",
    "pepita",
    "perbene",
    "percorso",
    "perdonato",
    "perforare",
    "pergamena",
    "periodo",
    "permesso",
    "perno",
    "perplesso",
    "persuaso",
    "pertugio",
    "pervaso",
    "pesatore",
    "pesista",
    "peso",
    "pestifero",
    "petalo",
    "pettine",
    "petulante",
    "pezzo",
    "piacere",
    "pianta",
    "piattino",
    "piccino",
    "picozza",
    "piega",
    "pietra",
    "piffero",
    "pigiama",
    "pigolio",
    "pigro",
    "pila",
    "pilifero",
    "pillola",
    "pilota",
    "pimpante",
    "pineta",
    "pinna",
    "pinolo",
    "pioggia",
    "piombo",
    "piramide",
    "piretico",
    "pirite",
    "pirolisi",
    "pitone",
    "pizzico",
    "placebo",
    "planare",
    "plasma",
    "platano",
    "plenario",
    "pochezza",
    "poderoso",
    "podismo",
    "poesia",
    "poggiare",
    "polenta",
    "poligono",
    "pollice",
    "polmonite",
    "polpetta",
    "polso",
    "poltrona",
    "polvere",
    "pomice",
    "pomodoro",
    "ponte",
    "popoloso",
    "porfido",
    "poroso",
    "porpora",
    "porre",
    "portata",
    "posa",
    "positivo",
    "possesso",
    "postulato",
    "potassio",
    "potere",
    "pranzo",
    "prassi",
    "pratica",
    "precluso",
    "predica",
    "prefisso",
    "pregiato",
    "prelievo",
    "premere",
    "prenotare",
    "preparato",
    "presenza",
    "pretesto",
    "prevalso",
    "prima",
    "principe",
    "privato",
    "problema",
    "procura",
    "produrre",
    "profumo",
    "progetto",
    "prolunga",
    "promessa",
    "pronome",
    "proposta",
    "proroga",
    "proteso",
    "prova",
    "prudente",
    "prugna",
    "prurito",
    "psiche",
    "pubblico",
    "pudica",
    "pugilato",
    "pugno",
    "pulce",
    "pulito",
    "pulsante",
    "puntare",
    "pupazzo",
    "pupilla",
    "puro",
    "quadro",
    "qualcosa",
    "quasi",
    "querela",
    "quota",
    "raccolto",
    "raddoppio",
    "radicale",
    "radunato",
    "raffica",
    "ragazzo",
    "ragione",
    "ragno",
    "ramarro",
    "ramingo",
    "ramo",
    "randagio",
    "rantolare",
    "rapato",
    "rapina",
    "rappreso",
    "rasatura",
    "raschiato",
    "rasente",
    "rassegna",
    "rastrello",
    "rata",
    "ravveduto",
    "reale",
    "recepire",
    "recinto",
    "recluta",
    "recondito",
    "recupero",
    "reddito",
    "redimere",
    "regalato",
    "registro",
    "regola",
    "regresso",
    "relazione",
    "remare",
    "remoto",
    "renna",
    "replica",
    "reprimere",
    "reputare",
    "resa",
    "residente",
    "responso",
    "restauro",
    "rete",
    "retina",
    "retorica",
    "rettifica",
    "revocato",
    "riassunto",
    "ribadire",
    "ribelle",
    "ribrezzo",
    "ricarica",
    "ricco",
    "ricevere",
    "riciclato",
    "ricordo",
    "ricreduto",
    "ridicolo",
    "ridurre",
    "rifasare",
    "riflesso",
    "riforma",
    "rifugio",
    "rigare",
    "rigettato",
    "righello",
    "rilassato",
    "rilevato",
    "rimanere",
    "rimbalzo",
    "rimedio",
    "rimorchio",
    "rinascita",
    "rincaro",
    "rinforzo",
    "rinnovo",
    "rinomato",
    "rinsavito",
    "rintocco",
    "rinuncia",
    "rinvenire",
    "riparato",
    "ripetuto",
    "ripieno",
    "riportare",
    "ripresa",
    "ripulire",
    "risata",
    "rischio",
    "riserva",
    "risibile",
    "riso",
    "rispetto",
    "ristoro",
    "risultato",
    "risvolto",
    "ritardo",
    "ritegno",
    "ritmico",
    "ritrovo",
    "riunione",
    "riva",
    "riverso",
    "rivincita",
    "rivolto",
    "rizoma",
    "roba",
    "robotico",
    "robusto",
    "roccia",
    "roco",
    "rodaggio",
    "rodere",
    "roditore",
    "rogito",
    "rollio",
    "romantico",
    "rompere",
    "ronzio",
    "rosolare",
    "rospo",
    "rotante",
    "rotondo",
    "rotula",
    "rovescio",
    "rubizzo",
    "rubrica",
    "ruga",
    "rullino",
    "rumine",
    "rumoroso",
    "ruolo",
    "rupe",
    "russare",
    "rustico",
    "sabato",
    "sabbiare",
    "sabotato",
    "sagoma",
    "salasso",
    "saldatura",
    "salgemma",
    "salivare",
    "salmone",
    "salone",
    "saltare",
    "saluto",
    "salvo",
    "sapere",
    "sapido",
    "saporito",
    "saraceno",
    "sarcasmo",
    "sarto",
    "sassoso",
    "satellite",
    "satira",
    "satollo",
    "saturno",
    "savana",
    "savio",
    "saziato",
    "sbadiglio",
    "sbalzo",
    "sbancato",
    "sbarra",
    "sbattere",
    "sbavare",
    "sbendare",
    "sbirciare",
    "sbloccato",
    "sbocciato",
    "sbrinare",
    "sbruffone",
    "sbuffare",
    "scabroso",
    "scadenza",
    "scala",
    "scambiare",
    "scandalo",
    "scapola",
    "scarso",
    "scatenare",
    "scavato",
    "scelto",
    "scenico",
    "scettro",
    "scheda",
    "schiena",
    "sciarpa",
    "scienza",
    "scindere",
    "scippo",
    "sciroppo",
    "scivolo",
    "sclerare",
    "scodella",
    "scolpito",
    "scomparto",
    "sconforto",
    "scoprire",
    "scorta",
    "scossone",
    "scozzese",
    "scriba",
    "scrollare",
    "scrutinio",
    "scuderia",
    "scultore",
    "scuola",
    "scuro",
    "scusare",
    "sdebitare",
    "sdoganare",
    "seccatura",
    "secondo",
    "sedano",
    "seggiola",
    "segnalato",
    "segregato",
    "seguito",
    "selciato",
    "selettivo",
    "sella",
    "selvaggio",
    "semaforo",
    "sembrare",
    "seme",
    "seminato",
    "sempre",
    "senso",
    "sentire",
    "sepolto",
    "sequenza",
    "serata",
    "serbato",
    "sereno",
    "serio",
    "serpente",
    "serraglio",
    "servire",
    "sestina",
    "setola",
    "settimana",
    "sfacelo",
    "sfaldare",
    "sfamato",
    "sfarzoso",
    "sfaticato",
    "sfera",
    "sfida",
    "sfilato",
    "sfinge",
    "sfocato",
    "sfoderare",
    "sfogo",
    "sfoltire",
    "sforzato",
    "sfratto",
    "sfruttato",
    "sfuggito",
    "sfumare",
    "sfuso",
    "sgabello",
    "sgarbato",
    "sgonfiare",
    "sgorbio",
    "sgrassato",
    "sguardo",
    "sibilo",
    "siccome",
    "sierra",
    "sigla",
    "signore",
    "silenzio",
    "sillaba",
    "simbolo",
    "simpatico",
    "simulato",
    "sinfonia",
    "singolo",
    "sinistro",
    "sino",
    "sintesi",
    "sinusoide",
    "sipario",
    "sisma",
    "sistole",
    "situato",
    "slitta",
    "slogatura",
    "sloveno",
    "smarrito",
    "smemorato",
    "smentito",
    "smeraldo",
    "smilzo",
    "smontare",
    "smottato",
    "smussato",
    "snellire",
    "snervato",
    "snodo",
    "sobbalzo",
    "sobrio",
    "soccorso",
    "sociale",
    "sodale",
    "soffitto",
    "sogno",
    "soldato",
    "solenne",
    "solido",
    "sollazzo",
    "solo",
    "solubile",
    "solvente",
    "somatico",
    "somma",
    "sonda",
    "sonetto",
    "sonnifero",
    "sopire",
    "soppeso",
    "sopra",
    "sorgere",
    "sorpasso",
    "sorriso",
    "sorso",
    "sorteggio",
    "sorvolato",
    "sospiro",
    "sosta",
    "sottile",
    "spada",
    "spalla",
    "spargere",
    "spatola",
    "spavento",
    "spazzola",
    "specie",
    "spedire",
    "spegnere",
    "spelatura",
    "speranza",
    "spessore",
    "spettrale",
    "spezzato",
    "spia",
    "spigoloso",
    "spillato",
    "spinoso",
    "spirale",
    "splendido",
    "sportivo",
    "sposo",
    "spranga",
    "sprecare",
    "spronato",
    "spruzzo",
    "spuntino",
    "squillo",
    "sradicare",
    "srotolato",
    "stabile",
    "stacco",
    "staffa",
    "stagnare",
    "stampato",
    "stantio",
    "starnuto",
    "stasera",
    "statuto",
    "stelo",
    "steppa",
    "sterzo",
    "stiletto",
    "stima",
    "stirpe",
    "stivale",
    "stizzoso",
    "stonato",
    "storico",
    "strappo",
    "stregato",
    "stridulo",
    "strozzare",
    "strutto",
    "stuccare",
    "stufo",
    "stupendo",
    "subentro",
    "succoso",
    "sudore",
    "suggerito",
    "sugo",
    "sultano",
    "suonare",
    "superbo",
    "supporto",
    "surgelato",
    "surrogato",
    "sussurro",
    "sutura",
    "svagare",
    "svedese",
    "sveglio",
    "svelare",
    "svenuto",
    "svezia",
    "sviluppo",
    "svista",
    "svizzera",
    "svolta",
    "svuotare",
    "tabacco",
    "tabulato",
    "tacciare",
    "taciturno",
    "tale",
    "talismano",
    "tampone",
    "tannino",
    "tara",
    "tardivo",
    "targato",
    "tariffa",
    "tarpare",
    "tartaruga",
    "tasto",
    "tattico",
    "taverna",
    "tavolata",
    "tazza",
    "teca",
    "tecnico",
    "telefono",
    "temerario",
    "tempo",
    "temuto",
    "tendone",
    "tenero",
    "tensione",
    "tentacolo",
    "teorema",
    "terme",
    "terrazzo",
    "terzetto",
    "tesi",
    "tesserato",
    "testato",
    "tetro",
    "tettoia",
    "tifare",
    "tigella",
    "timbro",
    "tinto",
    "tipico",
    "tipografo",
    "tiraggio",
    "tiro",
    "titanio",
    "titolo",
    "titubante",
    "tizio",
    "tizzone",
    "toccare",
    "tollerare",
    "tolto",
    "tombola",
    "tomo",
    "tonfo",
    "tonsilla",
    "topazio",
    "topologia",
    "toppa",
    "torba",
    "tornare",
    "torrone",
    "tortora",
    "toscano",
    "tossire",
    "tostatura",
    "totano",
    "trabocco",
    "trachea",
    "trafila",
    "tragedia",
    "tralcio",
    "tramonto",
    "transito",
    "trapano",
    "trarre",
    "trasloco",
    "trattato",
    "trave",
    "treccia",
    "tremolio",
    "trespolo",
    "tributo",
    "tricheco",
    "trifoglio",
    "trillo",
    "trincea",
    "trio",
    "tristezza",
    "triturato",
    "trivella",
    "tromba",
    "trono",
    "troppo",
    "trottola",
    "trovare",
    "truccato",
    "tubatura",
    "tuffato",
    "tulipano",
    "tumulto",
    "tunisia",
    "turbare",
    "turchino",
    "tuta",
    "tutela",
    "ubicato",
    "uccello",
    "uccisore",
    "udire",
    "uditivo",
    "uffa",
    "ufficio",
    "uguale",
    "ulisse",
    "ultimato",
    "umano",
    "umile",
    "umorismo",
    "uncinetto",
    "ungere",
    "ungherese",
    "unicorno",
    "unificato",
    "unisono",
    "unitario",
    "unte",
    "uovo",
    "upupa",
    "uragano",
    "urgenza",
    "urlo",
    "usanza",
    "usato",
    "uscito",
    "usignolo",
    "usuraio",
    "utensile",
    "utilizzo",
    "utopia",
    "vacante",
    "vaccinato",
    "vagabondo",
    "vagliato",
    "valanga",
    "valgo",
    "valico",
    "valletta",
    "valoroso",
    "valutare",
    "valvola",
    "vampata",
    "vangare",
    "vanitoso",
    "vano",
    "vantaggio",
    "vanvera",
    "vapore",
    "varano",
    "varcato",
    "variante",
    "vasca",
    "vedetta",
    "vedova",
    "veduto",
    "vegetale",
    "veicolo",
    "velcro",
    "velina",
    "velluto",
    "veloce",
    "venato",
    "vendemmia",
    "vento",
    "verace",
    "verbale",
    "vergogna",
    "verifica",
    "vero",
    "verruca",
    "verticale",
    "vescica",
    "vessillo",
    "vestale",
    "veterano",
    "vetrina",
    "vetusto",
    "viandante",
    "vibrante",
    "vicenda",
    "vichingo",
    "vicinanza",
    "vidimare",
    "vigilia",
    "vigneto",
    "vigore",
    "vile",
    "villano",
    "vimini",
    "vincitore",
    "viola",
    "vipera",
    "virgola",
    "virologo",
    "virulento",
    "viscoso",
    "visione",
    "vispo",
    "vissuto",
    "visura",
    "vita",
    "vitello",
    "vittima",
    "vivanda",
    "vivido",
    "viziare",
    "voce",
    "voga",
    "volatile",
    "volere",
    "volpe",
    "voragine",
    "vulcano",
    "zampogna",
    "zanna",
    "zappato",
    "zattera",
    "zavorra",
    "zefiro",
    "zelante",
    "zelo",
    "zenzero",
    "zerbino",
    "zibetto",
    "zinco",
    "zircone",
    "zitto",
    "zolla",
    "zotico",
    "zucchero",
    "zufolo",
    "zulu",
    "zuppa"
]

},
"+2zkD8kJfHO0kznqc9yjyAnu03W+fuY8Vri1j+vLgFY=":
function (require, module, exports, __dirname, __filename) {
// Following the BFE spec (formerly known as TFK), the naming convention in this
// file uses "T" to mean "Type byte", "TF" to mean "Type byte and Format byte"
// and "D" to mean "Data bytes".

const definitions = require('ssb-bfe-spec')
const SSBURI = require('ssb-uri2')
const { isSSBURI, isExperimentalSSBURI, isAddressSSBURI } = SSBURI
const {
  decorateBFE,
  definitionsToDict,
  findTypeFormatForSigilSuffix,
} = require('./util')

const TYPES = decorateBFE(definitions)
const NAMED_TYPES = definitionsToDict(definitions)

function toTF(type, format) {
  if (!NAMED_TYPES[type]) {
    throw new Error('toTF() got unknown type: ' + type)
  }
  if (!NAMED_TYPES[type].formats[format]) {
    throw new Error('toTF() got unknown format: ' + format)
  }
  return Buffer.from([
    NAMED_TYPES[type].code,
    NAMED_TYPES[type].formats[format].code,
  ])
}

const STRING_TF = toTF('generic', 'string-UTF8')
const NIL_TF = toTF('generic', 'nil')
const BYTES_TF = toTF('generic', 'any-bytes')
const BOOL_TF = toTF('generic', 'boolean')
const BOOL_TRUE = Buffer.from([1])
const BOOL_FALSE = Buffer.from([0])

const encoder = {
  sigilSuffix(input, type, format) {
    let data = input
    if (format.sigil) data = data.slice(1)
    if (format.suffix) data = data.slice(0, -format.suffix.length)

    return Buffer.concat([type.code, format.code, Buffer.from(data, 'base64')])
  },

  ssbURI(input) {
    // These URIs do not have BFE counterparts, so treat them as strings:
    if (isAddressSSBURI(input) || isExperimentalSSBURI(input)) {
      return encoder.string(input)
    }

    const { type: typeName, format: formatName, data } = SSBURI.decompose(input)

    const type = NAMED_TYPES[typeName]
    if (!type) return encoder.string(input)
    const format = type.formats[formatName]
    if (!format) {
      throw new Error(
        `No encoder for type=${typeName} format=${formatName} for SSB URI ${input}`
      )
    }
    const d = Buffer.from(data, 'base64')

    if (format.data_length && d.length !== format.data_length) {
      throw new Error(
        `expected data to be length ${format.data_length}, but found ${d.length}`
      )
    }

    const tf = Buffer.from([type.code, format.code])
    return Buffer.concat([tf, d])
  },

  string(input) {
    return Buffer.concat([STRING_TF, Buffer.from(input, 'utf8')])
  },

  boolean(input) {
    const d = input ? BOOL_TRUE : BOOL_FALSE
    return Buffer.concat([BOOL_TF, d])
  },

  nil() {
    return NIL_TF // note this type contains no data
  },

  bytes(input) {
    return Buffer.concat([BYTES_TF, input])
  },
}

function encode(input) {
  // cases we don't encode
  if (input === undefined) {
    return input
  } else if (Number.isInteger(input)) {
    return input
  }

  // strings
  else if (typeof input === 'string') {
    if (input.startsWith('ssb:')) return encoder.ssbURI(input)

    /* looks for classic sigil/suffix matches */
    const { type, format } = findTypeFormatForSigilSuffix(input, TYPES)
    if (type) {
      if (format) return encoder.sigilSuffix(input, type, format)
      else {
        throw new Error(
          `No encoder for type=${type.type} format=? for string ${input}`
        )
      }
    }
    // not a sigil-suffix ref
    return encoder.string(input)
  }

  // boolean
  else if (typeof input === 'boolean') {
    return encoder.boolean(input)
  }

  // nil
  else if (input === null) {
    return encoder.nil()
  }

  // bytes
  else if (Buffer.isBuffer(input)) {
    return encoder.bytes(input)
  }

  // recursions
  else if (Array.isArray(input)) {
    return input.map((x) => {
      const y = encode(x)
      return y === undefined ? encoder.nil() : y
    })
  } else if (typeof input === 'object') {
    const output = {}
    for (const key in input) {
      const y = encode(input[key])
      if (y !== undefined) output[key] = y
    }
    return output
  }

  // unknown
  else {
    throw new Error('No encoder for input ' + input)
  }
}

const decoder = {
  ssbURI(input, type, format) {
    const d = input.slice(2)
    const data = d.toString('base64')
    return SSBURI.compose({ type: type.type, format: format.format, data })
  },
  sigilSuffix(input, type, format) {
    const d = input.slice(2)
    return [format.sigil || '', d.toString('base64'), format.suffix || ''].join(
      ''
    )
  },

  string(input) {
    const d = input.slice(2)
    return d.toString('utf8')
  },

  bool(input) {
    if (input.size > 3) {
      throw new Error('Boolean BFE must be 3 bytes, was ' + input.size)
    }
    const d = input.slice(2)
    if (d.equals(BOOL_FALSE)) return false
    if (d.equals(BOOL_TRUE)) return true

    throw new Error('Invalid boolean BFE ' + input.toString('hex'))
  },

  bytes(input) {
    const d = input.slice(2)
    return d
  },
}

function decode(input) {
  // cases we don't decode
  if (input === null) {
    return null
  } else if (Number.isInteger(input)) {
    return input
  }

  // most values are buffers
  else if (Buffer.isBuffer(input)) {
    if (input.length < 2) {
      throw new Error(
        'Cannot decode buffer that is missing type & format fields: ' +
          input.toString('hex')
      )
    }

    const tf = input.slice(0, 2)
    if (tf.equals(NIL_TF)) return null
    else if (tf.equals(BOOL_TF)) return decoder.bool(input)
    else if (tf.equals(STRING_TF)) return decoder.string(input)
    else if (tf.equals(BYTES_TF)) return decoder.bytes(input)

    const t = input.slice(0, 1)
    const type = TYPES.find((type) => type.code.equals(t))
    if (type) {
      const f = input.slice(1, 2)
      const format = type.formats.find((format) => format.code.equals(f))
      if (format) {
        if (format.sigil || format.suffix) {
          return decoder.sigilSuffix(input, type, format)
        } else {
          return decoder.ssbURI(input, type, format)
        }
      } else {
        throw new Error(
          `No decoder for type=${type.type} format=<${f.toString(
            'hex'
          )}> for buffer ${input.toString('hex')}`
        )
      }
    }

    throw new Error('Cannot decode buffer ' + input.toString('hex'))
  }

  // recursions
  else if (Array.isArray(input)) {
    return input.map(decode)
  } else if (typeof input === 'object') {
    const output = {}
    for (const key in input) {
      output[key] = decode(input[key])
    }
    return output
  }

  // FIXME: more checks, including floats!

  // unknown
  else {
    throw new Error('Cannot decode input: ' + input)
  }
}

module.exports = {
  encode,
  decode,
  bfeTypes: definitions,
  bfeNamedTypes: NAMED_TYPES,
  toTF,
}

},
"+KjVs0WEmtTxrU6jegu5hZNYifjsLOhkIVRNmTKKXeo=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var ConnFirewall_1;
Object.defineProperty(exports, "__esModule", { value: true });
const secret_stack_decorators_1 = require("secret-stack-decorators");
const run = require("promisify-tuple");
const fs = require("fs");
const path = require("path");
const atomic = require('atomic-file-rw');
const Notify = require('pull-notify');
const Ref = require('ssb-ref');
const pull = require('pull-stream');
const pullPromise = require('pull-promise');
const cat = require('pull-cat');
const debug = require('debug')('ssb:conn-firewall');
const INCOMING_ATTEMPTS_FILENAME = 'conn-attempts.json';
const MAX_INCOMING_ATTEMPTS = 20;
const INCOMING_ATTEMPT_RECENTLY = 60 * 60e3;
const OUTGOING_FORGET_POLL = 1 * 60e3;
const OUTGOING_FORGET_THRESHOLD = 5 * 60e3;
let ConnFirewall = ConnFirewall_1 = class ConnFirewall {
    constructor(ssb, cfg) {
        var _a;
        this.attempts = (opts) => {
            var _a, _b;
            const old = (_a = opts === null || opts === void 0 ? void 0 : opts.old) !== null && _a !== void 0 ? _a : false;
            const live = (_b = opts === null || opts === void 0 ? void 0 : opts.live) !== null && _b !== void 0 ? _b : true;
            if (!old && !live)
                return pull.empty();
            if (old && !live)
                return this.oldIncomingAttempts();
            if (!old && live)
                return this.liveIncomingAttempts();
            if (old && live) {
                return cat([this.oldIncomingAttempts(), this.liveIncomingAttempts()]);
            }
        };
        this.reconfigure = (conf) => {
            if (!conf)
                return;
            if (typeof conf.rejectBlocked !== 'undefined') {
                this.config.rejectBlocked = !!conf.rejectBlocked;
            }
            if (typeof conf.rejectUnknown !== 'undefined') {
                this.config.rejectUnknown = !!conf.rejectUnknown;
            }
        };
        if (!((_a = ssb === null || ssb === void 0 ? void 0 : ssb.friends) === null || _a === void 0 ? void 0 : _a.graphStream)) {
            throw new Error('ssb-conn-firewall expects ssb-friends to be installed');
        }
        this.ssb = ssb;
        this.config = ConnFirewall_1.applyDefaults(cfg);
        this.incomingAttemptsMap = new Map();
        this.incomingAttemptsFilepath = path.join(cfg.path, INCOMING_ATTEMPTS_FILENAME);
        this.incomingAttemptsMapLoaded = this.loadOldIncomingAttempts();
        this.notifyIncomingAttempts = Notify();
        this.outgoingAttemptsMap = new Map();
        this.timerForgetOutgoing = null;
        this.init();
    }
    static applyDefaults(cfg) {
        var _a, _b, _c, _d;
        var _e, _f, _g;
        const output = { ...cfg };
        (_a = output.conn) !== null && _a !== void 0 ? _a : (output.conn = {});
        (_b = (_e = output.conn).firewall) !== null && _b !== void 0 ? _b : (_e.firewall = {});
        (_c = (_f = output.conn.firewall).rejectBlocked) !== null && _c !== void 0 ? _c : (_f.rejectBlocked = true);
        (_d = (_g = output.conn.firewall).rejectUnknown) !== null && _d !== void 0 ? _d : (_g.rejectUnknown = false);
        return output.conn.firewall;
    }
    static pruneAttemptsEntries(map) {
        return [...map.entries()]
            .sort((a, b) => b[1] - a[1])
            .slice(0, MAX_INCOMING_ATTEMPTS);
    }
    static prepareAttemptsData(map) {
        return ConnFirewall_1.pruneAttemptsEntries(map).map(([id, ts]) => ({ id, ts }));
    }
    async loadOldIncomingAttempts() {
        const filename = this.incomingAttemptsFilepath;
        if (!fs.existsSync(filename)) {
            return;
        }
        const [err, data] = await run(atomic.readFile)(filename, 'utf8');
        if (err) {
            console.error('failed to load ssb-conn-firewall attempts file: ' + err);
            return;
        }
        let entries = [];
        try {
            entries = JSON.parse(data.toString());
        }
        catch (err) {
            console.error('failed to parse ssb-conn-firewall attempts file: ' + err);
            return;
        }
        for (const [id, ts] of entries) {
            this.incomingAttemptsMap.set(id, ts);
        }
    }
    async saveOldIncomingAttempts() {
        const filename = this.incomingAttemptsFilepath;
        const prunedAttempts = ConnFirewall_1.pruneAttemptsEntries(this.incomingAttemptsMap);
        const json = JSON.stringify(prunedAttempts);
        const [err] = await run(atomic.writeFile)(filename, json, 'utf8');
        if (err) {
            console.error('failed to write ssb-conn-firewall attempts file: ' + err);
        }
    }
    scheduleForgetOutgoing() {
        var _a, _b;
        if (this.timerForgetOutgoing)
            return;
        this.timerForgetOutgoing = setInterval(() => {
            if (this.outgoingAttemptsMap.size === 0) {
                clearInterval(this.timerForgetOutgoing);
                this.timerForgetOutgoing = null;
            }
            const now = Date.now();
            for (const [id, ts] of this.outgoingAttemptsMap) {
                if (now - ts > OUTGOING_FORGET_THRESHOLD) {
                    this.outgoingAttemptsMap.delete(id);
                }
            }
        }, OUTGOING_FORGET_POLL);
        (_b = (_a = this.timerForgetOutgoing) === null || _a === void 0 ? void 0 : _a.unref) === null || _b === void 0 ? void 0 : _b.call(_a);
    }
    monitorSocialGraphChanges() {
        const { ssb, config } = this;
        pull(ssb.friends.graphStream({ live: true, old: false }), pull.drain((graph) => {
            for (const source of Object.keys(graph)) {
                for (const dest of Object.keys(graph[source])) {
                    const value = graph[source][dest];
                    if ((config.rejectBlocked &&
                        source === ssb.id &&
                        value === -1 &&
                        ssb.peers[dest]) ||
                        (config.rejectUnknown &&
                            source === ssb.id &&
                            value < -1 &&
                            ssb.peers[dest])) {
                        ssb.peers[dest].forEach((rpc) => rpc.close(true));
                        ssb.peers[dest] = [];
                    }
                    if (config.rejectUnknown &&
                        source === ssb.id &&
                        (value >= 0 || value === -1)) {
                        this.incomingAttemptsMap.delete(dest);
                        this.outgoingAttemptsMap.delete(dest);
                        this.saveOldIncomingAttempts();
                    }
                }
            }
        }));
    }
    monitorOutgoingConnections() {
        const firewall = this;
        const { ssb } = firewall;
        ssb.connect.hook(function (fn, args) {
            const [msaddr, _cb] = args;
            const feedId = Ref.getKeyFromAddress(msaddr);
            firewall.outgoingAttemptsMap.set(feedId, Date.now());
            firewall.scheduleForgetOutgoing();
            fn.apply(this, args);
        });
    }
    monitorIncomingConnections() {
        const firewall = this;
        const { ssb, config } = firewall;
        ssb.auth.hook(async function (fn, args) {
            var _a;
            const source = ssb.id;
            const [dest, cb] = args;
            if (config.rejectBlocked) {
                const [, blocked] = await run(ssb.friends.isBlocking)({ source, dest });
                if (blocked) {
                    debug('prevented blocked peer %s from connecting to us', dest);
                    cb(new Error('client is blocked'));
                    return;
                }
            }
            if (config.rejectUnknown) {
                if (firewall.outgoingAttemptsMap.has(dest)) {
                    fn.apply(this, args);
                    return;
                }
                const [, hops] = await run(ssb.friends.hops)({});
                if (hops && (hops[dest] == null || hops[dest] < -1)) {
                    debug('prevented unknown peer %s from connecting to us', dest);
                    cb(new Error('client is a stranger'));
                    const ts = Date.now();
                    const previousTS = (_a = firewall.incomingAttemptsMap.get(dest)) !== null && _a !== void 0 ? _a : 0;
                    firewall.incomingAttemptsMap.set(dest, ts);
                    if (previousTS + INCOMING_ATTEMPT_RECENTLY < ts) {
                        firewall.notifyIncomingAttempts({ id: dest, ts });
                    }
                    firewall.saveOldIncomingAttempts();
                    return;
                }
            }
            fn.apply(this, args);
        });
    }
    init() {
        this.monitorSocialGraphChanges();
        this.monitorOutgoingConnections();
        this.monitorIncomingConnections();
        this.debugInit();
    }
    debugInit() {
        if (!debug.enabled)
            return;
        const names = [];
        if (this.config.rejectBlocked)
            names.push('blocked peers');
        if (this.config.rejectUnknown)
            names.push('unknown peers');
        if (names.length === 0)
            return;
        debug('configured to reject ' + names.join(' and '));
    }
    oldIncomingAttempts() {
        return pull(pullPromise.source(this.incomingAttemptsMapLoaded), pull.map(() => ConnFirewall_1.prepareAttemptsData(this.incomingAttemptsMap)), pull.flatten());
    }
    liveIncomingAttempts() {
        return this.notifyIncomingAttempts.listen();
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], ConnFirewall.prototype, "attempts", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], ConnFirewall.prototype, "reconfigure", void 0);
ConnFirewall = ConnFirewall_1 = __decorate([
    secret_stack_decorators_1.plugin('0.1.0')
], ConnFirewall);
module.exports = ConnFirewall;

},
"+T7sQ04aU28GLFEBOj2FrWUH//Kh3I0/8/KMos/Nh4E=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const bluetoothTransportAndPlugin = require('ssb-bluetooth');
const BluetoothManager = require('ssb-mobile-bluetooth-manager');
const dummyBluetoothPlugin = {
    name: 'bluetooth',
    version: '1.0.0',
    manifest: {
        nearbyDevices: 'source',
        nearbyScuttlebuttDevices: 'source',
        bluetoothScanState: 'source',
        makeDeviceDiscoverable: 'async',
        isEnabled: 'async',
        getMetadataForDevice: 'async',
    },
    init: () => {
        return {
            nearbyDevices: () => pull.empty(),
            nearbyScuttlebuttDevices: () => pull.empty(),
            bluetoothScanState: () => pull.empty(),
            makeDeviceDiscoverable: (_interval, cb) => {
                cb(null, true);
            },
            isEnabled: (cb) => {
                cb(null, false);
            },
            getMetadataForDevice: (_address, _cb) => { },
        };
    },
};
module.exports = function createBluetoothPlugin(keys, appDataDir) {
    // Disable Bluetooth on iOS and Desktop, for now
    if (process.platform === 'ios' ||
        process.env.MANYVERSE_PLATFORM === 'desktop') {
        return dummyBluetoothPlugin;
    }
    const bluetoothManager = BluetoothManager({
        socketFolderPath: appDataDir,
        myIdent: '@' + keys.public,
        metadataServiceUUID: 'b4721184-46dc-4314-b031-bf52c2b197f3',
        controlSocketFilename: 'manyverse_bt_control.sock',
        incomingSocketFilename: 'manyverse_bt_incoming.sock',
        outgoingSocketFilename: 'manyverse_bt_outgoing.sock',
        logStreams: false,
    });
    return bluetoothTransportAndPlugin(bluetoothManager, { scope: 'public' });
};
//# sourceMappingURL=bluetooth.js.map
},
"+lJor2dtqZ6C1+x3yE+qwPLsbqTdxLdv+1/Vbq/t2VY=":
function (require, module, exports, __dirname, __filename) {

function makePlugin(opts) {

  let bluetoothManager = opts.bluetoothManager;

  let ownMacAddress = null;

  const name = "bluetooth"

  function scope() {
    return opts.scope || 'public';
  }

  function parse (addr) {
    if (!addr.startsWith("bt:")) return null;
    return addr.replace("bt:", "");
  }

  /**
   * The multiserver address format does not allow : symbols to be used, so we omit them internally.
   * This function adds them back in.
   * 
   * @param {} internalRepresentation the internal representation (e.g. 65D900DDB353)
   * @returns the bluetooth mac address implementation (e.g. 65:D9:00:DD:B3:53)
   */
  function toMacAddress(internalRepresentation) {
    const parts = [];

    // Take a copy of the string
    let btInternalRepresentation = internalRepresentation.slice();

    do { 
      parts.push(btInternalRepresentation.substring(0, 2)) 
    } 
    while( (btInternalRepresentation = btInternalRepresentation.substring(2, btInternalRepresentation.length)) != "" );

    return parts.join(":");
  }

  function toInternalAddress(macAddress) {
    return macAddress.split(":").join("");
  }

  function client (address, cb) {
    const macAddress = toMacAddress(address);

    bluetoothManager.connect(macAddress, cb);

    return function() {
      bluetoothManager.disconnect(address);
    }

  }

  function server (onConnection, startedCb) {

    bluetoothManager.getOwnMacAddress((err, address) => {
      
      ownMacAddress = address;

      // The bluetooth manager calls back with a duplex stream on a new connection
      // which we can then call back onConnection with
      bluetoothManager.listenForIncomingConnections(
        (err, connection) => onConnection(connection)
      )

      if (startedCb) {
        // Call back to let multiserver know that we're ready to accept incoming connections
        startedCb(err, address);
      }

    })

    return function() {
      bluetoothManager.stopServer();
    }
  }

  function stringify (s) {
    if (s !== scope()) return;
    return ['bt', toInternalAddress(ownMacAddress)].join(':')
  }

  return {
    name: name,
    scope: scope,
    parse: parse,
    client: client,
    server: server,
    stringify: stringify
  }

}

module.exports = makePlugin;

},
"+w3zC48+bmTsIfQxXg5tmXkKa8aEA9GPzIKmhuhTd8c=":
function (require, module, exports, __dirname, __filename) {
const pull = require('pull-stream')

exports.name = 'replicationScheduler'
exports.version = '1.0.0'
exports.manifest = {}

exports.init = function (ssb, config) {
  if (!ssb.ebt) {
    throw new Error('ssb-replication-scheduler expects ssb-ebt to be installed')
  }
  if (!ssb.friends) {
    throw new Error('ssb-replication-scheduler expects ssb-friends to be installed')
  }

  // Note: ssb.ebt.request and ssb.ebt.block are idempotent operations,
  // so it's safe to call these methods redundantly, which is most likely
  // true in most cases. These three blocks below may sometimes overlap, but
  // that's okay, as long as we cover *all* cases.

  // Replicate myself
  ssb.ebt.request(ssb.id, true)

  // For each edge in the social graph, call either `request` or `block`
  pull(
    ssb.friends.graphStream({old: true, live: true}),
    pull.drain((graph) => {
      for (const source of Object.keys(graph)) {
        for (const dest of Object.keys(graph[source])) {
          const value = graph[source][dest]
          // Only if I am the `source` and `value >= 0`, request replication
          if (source === ssb.id) {
            ssb.ebt.request(dest, value >= 0)
          }
          // Compute every block edge, unless I am the edge destination
          if (dest !== ssb.id) {
            ssb.ebt.block(source, dest, value === -1)
          }
        }
      }
    }),
  )

  // request/block nodes at a reachable distance (within hops config) from me
  pull(
    ssb.friends.hopStream({old: true, live: true}),
    pull.drain((hops) => {
      for (const dest of Object.keys(hops)) {
        const value = hops[dest]
        // myself or friendly peers
        if (value >= 0) {
          ssb.ebt.request(dest, true)
          ssb.ebt.block(ssb.id, dest, false)
        }
        // blocked peers
        else if (value === -1) {
          ssb.ebt.request(dest, false)
          ssb.ebt.block(ssb.id, dest, true)
        }
        // unfollowed/unblocked peers
        else if (value < -1) {
          ssb.ebt.request(dest, false)
        }
      }
    }),
  )

  return {}
}

},
"/+L1Gp0bOTCBtcd9Np60dTtpg8m7r0j72hK7DQ8MC+A=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var Obv = require('obv')
var Append = require('append-batch')
var createStreamCreator = require('pull-cursor')
var Cache = require('hashlru')
var Looper = require('pull-looper')
var pull = require('pull-stream')
var filter = require('pull-stream/throughs/filter')

module.exports = function (blocks, frame, codec, file, cache) {
  var since = Obv()
  cache = cache || Cache(256)

  var append = Append(function (batch, cb) {
    since.once(function () { // wait for file to load before appending...
      batch = batch.map(codec.encode).map(function (e) {
        return Buffer.isBuffer(e) ? e : Buffer.from(e)
      })
      var framed = frame.frame(batch, blocks.offset.value)
      var _since = frame.frame.offset
      blocks.append(framed, function (err, offset) {
        if(err) return cb(err)
        //else, get offset of last item.
        since.set(_since)
        cb(null, since.value)
      })
    })
  })

  var isDeleted = (b) => Buffer.isBuffer(b) && b.every(x => x === 0)
  var isNotDeleted = (b) => isDeleted(b) === false

  function getMeta (offset, useCache, cb) {
    if (useCache) {
      var data = cache.get(offset)
      if (data) {
        cb(null, data.value, data.prev, data.next)
        return
      }
    }

    frame.getMeta(offset, function (err, value, prev, next) {
      if(err) return cb(err)
      if (isDeleted(value)) return cb(null, value, prev, next) // skip decode

      var data = {
        value: codec.decode(codec.buffer ? value : value.toString()),
        prev: prev,
        next: next
      }

      if (useCache)
        cache.set(offset, data)
      cb(null, data.value, data.prev, data.next)
    })
  }

  var createStream = createStreamCreator(since, getMeta)

  frame.restore(function (err, offset) {
    if(err) throw err
    since.set(offset)
  })

  return {
    filename: file,
    since: since,
    stream: function (opts) {
      return pull(
        Looper(createStream(opts)),
        filter(item => {
          if (opts && opts.seqs === false) {
            return isNotDeleted(item)
          } else {
            return isNotDeleted(item.value)
          }
        })
      )
    },

    //if value is an array of buffers, then treat that as a batch.
    append: append,

    get: function (offset, cb) {
      frame.getMeta(offset, function (err, value) {
        if (err) return cb(err)
        if (isDeleted(value)) {
          const err = new Error('item has been deleted')
          err.code = 'flumelog:deleted'
          return cb(err, -1)
        }

        cb(null, codec.decode(value))
      })
    },
    /**
     * Overwrite items from the log with null bytes, which are filtered out by
     * `get()` and `stream()` methods, effectively deleting the database items.
     *
     * @param {(number|number[])} offsets - item offset(s) to be deleted
     * @param {function} cb - the callback that returns operation errors, if any
     */
    del: (offsets, cb) => {
      if (Array.isArray(offsets) === false) {
        // The `seqs` argument may be a single value or an array.
        // To minimize complexity, this ensures `seqs` is always an array.
        offsets = [ offsets ]
      }

      Promise.all(offsets.map(offset =>
        new Promise((resolve, reject) => {
          // Simple callback handler for promises.
          const promiseCb = (err) => {
            if (err) {
              reject(err)
            } else {
              resolve()
            }
          }

          cache.remove(offset)
          frame.overwrite(offset, promiseCb)
        })
      )).catch((err) => cb(err))
      .then(() => cb(null))
    },
    methods: {
      del: 'async'
    }
  }
}






},
"/XjQhkiFHi2xsZ4ScakK1VtkDQtq4rIK0RyUruyEezM=":
function (require, module, exports, __dirname, __filename) {
const optsArg = require('./lib/opts-arg.js')
const pathArg = require('./lib/path-arg.js')

const {mkdirpNative, mkdirpNativeSync} = require('./lib/mkdirp-native.js')
const {mkdirpManual, mkdirpManualSync} = require('./lib/mkdirp-manual.js')
const {useNative, useNativeSync} = require('./lib/use-native.js')


const mkdirp = (path, opts) => {
  path = pathArg(path)
  opts = optsArg(opts)
  return useNative(opts)
    ? mkdirpNative(path, opts)
    : mkdirpManual(path, opts)
}

const mkdirpSync = (path, opts) => {
  path = pathArg(path)
  opts = optsArg(opts)
  return useNativeSync(opts)
    ? mkdirpNativeSync(path, opts)
    : mkdirpManualSync(path, opts)
}

mkdirp.sync = mkdirpSync
mkdirp.native = (path, opts) => mkdirpNative(pathArg(path), optsArg(opts))
mkdirp.manual = (path, opts) => mkdirpManual(pathArg(path), optsArg(opts))
mkdirp.nativeSync = (path, opts) => mkdirpNativeSync(pathArg(path), optsArg(opts))
mkdirp.manualSync = (path, opts) => mkdirpManualSync(pathArg(path), optsArg(opts))

module.exports = mkdirp

},
"/cvNxPM80iuWFV+jxhXBKmglbAPdCZKVGWELQeNLVog=":
function (require, module, exports, __dirname, __filename) {
var Source = require('./')
var Sink = require('./sink')

function Set () {
  var err, value, cb
  return {
    set: function (_err, _value) {
      if(cb) cb(_err, _value)
      else err = _err, value = _value
    },
    get: function (_cb) {
      if(err || value) _cb(err, value)
      else cb = _cb
    }
  }
}

module.exports = function (continuable) {
  var set = Set()

  return {
    sink: Sink(function (cb) {
      continuable(function (err, stream) {
        if(err) {
          cb(err)
          set.set(err)
        }
        else {
          cb(null, stream.sink)
          set.set(null, stream.source)
        }
      })
    }),
    source: Source(set.get)
  }
}











},
"/fx0fuCbDWUiM/LBcUrrmSiCNF1DXye+jQ1sgy47XeQ=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const ltgt = require('ltgt')
const looper = require('looper')

module.exports = Stream

function Stream (blocks, opts) {
  opts = opts || {}

  this.blocks = blocks
  this.live = !!opts.live
  this.offsets = opts.offsets !== false
  this.values = opts.values !== false
  this.limit = opts.limit || 0

  this.min = this.max = this.min_inclusive = this.max_inclusive = null
  this.cursor = -1
  this.count = 0
  this.hasWritten = false
  this.writing = false
  this.ended = false
  this.skipNext = false

  this.opts = opts
  this._resumeCallback = this._resumeCallback.bind(this)
  this.blocks.onReady(this._ready.bind(this))
}

Stream.prototype._ready = function () {
  this.min = ltgt.lowerBound(this.opts, null)
  if (ltgt.lowerBoundInclusive(this.opts))
    this.min_inclusive = this.min

  this.max = ltgt.upperBound(this.opts, null)
  if (ltgt.upperBoundInclusive(this.opts))
    this.max_inclusive = this.max

  //note: cursor has default of the current length or zero.
  this.cursor = ltgt.lowerBound(this.opts, 0)

  if (this.cursor < 0) this.cursor = 0

  if (this.opts.gt >= 0) this.skipNext = true

  if (!this.live && this.cursor === 0 && this.blocks.since.value === -1)
    this.ended = true

  if (this.live && this.cursor === 0 && this.blocks.since.value === -1)
    this.cursor = -1

  this.resume()
}

Stream.prototype._writeToSink = function (data) {
  if (!this.hasWritten) this.hasWritten = true
  if (this.values) {
    if (this.offsets) this.sink.write({ offset: this.cursor, value: data })
    else this.sink.write(data)
  }
  else
    this.sink.write(this.cursor)
}

// returns true="next block", false="end stream", null="pause"
Stream.prototype._handleBlock = function(block) {
  while (true) {
    if (this.sink.paused) return null
    const [offset, data] = this.blocks.getDataNextOffset(block, this.cursor)

    if (this.skipNext) {
      this.skipNext = false

      if (offset > 0) {
        this.cursor = offset
        continue
      } else if (offset === 0) {
        return true // get next block
      } else if (offset === -1) {
        if (this.live === true)
          this.writing = false
        return false
      }
    }

    this.count++

    const o = this.cursor

    if (
      (this.min === null || this.min < o || this.min_inclusive === o) &&
      (this.max === null || this.max > o || this.max_inclusive === o)
    ) {
      this._writeToSink(data)

      if (offset > 0)
        this.cursor = offset
      else if (offset === 0) {
        return true // get next block
      } else if (offset === -1) {
        if (this.live === true)
          this.writing = false
        return false
      }

      if (this.limit > 0 && this.count >= this.limit)
        return false
    } else
      return false
  }
}

Stream.prototype._resume = function () {
  if (!this.sink || this.sink.paused) return

  if (this.ended) {
    if (!this.sink.ended) {
      if (this.ended === true && !this.live) return this.abort()
      else if (this.sink.end)
        return this.sink.end(this.ended === true ? null : this.ended)
    }
    return
  }

  if (this.cursor === -1)
    return // not ready yet

  if (this.live && !this.writing && this.hasWritten)
    return // wait for data

  this.writing = true
  this.blocks.getBlock(this.cursor, this._resumeCallback)
}

Stream.prototype._resumeCallback = function (err, block) {
  if (err) {
    console.error(err)
    return
  }

  const handled = this._handleBlock(block)
  if (handled === true) {
    this.cursor = this.blocks.getNextBlockIndex(this.cursor)
    this._next()
  }
  else if (handled === null) return
  else if (this.live !== true) this.abort()
}

Stream.prototype.resume = function () {
  this._next = looper(this._resume.bind(this))
  this._next()
}

Stream.prototype.abort = function (err) {
  this.ended = err || true
  const i = this.blocks.streams.indexOf(this)
  if (~i) this.blocks.streams.splice(i, 1)
  if (!this.sink.ended && this.sink.end) {
    this.sink.ended = true
    this.sink.end(err === true ? null : err)
  }
}

Stream.prototype.pipe = require('push-stream/pipe')

},
"/j4rIMHrtXw7OQyPaFrR4E5vSTUX+n5DL0NRu3ehpNA=":
function (require, module, exports, __dirname, __filename) {
/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */
exports.read = function (buffer, offset, isLE, mLen, nBytes) {
  var e, m
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var nBits = -7
  var i = isLE ? (nBytes - 1) : 0
  var d = isLE ? -1 : 1
  var s = buffer[offset + i]

  i += d

  e = s & ((1 << (-nBits)) - 1)
  s >>= (-nBits)
  nBits += eLen
  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  m = e & ((1 << (-nBits)) - 1)
  e >>= (-nBits)
  nBits += mLen
  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  if (e === 0) {
    e = 1 - eBias
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity)
  } else {
    m = m + Math.pow(2, mLen)
    e = e - eBias
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
}

exports.write = function (buffer, value, offset, isLE, mLen, nBytes) {
  var e, m, c
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)
  var i = isLE ? 0 : (nBytes - 1)
  var d = isLE ? 1 : -1
  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0

  value = Math.abs(value)

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0
    e = eMax
  } else {
    e = Math.floor(Math.log(value) / Math.LN2)
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--
      c *= 2
    }
    if (e + eBias >= 1) {
      value += rt / c
    } else {
      value += rt * Math.pow(2, 1 - eBias)
    }
    if (value * c >= 2) {
      e++
      c /= 2
    }

    if (e + eBias >= eMax) {
      m = 0
      e = eMax
    } else if (e + eBias >= 1) {
      m = ((value * c) - 1) * Math.pow(2, mLen)
      e = e + eBias
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)
      e = 0
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

  e = (e << mLen) | m
  eLen += mLen
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

  buffer[offset + i - d] |= s * 128
}

},
"/tH2HBDaFwSUvnskFV/HP5643XTWb3uGPICxxMnWb94=":
function (require, module, exports, __dirname, __filename) {
const bipf = require('bipf')
const pull = require('pull-stream')
const pl = require('pull-level')
const Plugin = require('ssb-db2/indexes/plugin')
const isFeed = require('ssb-ref').isFeed

const B_VALUE = Buffer.from('value')
const B_META = Buffer.from('meta')
const B_PRIVATE = Buffer.from('private')
const B_AUTHOR = Buffer.from('author')
const B_CONTENT = Buffer.from('content')
const B_TYPE = Buffer.from('type')
const B_CONTACT = Buffer.from('contact')

// This index has the following key/values:
//
// sourceIdx => { [destIdx1]: edgeValue, [destIdx2]: edgeValue, ... }
// "feeds" => [feedAIdx, feedBIdx, feedCIdx, ...]
//
// If the edge is private (from an encrypted contact msg), then the `edgeValue`
// is a string prefixed with "p", e.g. a private block is the string `"p-1"`,
// while a public block is just `"-1"`
module.exports = function db2Contacts (createLayer) {
  return class Friends extends Plugin {
    constructor (log, dir) {
      super(log, dir, 'contacts', 3, undefined, 'json')
      this.updatePublicLayer = createLayer('contactsPublic')
      this.updatePublicLayer({})
      this.updatePrivateLayer = createLayer('contactsPrivate')
      this.updatePrivateLayer({})

      // used for dictionary compression where a feed is mapped to its index
      this.feeds = []

      // a map of sourceIdx => { [destIdx1]: edgeValue, ... }
      this.edges = {}
      // assuming we have feed A (index 0) and B (index 1), and A follows B,
      // then `this.edges` looks like `{ 0: { 1: 1 } }`, meaning that feed A (0)
      // has an edge pointing to feed B (1) with value 1 (follow)
      //
      // `this.feeds` will be: [A,B] in this example

      // it turns out that if you place the same key in a batch multiple
      // times. Level will happily write that key as many times as you give
      // it, instead of just writing the last value for the key, so we have
      // to help the poor bugger
      this.batchKeys = {} // key to index
    }

    onFlush (cb) {
      this.batchKeys = {}
      cb()
    }

    isPrivateRecord (recBuffer) {
      const pMeta = bipf.seekKey(recBuffer, 0, B_META)
      if (pMeta < 0) return false
      const pPrivate = bipf.seekKey(recBuffer, pMeta, B_PRIVATE)
      if (pPrivate < 0) return false
      const isPrivate = bipf.decode(recBuffer, pPrivate)
      return isPrivate
    }

    processRecord (record, seq) {
      const recBuffer = record.value
      if (!recBuffer) return // deleted

      const pValue = bipf.seekKey(recBuffer, 0, B_VALUE)
      if (pValue < 0) return

      const pAuthor = bipf.seekKey(recBuffer, pValue, B_AUTHOR)
      const source = bipf.decode(recBuffer, pAuthor)

      const pContent = bipf.seekKey(recBuffer, pValue, B_CONTENT)
      if (pContent < 0) return

      const pType = bipf.seekKey(recBuffer, pContent, B_TYPE)
      if (pType < 0) return

      if (bipf.compareString(recBuffer, pType, B_CONTACT) === 0) {
        const content = bipf.decode(recBuffer, pContent)
        const dest = content.contact
        const privately = this.isPrivateRecord(recBuffer)

        if (isFeed(source) && isFeed(dest)) {
          const edgeValue = content.blocking || content.flagged
            ? -1
            : content.following === true
              ? 1
              : -2

          let updateFeeds = false

          let sourceIdx = this.feeds.indexOf(source)
          if (sourceIdx === -1) {
            this.feeds.push(source)
            sourceIdx = this.feeds.length - 1
            updateFeeds = true
          }

          let destIdx = this.feeds.indexOf(dest)
          if (destIdx === -1) {
            this.feeds.push(dest)
            destIdx = this.feeds.length - 1
            updateFeeds = true
          }

          const sourceEdges = this.edges[sourceIdx] || {}
          if (privately) {
            sourceEdges[destIdx] = 'p' + edgeValue
          } else {
            sourceEdges[destIdx] = edgeValue
          }
          this.edges[sourceIdx] = sourceEdges

          const edgeEntry = {
            type: 'put',
            key: sourceIdx,
            value: sourceEdges
          }

          const existingKeyIndex = this.batchKeys[sourceIdx]
          if (existingKeyIndex) {
            this.batch[existingKeyIndex] = edgeEntry
          } else {
            this.batch.push(edgeEntry)
            this.batchKeys[sourceIdx] = this.batch.length - 1
          }

          if (updateFeeds) {
            const feedsEntry = {
              type: 'put',
              key: 'feeds',
              value: this.feeds
            }

            const existingFeedsIndex = this.batchKeys.feeds
            if (existingFeedsIndex) {
              this.batch[existingFeedsIndex] = feedsEntry
            } else {
              this.batch.push(feedsEntry)
              this.batchKeys.feeds = this.batch.length - 1
            }
          }

          if (privately) {
            this.updatePrivateLayer(source, dest, edgeValue)
          } else {
            this.updatePublicLayer(source, dest, edgeValue)
          }
        }
      }
    }

    onLoaded (cb) {
      pull(
        pl.read(this.level, {
          valueEncoding: this.valueEncoding,
          keys: true
        }),
        pull.collect((err, entries) => {
          if (err) return cb(err)

          for (let i = 0; i < entries.length; ++i) {
            if (entries[i].key === 'feeds') {
              this.feeds = entries[i].value
              break
            }
          }

          const publicLayer = {}
          const privateLayer = {}
          for (let i = 0; i < entries.length; ++i) {
            const entry = entries[i]

            if (entry.key !== '\x00' && entry.key !== 'feeds') {
              const sourceIdx = parseInt(entry.key, 10)
              const source = this.feeds[sourceIdx]
              const publicLayerEdges = publicLayer[source] || {}
              const privateLayerEdges = privateLayer[source] || {}
              const sourceEdges = this.edges[sourceIdx] || {}

              const destIdxs = Object.keys(entry.value)
              for (let v = 0; v < destIdxs.length; ++v) {
                const destIdx = destIdxs[v]
                const dest = this.feeds[destIdx]
                const rawEdgeValue = entry.value[destIdx]
                const privately = rawEdgeValue[0] === 'p'
                const edgeValue = privately
                  ? parseInt(rawEdgeValue.slice(1), 10)
                  : parseInt(rawEdgeValue, 10)
                if (privately) {
                  privateLayerEdges[dest] = edgeValue
                } else {
                  publicLayerEdges[dest] = edgeValue
                }
                sourceEdges[destIdx] = rawEdgeValue
              }

              publicLayer[source] = publicLayerEdges
              privateLayer[source] = privateLayerEdges
              this.edges[sourceIdx] = sourceEdges
            }
          }

          this.updatePublicLayer(publicLayer)
          this.updatePrivateLayer(privateLayer)
          cb()
        })
      )
    }
  }
}

},
"/tHhT006ZQSTZmaXiJ5367O+bMtgVOn1UZdWbRzw7qg=":
function (require, module, exports, __dirname, __filename) {
const fs = require('fs')

const version = process.env.__TESTING_MKDIRP_NODE_VERSION__ || process.version
const versArr = version.replace(/^v/, '').split('.')
const hasNative = +versArr[0] > 10 || +versArr[0] === 10 && +versArr[1] >= 12

const useNative = !hasNative ? () => false : opts => opts.mkdir === fs.mkdir
const useNativeSync = !hasNative ? () => false : opts => opts.mkdirSync === fs.mkdirSync

module.exports = {useNative, useNativeSync}

},
"/uTEjzzH3brhfJ65dBWMQ9ZokSzxbWV7FTgbybBkRL8=":
function (require, module, exports, __dirname, __filename) {
var Live     = require('pull-live')

exports.old = require('./old')
exports.live = require('./live')


exports.read =
exports.readStream =
exports.createReadStream = require('./read')

exports.write =
exports.writeStream =
exports.createWriteStream = require('./write')

},
"/xj/D2HNeAgc46GiRf1m5DmBFYlnsqX6oJ9W/FF0TEU=":
function (require, module, exports, __dirname, __filename) {
var Buffer = require('safe-buffer').Buffer

var checkParameters = require('./precondition')
var defaultEncoding = require('./default-encoding')
var sync = require('./sync')
var toBuffer = require('./to-buffer')

var ZERO_BUF
var subtle = global.crypto && global.crypto.subtle
var toBrowser = {
  sha: 'SHA-1',
  'sha-1': 'SHA-1',
  sha1: 'SHA-1',
  sha256: 'SHA-256',
  'sha-256': 'SHA-256',
  sha384: 'SHA-384',
  'sha-384': 'SHA-384',
  'sha-512': 'SHA-512',
  sha512: 'SHA-512'
}
var checks = []
function checkNative (algo) {
  if (global.process && !global.process.browser) {
    return Promise.resolve(false)
  }
  if (!subtle || !subtle.importKey || !subtle.deriveBits) {
    return Promise.resolve(false)
  }
  if (checks[algo] !== undefined) {
    return checks[algo]
  }
  ZERO_BUF = ZERO_BUF || Buffer.alloc(8)
  var prom = browserPbkdf2(ZERO_BUF, ZERO_BUF, 10, 128, algo)
    .then(function () {
      return true
    }).catch(function () {
      return false
    })
  checks[algo] = prom
  return prom
}
var nextTick
function getNextTick () {
  if (nextTick) {
    return nextTick
  }
  if (global.process && global.process.nextTick) {
    nextTick = global.process.nextTick
  } else if (global.queueMicrotask) {
    nextTick = global.queueMicrotask
  } else if (global.setImmediate) {
    nextTick = global.setImmediate
  } else {
    nextTick = global.setTimeout
  }
  return nextTick
}
function browserPbkdf2 (password, salt, iterations, length, algo) {
  return subtle.importKey(
    'raw', password, { name: 'PBKDF2' }, false, ['deriveBits']
  ).then(function (key) {
    return subtle.deriveBits({
      name: 'PBKDF2',
      salt: salt,
      iterations: iterations,
      hash: {
        name: algo
      }
    }, key, length << 3)
  }).then(function (res) {
    return Buffer.from(res)
  })
}

function resolvePromise (promise, callback) {
  promise.then(function (out) {
    getNextTick()(function () {
      callback(null, out)
    })
  }, function (e) {
    getNextTick()(function () {
      callback(e)
    })
  })
}
module.exports = function (password, salt, iterations, keylen, digest, callback) {
  if (typeof digest === 'function') {
    callback = digest
    digest = undefined
  }

  digest = digest || 'sha1'
  var algo = toBrowser[digest.toLowerCase()]

  if (!algo || typeof global.Promise !== 'function') {
    getNextTick()(function () {
      var out
      try {
        out = sync(password, salt, iterations, keylen, digest)
      } catch (e) {
        return callback(e)
      }
      callback(null, out)
    })
    return
  }

  checkParameters(iterations, keylen)
  password = toBuffer(password, defaultEncoding, 'Password')
  salt = toBuffer(salt, defaultEncoding, 'Salt')
  if (typeof callback !== 'function') throw new Error('No callback provided to pbkdf2')

  resolvePromise(checkNative(algo).then(function (resp) {
    if (resp) return browserPbkdf2(password, salt, iterations, keylen, algo)

    return sync(password, salt, iterations, keylen, digest)
  }), callback)
}

},
"/zFQoSDNfJ+hXgO0jFfy8uPR09vTZ4UxMBxW8yVrL3I=":
function (require, module, exports, __dirname, __filename) {
var os = require('os');
var ip = require('ip');
//pick the first reasonable looking host.
//this should *just work* when running on a vps.

var isPrivate = ip.isPrivate;

function isNonPrivate(e) {
  return !isPrivate(e);
}

var address = (module.exports = function(inter, filter) {
  inter = inter || os.networkInterfaces();
  filter = filter || isNonPrivate;
  var score = 0;
  var candidate = undefined;
  for (var k in inter) {
    for (var i in inter[k]) {
      var e = inter[k][i];

      // Must not be loopback:
      if (e.internal) continue;
      // Must pass our filter:
      if (!filter(e.address, e)) continue;

      // Prioritize IPv4 wlan:
      if (k.startsWith('wl') && e.family === 'IPv4' && score < 8) {
        score = 8;
        candidate = e.address;
      }
      // Prioritize IPv4 ethernet:
      else if (k.startsWith('en') && e.family === 'IPv4' && score < 7) {
        score = 7;
        candidate = e.address;
      }
      // Prioritize IPv4 OLD ethernet:
      else if (k.startsWith('eth') && e.family === 'IPv4' && score < 6) {
        score = 6;
        candidate = e.address;
      }
      // Prioritize wlan:
      else if (k.startsWith('wl') && e.family === 'IPv6' && score < 5) {
        score = 5;
        candidate = e.address + '%' + k;
      }
      // Prioritize ethernet:
      else if (k.startsWith('en') && e.family === 'IPv6' && score < 4) {
        score = 4;
        candidate = e.address + '%' + k;
      }
      // Prioritize OLD ethernet:
      else if (k.startsWith('eth') && e.family === 'IPv6' && score < 3) {
        score = 3;
        candidate = e.address + '%' + k;
      }
      // Prioritize IPv4 tunnels (VPN):
      else if (k.startsWith('tun') && e.family === 'IPv4' && score < 2) {
        score = 2;
        candidate = e.address;
      }
      // Prioritize tunnels (VPN):
      else if (k.startsWith('tun') && e.family === 'IPv6' && score < 1) {
        score = 1;
        candidate = e.address + '%' + k;
      }
    }
  }
  return candidate;
});

function isV4(e) {
  return e.family === 'IPv4';
}

function isV6(e) {
  return e.family === 'IPv6';
}

var _private = (module.exports.private = function(inter) {
  return address(inter, isPrivate);
});

module.exports.v4 = address(null, function(addr, e) {
  return isV4(e) && isNonPrivate(addr);
});

module.exports.v6 = address(null, function(addr, e) {
  return isV6(e) && isNonPrivate(addr);
});

_private.v4 = address(null, function(addr, e) {
  return isV4(e) && isPrivate(addr);
});

_private.v6 = address(null, function(addr, e) {
  return isV6(e) && isPrivate(addr);
});

module.exports.all = {
  public: {
    v4: module.exports.v4,
    v6: module.exports.v6,
  },
  private: {
    v4: _private.v4,
    v6: _private.v6,
  },
};

},
"02mP/70TntdBmhroiQH3+OShqJkBlGFUqU1G4DOOvZQ=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = function (version) {

  const { note, getReceive, getReplicate, getSequence } = version

  var exports = {
    note,
    getReceive,
    getReplicate,
    getSequence
  }

  function isEmpty (o) {
    for (var k in o) return false
    return true
  }

  function isObject (o) {
    return o && 'object' === typeof o
  }

  function isBlocked(state, id, target) {
    return state.blocks[id] && state.blocks[id][target]
  }

  function isShared (state, id, peerId) {
    return state.follows[id] && !isBlocked(state, id, peerId)
  }

  //check if a feed is already being replicated on another peer from ignoreId
  function isAlreadyReplicating(state, feedId, ignoreId) {
    for (var id in state.peers) {
      if (id !== ignoreId) {
        var peer = state.peers[id]
        if (peer.notes && getReceive(peer.notes[id])) return id

        // for replicating the node must have replicated something not just rx
        // this fixed a partial replication bug where a node is unable to send the full log
        var idHasSent = peer.replicating && peer.replicating[id] && peer.replicating[id].sent != -1
        if (peer.replicating && peer.replicating[feedId] && peer.replicating[feedId].rx && idHasSent) return id
      }
    }
    return false
  }

  // lower numbers should be respected
  // if one is -1 and the other is not, use the other
  function fixSeq (local, remote) {
    if (local == null) return remote
    if (local == -1 || remote == -1) return remote
    if (remote == 0) return 0
    if (remote > 0 && local > 0 && remote < local) return remote
    return Math.max(local, remote)
  }

  //check if a feed is available from a peer apart from ignoreId

  function isAvailable(state, feedId, ignoreId) {
    for (var peerId in state.peers) {
      if (peerId != ignoreId) {
        var peer = state.peers[peerId]
        //BLOCK: check wether id has blocked this peer
        if ((peer.clock && peer.clock[feedId] || 0) > (state.clock[feedId] || 0) && isShared(state, feedId, peerId)) {
          return true
        }
      }
    }
  }

  //jump to a particular key in a list, then iterate from there
  //back around to the key. this is used for switching away from
  //peers that stall so that you'll rotate through all the peers
  //not just swich between two different peers.

  function eachFrom(keys, key, iter) {
    var i = keys.indexOf(key)
    if (!~i) return
    //start at 1 because we want to visit all keys but key.
    for (var j = 1; j < keys.length; j++)
      if (iter(keys[(j+i) % keys.length], j))
        return
  }

  function setNotes (peer, feed, seq, rx) {
    peer.notes = peer.notes || {}
    peer.notes[feed] = note(seq, rx)

    var rep = peer.replicating[feed]
    if (rep) {
      rep.rx = rx
      rep.requested = seq
    }
  }

  // defaults for backwards compatibility
  exports.getMsgAuthor = function(msg) {
    return msg.author
  }
  exports.getMsgSequence = function(msg) {
    return msg.sequence
  }

  exports.initialize = function (id, getMsgAuthor, getMsgSequence) {
    if (getMsgAuthor)
      exports.getMsgAuthor = getMsgAuthor
    if (getMsgSequence)
      exports.getMsgSequence = getMsgSequence

    return {
      id: id,
      clock: null,
      follows: {},
      blocks: {},
      peers: {},
      receive: []
    }
  }

  exports.clock = function (state, clock) {
    state.clock = clock
    return state
  }

  exports.connect = function (state, ev) {
    if (state.peers[ev.id]) throw new Error('already connected to peer:'+ev.id)
    if (typeof ev.client != 'boolean') throw new Error('connect.client must be boolean')

    //  if (isBlocked(state, state.id, ev.id)) return state

    state.peers[ev.id] = {
      blocked: isBlocked(state, state.id, ev.id),
      clock: null,
      client: !!ev.client,
      msgs: [],
      retrive: [],
      notes: null,
      //if we are client, wait until we receive notes to send code.
      //this is a weird way of doing it! shouldn't we just have a bit of state
      //for wether we have received a vector clock
      replicating: ev.client ? null : {}
    }

    return state
  }

  exports.disconnect = function (state, ev) {
    delete state.peers[ev.id]
    return state
  }

  //this is when the stored peer clock has been loaded from the local database.
  //note, this must be handled before any messages are received.
  exports.peerClock = function (state, ev) {
    if (!state.peers[ev.id])
      throw new Error('peerClock called for:'+ev.id + ' but only connected to:'+ Object.keys(state.peers))
    var peer = state.peers[ev.id]
    var clock = peer.clock = ev.value

    //client should wait for the server notes, so that stream
    //can error before a peer sends a massive handshake.
    if (peer.replicating == null) return state

    //always set an empty clock here, so that if we don't have anything
    //to send, we still send this empty clock. This only happens on a new connection.
    //in every other situation, clock is only sent if there is something in it.
    peer.notes = peer.notes || {}

    //iterate over following and create replications.
    //if we want to replicate a peer that has changed since their clock,
    //create a replication for that peer.

    for (var id in state.follows) {
      var seq = clock[id] || 0, lseq = state.clock[id] || 0
      //BLOCK: check wether id has blocked this peer
      if (isShared(state, id, ev.id) && seq !== -1 && seq !== state.clock[id]) {

        //if we are already replicating, and this feed is at zero, ask for it anyway,
        //XXX if a feed is at zero, but we are replicating on another peer
        //just don't ask for it yet?
        var replicating = isAlreadyReplicating(state, id, ev.id)// && lseq
        peer.replicating = peer.replicating || {}
        peer.replicating[id] = {
          tx: false,
          rx: !replicating,
          sent: null,
          requested: lseq
        }
        setNotes(peer, id, lseq, !replicating)
      }
    }

    return state
  }

  //XXX handle replicating with only one peer.
  exports.follow = function (state, ev) {
    //set to true once we have asked for this feed from someone.
    var replicating = false
    if (!!state.follows[ev.id] !== ev.value) {
      state.follows[ev.id] = ev.value
      for (var id in state.peers) {
        var peer = state.peers[id]
        if (!peer.clock || !peer.replicating || !isShared(state, ev.id, id)) continue
        //BLOCK: check wether this feed has has blocked this peer.
        //..... don't replicate feeds with peers that have blocked them at all?

        //cases:
        //  don't have feed
        //  do have feed
        //  peer has feed
        //  peer rejects feed
        var seq = peer.clock[ev.id] || 0, lseq = state.clock[ev.id] || 0
        if (seq === -1) {
          //peer explicitly does not replicate this feed, don't ask for it.
        }
        else if (ev.value === false) { //unfollow
          setNotes(peer, ev.id, -1, false)
        }
        else if (ev.value === true && seq !== state.clock[ev.id]) {
          peer.replicating[ev.id] = {
            rx: true, tx: false,
            sent: -1, requested: lseq
          }
          setNotes(peer, ev.id, lseq, !replicating)
          replicating = true
        }
      }
    }
    return state
  }

  exports.retrive = function (state, msg) {
    //check if any peer requires this msg
    for (var id in state.peers) {
      var peer = state.peers[id]
      if (!peer.replicating) continue
      //BLOCK: check wether id has blocked this peer
      const author = exports.getMsgAuthor(msg)
      const sequence = exports.getMsgSequence(msg)
      var rep = peer.replicating[author]

      if (rep && rep.tx && rep.sent === sequence - 1) {
        rep.sent++
        peer.msgs.push(msg)
        if (rep.sent < state.clock[author]) {
          //use continue, not return because we still need to loop through other peers.
          if (~peer.retrive.indexOf(author)) continue
          peer.retrive.push(author)
        }
      }
    }
    return state
  }

  function isAhead(seq1, seq2) {
    if (seq2 === -1) return false
    if (seq2 == null) return true
    if (seq1 > seq2) return true
  }

  exports.append = function (state, msg) {
    const author = exports.getMsgAuthor(msg)
    const sequence = exports.getMsgSequence(msg)
    //check if any peer requires this msg
    if (state.clock[author] != null && state.clock[author] !== sequence - 1)
      return state //ignore

    var lseq = state.clock[author] = sequence
    for (var id in state.peers) {
      var peer = state.peers[id]
      if (!peer.clock || !peer.replicating || !isShared(state, author, id)) continue
      //BLOCK: check wether msg.author has blocked this peer

      var seq = peer.clock[author]

      var rep = peer.replicating[author]

      if (rep && rep.tx && rep.sent == lseq - 1 && lseq > seq) {
        peer.msgs.push(msg)
        rep.sent++
      }
      //if we are ahead of this peer, and not in tx mode, let them know that.
      else if (
        isAhead(lseq, seq) &&
          (rep ? !rep.tx && rep.sent != null : state.follows[author])
      )
        setNotes(peer, author, sequence, false)
    }

    return state
  }

  //XXX if we only receive from a single peer,
  //then we shouldn't really get known messages?
  //except during the race when we have disabled a peer
  //but they havn't noticed yet.
  exports.receive = function (state, ev) {
    var msg = ev.value
    //receive a message, validate and append.
    //if this message is forked, disable this feed

    if (!state.peers[ev.id]) throw new Error('lost peer state:'+ev.id)

    //we _know_ that this peer is upto at least this message now.
    //(but maybe they already told us they where ahead further)
    const author = exports.getMsgAuthor(msg)
    const sequence = exports.getMsgSequence(msg)
    var peer = state.peers[ev.id]
    var rep = peer.replicating[author]

    //if we havn't asked for this, ignore it. (this is remote speaking protocol wrong!)
    if (!rep) return state

    peer.clock[author] = Math.max(peer.clock[author], sequence)
    rep.sent = Math.max(rep.sent, sequence)

    //if this message has already been seen, ignore.
    if (state.clock[author] >= sequence) {
      if (rep.rx) {
        setNotes(peer, author, state.clock[author], false)
      }
      //XXX activate some other peer?
      return state
    }

    //remember the time of the last message received
    state.peers[ev.id].ts = ev.ts

    //FORKS ignore additional messages if we have already found an invalid one.
    if (isShared(state, exports.getMsgAuthor(ev.value), ev.id))
      state.receive.push(ev)
    //Q: possibly update the receiving mode?

    return state
  }

  //XXX check if we are already receiving a feed
  //and if so put this into lazy mode.
  exports.notes = function (state, ev) {
    //update replicating modes
    var clock = ev.value

    //support sending clocks inside a thing with additional properties.
    //this is to allow room for backwards compatible upgrades.
    if (isObject(ev.value.clock))
      clock = ev.value.clock

    var peer = state.peers[ev.id]
    if (!peer) throw new Error('lost state of peer:'+ev.id)
    if (!peer.clock) throw new Error("received notes, but has not set the peer's clock yet")
    var count = 0

    //if we are client, and this is the first notes we receive
    if (!peer.replicating) {
      peer.replicating = {}
      state = exports.peerClock(state, {id: ev.id, value: state.peers[ev.id].clock})
    }

    for (var id in clock) {
      count++

      var seq = peer.clock[id] = fixSeq(peer.clock[id], getSequence(clock[id]))
      var tx = getReceive(clock[id]) // is even
      var isReplicate = getReplicate(clock[id]) // !== -1

      var lseq = state.clock[id] || 0

      //check if we are not following this feed.
      //BLOCK: or wether id has blocked this peer
      if (!isShared(state, id, ev.id)) {
        if (!peer.replicating[id])
          setNotes(peer, id, -1, false)
        peer.replicating[id] = {tx: false, rx: false, sent: -1, requested: -1}
      }
      else {
        var rep = peer.replicating[id]
        var replicating = isAlreadyReplicating(state, id, ev.id)
        if (!rep) {
          rep = peer.replicating[id] = {
            tx: true,
            rx: true,
            sent: seq,
            requested: lseq
          }
          setNotes(peer, id, lseq, lseq < seq && !replicating)
        }
        else if (!rep.rx && seq > lseq) {
          if (!replicating) {
            peer.ts = ev.ts //remember ts, so we can switch this feed if necessary
            setNotes(peer, id, lseq, true)
          } else {
            //if we are already replicating this via another peer
            //switch to this peer if it is further ahead.
            //(todo?: switch if the other peer's timestamp is old?)
            var _peer = state.peers[replicating]
            // note: _peer.clock[id] may be undefined, if we have
            // just connected to them and sent our notes but not
            // received theirs.
            if (seq > (_peer.clock[id] || 0)) {
              peer.ts = ev.ts
              setNotes(peer, id, lseq, true)
              setNotes(_peer, id, lseq, false) //deactivate the previous peer
            }
          }
        }

        //positive seq means "send this to me please"
        rep.tx = tx
        //in the case we are already ahead, get ready to send them messages.
        rep.sent = seq
        if (lseq > seq) {
          if (tx) peer.retrive.push(id)
          else if (isReplicate) setNotes(peer, id, lseq, rep.rx)
        }
      }
    }

    peer.recvNotes = (peer.recvNotes || 0) + count
    return state
  }

  exports.timeout = function (state, ev) {
    var want = {}

    for (var peerId in state.peers) {
      var peer = state.peers[peerId]
      //check if the peer hasn't received a message recently.

      //if we havn't received a message from this peer recently
      if ((peer.ts || 0) + state.timeout < ev.ts) {
        //check if they have claimed a higher sequence, but not sent us
        for (var id in peer.replicating) {

          var rep = peer.replicating[id]
          //if yes, prepare to switch this feed to that peer
          if (rep.rx && isAvailable(state, id, peerId)) {
            want[id] = peerId
            setNotes(peer, id, state.clock[id], false)
          }
        }
      }
    }

    var peerIds = Object.keys(state.peers)
    for (var feedId in want) {
      var ignoreId = want[feedId]
      eachFrom(peerIds, ignoreId, function (peerId) {
        var peer = state.peers[peerId]
        if (peer.clock && peer.clock[feedId] || 0 > state.clock[feedId] || 0) {
          peer.replicating = peer.replicating || {}
          peer.replicating[feedId] = peer.replicating[feedId] || {
            tx: false, rx: true, sent: -1, requested: state.clock[feedId]
          }
          setNotes(peer, feedId, state.clock[feedId], true)
          peer.ts = ev.ts
          //returning true triggers the end of eachFrom
          return true
        }
      })
    }

    return state
  }

  exports.block = function (state, ev) {
    if (!ev.value) {
      if (state.blocks[ev.id]) delete state.blocks[ev.id][ev.target]
      if (isEmpty(state.blocks[ev.id]))
        delete state.blocks[ev.id]
    }
    else {
      state.blocks[ev.id] = state.blocks[ev.id] || {}
      state.blocks[ev.id][ev.target] = true

      //if we blocked this peer, and we are also connected to them.
      //then stop replicating immediately.
      if (state.id === ev.id && state.peers[ev.target]) {
        //end replication immediately.
        state.peers[ev.target].blocked = ev.value
      }

      for (var id in state.peers) {
        var peer = state.peers[id]
        if (!peer.replicating) continue
        if (id === ev.target && peer.replicating[ev.id])
          setNotes(peer, ev.id, -1, false)
      }
    }

    return state
  }

  return exports
}

/*
  what does a fork proof look like?

  usually, you have one message, and receive a subsequent message.
  (n, n'+1), except that n'+1 does not extend n. but both have valid
  signatures.

*/

},
"0FoMFq6AS2Z3T/RGdsPOqRbwcie/Sg7VUr5FURaBI1k=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (fn, opts) {
  return new TakeStream(fn, opts)
}

var ThroughStream = require('./through')

function TakeStream(test, opts) {
  this.fn = test
  this._includeLast = opts && opts.last

  if('number' === typeof test) {
    var n = test
    this._includeLast = true
    this.fn = function () { return --n }
  }

  this.paused = true
  this.ended = false
  this.source = this.sink = null

}

TakeStream.prototype = ThroughStream()

TakeStream.prototype.write = function (data) {
  var test = this.fn(data)
  if(test) {
    this.sink.write(data)
    this.paused = this.sink.paused
  }
  else if(this._includeLast) {
    //abort immediately, so we don't stall waiting for the next message just to end
    this._includeLast = false
    this.sink.write(data)
    this.source.abort()
  }
  else
    this.source.abort()
}

},
"0LRE9AZXeIuQjycmZQioBk33CRl8wVU1ATgXR5kzTvc=":
function (require, module, exports, __dirname, __filename) {
'use strict';

module.exports = {
	extensions: [
		'jpg',
		'png',
		'apng',
		'gif',
		'webp',
		'flif',
		'xcf',
		'cr2',
		'cr3',
		'orf',
		'arw',
		'dng',
		'nef',
		'rw2',
		'raf',
		'tif',
		'bmp',
		'icns',
		'jxr',
		'psd',
		'indd',
		'zip',
		'tar',
		'rar',
		'gz',
		'bz2',
		'7z',
		'dmg',
		'mp4',
		'mid',
		'mkv',
		'webm',
		'mov',
		'avi',
		'mpg',
		'mp2',
		'mp3',
		'm4a',
		'oga',
		'ogg',
		'ogv',
		'opus',
		'flac',
		'wav',
		'spx',
		'amr',
		'pdf',
		'epub',
		'exe',
		'swf',
		'rtf',
		'wasm',
		'woff',
		'woff2',
		'eot',
		'ttf',
		'otf',
		'ico',
		'flv',
		'ps',
		'xz',
		'sqlite',
		'nes',
		'crx',
		'xpi',
		'cab',
		'deb',
		'ar',
		'rpm',
		'Z',
		'lz',
		'cfb',
		'mxf',
		'mts',
		'blend',
		'bpg',
		'docx',
		'pptx',
		'xlsx',
		'3gp',
		'3g2',
		'jp2',
		'jpm',
		'jpx',
		'mj2',
		'aif',
		'qcp',
		'odt',
		'ods',
		'odp',
		'xml',
		'mobi',
		'heic',
		'cur',
		'ktx',
		'ape',
		'wv',
		'dcm',
		'ics',
		'glb',
		'pcap',
		'dsf',
		'lnk',
		'alias',
		'voc',
		'ac3',
		'm4v',
		'm4p',
		'm4b',
		'f4v',
		'f4p',
		'f4b',
		'f4a',
		'mie',
		'asf',
		'ogm',
		'ogx',
		'mpc',
		'arrow',
		'shp',
		'aac',
		'mp1',
		'it',
		's3m',
		'xm',
		'ai',
		'skp',
		'avif',
		'eps',
		'lzh',
		'pgp',
		'asar',
		'stl',
		'chm',
		'3mf',
		'zst',
		'jxl',
		'vcf'
	],
	mimeTypes: [
		'image/jpeg',
		'image/png',
		'image/gif',
		'image/webp',
		'image/flif',
		'image/x-xcf',
		'image/x-canon-cr2',
		'image/x-canon-cr3',
		'image/tiff',
		'image/bmp',
		'image/vnd.ms-photo',
		'image/vnd.adobe.photoshop',
		'application/x-indesign',
		'application/epub+zip',
		'application/x-xpinstall',
		'application/vnd.oasis.opendocument.text',
		'application/vnd.oasis.opendocument.spreadsheet',
		'application/vnd.oasis.opendocument.presentation',
		'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
		'application/vnd.openxmlformats-officedocument.presentationml.presentation',
		'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
		'application/zip',
		'application/x-tar',
		'application/x-rar-compressed',
		'application/gzip',
		'application/x-bzip2',
		'application/x-7z-compressed',
		'application/x-apple-diskimage',
		'application/x-apache-arrow',
		'video/mp4',
		'audio/midi',
		'video/x-matroska',
		'video/webm',
		'video/quicktime',
		'video/vnd.avi',
		'audio/vnd.wave',
		'audio/qcelp',
		'audio/x-ms-asf',
		'video/x-ms-asf',
		'application/vnd.ms-asf',
		'video/mpeg',
		'video/3gpp',
		'audio/mpeg',
		'audio/mp4', // RFC 4337
		'audio/opus',
		'video/ogg',
		'audio/ogg',
		'application/ogg',
		'audio/x-flac',
		'audio/ape',
		'audio/wavpack',
		'audio/amr',
		'application/pdf',
		'application/x-msdownload',
		'application/x-shockwave-flash',
		'application/rtf',
		'application/wasm',
		'font/woff',
		'font/woff2',
		'application/vnd.ms-fontobject',
		'font/ttf',
		'font/otf',
		'image/x-icon',
		'video/x-flv',
		'application/postscript',
		'application/eps',
		'application/x-xz',
		'application/x-sqlite3',
		'application/x-nintendo-nes-rom',
		'application/x-google-chrome-extension',
		'application/vnd.ms-cab-compressed',
		'application/x-deb',
		'application/x-unix-archive',
		'application/x-rpm',
		'application/x-compress',
		'application/x-lzip',
		'application/x-cfb',
		'application/x-mie',
		'application/mxf',
		'video/mp2t',
		'application/x-blender',
		'image/bpg',
		'image/jp2',
		'image/jpx',
		'image/jpm',
		'image/mj2',
		'audio/aiff',
		'application/xml',
		'application/x-mobipocket-ebook',
		'image/heif',
		'image/heif-sequence',
		'image/heic',
		'image/heic-sequence',
		'image/icns',
		'image/ktx',
		'application/dicom',
		'audio/x-musepack',
		'text/calendar',
		'text/vcard',
		'model/gltf-binary',
		'application/vnd.tcpdump.pcap',
		'audio/x-dsf', // Non-standard
		'application/x.ms.shortcut', // Invented by us
		'application/x.apple.alias', // Invented by us
		'audio/x-voc',
		'audio/vnd.dolby.dd-raw',
		'audio/x-m4a',
		'image/apng',
		'image/x-olympus-orf',
		'image/x-sony-arw',
		'image/x-adobe-dng',
		'image/x-nikon-nef',
		'image/x-panasonic-rw2',
		'image/x-fujifilm-raf',
		'video/x-m4v',
		'video/3gpp2',
		'application/x-esri-shape',
		'audio/aac',
		'audio/x-it',
		'audio/x-s3m',
		'audio/x-xm',
		'video/MP1S',
		'video/MP2P',
		'application/vnd.sketchup.skp',
		'image/avif',
		'application/x-lzh-compressed',
		'application/pgp-encrypted',
		'application/x-asar',
		'model/stl',
		'application/vnd.ms-htmlhelp',
		'model/3mf',
		'image/jxl',
		'application/zstd'
	]
};

},
"0QsVYkCP3wzxfSvVSCLHXUCISRE0LgGpmfA3aNDYHs0=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var json = require('./json')
var Store = require('./store')
var atomic = require('atomic-file-rw')
var path = require('path')

module.exports = function (dir, codec, keyCodec) {
  if (!dir) {
    console.error('key-value-file-store missing dir, skipping persistence')

    return Store(
      function (v, cb) { cb() },
      function (k,v,cb) { cb() }
    )
  }

  codec = codec || json
  var keyEncode = keyCodec
    ? keyCodec.encode || keyCodec
    : function (e) { return e }

  function toPath(id) {
    return path.join(dir, keyEncode(id))
  }

  return Store(function read (id, cb) {
    atomic.readFile(toPath(id), function (err, value) {
      if(err) return cb(err)
      try { value = codec.decode(value) }
      catch (err) { return cb(err) }
      return cb(null, value)
    })
  }, function write (id, value, cb) {
    try { value = codec.encode(value) }
    catch (err) { return cb(err) }
    atomic.writeFile(toPath(id), value, cb)
  })
}

},
"0USpmsILuN6k9ei85R4WvKV4b7XOs8EQtm7X8xiHOmc=":
function (require, module, exports, __dirname, __filename) {
module.exports = function Catch (onError) {
    onError = onError || function noop () {}
    var errd
    return function sink (read) {
        return function source (abort, cb) {
            read(abort, function onNext (end, data) {
                if (errd) return cb(true)
                if (end && end !== true) {  // if error
                    var _end = onError(end)
                    if (_end === false) return cb(end)
                    if (_end && _end !== true) {
                        errd = true
                        return cb(null, _end)
                    }
                    return cb(true)
                }
                cb(end, data)
            })
        }
    }
}

},
"0b/cE6EoTU+KEH+wyJv4TfPVA8ZShZK98xLQuog1vKE=":
function (require, module, exports, __dirname, __filename) {
// Generated by CoffeeScript 1.8.0
(function() {
  var Heap, defaultCmp, floor, heapify, heappop, heappush, heappushpop, heapreplace, insort, min, nlargest, nsmallest, updateItem, _siftdown, _siftup;

  floor = Math.floor, min = Math.min;


  /*
  Default comparison function to be used
   */

  defaultCmp = function(x, y) {
    if (x < y) {
      return -1;
    }
    if (x > y) {
      return 1;
    }
    return 0;
  };


  /*
  Insert item x in list a, and keep it sorted assuming a is sorted.
  
  If x is already in a, insert it to the right of the rightmost x.
  
  Optional args lo (default 0) and hi (default a.length) bound the slice
  of a to be searched.
   */

  insort = function(a, x, lo, hi, cmp) {
    var mid;
    if (lo == null) {
      lo = 0;
    }
    if (cmp == null) {
      cmp = defaultCmp;
    }
    if (lo < 0) {
      throw new Error('lo must be non-negative');
    }
    if (hi == null) {
      hi = a.length;
    }
    while (lo < hi) {
      mid = floor((lo + hi) / 2);
      if (cmp(x, a[mid]) < 0) {
        hi = mid;
      } else {
        lo = mid + 1;
      }
    }
    return ([].splice.apply(a, [lo, lo - lo].concat(x)), x);
  };


  /*
  Push item onto heap, maintaining the heap invariant.
   */

  heappush = function(array, item, cmp) {
    if (cmp == null) {
      cmp = defaultCmp;
    }
    array.push(item);
    return _siftdown(array, 0, array.length - 1, cmp);
  };


  /*
  Pop the smallest item off the heap, maintaining the heap invariant.
   */

  heappop = function(array, cmp) {
    var lastelt, returnitem;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    lastelt = array.pop();
    if (array.length) {
      returnitem = array[0];
      array[0] = lastelt;
      _siftup(array, 0, cmp);
    } else {
      returnitem = lastelt;
    }
    return returnitem;
  };


  /*
  Pop and return the current smallest value, and add the new item.
  
  This is more efficient than heappop() followed by heappush(), and can be
  more appropriate when using a fixed size heap. Note that the value
  returned may be larger than item! That constrains reasonable use of
  this routine unless written as part of a conditional replacement:
      if item > array[0]
        item = heapreplace(array, item)
   */

  heapreplace = function(array, item, cmp) {
    var returnitem;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    returnitem = array[0];
    array[0] = item;
    _siftup(array, 0, cmp);
    return returnitem;
  };


  /*
  Fast version of a heappush followed by a heappop.
   */

  heappushpop = function(array, item, cmp) {
    var _ref;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    if (array.length && cmp(array[0], item) < 0) {
      _ref = [array[0], item], item = _ref[0], array[0] = _ref[1];
      _siftup(array, 0, cmp);
    }
    return item;
  };


  /*
  Transform list into a heap, in-place, in O(array.length) time.
   */

  heapify = function(array, cmp) {
    var i, _i, _j, _len, _ref, _ref1, _results, _results1;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    _ref1 = (function() {
      _results1 = [];
      for (var _j = 0, _ref = floor(array.length / 2); 0 <= _ref ? _j < _ref : _j > _ref; 0 <= _ref ? _j++ : _j--){ _results1.push(_j); }
      return _results1;
    }).apply(this).reverse();
    _results = [];
    for (_i = 0, _len = _ref1.length; _i < _len; _i++) {
      i = _ref1[_i];
      _results.push(_siftup(array, i, cmp));
    }
    return _results;
  };


  /*
  Update the position of the given item in the heap.
  This function should be called every time the item is being modified.
   */

  updateItem = function(array, item, cmp) {
    var pos;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    pos = array.indexOf(item);
    if (pos === -1) {
      return;
    }
    _siftdown(array, 0, pos, cmp);
    return _siftup(array, pos, cmp);
  };


  /*
  Find the n largest elements in a dataset.
   */

  nlargest = function(array, n, cmp) {
    var elem, result, _i, _len, _ref;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    result = array.slice(0, n);
    if (!result.length) {
      return result;
    }
    heapify(result, cmp);
    _ref = array.slice(n);
    for (_i = 0, _len = _ref.length; _i < _len; _i++) {
      elem = _ref[_i];
      heappushpop(result, elem, cmp);
    }
    return result.sort(cmp).reverse();
  };


  /*
  Find the n smallest elements in a dataset.
   */

  nsmallest = function(array, n, cmp) {
    var elem, i, los, result, _i, _j, _len, _ref, _ref1, _results;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    if (n * 10 <= array.length) {
      result = array.slice(0, n).sort(cmp);
      if (!result.length) {
        return result;
      }
      los = result[result.length - 1];
      _ref = array.slice(n);
      for (_i = 0, _len = _ref.length; _i < _len; _i++) {
        elem = _ref[_i];
        if (cmp(elem, los) < 0) {
          insort(result, elem, 0, null, cmp);
          result.pop();
          los = result[result.length - 1];
        }
      }
      return result;
    }
    heapify(array, cmp);
    _results = [];
    for (i = _j = 0, _ref1 = min(n, array.length); 0 <= _ref1 ? _j < _ref1 : _j > _ref1; i = 0 <= _ref1 ? ++_j : --_j) {
      _results.push(heappop(array, cmp));
    }
    return _results;
  };

  _siftdown = function(array, startpos, pos, cmp) {
    var newitem, parent, parentpos;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    newitem = array[pos];
    while (pos > startpos) {
      parentpos = (pos - 1) >> 1;
      parent = array[parentpos];
      if (cmp(newitem, parent) < 0) {
        array[pos] = parent;
        pos = parentpos;
        continue;
      }
      break;
    }
    return array[pos] = newitem;
  };

  _siftup = function(array, pos, cmp) {
    var childpos, endpos, newitem, rightpos, startpos;
    if (cmp == null) {
      cmp = defaultCmp;
    }
    endpos = array.length;
    startpos = pos;
    newitem = array[pos];
    childpos = 2 * pos + 1;
    while (childpos < endpos) {
      rightpos = childpos + 1;
      if (rightpos < endpos && !(cmp(array[childpos], array[rightpos]) < 0)) {
        childpos = rightpos;
      }
      array[pos] = array[childpos];
      pos = childpos;
      childpos = 2 * pos + 1;
    }
    array[pos] = newitem;
    return _siftdown(array, startpos, pos, cmp);
  };

  Heap = (function() {
    Heap.push = heappush;

    Heap.pop = heappop;

    Heap.replace = heapreplace;

    Heap.pushpop = heappushpop;

    Heap.heapify = heapify;

    Heap.updateItem = updateItem;

    Heap.nlargest = nlargest;

    Heap.nsmallest = nsmallest;

    function Heap(cmp) {
      this.cmp = cmp != null ? cmp : defaultCmp;
      this.nodes = [];
    }

    Heap.prototype.push = function(x) {
      return heappush(this.nodes, x, this.cmp);
    };

    Heap.prototype.pop = function() {
      return heappop(this.nodes, this.cmp);
    };

    Heap.prototype.peek = function() {
      return this.nodes[0];
    };

    Heap.prototype.contains = function(x) {
      return this.nodes.indexOf(x) !== -1;
    };

    Heap.prototype.replace = function(x) {
      return heapreplace(this.nodes, x, this.cmp);
    };

    Heap.prototype.pushpop = function(x) {
      return heappushpop(this.nodes, x, this.cmp);
    };

    Heap.prototype.heapify = function() {
      return heapify(this.nodes, this.cmp);
    };

    Heap.prototype.updateItem = function(x) {
      return updateItem(this.nodes, x, this.cmp);
    };

    Heap.prototype.clear = function() {
      return this.nodes = [];
    };

    Heap.prototype.empty = function() {
      return this.nodes.length === 0;
    };

    Heap.prototype.size = function() {
      return this.nodes.length;
    };

    Heap.prototype.clone = function() {
      var heap;
      heap = new Heap();
      heap.nodes = this.nodes.slice(0);
      return heap;
    };

    Heap.prototype.toArray = function() {
      return this.nodes.slice(0);
    };

    Heap.prototype.insert = Heap.prototype.push;

    Heap.prototype.top = Heap.prototype.peek;

    Heap.prototype.front = Heap.prototype.peek;

    Heap.prototype.has = Heap.prototype.contains;

    Heap.prototype.copy = Heap.prototype.clone;

    return Heap;

  })();

  (function(root, factory) {
    if (typeof define === 'function' && define.amd) {
      return define([], factory);
    } else if (typeof exports === 'object') {
      return module.exports = factory();
    } else {
      return root.Heap = factory();
    }
  })(this, function() {
    return Heap;
  });

}).call(this);

},
"0ctY+ep4+F5/Kvk7cLkYlpHMnljPFrV5iNuugfJJSU0=":
function (require, module, exports, __dirname, __filename) {
// If `Date.now()` is invoked twice quickly, it's possible to get two
// identical time stamps. To avoid generation duplications, subsequent
// calls are manually ordered to force uniqueness.

var _last = 0
var _count = 1
var adjusted = 0
var _adjusted = 0

module.exports =
function timestamp() {
  /**
  Returns NOT an accurate representation of the current time.
  Since js only measures time as ms, if you call `Date.now()`
  twice quickly, it's possible to get two identical time stamps.
  This function guarantees unique but maybe inaccurate results
  on each call.
  **/
  //uncomment this wen
  var time = Date.now()
  //time = ~~ (time / 1000) 
  //^^^uncomment when testing...

  /**
  If time returned is same as in last call, adjust it by
  adding a number based on the counter. 
  Counter is incremented so that next call get's adjusted properly.
  Because floats have restricted precision, 
  may need to step past some values...
  **/
  if (_last === time)  {
    do {
      adjusted = time + ((_count++) / (_count + 999))
    } while (adjusted === _adjusted)
    _adjusted = adjusted
  }
  // If last time was different reset timer back to `1`.
  else {
    _count = 1
    adjusted = time
  }
  _adjusted = adjusted
  _last = time
  return adjusted
}

},
"0g4TXknmIVjmOwJNN4VBXhU+HE4pkx8bTCijb5TR4RI=":
function (require, module, exports, __dirname, __filename) {

var N1 = Math.pow(2,  7)
var N2 = Math.pow(2, 14)
var N3 = Math.pow(2, 21)
var N4 = Math.pow(2, 28)
var N5 = Math.pow(2, 35)
var N6 = Math.pow(2, 42)
var N7 = Math.pow(2, 49)
var N8 = Math.pow(2, 56)
var N9 = Math.pow(2, 63)

module.exports = function (value) {
  return (
    value < N1 ? 1
  : value < N2 ? 2
  : value < N3 ? 3
  : value < N4 ? 4
  : value < N5 ? 5
  : value < N6 ? 6
  : value < N7 ? 7
  : value < N8 ? 8
  : value < N9 ? 9
  :              10
  )
}

},
"0vwyYoswQgtCoEP6xFmarlTOtZIddwv7w6GLRb1Ewc4=":
function (require, module, exports, __dirname, __filename) {
var ltgt = require('ltgt')

module.exports = function (opts) {
  var start = opts.reverse ?
    ltgt.upperBound(opts, null) :
    ltgt.lowerBound(opts, 0)

  var startInclusive = ltgt.startInclusive(opts)
  if(start < 0) {
    start = 0
    startInclusive = true
  }
  return {
    start: start,
    end: (
      opts.reverse ?
      ltgt.lowerBound(opts, 0) :
      ltgt.upperBound(opts, null)
    ),
    startInclusive: startInclusive,
    endInclusive: ltgt.endInclusive(opts),
    reverse: !!opts.reverse,
    live: opts.live,
    old: opts.old,
    limit: opts.limit,
    seqs: opts.seqs, values: opts.values,
    cache: opts.cache !== false
  }
}

},
"0wFt4B8du4P4lVQyBzAOtjT62+VD7f6bbqGhJRwUMFA=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.muxrpcMissing = exports.toTunnelAddress = exports.openRoomInviteToAddress = exports.addressToOpenRoomInvite = exports.isOpenRoomInvite = exports.SEED = void 0;
const { isAddress } = require('ssb-ref');
exports.SEED = 'SSB+Room+PSK3TLYC2T86EHQCUHBUHASCASE18JBV24=';
function isOpenRoomInvite(invite) {
    if (typeof invite !== 'string')
        return false;
    if (!invite)
        return false;
    if (!invite.endsWith(':' + exports.SEED))
        return false;
    const [addr] = invite.split(':' + exports.SEED);
    if (!addr)
        return false;
    if (!isAddress(addr))
        return false;
    return true;
}
exports.isOpenRoomInvite = isOpenRoomInvite;
function addressToOpenRoomInvite(addr) {
    return typeof addr === 'string' ? `${addr}:${exports.SEED}` : null;
}
exports.addressToOpenRoomInvite = addressToOpenRoomInvite;
function openRoomInviteToAddress(invite) {
    return isOpenRoomInvite(invite) ? invite.split(':' + exports.SEED)[0] : null;
}
exports.openRoomInviteToAddress = openRoomInviteToAddress;
function toTunnelAddress(portal, target) {
    const shs = target.slice(1, -8);
    return `tunnel:${portal}:${target}~shs:${shs}`;
}
exports.toTunnelAddress = toTunnelAddress;
function muxrpcMissing(err) {
    if (!err)
        return false;
    const errString = typeof err.message === 'string'
        ? err.message
        : typeof err === 'string'
            ? err
            : '';
    return errString.endsWith('not in list of allowed methods');
}
exports.muxrpcMissing = muxrpcMissing;

},
"12maJ3l0vAfBsxjeIoAkoSVt8+jdCUQMjBftutRwb1I=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const pull = require('pull-stream')
const cat = require('pull-cat')
const { descending, live, toPullStream } = require('../operators')

// exports.name is blank to merge into global namespace

exports.manifest = {
  createLogStream: 'source',
}

exports.init = function (sbot) {
  sbot.createLogStream = function createLogStream(opts) {
    // Apply default values
    opts = opts || {}
    const optsKeys = opts.keys === false ? false : true
    const optsValues = opts.values === false ? false : true
    const optsSync = opts.sync === false ? false : true
    const optsLive = opts.live === true ? true : false
    const optsOld = opts.old === true ? true : false
    const optsLimit = typeof opts.limit === 'number' ? opts.limit : -1
    const optsReverse = opts.reverse === true ? true : false

    function format(msg) {
      if (!optsKeys && optsValues) return msg.value
      else if (optsKeys && !optsValues) return msg.key
      else return msg
    }

    function applyLimit(source) {
      if (optsLimit < 0) return source
      else if (optsLimit === 0) return pull.empty()
      else return pull(source, pull.take(optsLimit))
    }

    const old$ = pull(
      sbot.db.query(optsReverse ? descending() : null, toPullStream()),
      pull.map(format)
    )
    const sync$ = pull.values([{ sync: true }])
    const live$ = pull(sbot.db.query(live(), toPullStream()), pull.map(format))

    if (!optsLive) return applyLimit(old$)
    if (optsOld && optsSync) return applyLimit(cat([old$, sync$, live$]))
    if (optsOld && !optsSync) return applyLimit(cat([old$, live$]))
    if (!optsOld && optsSync) return applyLimit(cat([sync$, live$]))
    if (!optsOld && !optsSync) return applyLimit(live$)
  }
}

},
"15Xpz9+kzWDcRjyolLaaUMvt+u1g3Tt9nuLZZmZYLTo=":
function (require, module, exports, __dirname, __filename) {
function AbstractChainedBatch (db) {
  if (typeof db !== 'object' || db === null) {
    throw new TypeError('First argument must be an abstract-leveldown compliant store')
  }

  this.db = db
  this._operations = []
  this._written = false
}

AbstractChainedBatch.prototype._checkWritten = function () {
  if (this._written) {
    throw new Error('write() already called on this batch')
  }
}

AbstractChainedBatch.prototype.put = function (key, value) {
  this._checkWritten()

  var err = this.db._checkKey(key) || this.db._checkValue(value)
  if (err) throw err

  key = this.db._serializeKey(key)
  value = this.db._serializeValue(value)

  this._put(key, value)

  return this
}

AbstractChainedBatch.prototype._put = function (key, value) {
  this._operations.push({ type: 'put', key: key, value: value })
}

AbstractChainedBatch.prototype.del = function (key) {
  this._checkWritten()

  var err = this.db._checkKey(key)
  if (err) throw err

  key = this.db._serializeKey(key)
  this._del(key)

  return this
}

AbstractChainedBatch.prototype._del = function (key) {
  this._operations.push({ type: 'del', key: key })
}

AbstractChainedBatch.prototype.clear = function () {
  this._checkWritten()
  this._clear()

  return this
}

AbstractChainedBatch.prototype._clear = function () {
  this._operations = []
}

AbstractChainedBatch.prototype.write = function (options, callback) {
  this._checkWritten()

  if (typeof options === 'function') { callback = options }
  if (typeof callback !== 'function') {
    throw new Error('write() requires a callback argument')
  }
  if (typeof options !== 'object' || options === null) {
    options = {}
  }

  this._written = true
  this._write(options, callback)
}

AbstractChainedBatch.prototype._write = function (options, callback) {
  this.db._batch(this._operations, options, callback)
}

module.exports = AbstractChainedBatch

},
"18Fc7E2hFtjB+iI+xuiQwSfH+/wRydXt0qUqjhgOUd8=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var sources  = require('./sources')
var sinks    = require('./sinks')
var throughs = require('./throughs')

exports = module.exports = require('./pull')

exports.pull = exports

for(var k in sources)
  exports[k] = sources[k]

for(var k in throughs)
  exports[k] = throughs[k]

for(var k in sinks)
  exports[k] = sinks[k]


},
"1HfbeL4+90mEuhzQNZEUE/rMuqjoxhtcKqVdCCdqszA=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bencode = require('bencode')
const ssbKeys = require('ssb-keys')
const bfe = require('ssb-bfe')
const SSBURI = require('ssb-uri2')
const isCanonicalBase64 = require('is-canonical-base64')

const CONTENT_SIG_PREFIX = Buffer.from('bendybutt', 'utf8')

function decodeBox2(box2) {
  const decoded = bencode.decode(box2)
  return bfe.decode(decoded)
}

function isBoxedString(x) {
  return typeof x === 'string' && x.endsWith('.box2')
}

/**
 * Decode a bendy-butt message into an object useful for ssb-db and ssb-db2.
 * Assumes the bendy-butt message has already been validated.
 *
 * @param {Buffer} bbmsg a bendy-butt message encoded with `bencode`
 * @returns {Object} an object compatible with ssb/classic `msg.value`
 */
function decode(bbmsg) {
  const msgBFE = bencode.decode(bbmsg)
  const [payload, signature] = bfe.decode(msgBFE)
  const [author, sequence, previous, timestamp, contentSection] = payload

  const msgVal = {
    author,
    sequence,
    previous,
    timestamp,
    signature,
  }
  if (isBoxedString(contentSection)) {
    msgVal.content = contentSection
  } else {
    const [content, contentSignature] = contentSection
    msgVal.content = content
    msgVal.contentSignature = contentSignature
  }

  return msgVal
}

/**
 * Encode a database "msg value" to a bendy-butt msg in a Buffer.
 *
 * @param {Object} msgVal an object compatible with ssb/classic `msg.value`
 * @returns {Buffer} a bendy-butt message encoded with `bencode`
 */
function encode(msgVal) {
  const {
    author,
    sequence,
    previous,
    timestamp,
    signature,
    content,
    contentSignature,
  } = msgVal

  const contentSection = isBoxedString(content)
    ? content
    : [content, contentSignature]

  const payload = [author, sequence, previous, timestamp, contentSection]

  const msgBFE = bfe.encode([payload, signature])
  const bbmsg = bencode.encode(msgBFE)
  return bbmsg
}

/**
 * @callback Boxer
 * @param {Buffer} bbAuthor author feed ID, encoded in `bencode` and BFE
 * @param {Buffer} bbContentSection content-and-signature tuple, encoded in
 * `bencode` and BFE
 * @param {Buffer} bbPrevious previous message ID, encoded in `bencode` and BFE
 * @param {Array} recps an Array of recipient IDs
 * @returns {string} a ciphertext (i.e. "boxed") string, suffixed with `.box2`
 */

/**
 *
 * @param {Object} content an arbitrary object content the message contents
 * @param {import('ssb-keys').Keys | null} contentKeys the keys object of the
 * author to use for signing the content. May be different from `keys`.
 * @param {import('ssb-keys').Keys} keys the keys object of the author, to use
 * for signing the payload.
 * @param {number} sequence sequence number of the new msg to be created
 * @param {string | null} previous msg ID of the previous bendy-butt msg in the
 * feed
 * @param {number} timestamp when the message was created
 * @param {Buffer | null} hmacKey hmac key for signatures
 * @param {Boxer | undefined} boxer function to encrypt the contents
 * @returns {Buffer} a bendy-butt message encoded with `bencode`
 */
function encodeNew(
  content,
  contentKeys,
  keys,
  sequence,
  previous,
  timestamp,
  hmacKey,
  boxer
) {
  const author = keys.id
  const contentBFE = bfe.encode(content)
  const contentSignature = ssbKeys.sign(
    contentKeys || keys,
    hmacKey,
    Buffer.concat([CONTENT_SIG_PREFIX, bencode.encode(contentBFE)])
  )

  let contentSection = [content, contentSignature]
  if (content.recps) {
    contentSection = boxer(
      bfe.encode(author),
      bencode.encode(bfe.encode(contentSection)),
      bfe.encode(previous),
      content.recps
    )
  }

  const payload = [author, sequence, previous, timestamp, contentSection]
  const payloadBFE = bfe.encode(payload)
  const signature = ssbKeys.sign(keys, hmacKey, bencode.encode(payloadBFE))

  const msgBFE = bfe.encode([payload, signature])
  const bbmsg = bencode.encode(msgBFE)
  return bbmsg
}

/**
 * Calculate the message key for the given "msg value".
 *
 * @param {Object} msgVal an object compatible with ssb/classic `msg.value`
 * @returns {string} an SSB URI uniquely identifying the `msgVal`
 */
function hash(msgVal) {
  let data = ssbKeys.hash(encode(msgVal))
  if (data.endsWith('.sha256')) data = data.slice(0, -'.sha256'.length)
  return SSBURI.compose({ type: 'message', format: 'bendybutt-v1', data })
}

/**
 * Validate a decoded bendy-butt message value.
 *
 * @param {Object} msgVal - an object compatible with ssb/classic `msg.value`
 * @param {Object} previousMsg - a decoded `msgVal` object
 * @param {Buffer | string | null} hmacKey - a valid hmac key for signature verification
 * @returns {Object | undefined} an `Error` object with descriptive message or an `undefined` value for successful validation
 */
function validateSingle(msgVal, previousMsg, hmacKey) {
  const {
    author,
    sequence,
    previous,
    timestamp,
    signature,
    content,
    contentSignature,
  } = msgVal

  if (!SSBURI.isBendyButtV1FeedSSBURI(author))
    return new Error(
      `invalid message: author is "${author}", expected a valid feed identifier`
    )

  if (sequence < 1)
    return new Error(
      `invalid message: sequence is "${sequence}", expected a value greater than or equal to 1`
    )

  const previousErr = validatePrevious(author, sequence, previous, previousMsg)
  if (previousErr) return previousErr

  if (typeof timestamp !== 'number' || isNaN(timestamp) || !isFinite(timestamp))
    return new Error(
      `invalid message: timestamp is "${timestamp}", expected a 32 bit integer`
    )

  let contentSection = [content, contentSignature]
  if (content.recps) {
    contentSection = boxer(
      bfe.encode(author),
      bencode.encode(contentSection),
      bfe.encode(previous),
      content.recps
    )
  } else if (isBoxedString(content)) {
    contentSection = content
  }

  const payload = [author, sequence, previous, timestamp, contentSection]
  const payloadBFE = bfe.encode(payload)
  const payloadBen = bencode.encode(payloadBFE)

  const signatureErr = validateSignature(author, payloadBen, signature, hmacKey)
  if (signatureErr) return signatureErr

  // final encoding steps to allow byte-length check
  const msgBFE = bfe.encode([payload, signature])
  const bbmsg = bencode.encode(msgBFE)

  if (bbmsg.length > 8192)
    return new Error(
      `invalid message size: ${bbmsg.length} bytes, must not be greater than 8192 bytes`
    )
}

/**
 * Decode a bendy-butt message into an object useful for ssb-db and ssb-db2.
 * Performs message validation before returning the decoded message object.
 *
 * @param {Buffer} bbmsg a bendy-butt message encoded with `bencode`
 * @param {Object} previousMsg a decoded `msgVal` object
 * @param {Buffer | string | null} hmacKey a valid hmac key for signature verification
 * @returns {Object} an object compatible with ssb/classic `msg.value` or an `Error`
 */
function decodeAndValidateSingle(bbmsg, previousMsg, hmacKey) {
  if (bbmsg.length > 8192)
    return new Error(
      `invalid message size: ${bbmsg.length} bytes, must not be greater than 8192 bytes`
    )

  const msgBFE = bencode.decode(bbmsg)

  if (!Array.isArray(msgBFE) || msgBFE.length !== 2)
    return new Error(
      `invalid message: ${typeof msgBFE} with length ${
        msgBFE.length
      }, expected a list of payload and signature`
    )

  const typeFormatErr = validateTypeFormatData(msgBFE)
  if (typeFormatErr) return typeFormatErr

  const [payload, signature] = bfe.decode(msgBFE)

  if (!Array.isArray(payload) || payload.length !== 5)
    return new Error(
      `invalid message payload: ${typeof payload} with length ${
        payload.length
      }, expected a list of author, sequence, previous, timestamp and contentSection`
    )

  const [author, sequence, previous, timestamp, contentSection] = payload

  const previousErr = validatePrevious(author, sequence, previous, previousMsg)
  if (previousErr) return previousErr

  const payloadBen = bencode.encode(msgBFE[0])
  const signatureErr = validateSignature(author, payloadBen, signature, hmacKey)
  if (signatureErr) return signatureErr

  const msgVal = {
    author,
    sequence,
    previous,
    timestamp,
    signature,
  }
  if (isBoxedString(contentSection)) {
    msgVal.content = contentSection
  } else {
    if (!(Array.isArray(contentSection) && contentSection.length === 2))
      return new Error(
        `invalid message: contentSection ${typeof contentSection} with length ${
          contentSection.length
        } is incorrect, expected a list of content and contentSignature`
      )

    const [content, contentSignature] = contentSection
    msgVal.content = content
    msgVal.contentSignature = contentSignature
  }

  return msgVal
}

/**
 * Verify that the top-level signature correctly signs the message payload.
 *
 * @param {string} author - Author ID for the message
 * @param {Buffer} payloadBen - Bencoded message payload containing a BFE-encoded list of `author, sequence, previous, timestamp, contentSection`
 * @param {string} signature - Base64-encoded signature for the given payload
 * @param {Buffer | string | null} hmacKey - HMAC key that was used to sign the payload
 * @returns {Object | undefined} Either an Error containing a message or an `undefined` value for successful verification
 */
function validateSignature(author, payloadBen, signature, hmacKey) {
  const hmacKeyErr = validateHmacKey(hmacKey)
  if (hmacKeyErr) return hmacKeyErr

  const isSignatureRx = isCanonicalBase64('', '\\.sig.\\w+')

  if (!isSignatureRx.test(signature))
    return new Error(
      `invalid message: signature "${signature}", expected a base64 string`
    )

  const { data } = SSBURI.decompose(author)
  if (
    !ssbKeys.verify(
      { public: data, curve: 'ed25519' },
      signature,
      hmacKey,
      payloadBen
    )
  )
    return new Error(
      'invalid message: signature must correctly sign the payload',
      author
    )
}

/**
 * Validate a message in relation to the previous message on the feed.
 *
 * @param {string} author - Author ID for the message
 * @param {number} sequence - Sequence number of the message being validated
 * @param {string | null} previous - Message ID of the previous message on the feed (`null` if `sequence` is `1`)
 * @param {Object | null} previousMsg - Previous message value as an object (`null` if `sequence` is `1`)
 * @returns {Object | undefined} Either an Error containing a message or an `undefined` value for successful validation
 */
function validatePrevious(author, sequence, previous, previousMsg) {
  if (sequence === 1) {
    if (previous !== null)
      return new Error(
        `invalid message: previous is "${previous}", expected a value of null because sequence is 1`
      )
  } else {
    if (!SSBURI.isBendyButtV1MessageSSBURI(previous))
      return new Error(
        `invalid message: previous is "${previous}", expected a valid message identifier`
      )
    if (!previousMsg)
      return new Error(
        'invalid previousMsg: value must not be undefined if sequence > 1'
      )
    if (author !== previousMsg.author)
      return new Error(
        `invalid message: author is "${author}" but previous message author is "${previousMsg.author}", expected values to be identical`
      )
    if (sequence !== previousMsg.sequence + 1)
      return new Error(
        `invalid message: sequence is ${sequence} but prevMsg sequence is ${previousMsg.sequence}, expected sequence to be prevMsg.sequence + 1`
      )

    const previousHash = hash(previousMsg)
    if (previous !== previousHash)
      return new Error(
        `invalid message: previous is "${previous}" but the computed hash of the previous message is "${previousHash}", expected values to be identical`
      )
  }
}

/**
 * Validate the BFE type-format-data encodings for the `author` and `previous` ID values.
 *
 * @param {Object} msgBFE - A BFE-encoded message value
 * @returns {Object | undefined} Either an Error containing a message or an `undefined` value for successful validation
 */
function validateTypeFormatData(msgBFE) {
  const payload = msgBFE[0]
  const [author, sequence, previous] = payload

  const authorTypeFormat = author.slice(0, 2).toString('hex')
  const previousTypeFormat = previous.slice(0, 2).toString('hex')

  if (authorTypeFormat !== '0003')
    return new Error(
      `invalid message: author type-format "0x${authorTypeFormat}" is incorrect, expected 0x0003`
    )

  if (sequence === 1) {
    if (previousTypeFormat !== '0602')
      return new Error(
        `invalid message: previous type-format "0x${previousTypeFormat}" is incorrect, expected 0x0602 (nil type-format) because sequence is 1`
      )
  } else {
    if (previousTypeFormat !== '0104')
      return new Error(
        `invalid message: previous type-format "0x${previousTypeFormat}" is incorrect, expected 0x0104`
      )
  }

  if (author.length !== 34)
    return new Error(
      `invalid message: author type-format-data length of ${author.length} bytes is incorrect, expected 34 bytes`
    )
}

/**
 * Validate an HMAC key.
 *
 * @param {Buffer | string | null | undefined} hmacKey
 * @returns {Object | undefined} Either an Error containing a message or an `undefined` value for successful validation
 */
function validateHmacKey(hmacKey) {
  if (hmacKey === undefined || hmacKey === null) return undefined

  const bytes = Buffer.isBuffer(hmacKey)
    ? hmacKey
    : Buffer.from(hmacKey, 'base64')

  if (typeof hmacKey === 'string') {
    if (bytes.toString('base64') !== hmacKey)
      return new Error(
        `invalid hmac key: "${hmacKey}", expected string to be base64 encoded`
      )
  }

  if (bytes.length !== 32)
    return new Error(
      `invalid hmac key: "${hmacKey}" with length ${hmacKey.length}, expected 32 bytes`
    )
}

module.exports = {
  decodeBox2,
  decode,
  encode,
  encodeNew,
  hash,
  decodeAndValidateSingle,
  validateSingle,
}

},
"1KZeGX3adyx7FFG+EWqY06bl4IWMm9hDXtEdAcP0Jm8=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var range = require('./range')
var Skip = require('./skip')
var createCursor = require('./cursor')
var Take = require('pull-stream/throughs/take')

function Test(opts) {
  var end = opts.end
  if(end == null) return
  if(!opts.endInclusive) {
    return function (seq) {
      return opts.reverse ? seq > end : seq < end
    }
  }
  else {
    var once = false
    return function (seq) {
      if(once)
        return false
      else if(!(opts.reverse ? seq > end : seq < end))
        return once = true
      else
        return true
    }
  }
}

function Format (seqs, values) {
  return function (seq, value) {
    return (
      seqs
      ? (values ? {value: value, seq: seq} : seq)
      : value
    )
  }
}

module.exports = function (since, getMeta) {
  var Cursor = createCursor(since, getMeta)
  return function (opts) {
    opts = range(opts || {})

    var stream = Cursor(
      opts.old === false ? null : opts.start,
      opts.live || (opts.old === false),
      opts.reverse,
      Format(opts.seqs !== false, opts.values !== false),
      Test(opts),
      opts.cache
    )

    if(!opts.startInclusive || opts.old === false)
      stream = Skip(1)(stream)
    if(opts.limit)
      stream = Take(opts.limit)(stream)
    return stream
  }
}


},
"1Po//hmkciAoo9NJgrderk1tLEXXN+eWf/upzhNRXEw=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var bind = require('function-bind');

module.exports = bind.call(Function.call, Object.prototype.hasOwnProperty);

},
"1YryHLBRiGTQxQV0LRr3HlteHxQvTA8nNTqg9DGmFtQ=":
function (require, module, exports, __dirname, __filename) {
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},
"1gi2b2zi1u8J8RnO+JeLS7H3zsegip+j9MtKgSBwWaw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Ref = require('ssb-ref');
const ssbKeys = require('ssb-keys');
const Notify = require('pull-notify');
const run = require("promisify-tuple");
const minireq = typeof window !== 'undefined'
    ? require('@minireq/browser').makeRequest()
    : require('@minireq/node').makeRequest();
function sleep(period) {
    return new Promise((resolve) => {
        setTimeout(resolve, period, null);
    });
}
const ALIAS_URI_ACTION = 'consume-alias';
function aliasRegistrationStr(roomId, userId, alias) {
    return `=room-alias-registration:${roomId}:${userId}:${alias}`;
}
module.exports = {
    name: 'roomClient',
    version: '1.0.0',
    manifest: {
        discoveredAttendants: 'source',
        consumeAliasUri: 'async',
        registerAlias: 'async',
        revokeAlias: 'async',
    },
    permissions: {
        anonymous: {},
    },
    init(ssb, config) {
        if (!ssb.tunnel.getRoomsMap)
            throw new Error('missing tunnel plugin');
        function jsonResponseFailed(data) {
            return (typeof data.status === 'string' &&
                data.status !== 'successful' &&
                data.error);
        }
        async function consumeAlias(opts, cb) {
            var _a, _b;
            if (!Ref.isAddress(opts.multiserverAddress)) {
                cb(new Error(`bad multiserverAddress: ${opts.multiserverAddress}`));
                return;
            }
            if (!Ref.isFeed(opts.roomId)) {
                cb(new Error(`bad roomId: ${opts.roomId}`));
                return;
            }
            if (!Ref.isFeed(opts.userId)) {
                cb(new Error(`bad userId: ${opts.userId}`));
                return;
            }
            if (!opts.alias || typeof opts.alias !== 'string') {
                cb(new Error(`bad alias: ${opts.alias}`));
                return;
            }
            if (!opts.signature || typeof opts.signature !== 'string') {
                cb(new Error(`bad signature: ${opts.signature}`));
                return;
            }
            const { multiserverAddress, roomId, userId, alias, signature } = opts;
            const roomAddress = multiserverAddress;
            const sig = signature.replace(/_/g, '/').replace(/-/g, '+');
            const body = aliasRegistrationStr(roomId, userId, alias);
            const ok = ssbKeys.verify(userId, sig, body);
            if (!ok) {
                cb(new Error(`cannot consumeAlias because the signature is wrong`));
                return;
            }
            const rooms = ssb.tunnel.getRoomsMap();
            const [err] = await run(ssb.conn.connect)(roomAddress);
            if (err) {
                cb(new Error((_a = `cannot consumeAlias ${alias} because ` +
                    `cannot connect to room ${roomId} due to: ` +
                    err.message) !== null && _a !== void 0 ? _a : err));
                return;
            }
            let period = 32;
            while (!rooms.has(roomId)) {
                if (period < 8000) {
                    await sleep((period = period * 2));
                }
                else {
                    cb(new Error(`cannot consumeAlias ${alias} because room ${roomId} ` +
                        `is missing from our internal cache`));
                    return;
                }
            }
            const roomData = ssb.conn.db().get(roomAddress);
            const haveMembershipHere = roomData === null || roomData === void 0 ? void 0 : roomData.membership;
            const isForeignRoom = !roomData;
            let connectedToOtherAttendants = false;
            for (const [, data] of ssb.conn.hub().entries()) {
                if (data.room === roomId) {
                    connectedToOtherAttendants = true;
                    break;
                }
            }
            const shs = userId.slice(1, -8);
            const tunnelAddr = `tunnel:${roomId}:${userId}~shs:${shs}`;
            const [err2, aliasRpc] = await run(ssb.conn.connect)(tunnelAddr);
            if (err2) {
                cb(new Error((_b = `alias appears to be offline (${alias}): ` + err2.message) !== null && _b !== void 0 ? _b : err2));
                if (isForeignRoom && !connectedToOtherAttendants) {
                    ssb.conn.disconnect(roomAddress);
                }
                return;
            }
            if (!haveMembershipHere) {
                ssb.conn.remember(tunnelAddr, {
                    type: 'room-attendant',
                    key: userId,
                    room: roomId,
                    roomAddress,
                    alias,
                    autoconnect: true,
                });
            }
            cb(null, aliasRpc);
        }
        async function consumeAliasUri(input, cb) {
            if (!input) {
                cb(new Error('missing URI input'));
                return;
            }
            if (typeof input !== 'string') {
                cb(new Error('URI input should be a string'));
                return;
            }
            let url;
            try {
                const coolURL = /^(\w+\.\w+\.\w+|\w+\.\w+\/\w+)$/;
                if (input.match(coolURL)) {
                    url = new URL(`https://${input}`);
                }
                else {
                    url = new URL(input);
                }
            }
            catch (err) {
                cb(err);
                return;
            }
            if (url.protocol.startsWith('http')) {
                url.searchParams.set('encoding', 'json');
                const jsonUrl = url.toString();
                try {
                    const { status, data } = await minireq({
                        url: jsonUrl,
                        method: 'GET',
                        accept: 'application/json',
                        timeout: 10e3,
                    }).promise;
                    if (!(status >= 200 && status < 300)) {
                        cb(new Error(`failed (${status}) to get alias from ${jsonUrl}`));
                        return;
                    }
                    if (jsonResponseFailed(data)) {
                        cb(new Error(data.error));
                        return;
                    }
                    consumeAlias(data, cb);
                }
                catch (err) {
                    cb(err);
                    return;
                }
            }
            else if (url.protocol === 'ssb:') {
                if (url.pathname !== 'experimental' && url.host !== 'experimental') {
                    cb(new Error('SSB URI input isnt experimental'));
                    return;
                }
                const action = url.searchParams.get('action');
                if (action !== ALIAS_URI_ACTION) {
                    cb(new Error(`SSB URI input isnt ${ALIAS_URI_ACTION}: ${input}`));
                    return;
                }
                const data = {
                    multiserverAddress: url.searchParams.get('multiserverAddress'),
                    roomId: url.searchParams.get('roomId'),
                    userId: url.searchParams.get('userId'),
                    alias: url.searchParams.get('alias'),
                    signature: url.searchParams.get('signature'),
                };
                consumeAlias(data, cb);
            }
            else {
                cb(new Error(`unsupported URI input: ${input}`));
                return;
            }
        }
        async function registerAlias(roomKey, alias, cb) {
            var _a;
            if (!Ref.isFeed(roomKey)) {
                cb(new Error(`cannot registerAlias at invalid room ${roomKey}`));
                return;
            }
            const rooms = ssb.tunnel.getRoomsMap();
            let roomRPC = null;
            if (rooms.has(roomKey)) {
                roomRPC = rooms.get(roomKey).rpc;
            }
            if (!roomRPC) {
                const msaddr = ssb.conn.db().getAddressForId(roomKey);
                if (msaddr) {
                    const [err, rpc] = await run(ssb.conn.connect)(msaddr);
                    if (err) {
                        cb(new Error((_a = `cannot registerAlias because ` +
                            `cant reach the room ${roomKey} due to: ` +
                            err.message) !== null && _a !== void 0 ? _a : err));
                        return;
                    }
                    roomRPC = rpc;
                }
            }
            if (!roomRPC) {
                cb(new Error(`cannot registerAlias at offline or unknown room ${roomKey}`));
                return;
            }
            const body = aliasRegistrationStr(roomKey, ssb.id, alias);
            const sig = ssbKeys.sign(config.keys, body);
            roomRPC.room.registerAlias(alias, sig, cb);
        }
        async function revokeAlias(roomKey, alias, cb) {
            var _a;
            if (!Ref.isFeed(roomKey)) {
                cb(new Error(`cannot revokeAlias at invalid room ${roomKey}`));
                return;
            }
            const rooms = ssb.tunnel.getRoomsMap();
            let roomRPC = null;
            if (rooms.has(roomKey)) {
                roomRPC = rooms.get(roomKey).rpc;
            }
            if (!roomRPC) {
                const msaddr = ssb.conn.db().getAddressForId(roomKey);
                if (msaddr) {
                    const [err, rpc] = await run(ssb.conn.connect)(msaddr);
                    if (err) {
                        cb(new Error((_a = `cannot revokeAlias because ` +
                            `cant reach the room ${roomKey} due to: ` +
                            err.message) !== null && _a !== void 0 ? _a : err));
                        return;
                    }
                    roomRPC = rpc;
                }
            }
            if (!roomRPC) {
                cb(new Error(`cannot revokeAlias at offline or unknown room ${roomKey}`));
                return;
            }
            roomRPC.room.revokeAlias(alias, cb);
        }
        const _notifyDiscoveredAttendant = Notify();
        function discoveredAttendants() {
            return _notifyDiscoveredAttendant.listen();
        }
        ssb.close.hook(function (fn, args) {
            _notifyDiscoveredAttendant === null || _notifyDiscoveredAttendant === void 0 ? void 0 : _notifyDiscoveredAttendant.end();
            fn.apply(this, args);
        });
        return {
            discoveredAttendants,
            consumeAliasUri,
            registerAlias,
            revokeAlias,
            _notifyDiscoveredAttendant,
        };
    },
};

},
"1s7gNWL9bv3u1Jt8UO9OkwtwLbkbS3pXzZDOUI2E6Xw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.solve = void 0;
const ssbKeys = require('ssb-keys');
function solve(keys, sid, cid, sc, cc) {
    const body = `=http-auth-sign-in:${sid}:${cid}:${sc}:${cc}`;
    const sol = ssbKeys.sign(keys, body);
    return sol;
}
exports.solve = solve;

},
"1vWcuCm2V7HDbRtKIl7+f67gDyhuQpcXu2md8vRAW0I=":
function (require, module, exports, __dirname, __filename) {

module.exports = function (each, done) {
  return {
    paused: false,
    write: function (data) {
      if(each(data) === false) {
        this.abort()
      }
    },
    end: done,
    abort: function (err) {
      this.ended = err || true
      this.source.abort(err)
    }
  }
}

},
"1wSZ5U01FYlmrtFORry+hgFMXPPFEOmZpuJTspxVStg=":
function (require, module, exports, __dirname, __filename) {

exports.through = require('./through')
exports.source = require('./source')

},
"2+GLHn3KBKlfSWUQjnzwKa1WgDYtjV6aVR48BzwmwVs=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2019 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const Mnemonic = require('ssb-keys-mnemonic');
module.exports = {
    name: 'keysUtils',
    version: '1.0.0',
    manifest: {
        getMnemonic: 'sync',
    },
    permissions: {
        master: {
            allow: ['getMnemonic'],
        },
    },
    init: function init(ssb, _config) {
        return {
            getMnemonic() {
                return Mnemonic.keysToWords(ssb.keys);
            },
        };
    },
};
//# sourceMappingURL=keysUtils.js.map
},
"22sklfka1IsRm6XzsoQA3EILAS58dJfXfWfNV3KfF1I=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.NONCE_LENGTH_BASE64 = exports.NONCE_LENGTH_BYTE = exports.NONCE_LENGTH = void 0;
exports.NONCE_LENGTH = 256;
exports.NONCE_LENGTH_BYTE = exports.NONCE_LENGTH / 8;
exports.NONCE_LENGTH_BASE64 = Math.ceil(exports.NONCE_LENGTH / 6);

},
"23ExSkdQgwdR5Q2Nt84Ti7Y1BXJ1CPUdGKLqFtft8Pc=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const PacketStream = require('packet-stream')
const pullWeird = require('./pull-weird')
const goodbye = require('pull-goodbye')
const u = require('./util')
const explain = require('explain-error')

module.exports = function initStream (localCall, codec, onClose) {
  let ps = PacketStream({
    message () {
      // if (isString(msg)) return
      // if (msg.length > 0 && isString(msg[0]))
      //   localCall('msg', 'emit', msg)
    },
    request (opts, cb) {
      if (!Array.isArray(opts.args)) {
        return cb(new Error(`invalid request, args should be array, was: ${JSON.stringify(opts)}`))
      }
      const name = opts.name
      const args = opts.args
      let inCB = false
      let called = false

      args.push((err, value) => {
        called = true
        inCB = true
        cb(err, value)
      })
      try {
        localCall('async', name, args)
      } catch (err) {
        if (inCB || called) {
          throw explain(err, 'no callback provided to muxrpc async funtion')
        }
        cb(err)
      }
    },
    stream (stream) {
      stream.read = function read (data, end) {
        // how would this actually happen?
        if (end) return stream.write(null, end)

        const { name, type, args } = data
        let err, value

        stream.read = null

        if (!u.isStream(type)) {
          return stream.write(null, new Error(`unsupported stream type: ${type}`))
        }

        try {
          value = localCall(type, name, args)
        } catch (_err) {
          err = _err
        }

        const antiType =
          type === 'source'
            ? 'sink'
            : type === 'sink'
              ? 'source'
              : 'duplex'
        const _stream = pullWeird[antiType](stream)

        return u.pipeToStream(
          type,
          _stream,
          err ? u.errorAsStream(type, err) : value
        )

        //        if(isSource(type))
        //          _stream(err ? pull.error(err) : value)
        //        else if (isSink(type))
        //          (err ? abortSink(err) : value)(_stream)
        //        else if (isDuplex(type))
        //          pull(_stream, err ? abortDuplex(err) : value, _stream)
      }
    },

    close (err) {
      ps = null // deallocate
      ws.ended = true
      if (ws.closed) return
      ws.closed = true
      if (onClose) {
        const close = onClose
        onClose = null
        close(err)
      }
    }
  })

  let ws = goodbye(pullWeird(ps, () => {
    // this error will be handled in PacketStream.close
  }))

  ws = codec ? codec(ws) : ws

  ws.remoteCall = function (type, name, args, cb) {
    if (name === 'emit') return ps.message(args)

    if (!(u.isRequest(type) || u.isStream(type))) {
      throw new Error(`unsupported type: ${JSON.stringify(type)}`)
    }

    if (u.isRequest(type)) {
      return ps.request({ name, args }, cb)
    }

    const ws = ps.stream()
    const s = pullWeird[type](ws, cb)
    ws.write({ name, args, type })
    return s
  }

  // hack to work around ordering in setting ps.ended.
  // Question: if an object has subobjects, which
  // all have close events, should the subobjects fire close
  // before the parent? or should parents close after?
  // should there be a preclose event on the parent
  // that fires when it's about to close all the children?
  ws.isOpen = function () {
    return !ps.ended
  }

  ws.close = function (err, cb) {
    if (typeof err === 'function') {
      cb = err
      err = false
    }
    if (!ps) {
      if (cb) cb()
      return
    }
    if (err) {
      ps.destroy(err)
      if (cb) cb()
      return
    }

    ps.close((err) => {
      if (cb) cb(err)
      else if (err) throw explain(err, 'no callback provided for muxrpc close')
    })

    return this
  }
  ws.closed = false

  return ws
}

},
"26dye6s1OH2zki3bHmc/SGdSTEpBF1WswVtN4KJ2AB4=":
function (require, module, exports, __dirname, __filename) {
const PacketStreamSubstream = require('./substream')
const {flat, closedread} = require('./utils')

function PacketStream (opts) {
  this.ended = false
  this.opts  = opts // must release, may capture `this`

  this._req_counter = 1
  this._requests    = new Map() // must release, may capture `this`
  this._instreams   = new Map() // must release, may capture `this`
  this._outstreams  = new Map() // must release, may capture `this`
  this._closecbs    = []        // must release, may capture `this`
  this._closing     = false
  this._closed      = false
  if (opts.close)
    this._closecbs.push(opts.close)
}

// Sends a single message to the other end
PacketStream.prototype.message = function (obj) {
  this.read({req: 0, stream: false, end: false, value: obj})
}

// Sends a message to the other end, expects an (err, obj) response
PacketStream.prototype.request = function (obj, cb) {
  if (this._closing) return cb(new Error('parent stream is closing'))
  const rid = this._req_counter++
  this._requests.set(rid, (err, value) => {
    this._requests.delete(rid)
    cb(err, value)
    this._maybedone(err)
  })
  this.read({ req: rid, stream: false, end: false, value: obj })
}

// Sends a request to the other end for a stream
PacketStream.prototype.stream = function () {
  if (this._closing) throw new Error('parent stream is closing')
  const rid = this._req_counter++
  const outs = new PacketStreamSubstream(rid, this, () => {
    this._outstreams.delete(rid)
  })
  this._outstreams.set(rid, outs)
  return outs
}

// Marks the packetstream to close when all current IO is finished
PacketStream.prototype.close = function (cb) {
  if (!cb) throw new Error('packet-stream.close *must* have callback')
  if (this._closed) return cb()
  this._closecbs.push(cb)
  this._closing = true
  this._maybedone()
}

// Forces immediate close of the PacketStream
// - usually triggered by an `end` packet from the other end
PacketStream.prototype.destroy = function (end) {
  end = end || flat(end)
  this.ended = end
  this._closing = true

  let err = (end === true)
    ? new Error('unexpected end of parent stream')
    : end

  // force-close all requests and substreams
  let numended = 0
  this._requests.forEach((fn) => {
    numended++;
    fn(err)
  })
  this._instreams.forEach((ins) => {
    numended++;
    // destroy substream without sending it a message
    ins.writeEnd = true
    ins.destroy(err)
  })
  this._outstreams.forEach((outs) => {
    numended++
    // destroy substream without sending it a message
    outs.writeEnd = true
    outs.destroy(err)
  })

  //from the perspective of the outside stream it's not an error
  //if the stream was in a state that where end was okay. (no open requests/streams)
  if (numended === 0 && end === true) err = null
  this._maybedone(err)
}

PacketStream.prototype._maybedone = function (err) {
  if (this._closed || !this._closing)
    return

  // check if all requests and streams finished
  if (this._requests.size !== 0 ||
      this._instreams.size !== 0 ||
      this._outstreams.size !== 0)
    return // not yet

  // close
  this.read(null, err || true)
  this._closed = true
  this._closecbs.forEach((cb) => { cb(err) })

  // deallocate
  this.opts = null
  this._closecbs.length = 0
  this.read = closedread
  this._requests.clear()
  this._instreams.clear()
  this._outstreams.clear()
}

// Sends data out to the other end
// - to be overridden by the PacketStream consumer
PacketStream.prototype.read = function (msg) {
  console.error('please overwrite read method to do IO', msg)
}

// Accepts data from the other end
PacketStream.prototype.write = function (msg, end) {
  if (this.ended) return

  if (end)                         this.destroy(end)
  else if (msg.req && !msg.stream) this._onrequest(msg)
  else if (msg.req && msg.stream)  this._onstream(msg)
  else                             this._onmessage(msg)
}

// Internal handler of incoming message msgs
PacketStream.prototype._onmessage = function (msg) {
  if (this.opts && typeof this.opts.message === 'function')
    this.opts.message(msg.value)
}

// Internal handler of incoming request msgs
PacketStream.prototype._onrequest = function (msg) {
  const rid = msg.req*-1
  if (msg.req < 0) {
    // A incoming response
    if (this._requests.has(rid))
      this._requests.get(rid)(
        msg.end ? msg.value : null,
        msg.end ? null : msg.value
      )
  }
  else {
    // An incoming request
    if (this.opts && typeof this.opts.request === 'function') {
      let once = false
      this.opts.request(msg.value, (err, value) => {
        if (once) throw new Error('cb called twice from local api')
        once = true
        if (err) this.read({ value: flat(err), end: true, req: rid })
        else     this.read({ value: value, end: false, req: rid })
        this._maybedone()
      })
    } else {
      if (this.ended) {
        // FIXME: this block seems unreachable because of line 131
        const err = (this.ended === true)
          ? new Error('unexpected end of parent stream')
          : this.ended
        this.read({ value: flat(err), end: true, stream: false, req: rid })
      } else {
        this.read({
          value: {
            message: 'Unable to handle requests',
            name: 'NO_REQUEST_HANDLER', stack: null
          },
          end: true, stream: false, req: rid
        })
      }
      this._maybedone()
    }
  }
}

// Internal handler of incoming stream msgs
PacketStream.prototype._onstream = function (msg) {
  if (msg.req < 0) {
    // Incoming stream data
    const rid = msg.req * -1
    const outs = this._outstreams.get(rid)
    if (!outs)
      return console.error('no stream for incoming msg', msg)

    if (msg.end) {
      if (outs.writeEnd)
        this._outstreams.delete(rid)
      outs.readEnd = true
      outs.read(null, msg.value)
      this._maybedone()
    }
    else
      outs.read(msg.value)
  }
  else {
    // Incoming stream request
    const rid = msg.req
    let ins = this._instreams.get(rid)

    if (!ins) {
      // New stream
      ins = new PacketStreamSubstream(rid * -1, this, () => {
        this._instreams.delete(rid)
      })
      this._instreams.set(rid, ins)
      if (this.opts && typeof this.opts.stream === 'function')
        this.opts.stream(ins)
    }

    if (msg.end) {
      if (ins.writeEnd)
        this._instreams.delete(rid)
      ins.readEnd = true
      if (ins.read)
        ins.read(null, msg.value)
      this._maybedone()
    }
    else if (ins.read)
      ins.read(msg.value)
    else
      console.error('no .read for stream:', ins.id, 'dropped:', msg)
  }
}

module.exports = (opts) => new PacketStream(opts)

},
"29Jh0EJBivwEt5btjv67KcmQxSvDgWBHRR98xIc+p/Q=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2020 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const Read = require('pull-file');
module.exports = {
    name: 'blobsUtils',
    version: '1.0.0',
    manifest: {
        addFromPath: 'async',
    },
    permissions: {
        master: {
            allow: ['addFromPath'],
        },
    },
    init: function init(ssb) {
        var _a;
        if (!((_a = ssb.blobs) === null || _a === void 0 ? void 0 : _a.add)) {
            throw new Error('"blobsUtils" is missing required plugin "ssb-blobs"');
        }
        return {
            addFromPath(path, cb) {
                pull(Read(path, {}), ssb.blobs.add(cb));
            },
        };
    },
};
//# sourceMappingURL=blobsUtils.js.map
},
"2AeMBMOSc/5k20IYF42HLOAJXiNOJGJoyb8U79p3Wc4=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var values = require('./values')
module.exports = function (object) {
  return values(Object.keys(object))
}



},
"2CeEp9hcJXbTazlXf+iMgZjGlVj8fIgTlqAAn6ZauOg=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
Object.defineProperty(exports, "__esModule", { value: true });
const fs = require("fs");
const path = require("path");
const Mnemonic = require('ssb-keys-mnemonic');
const mkdirp = require('mkdirp');
function fileSize(filename) {
    try {
        const stats = fs.statSync(filename);
        return stats.size;
    }
    catch (err) {
        if (err.code === 'ENOENT')
            return 0;
        else
            throw err;
    }
}
module.exports = function restore(words) {
    // Check if there is another mature account
    if (!fs.existsSync(process.env.SSB_DIR))
        mkdirp.sync(process.env.SSB_DIR);
    const oldLogPath = path.join(process.env.SSB_DIR, 'flume', 'log.offset');
    const oldLogSize = fileSize(oldLogPath);
    if (oldLogSize >= 10)
        return 'OVERWRITE_RISK';
    const newLogPath = path.join(process.env.SSB_DIR, 'db2', 'log.bipf');
    const newLogSize = fileSize(newLogPath);
    if (newLogSize >= 10)
        return 'OVERWRITE_RISK';
    // Basic validation of input words
    const wordsArr = words.split(' ').map((s) => s.trim().toLowerCase());
    if (wordsArr.length < 24)
        return 'TOO_SHORT';
    if (wordsArr.length > 48)
        return 'TOO_LONG';
    // Convert words to keys
    let keys;
    try {
        keys = Mnemonic.wordsToKeys(wordsArr.join(' '));
    }
    catch (err) {
        if (err.message) {
            if (err.message.startsWith('invalid words')) {
                return 'INCORRECT';
            }
            if (err.message.startsWith('there should be 24 words')) {
                return 'WRONG_LENGTH';
            }
        }
        throw err;
    }
    // Overwrite `secret` with the newly restored keys
    const json = JSON.stringify(keys, null, 2);
    const secretPath = path.join(process.env.SSB_DIR, 'secret');
    try {
        if (fileSize(secretPath) >= 10) {
            fs.unlinkSync(secretPath);
        }
        const writeOpts = { mode: 0x100, flag: 'w' };
        fs.writeFileSync(secretPath, json, writeOpts);
    }
    catch (err) {
        throw err;
    }
    return 'IDENTITY_READY';
};
//# sourceMappingURL=restore.js.map
},
"2FuyuMa6PPceaudZNC34ne6VmBxoVun03AuF1wz2C1k=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a transform stream is a readable/writable stream where you do
// something with the data.  Sometimes it's called a "filter",
// but that's not a great name for it, since that implies a thing where
// some bits pass through, and others are simply ignored.  (That would
// be a valid example of a transform, of course.)
//
// While the output is causally related to the input, it's not a
// necessarily symmetric or synchronous transformation.  For example,
// a zlib stream might take multiple plain-text writes(), and then
// emit a single compressed chunk some time in the future.
//
// Here's how this works:
//
// The Transform stream has all the aspects of the readable and writable
// stream classes.  When you write(chunk), that calls _write(chunk,cb)
// internally, and returns false if there's a lot of pending writes
// buffered up.  When you call read(), that calls _read(n) until
// there's enough pending readable data buffered up.
//
// In a transform stream, the written data is placed in a buffer.  When
// _read(n) is called, it transforms the queued up data, calling the
// buffered _write cb's as it consumes chunks.  If consuming a single
// written chunk would result in multiple output chunks, then the first
// outputted bit calls the readcb, and subsequent chunks just go into
// the read buffer, and will cause it to emit 'readable' if necessary.
//
// This way, back-pressure is actually determined by the reading side,
// since _read has to be called to start processing a new chunk.  However,
// a pathological inflate type of transform can cause excessive buffering
// here.  For example, imagine a stream where every byte of input is
// interpreted as an integer from 0-255, and then results in that many
// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in
// 1kb of data being output.  In this case, you could write a very small
// amount of input, and end up with a very large amount of output.  In
// such a pathological inflating mechanism, there'd be no way to tell
// the system to stop doing the transform.  A single 4MB write could
// cause the system to run out of memory.
//
// However, even in such a pathological case, only a single written chunk
// would be consumed, and then the rest would wait (un-transformed) until
// the results of the previous transformed chunk were consumed.
'use strict';

module.exports = Transform;

var _require$codes = require('../errors').codes,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,
    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;

var Duplex = require('./_stream_duplex');

require('inherits')(Transform, Duplex);

function afterTransform(er, data) {
  var ts = this._transformState;
  ts.transforming = false;
  var cb = ts.writecb;

  if (cb === null) {
    return this.emit('error', new ERR_MULTIPLE_CALLBACK());
  }

  ts.writechunk = null;
  ts.writecb = null;
  if (data != null) // single equals check for both `null` and `undefined`
    this.push(data);
  cb(er);
  var rs = this._readableState;
  rs.reading = false;

  if (rs.needReadable || rs.length < rs.highWaterMark) {
    this._read(rs.highWaterMark);
  }
}

function Transform(options) {
  if (!(this instanceof Transform)) return new Transform(options);
  Duplex.call(this, options);
  this._transformState = {
    afterTransform: afterTransform.bind(this),
    needTransform: false,
    transforming: false,
    writecb: null,
    writechunk: null,
    writeencoding: null
  }; // start out asking for a readable event once data is transformed.

  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things
  // that Readable wants before the first _read call, so unset the
  // sync guard flag.

  this._readableState.sync = false;

  if (options) {
    if (typeof options.transform === 'function') this._transform = options.transform;
    if (typeof options.flush === 'function') this._flush = options.flush;
  } // When the writable side finishes, then flush out anything remaining.


  this.on('prefinish', prefinish);
}

function prefinish() {
  var _this = this;

  if (typeof this._flush === 'function' && !this._readableState.destroyed) {
    this._flush(function (er, data) {
      done(_this, er, data);
    });
  } else {
    done(this, null, null);
  }
}

Transform.prototype.push = function (chunk, encoding) {
  this._transformState.needTransform = false;
  return Duplex.prototype.push.call(this, chunk, encoding);
}; // This is the part where you do stuff!
// override this function in implementation classes.
// 'chunk' is an input chunk.
//
// Call `push(newChunk)` to pass along transformed output
// to the readable side.  You may call 'push' zero or more times.
//
// Call `cb(err)` when you are done with this chunk.  If you pass
// an error, then that'll put the hurt on the whole operation.  If you
// never call cb(), then you'll never get another chunk.


Transform.prototype._transform = function (chunk, encoding, cb) {
  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));
};

Transform.prototype._write = function (chunk, encoding, cb) {
  var ts = this._transformState;
  ts.writecb = cb;
  ts.writechunk = chunk;
  ts.writeencoding = encoding;

  if (!ts.transforming) {
    var rs = this._readableState;
    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);
  }
}; // Doesn't matter what the args are here.
// _transform does all the work.
// That we got here means that the readable side wants more data.


Transform.prototype._read = function (n) {
  var ts = this._transformState;

  if (ts.writechunk !== null && !ts.transforming) {
    ts.transforming = true;

    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);
  } else {
    // mark that we need a transform, so that any data that comes in
    // will get processed, now that we've asked for it.
    ts.needTransform = true;
  }
};

Transform.prototype._destroy = function (err, cb) {
  Duplex.prototype._destroy.call(this, err, function (err2) {
    cb(err2);
  });
};

function done(stream, er, data) {
  if (er) return stream.emit('error', er);
  if (data != null) // single equals check for both `null` and `undefined`
    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases
  // if there's nothing in the write buffer, then that means
  // that nothing more will ever be provided

  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();
  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();
  return stream.push(null);
}
},
"2NZ17+yHfioBRKI1kM7M6cvf8v57kj63H+F/mYOth9M=":
function (require, module, exports, __dirname, __filename) {
'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});

var _buffer = require('buffer');

var createBuffer = _buffer.Buffer.from && _buffer.Buffer.alloc && _buffer.Buffer.allocUnsafe && _buffer.Buffer.allocUnsafeSlow ? _buffer.Buffer.from : // support for Node < 5.10
function (val) {
  return new _buffer.Buffer(val);
};

exports.default = createBuffer;

},
"2Y2ZC8CxBt7Bw3QLvjvOTALAHIlSzSRJfk9JOyNrpTs=":
function (require, module, exports, __dirname, __filename) {
'use strict'
//a stream that ends immediately.
module.exports = function empty () {
  return function (abort, cb) {
    cb(true)
  }
}

},
"2iCI3PqEe+KyagxP1GSA4qeHsxILys65hVVlS7ulNjE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const { EMPTY_BUFFER } = require('./constants');

/**
 * Merges an array of buffers into a new buffer.
 *
 * @param {Buffer[]} list The array of buffers to concat
 * @param {Number} totalLength The total length of buffers in the list
 * @return {Buffer} The resulting buffer
 * @public
 */
function concat(list, totalLength) {
  if (list.length === 0) return EMPTY_BUFFER;
  if (list.length === 1) return list[0];

  const target = Buffer.allocUnsafe(totalLength);
  let offset = 0;

  for (let i = 0; i < list.length; i++) {
    const buf = list[i];
    target.set(buf, offset);
    offset += buf.length;
  }

  if (offset < totalLength) return target.slice(0, offset);

  return target;
}

/**
 * Masks a buffer using the given mask.
 *
 * @param {Buffer} source The buffer to mask
 * @param {Buffer} mask The mask to use
 * @param {Buffer} output The buffer where to store the result
 * @param {Number} offset The offset at which to start writing
 * @param {Number} length The number of bytes to mask.
 * @public
 */
function _mask(source, mask, output, offset, length) {
  for (let i = 0; i < length; i++) {
    output[offset + i] = source[i] ^ mask[i & 3];
  }
}

/**
 * Unmasks a buffer using the given mask.
 *
 * @param {Buffer} buffer The buffer to unmask
 * @param {Buffer} mask The mask to use
 * @public
 */
function _unmask(buffer, mask) {
  // Required until https://github.com/nodejs/node/issues/9006 is resolved.
  const length = buffer.length;
  for (let i = 0; i < length; i++) {
    buffer[i] ^= mask[i & 3];
  }
}

/**
 * Converts a buffer to an `ArrayBuffer`.
 *
 * @param {Buffer} buf The buffer to convert
 * @return {ArrayBuffer} Converted buffer
 * @public
 */
function toArrayBuffer(buf) {
  if (buf.byteLength === buf.buffer.byteLength) {
    return buf.buffer;
  }

  return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
}

/**
 * Converts `data` to a `Buffer`.
 *
 * @param {*} data The data to convert
 * @return {Buffer} The buffer
 * @throws {TypeError}
 * @public
 */
function toBuffer(data) {
  toBuffer.readOnly = true;

  if (Buffer.isBuffer(data)) return data;

  let buf;

  if (data instanceof ArrayBuffer) {
    buf = Buffer.from(data);
  } else if (ArrayBuffer.isView(data)) {
    buf = Buffer.from(data.buffer, data.byteOffset, data.byteLength);
  } else {
    buf = Buffer.from(data);
    toBuffer.readOnly = false;
  }

  return buf;
}

try {
  const bufferUtil = require('bufferutil');
  const bu = bufferUtil.BufferUtil || bufferUtil;

  module.exports = {
    concat,
    mask(source, mask, output, offset, length) {
      if (length < 48) _mask(source, mask, output, offset, length);
      else bu.mask(source, mask, output, offset, length);
    },
    toArrayBuffer,
    toBuffer,
    unmask(buffer, mask) {
      if (buffer.length < 32) _unmask(buffer, mask);
      else bu.unmask(buffer, mask);
    }
  };
} catch (e) /* istanbul ignore next */ {
  module.exports = {
    concat,
    mask: _mask,
    toArrayBuffer,
    toBuffer,
    unmask: _unmask
  };
}

},
"2uBTHH0mScjN6VwbN2yQcRtjLsMVQI2dw3Bz0+Oi0go=":
function (require, module, exports, __dirname, __filename) {
var ltgt = require('ltgt')

function eq (a, b) {
  if (Buffer.isBuffer(a) && Buffer.isBuffer(b)) {
    return beq(a, b)
  }
  else return a === b
}

module.exports = function post (db, opts, each) {
  if(!each)
    each = opts, opts = {}

  if('function' === typeof db.post)
    return db.post(opts, each)

  var encode = (opts && opts.keyEncoding && opts.keyEncoding.encode)
    || (db.options && db.options.keyEncoding && db.options.keyEncoding.encode)
    || function (x) { return x }

  var _opts = ltgt.toLtgt(opts, {}, encode)

  function cmp (key) {
    return ltgt.contains(_opts, encode(key))
  }

  function onPut (key, val) {
    if(cmp(key))
      each({type: 'put', key: key, value: val})
  }

  function onDel (key, val) {
    if(cmp(key))
      each({type: 'del', key: key, value: val})
  }

  function onBatch (ary) {
    ary.forEach(function (op) {
      if(cmp(op.key))
        each(op)
    })
  }

  db.on('put', onPut)
  db.on('del', onDel)
  db.on('batch', onBatch)

  return function () {
    db.removeListener('put', onPut)
    db.removeListener('del', onDel)
    db.removeListener('batch', onBatch)
  }
}


},
"3CkTk26fOLUi82dbSnycCyGuWbLHMkto77jsauPEcCg=":
function (require, module, exports, __dirname, __filename) {
module.exports = function reduce (acc, value) {
  //handle when called without initial
  if('number' === typeof acc)
    return reduce(reduce(null, acc), value)
  //set initial if initial was null
  else if(null == acc)
    return {
      mean: value,
      stdev: 0,

      count: 1,
      sum: value,
      sqsum: value*value
    }

  var sum = acc.sum + value
  var count = acc.count + 1
  var sq = value*value

  var mean = sum/count
  var sqsum = acc.sqsum + sq

  return {
    //these values useful output
    mean: mean,
    stdev: Math.sqrt(sqsum/count - mean*mean),

    //these values needed to maintain state.
    count: count,
    sum: sum,
    sqsum: sqsum
  }
}

module.exports.initial = require('./initial')


},
"3GKP0QabXZg3mQoJ7x/raDTxNNhhg0bca9j8uUazKaM=":
function (require, module, exports, __dirname, __filename) {

function isFunction (f) {
  return 'function' === typeof f
}

function isDuplex (d) {
  return 'object' === typeof d && isSource(d.source) && isSink(d.sink)
}

function isSource (s) {
  return isFunction(s) && s.length === 2
}

function isSink (s) {
  return isFunction(s) && s.length === 1
}

exports.isDuplex = isDuplex
exports.isSource = isSource
exports.isSink = isSink
//can't do is through, it will appear as a sink til you git it a source.


},
"3Huaa8u+AMVeAEB3XNau1l9qkfu/XPnLSZkufQnuZGc=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var keys = require('object-keys');
var hasSymbols = typeof Symbol === 'function' && typeof Symbol('foo') === 'symbol';

var toStr = Object.prototype.toString;
var concat = Array.prototype.concat;
var origDefineProperty = Object.defineProperty;

var isFunction = function (fn) {
	return typeof fn === 'function' && toStr.call(fn) === '[object Function]';
};

var arePropertyDescriptorsSupported = function () {
	var obj = {};
	try {
		origDefineProperty(obj, 'x', { enumerable: false, value: obj });
		// eslint-disable-next-line no-unused-vars, no-restricted-syntax
		for (var _ in obj) { // jscs:ignore disallowUnusedVariables
			return false;
		}
		return obj.x === obj;
	} catch (e) { /* this is IE 8. */
		return false;
	}
};
var supportsDescriptors = origDefineProperty && arePropertyDescriptorsSupported();

var defineProperty = function (object, name, value, predicate) {
	if (name in object && (!isFunction(predicate) || !predicate())) {
		return;
	}
	if (supportsDescriptors) {
		origDefineProperty(object, name, {
			configurable: true,
			enumerable: false,
			value: value,
			writable: true
		});
	} else {
		object[name] = value;
	}
};

var defineProperties = function (object, map) {
	var predicates = arguments.length > 2 ? arguments[2] : {};
	var props = keys(map);
	if (hasSymbols) {
		props = concat.call(props, Object.getOwnPropertySymbols(map));
	}
	for (var i = 0; i < props.length; i += 1) {
		defineProperty(object, props[i], map[props[i]], predicates[props[i]]);
	}
};

defineProperties.supportsDescriptors = !!supportsDescriptors;

module.exports = defineProperties;

},
"3PFOGJDDD5HnzobxKjYpLIqOmTcCYDinOmM/VKH+SoA=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const pull = require('pull-stream')

function isEmpty (obj) {
  if (!obj) return true
  return Object.keys(obj).length === 0
}

// I wrote set as part of permissions.js
// and then later mount, they do nearly the same thing
// but not quite. this should be refactored sometime.
// what differs is that set updates the last key in the path
// to the new value, but mount merges the last value
// which makes sense if it's an object, and set makes sense if it's
// a string/number/boolean.

exports.set = function set (obj, path, value) {
  let _obj, _k
  for (let i = 0; i < path.length; i++) {
    const k = path[i]
    obj[k] = obj[k] || {}
    _obj = obj
    _k = k
    obj = obj[k]
  }
  _obj[_k] = value
}

exports.get = function get (obj, path) {
  if (typeof path === 'string') return obj[path]
  let value
  for (let i = 0; i < path.length; i++) {
    const k = path[i]
    value = obj = obj[k]
    if (obj == null) return obj
  }
  return value
}

exports.prefix = function prefix (obj, path) {
  let value

  for (let i = 0; i < path.length; i++) {
    const k = path[i]
    value = obj = obj[k]
    if (typeof obj !== 'object') {
      return obj
    }
  }
  return typeof value !== 'object' ? !!value : false
}

function mkPath (obj, path) {
  for (const i in path) {
    const key = path[i]
    if (!obj[key]) obj[key] = {}
    obj = obj[key]
  }
  return obj
}

function rmPath (obj, path) {
  (function r (obj, i) {
    const key = path[i]
    if (!obj) return
    else if (path.length - 1 === i) {
      delete obj[key]
    } else if (i < path.length) r(obj[key], i + 1)
    if (isEmpty(obj[key])) delete obj[key]
  })(obj, 0)
}

function merge (obj, _obj) {
  for (const k in _obj) {
    obj[k] = _obj[k]
  }
  return obj
}

exports.mount = function mount (obj, path, _obj) {
  if (!Array.isArray(path)) {
    throw new Error('path must be array of strings')
  }
  return merge(mkPath(obj, path), _obj)
}

exports.unmount = function unmount (obj, path) {
  return rmPath(obj, path)
}

const isSource = (t) => t === 'source'
const isSink = (t) => t === 'sink'
const isDuplex = (t) => t === 'duplex'
const isSync = (t) => t === 'sync'
const isAsync = (t) => t === 'async'
const isRequest = (t) => isSync(t) || isAsync(t)
const isStream = (t) => isSource(t) || isSink(t) || isDuplex(t)

exports.isRequest = isRequest
exports.isStream = isStream

function abortSink (err) {
  return function (read) {
    read(err || true, () => {})
  }
}

function abortDuplex (err) {
  return { source: pull.error(err), sink: abortSink(err) }
}

exports.errorAsStream = function errorAsStream (type, err) {
  return isSource(type)
    ? pull.error(err)
    : isSink(type)
      ? abortSink(err)
      : abortDuplex(err)
}

exports.errorAsStreamOrCb = function errorAsStreamOrCb (type, err, cb) {
  return (
    isRequest(type)
      ? cb(err)
      : isSource(type)
        ? pull.error(err)
        : isSink(type)
          ? abortSink(err)
          : cb(err),
    abortDuplex(err)
  )
}

exports.pipeToStream = function pipeToStream (type, _stream, stream) {
  if (isSource(type)) {
    _stream(stream)
  } else if (isSink(type)) {
    stream(_stream)
  } else if (isDuplex(type)) {
    pull(_stream, stream, _stream)
  }
}

},
"3SuPvFPLYoUfRoj6Dxl7RevRZvTIPEBHkRVllexmQAA=":
function (require, module, exports, __dirname, __filename) {
const bencode = module.exports

bencode.encode = require('./encode.js')
bencode.decode = require('./decode.js')

/**
 * Determines the amount of bytes
 * needed to encode the given value
 * @param  {Object|Array|Buffer|String|Number|Boolean} value
 * @return {Number} byteCount
 */
bencode.byteLength = bencode.encodingLength = require('./encoding-length.js')

},
"3Wto9YvbeST2Hedm2a3EJGeF/aOc+5dkJqygwHeYuYs=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports =
function Empty (err) {
  return {
    resume: function () {
      this.sink.end(err)
    },
    pipe: require('../pipe')
  }
}

},
"3mbElOEt6wnYkLfQf1uSbWPx+Nn5pCsTpToNmPWHr8s=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var sodium      = require('chloride')

// var keypair     = sodium.crypto_box_seed_keypair
var from_seed   = sodium.crypto_sign_seed_keypair
var shared      = sodium.crypto_scalarmult
var hash        = sodium.crypto_hash_sha256
var sign        = sodium.crypto_sign_detached
var verify      = sodium.crypto_sign_verify_detached
var auth        = sodium.crypto_auth
var verify_auth = sodium.crypto_auth_verify
var curvify_pk  = sodium.crypto_sign_ed25519_pk_to_curve25519
var curvify_sk  = sodium.crypto_sign_ed25519_sk_to_curve25519
var box         = sodium.crypto_secretbox_easy
var unbox       = sodium.crypto_secretbox_open_easy

var concat = Buffer.concat

var nonce = Buffer.alloc(24); nonce.fill(0)

var isBuffer = Buffer.isBuffer

exports.challenge_length = 64
exports.client_auth_length = 16+32+64
exports.server_auth_length = 16+64
exports.mac_length = 16

//both client and server

function assert_length(buf, name, length) {
  if(buf.length !== length)
    throw new Error('expected '+name+' to have length' + length + ', but was:'+buf.length)
}

exports.initialize = function (state) {

  if(state.seed) state.local = from_seed(state.seed)

  //TODO: sodium is missing box_seed_keypair. should make PR for that.
  // mix: sodium-native has this fn https://github.com/sodium-friends/sodium-native

  var _key = from_seed(state.random)
  //  var kx = keypair(random)
  var kx_pk = curvify_pk(_key.publicKey)
  var kx_sk = curvify_sk(_key.secretKey)

  state.local = {
    kx_pk: kx_pk,
    kx_sk: kx_sk,
    publicKey: state.local.publicKey,
    secretKey: state.local.secretKey,
    app_mac: auth(kx_pk, state.app_key)
  }

  state.remote = state.remote || {}

  return state
}

exports.createChallenge = function (state) {
  return concat([state.local.app_mac, state.local.kx_pk])
}


exports.verifyChallenge = function (state, challenge) {
  assert_length(challenge, 'challenge', exports.challenge_length)

  var mac = challenge.slice(0, 32)
  var remote_pk = challenge.slice(32, exports.challenge_length)

  if(0 !== verify_auth(mac, remote_pk, state.app_key))
    return null

  state.remote.kx_pk = remote_pk
  state.remote.app_mac = mac
  state.secret = shared(state.local.kx_sk, state.remote.kx_pk)
  state.shash = hash(state.secret)

  return state
}

exports.clean = function (state) {
  // clean away all the secrets for forward security.
  // use a different secret hash(secret3) in the rest of the session,
  // and so that a sloppy application cannot compromise the handshake.

  state.shash.fill(0)
  state.secret.fill(0)
  state.a_bob.fill(0)
  state.b_alice.fill(0)

  state.secret = hash(state.secret3)
  state.encryptKey = hash(concat([state.secret, state.remote.publicKey]))
  state.decryptKey = hash(concat([state.secret, state.local.publicKey]))

  state.secret2.fill(0)
  state.secret3.fill(0)
  state.local.kx_sk.fill(0)

  state.shash = null
  state.secret2 = null
  state.secret3 = null
  state.a_bob = null
  state.b_alice = null
  state.local.kx_sk = null
  return state
}

//client side only (Alice)

exports.clientVerifyChallenge = function (state, challenge) {
  assert_length(challenge, 'challenge', exports.challenge_length)
  state = exports.verifyChallenge(state, challenge)
  if(!state) return null

  //now we have agreed on the secret.
  //this can be an encryption secret,
  //or a hmac secret.
  var curve = curvify_pk(state.remote.publicKey)
  if(!curve) return null
  var a_bob = shared(state.local.kx_sk, curve)
  state.a_bob = a_bob
  state.secret2 = hash(concat([state.app_key, state.secret, a_bob]))

  var signed = concat([state.app_key, state.remote.publicKey, state.shash])
  var sig = sign(signed, state.local.secretKey)

  state.local.hello = Buffer.concat([sig, state.local.publicKey])
  return state
}

exports.clientCreateAuth = function (state) {
  return box(state.local.hello, nonce, state.secret2)
}

exports.clientVerifyAccept = function (state, boxed_okay) {
  assert_length(boxed_okay, 'server_auth', exports.server_auth_length)

  var b_alice = shared(curvify_sk(state.local.secretKey), state.remote.kx_pk)
  state.b_alice = b_alice
  state.secret3 = hash(concat([state.app_key, state.secret, state.a_bob, state.b_alice]))

  var sig = unbox(boxed_okay, nonce, state.secret3)
  if(!sig) return null
  var signed = concat([state.app_key, state.local.hello, state.shash])
  if(!verify(sig, signed, state.remote.publicKey))
      return null
  return state
}

//server side only (Bob)

exports.serverVerifyAuth = function (state, data) {
  assert_length(data, 'client_auth', exports.client_auth_length)

  var a_bob = shared(curvify_sk(state.local.secretKey), state.remote.kx_pk)
  state.a_bob = a_bob
  state.secret2 = hash(concat([state.app_key, state.secret, a_bob]))

  state.remote.hello = unbox(data, nonce, state.secret2)
  if(!state.remote.hello)
    return null

  var sig = state.remote.hello.slice(0, 64)
  var publicKey = state.remote.hello.slice(64, 96)

  var signed = concat([state.app_key, state.local.publicKey, state.shash])
  if(!verify(sig, signed, publicKey))
    return null

  state.remote.publicKey = publicKey
  //shared key between my local ephemeral key + remote public
  var b_alice = shared(state.local.kx_sk, curvify_pk(state.remote.publicKey))
  state.b_alice = b_alice
  state.secret3 = hash(concat([state.app_key, state.secret, state.a_bob, state.b_alice]))

  return state

}

exports.serverCreateAccept = function (state) {
  var signed = concat([state.app_key, state.remote.hello, state.shash])
  var okay = sign(signed, state.local.secretKey)
  return box(okay, nonce, state.secret3)
}

exports.toKeys = function (keys) {
  if(isBuffer(keys, 32))
    return sodium.crypto_sign_seed_keypair(keys)
  return keys
}

},
"3nAqcqzkBNDPu9t2hcW10UP2hB9qCJRS/8Zz+5ZDqd4=":
function (require, module, exports, __dirname, __filename) {
var RC = require('rc')
var setDefaults = require('./defaults')

module.exports = function (name, override) {
  name = name || 'ssb'
  var rc = RC(name, override || {})
  var config = setDefaults(name, rc)
  return config
}

},
"3p6myKHUlW9PdND2YLlWi/MgrVPUa1t7YVRNrgd8nXE=":
function (require, module, exports, __dirname, __filename) {
var pull     = require('pull-stream/pull')
var Map      = require('pull-stream/throughs/map')
var AsyncMap = require('pull-stream/throughs/async-map')
var Drain    = require('pull-stream/sinks/drain')
var Window   = require('pull-window')

module.exports = function (db, opts, done) {
  if('function' === typeof opts)
    done = opts, opts = null
  opts = opts || {}
  return pull(
    Map(function (e) {
      if(e.type) return e
      return {
        key   : e.key, 
        value : e.value,
        type  : e.value == null ? 'del' : 'put'
      }
    }),
    Window.recent(opts.windowSize, opts.windowTime),
    AsyncMap(function (batch, cb) {
      db.batch(batch, cb)
    }),
    Drain(null, done)
  )
}


},
"4/PR/VSqJBM6PVGK5+rybVy8G5SWOJ4Y3SS6Y+p2PtM=":
function (require, module, exports, __dirname, __filename) {
// Approach:
//
// 1. Get the minimatch set
// 2. For each pattern in the set, PROCESS(pattern, false)
// 3. Store matches per-set, then uniq them
//
// PROCESS(pattern, inGlobStar)
// Get the first [n] items from pattern that are all strings
// Join these together.  This is PREFIX.
//   If there is no more remaining, then stat(PREFIX) and
//   add to matches if it succeeds.  END.
//
// If inGlobStar and PREFIX is symlink and points to dir
//   set ENTRIES = []
// else readdir(PREFIX) as ENTRIES
//   If fail, END
//
// with ENTRIES
//   If pattern[n] is GLOBSTAR
//     // handle the case where the globstar match is empty
//     // by pruning it out, and testing the resulting pattern
//     PROCESS(pattern[0..n] + pattern[n+1 .. $], false)
//     // handle other cases.
//     for ENTRY in ENTRIES (not dotfiles)
//       // attach globstar + tail onto the entry
//       // Mark that this entry is a globstar match
//       PROCESS(pattern[0..n] + ENTRY + pattern[n .. $], true)
//
//   else // not globstar
//     for ENTRY in ENTRIES (not dotfiles, unless pattern[n] is dot)
//       Test ENTRY against pattern[n]
//       If fails, continue
//       If passes, PROCESS(pattern[0..n] + item + pattern[n+1 .. $])
//
// Caveat:
//   Cache all stats and readdirs results to minimize syscall.  Since all
//   we ever care about is existence and directory-ness, we can just keep
//   `true` for files, and [children,...] for directories, or `false` for
//   things that don't exist.

module.exports = glob

var fs = require('fs')
var rp = require('fs.realpath')
var minimatch = require('minimatch')
var Minimatch = minimatch.Minimatch
var inherits = require('inherits')
var EE = require('events').EventEmitter
var path = require('path')
var assert = require('assert')
var isAbsolute = require('path-is-absolute')
var globSync = require('./sync.js')
var common = require('./common.js')
var alphasort = common.alphasort
var alphasorti = common.alphasorti
var setopts = common.setopts
var ownProp = common.ownProp
var inflight = require('inflight')
var util = require('util')
var childrenIgnored = common.childrenIgnored
var isIgnored = common.isIgnored

var once = require('once')

function glob (pattern, options, cb) {
  if (typeof options === 'function') cb = options, options = {}
  if (!options) options = {}

  if (options.sync) {
    if (cb)
      throw new TypeError('callback provided to sync glob')
    return globSync(pattern, options)
  }

  return new Glob(pattern, options, cb)
}

glob.sync = globSync
var GlobSync = glob.GlobSync = globSync.GlobSync

// old api surface
glob.glob = glob

function extend (origin, add) {
  if (add === null || typeof add !== 'object') {
    return origin
  }

  var keys = Object.keys(add)
  var i = keys.length
  while (i--) {
    origin[keys[i]] = add[keys[i]]
  }
  return origin
}

glob.hasMagic = function (pattern, options_) {
  var options = extend({}, options_)
  options.noprocess = true

  var g = new Glob(pattern, options)
  var set = g.minimatch.set

  if (!pattern)
    return false

  if (set.length > 1)
    return true

  for (var j = 0; j < set[0].length; j++) {
    if (typeof set[0][j] !== 'string')
      return true
  }

  return false
}

glob.Glob = Glob
inherits(Glob, EE)
function Glob (pattern, options, cb) {
  if (typeof options === 'function') {
    cb = options
    options = null
  }

  if (options && options.sync) {
    if (cb)
      throw new TypeError('callback provided to sync glob')
    return new GlobSync(pattern, options)
  }

  if (!(this instanceof Glob))
    return new Glob(pattern, options, cb)

  setopts(this, pattern, options)
  this._didRealPath = false

  // process each pattern in the minimatch set
  var n = this.minimatch.set.length

  // The matches are stored as {<filename>: true,...} so that
  // duplicates are automagically pruned.
  // Later, we do an Object.keys() on these.
  // Keep them as a list so we can fill in when nonull is set.
  this.matches = new Array(n)

  if (typeof cb === 'function') {
    cb = once(cb)
    this.on('error', cb)
    this.on('end', function (matches) {
      cb(null, matches)
    })
  }

  var self = this
  this._processing = 0

  this._emitQueue = []
  this._processQueue = []
  this.paused = false

  if (this.noprocess)
    return this

  if (n === 0)
    return done()

  var sync = true
  for (var i = 0; i < n; i ++) {
    this._process(this.minimatch.set[i], i, false, done)
  }
  sync = false

  function done () {
    --self._processing
    if (self._processing <= 0) {
      if (sync) {
        process.nextTick(function () {
          self._finish()
        })
      } else {
        self._finish()
      }
    }
  }
}

Glob.prototype._finish = function () {
  assert(this instanceof Glob)
  if (this.aborted)
    return

  if (this.realpath && !this._didRealpath)
    return this._realpath()

  common.finish(this)
  this.emit('end', this.found)
}

Glob.prototype._realpath = function () {
  if (this._didRealpath)
    return

  this._didRealpath = true

  var n = this.matches.length
  if (n === 0)
    return this._finish()

  var self = this
  for (var i = 0; i < this.matches.length; i++)
    this._realpathSet(i, next)

  function next () {
    if (--n === 0)
      self._finish()
  }
}

Glob.prototype._realpathSet = function (index, cb) {
  var matchset = this.matches[index]
  if (!matchset)
    return cb()

  var found = Object.keys(matchset)
  var self = this
  var n = found.length

  if (n === 0)
    return cb()

  var set = this.matches[index] = Object.create(null)
  found.forEach(function (p, i) {
    // If there's a problem with the stat, then it means that
    // one or more of the links in the realpath couldn't be
    // resolved.  just return the abs value in that case.
    p = self._makeAbs(p)
    rp.realpath(p, self.realpathCache, function (er, real) {
      if (!er)
        set[real] = true
      else if (er.syscall === 'stat')
        set[p] = true
      else
        self.emit('error', er) // srsly wtf right here

      if (--n === 0) {
        self.matches[index] = set
        cb()
      }
    })
  })
}

Glob.prototype._mark = function (p) {
  return common.mark(this, p)
}

Glob.prototype._makeAbs = function (f) {
  return common.makeAbs(this, f)
}

Glob.prototype.abort = function () {
  this.aborted = true
  this.emit('abort')
}

Glob.prototype.pause = function () {
  if (!this.paused) {
    this.paused = true
    this.emit('pause')
  }
}

Glob.prototype.resume = function () {
  if (this.paused) {
    this.emit('resume')
    this.paused = false
    if (this._emitQueue.length) {
      var eq = this._emitQueue.slice(0)
      this._emitQueue.length = 0
      for (var i = 0; i < eq.length; i ++) {
        var e = eq[i]
        this._emitMatch(e[0], e[1])
      }
    }
    if (this._processQueue.length) {
      var pq = this._processQueue.slice(0)
      this._processQueue.length = 0
      for (var i = 0; i < pq.length; i ++) {
        var p = pq[i]
        this._processing--
        this._process(p[0], p[1], p[2], p[3])
      }
    }
  }
}

Glob.prototype._process = function (pattern, index, inGlobStar, cb) {
  assert(this instanceof Glob)
  assert(typeof cb === 'function')

  if (this.aborted)
    return

  this._processing++
  if (this.paused) {
    this._processQueue.push([pattern, index, inGlobStar, cb])
    return
  }

  //console.error('PROCESS %d', this._processing, pattern)

  // Get the first [n] parts of pattern that are all strings.
  var n = 0
  while (typeof pattern[n] === 'string') {
    n ++
  }
  // now n is the index of the first one that is *not* a string.

  // see if there's anything else
  var prefix
  switch (n) {
    // if not, then this is rather simple
    case pattern.length:
      this._processSimple(pattern.join('/'), index, cb)
      return

    case 0:
      // pattern *starts* with some non-trivial item.
      // going to readdir(cwd), but not include the prefix in matches.
      prefix = null
      break

    default:
      // pattern has some string bits in the front.
      // whatever it starts with, whether that's 'absolute' like /foo/bar,
      // or 'relative' like '../baz'
      prefix = pattern.slice(0, n).join('/')
      break
  }

  var remain = pattern.slice(n)

  // get the list of entries.
  var read
  if (prefix === null)
    read = '.'
  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {
    if (!prefix || !isAbsolute(prefix))
      prefix = '/' + prefix
    read = prefix
  } else
    read = prefix

  var abs = this._makeAbs(read)

  //if ignored, skip _processing
  if (childrenIgnored(this, read))
    return cb()

  var isGlobStar = remain[0] === minimatch.GLOBSTAR
  if (isGlobStar)
    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar, cb)
  else
    this._processReaddir(prefix, read, abs, remain, index, inGlobStar, cb)
}

Glob.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar, cb) {
  var self = this
  this._readdir(abs, inGlobStar, function (er, entries) {
    return self._processReaddir2(prefix, read, abs, remain, index, inGlobStar, entries, cb)
  })
}

Glob.prototype._processReaddir2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {

  // if the abs isn't a dir, then nothing can match!
  if (!entries)
    return cb()

  // It will only match dot entries if it starts with a dot, or if
  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.
  var pn = remain[0]
  var negate = !!this.minimatch.negate
  var rawGlob = pn._glob
  var dotOk = this.dot || rawGlob.charAt(0) === '.'

  var matchedEntries = []
  for (var i = 0; i < entries.length; i++) {
    var e = entries[i]
    if (e.charAt(0) !== '.' || dotOk) {
      var m
      if (negate && !prefix) {
        m = !e.match(pn)
      } else {
        m = e.match(pn)
      }
      if (m)
        matchedEntries.push(e)
    }
  }

  //console.error('prd2', prefix, entries, remain[0]._glob, matchedEntries)

  var len = matchedEntries.length
  // If there are no matched entries, then nothing matches.
  if (len === 0)
    return cb()

  // if this is the last remaining pattern bit, then no need for
  // an additional stat *unless* the user has specified mark or
  // stat explicitly.  We know they exist, since readdir returned
  // them.

  if (remain.length === 1 && !this.mark && !this.stat) {
    if (!this.matches[index])
      this.matches[index] = Object.create(null)

    for (var i = 0; i < len; i ++) {
      var e = matchedEntries[i]
      if (prefix) {
        if (prefix !== '/')
          e = prefix + '/' + e
        else
          e = prefix + e
      }

      if (e.charAt(0) === '/' && !this.nomount) {
        e = path.join(this.root, e)
      }
      this._emitMatch(index, e)
    }
    // This was the last one, and no stats were needed
    return cb()
  }

  // now test all matched entries as stand-ins for that part
  // of the pattern.
  remain.shift()
  for (var i = 0; i < len; i ++) {
    var e = matchedEntries[i]
    var newPattern
    if (prefix) {
      if (prefix !== '/')
        e = prefix + '/' + e
      else
        e = prefix + e
    }
    this._process([e].concat(remain), index, inGlobStar, cb)
  }
  cb()
}

Glob.prototype._emitMatch = function (index, e) {
  if (this.aborted)
    return

  if (isIgnored(this, e))
    return

  if (this.paused) {
    this._emitQueue.push([index, e])
    return
  }

  var abs = isAbsolute(e) ? e : this._makeAbs(e)

  if (this.mark)
    e = this._mark(e)

  if (this.absolute)
    e = abs

  if (this.matches[index][e])
    return

  if (this.nodir) {
    var c = this.cache[abs]
    if (c === 'DIR' || Array.isArray(c))
      return
  }

  this.matches[index][e] = true

  var st = this.statCache[abs]
  if (st)
    this.emit('stat', e, st)

  this.emit('match', e)
}

Glob.prototype._readdirInGlobStar = function (abs, cb) {
  if (this.aborted)
    return

  // follow all symlinked directories forever
  // just proceed as if this is a non-globstar situation
  if (this.follow)
    return this._readdir(abs, false, cb)

  var lstatkey = 'lstat\0' + abs
  var self = this
  var lstatcb = inflight(lstatkey, lstatcb_)

  if (lstatcb)
    fs.lstat(abs, lstatcb)

  function lstatcb_ (er, lstat) {
    if (er && er.code === 'ENOENT')
      return cb()

    var isSym = lstat && lstat.isSymbolicLink()
    self.symlinks[abs] = isSym

    // If it's not a symlink or a dir, then it's definitely a regular file.
    // don't bother doing a readdir in that case.
    if (!isSym && lstat && !lstat.isDirectory()) {
      self.cache[abs] = 'FILE'
      cb()
    } else
      self._readdir(abs, false, cb)
  }
}

Glob.prototype._readdir = function (abs, inGlobStar, cb) {
  if (this.aborted)
    return

  cb = inflight('readdir\0'+abs+'\0'+inGlobStar, cb)
  if (!cb)
    return

  //console.error('RD %j %j', +inGlobStar, abs)
  if (inGlobStar && !ownProp(this.symlinks, abs))
    return this._readdirInGlobStar(abs, cb)

  if (ownProp(this.cache, abs)) {
    var c = this.cache[abs]
    if (!c || c === 'FILE')
      return cb()

    if (Array.isArray(c))
      return cb(null, c)
  }

  var self = this
  fs.readdir(abs, readdirCb(this, abs, cb))
}

function readdirCb (self, abs, cb) {
  return function (er, entries) {
    if (er)
      self._readdirError(abs, er, cb)
    else
      self._readdirEntries(abs, entries, cb)
  }
}

Glob.prototype._readdirEntries = function (abs, entries, cb) {
  if (this.aborted)
    return

  // if we haven't asked to stat everything, then just
  // assume that everything in there exists, so we can avoid
  // having to stat it a second time.
  if (!this.mark && !this.stat) {
    for (var i = 0; i < entries.length; i ++) {
      var e = entries[i]
      if (abs === '/')
        e = abs + e
      else
        e = abs + '/' + e
      this.cache[e] = true
    }
  }

  this.cache[abs] = entries
  return cb(null, entries)
}

Glob.prototype._readdirError = function (f, er, cb) {
  if (this.aborted)
    return

  // handle errors, and cache the information
  switch (er.code) {
    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205
    case 'ENOTDIR': // totally normal. means it *does* exist.
      var abs = this._makeAbs(f)
      this.cache[abs] = 'FILE'
      if (abs === this.cwdAbs) {
        var error = new Error(er.code + ' invalid cwd ' + this.cwd)
        error.path = this.cwd
        error.code = er.code
        this.emit('error', error)
        this.abort()
      }
      break

    case 'ENOENT': // not terribly unusual
    case 'ELOOP':
    case 'ENAMETOOLONG':
    case 'UNKNOWN':
      this.cache[this._makeAbs(f)] = false
      break

    default: // some unusual error.  Treat as failure.
      this.cache[this._makeAbs(f)] = false
      if (this.strict) {
        this.emit('error', er)
        // If the error is handled, then we abort
        // if not, we threw out of here
        this.abort()
      }
      if (!this.silent)
        console.error('glob error', er)
      break
  }

  return cb()
}

Glob.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar, cb) {
  var self = this
  this._readdir(abs, inGlobStar, function (er, entries) {
    self._processGlobStar2(prefix, read, abs, remain, index, inGlobStar, entries, cb)
  })
}


Glob.prototype._processGlobStar2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {
  //console.error('pgs2', prefix, remain[0], entries)

  // no entries means not a dir, so it can never have matches
  // foo.txt/** doesn't match foo.txt
  if (!entries)
    return cb()

  // test without the globstar, and with every child both below
  // and replacing the globstar.
  var remainWithoutGlobStar = remain.slice(1)
  var gspref = prefix ? [ prefix ] : []
  var noGlobStar = gspref.concat(remainWithoutGlobStar)

  // the noGlobStar pattern exits the inGlobStar state
  this._process(noGlobStar, index, false, cb)

  var isSym = this.symlinks[abs]
  var len = entries.length

  // If it's a symlink, and we're in a globstar, then stop
  if (isSym && inGlobStar)
    return cb()

  for (var i = 0; i < len; i++) {
    var e = entries[i]
    if (e.charAt(0) === '.' && !this.dot)
      continue

    // these two cases enter the inGlobStar state
    var instead = gspref.concat(entries[i], remainWithoutGlobStar)
    this._process(instead, index, true, cb)

    var below = gspref.concat(entries[i], remain)
    this._process(below, index, true, cb)
  }

  cb()
}

Glob.prototype._processSimple = function (prefix, index, cb) {
  // XXX review this.  Shouldn't it be doing the mounting etc
  // before doing stat?  kinda weird?
  var self = this
  this._stat(prefix, function (er, exists) {
    self._processSimple2(prefix, index, er, exists, cb)
  })
}
Glob.prototype._processSimple2 = function (prefix, index, er, exists, cb) {

  //console.error('ps2', prefix, exists)

  if (!this.matches[index])
    this.matches[index] = Object.create(null)

  // If it doesn't exist, then just mark the lack of results
  if (!exists)
    return cb()

  if (prefix && isAbsolute(prefix) && !this.nomount) {
    var trail = /[\/\\]$/.test(prefix)
    if (prefix.charAt(0) === '/') {
      prefix = path.join(this.root, prefix)
    } else {
      prefix = path.resolve(this.root, prefix)
      if (trail)
        prefix += '/'
    }
  }

  if (process.platform === 'win32')
    prefix = prefix.replace(/\\/g, '/')

  // Mark this as a match
  this._emitMatch(index, prefix)
  cb()
}

// Returns either 'DIR', 'FILE', or false
Glob.prototype._stat = function (f, cb) {
  var abs = this._makeAbs(f)
  var needDir = f.slice(-1) === '/'

  if (f.length > this.maxLength)
    return cb()

  if (!this.stat && ownProp(this.cache, abs)) {
    var c = this.cache[abs]

    if (Array.isArray(c))
      c = 'DIR'

    // It exists, but maybe not how we need it
    if (!needDir || c === 'DIR')
      return cb(null, c)

    if (needDir && c === 'FILE')
      return cb()

    // otherwise we have to stat, because maybe c=true
    // if we know it exists, but not what it is.
  }

  var exists
  var stat = this.statCache[abs]
  if (stat !== undefined) {
    if (stat === false)
      return cb(null, stat)
    else {
      var type = stat.isDirectory() ? 'DIR' : 'FILE'
      if (needDir && type === 'FILE')
        return cb()
      else
        return cb(null, type, stat)
    }
  }

  var self = this
  var statcb = inflight('stat\0' + abs, lstatcb_)
  if (statcb)
    fs.lstat(abs, statcb)

  function lstatcb_ (er, lstat) {
    if (lstat && lstat.isSymbolicLink()) {
      // If it's a symlink, then treat it as the target, unless
      // the target does not exist, then treat it as a file.
      return fs.stat(abs, function (er, stat) {
        if (er)
          self._stat2(f, abs, null, lstat, cb)
        else
          self._stat2(f, abs, er, stat, cb)
      })
    } else {
      self._stat2(f, abs, er, lstat, cb)
    }
  }
}

Glob.prototype._stat2 = function (f, abs, er, stat, cb) {
  if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {
    this.statCache[abs] = false
    return cb()
  }

  var needDir = f.slice(-1) === '/'
  this.statCache[abs] = stat

  if (abs.slice(-1) === '/' && stat && !stat.isDirectory())
    return cb(null, false, stat)

  var c = true
  if (stat)
    c = stat.isDirectory() ? 'DIR' : 'FILE'
  this.cache[abs] = this.cache[abs] || c

  if (needDir && c === 'FILE')
    return cb()

  return cb(null, c, stat)
}

},
"4/vtdCbL5dshSa2VbKM4ZGuYoUwj6oIAdXqNiip2TwM=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN
var AbstractChainedBatch = require('abstract-leveldown').AbstractChainedBatch
var AbstractIterator = require('abstract-leveldown').AbstractIterator
var inherits = require('inherits')
var Codec = require('level-codec')
var EncodingError = require('level-errors').EncodingError

module.exports = DB.default = DB

function DB (db, opts) {
  if (!(this instanceof DB)) return new DB(db, opts)
  AbstractLevelDOWN.call(this, '')

  opts = opts || {}
  if (typeof opts.keyEncoding === 'undefined') opts.keyEncoding = 'utf8'
  if (typeof opts.valueEncoding === 'undefined') opts.valueEncoding = 'utf8'

  this.db = db
  this.codec = new Codec(opts)
}

inherits(DB, AbstractLevelDOWN)

DB.prototype._serializeKey =
DB.prototype._serializeValue = function (datum) {
  return datum
}

DB.prototype._open = function (opts, cb) {
  this.db.open(opts, cb)
}

DB.prototype._close = function (cb) {
  this.db.close(cb)
}

DB.prototype._put = function (key, value, opts, cb) {
  key = this.codec.encodeKey(key, opts)
  value = this.codec.encodeValue(value, opts)
  this.db.put(key, value, opts, cb)
}

DB.prototype._get = function (key, opts, cb) {
  var self = this
  key = this.codec.encodeKey(key, opts)
  opts.asBuffer = this.codec.valueAsBuffer(opts)
  this.db.get(key, opts, function (err, value) {
    if (err) return cb(err)
    try {
      value = self.codec.decodeValue(value, opts)
    } catch (err) {
      return cb(new EncodingError(err))
    }
    cb(null, value)
  })
}

DB.prototype._del = function (key, opts, cb) {
  key = this.codec.encodeKey(key, opts)
  this.db.del(key, opts, cb)
}

DB.prototype._chainedBatch = function () {
  return new Batch(this)
}

DB.prototype._batch = function (ops, opts, cb) {
  ops = this.codec.encodeBatch(ops, opts)
  this.db.batch(ops, opts, cb)
}

DB.prototype._iterator = function (opts) {
  opts.keyAsBuffer = this.codec.keyAsBuffer(opts)
  opts.valueAsBuffer = this.codec.valueAsBuffer(opts)
  return new Iterator(this, opts)
}

DB.prototype.approximateSize = function (start, end, opts, cb) {
  start = this.codec.encodeKey(start, opts)
  end = this.codec.encodeKey(end, opts)
  return this.db.approximateSize(start, end, opts, cb)
}

function Iterator (db, opts) {
  AbstractIterator.call(this, db)
  this.codec = db.codec
  this.keys = opts.keys
  this.values = opts.values
  this.opts = this.codec.encodeLtgt(opts)
  this.it = db.db.iterator(this.opts)
}

inherits(Iterator, AbstractIterator)

Iterator.prototype._next = function (cb) {
  var self = this
  this.it.next(function (err, key, value) {
    if (err) return cb(err)
    try {
      if (self.keys && typeof key !== 'undefined') {
        key = self.codec.decodeKey(key, self.opts)
      } else {
        key = undefined
      }

      if (self.values && typeof value !== 'undefined') {
        value = self.codec.decodeValue(value, self.opts)
      } else {
        value = undefined
      }
    } catch (err) {
      return cb(new EncodingError(err))
    }
    cb(null, key, value)
  })
}

Iterator.prototype._seek = function (key) {
  key = this.codec.encodeKey(key, this.opts)
  this.it.seek(key)
}

Iterator.prototype._end = function (cb) {
  this.it.end(cb)
}

function Batch (db, codec) {
  AbstractChainedBatch.call(this, db)
  this.codec = db.codec
  this.batch = db.db.batch()
}

inherits(Batch, AbstractChainedBatch)

Batch.prototype._put = function (key, value) {
  key = this.codec.encodeKey(key)
  value = this.codec.encodeValue(value)
  this.batch.put(key, value)
}

Batch.prototype._del = function (key) {
  key = this.codec.encodeKey(key)
  this.batch.del(key)
}

Batch.prototype._clear = function () {
  this.batch.clear()
}

Batch.prototype._write = function (opts, cb) {
  this.batch.write(opts, cb)
}

},
"45XtBV6cxlTt8Muqcbwg3PeklxoRKZBXz3VXbZNnATs=":
function (require, module, exports, __dirname, __filename) {

module.exports = function (values) {
  return new ValueStream(values)
}

function ValueStream (values) {
//  if(!(this instanceof ValueStream)) return new ValueStream(values)
  this._i = 0
  this._values = values
  this.paused = true
  this.sink = null //no source, because this is the source.
}

ValueStream.prototype.resume = function () {
  while(!this.sink.paused && !(this.ended || (this.ended = this._i >= this._values.length)))
    this.sink.write(this._values[this._i++])

  if(this.ended && !this.sink.ended)
    this.sink.end()
}

ValueStream.prototype.abort = function (err) {
  this.sink.end(this.ended = err || true)
}

ValueStream.prototype.pipe = require('../pipe')

},
"4EadS4P2unZLFfgOF2a3XBNvv/aPBI9MBQ8LHH8GX2k=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const kDone = Symbol('kDone');
const kRun = Symbol('kRun');

/**
 * A very simple job queue with adjustable concurrency. Adapted from
 * https://github.com/STRML/async-limiter
 */
class Limiter {
  /**
   * Creates a new `Limiter`.
   *
   * @param {Number} [concurrency=Infinity] The maximum number of jobs allowed
   *     to run concurrently
   */
  constructor(concurrency) {
    this[kDone] = () => {
      this.pending--;
      this[kRun]();
    };
    this.concurrency = concurrency || Infinity;
    this.jobs = [];
    this.pending = 0;
  }

  /**
   * Adds a job to the queue.
   *
   * @param {Function} job The job to run
   * @public
   */
  add(job) {
    this.jobs.push(job);
    this[kRun]();
  }

  /**
   * Removes a job from the queue and runs it if possible.
   *
   * @private
   */
  [kRun]() {
    if (this.pending === this.concurrency) return;

    if (this.jobs.length) {
      const job = this.jobs.shift();

      this.pending++;
      job(this[kDone]);
    }
  }
}

module.exports = Limiter;

},
"4NofZKFbc2vMn7lZ0/YC8QunKMECU0DsGy7LKBDXfA0=":
function (require, module, exports, __dirname, __filename) {

var ThroughStream = require('./through')

function FilterStream(fn) {
  if(!(this instanceof FilterStream)) return new FilterStream(fn)
  ThroughStream.call(this)
  this.fn = fn
}

FilterStream.prototype = new ThroughStream()

FilterStream.prototype.write = function (data) {
  if(this.fn(data)) this.sink.write(data)
  this.paused = this.sink.paused
}

module.exports = FilterStream

},
"4ZQIBPA8MEvS5nlNTbzX9lMWLK5xzfIamk/MRkI9EfU=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const ref = require('ssb-ref');
const { where, votesFor, live, toPullStream } = require('ssb-db2/operators');
const THUMBS_UP_UNICODE = '\ud83d\udc4d';
function collectUniqueAuthors() {
    const theMap = new Map();
    return function sink(read) {
        const outputSource = (abort, cb) => {
            read(abort, function next(endOrErr, msg) {
                var _a, _b;
                if (endOrErr) {
                    cb(endOrErr);
                    return;
                }
                if (!msg ||
                    msg.sync ||
                    !((_a = msg.value) === null || _a === void 0 ? void 0 : _a.content) ||
                    msg.value.content.type !== 'vote' ||
                    !msg.value.content.vote) {
                    read(abort, next);
                    return;
                }
                const author = msg.value.author;
                const voteValue = msg.value.content.vote.value;
                const voteExpression = (_b = msg.value.content.vote.expression) !== null && _b !== void 0 ? _b : THUMBS_UP_UNICODE;
                if (voteValue < 1 && theMap.has(author)) {
                    theMap.delete(author);
                }
                else if (voteValue >= 1) {
                    // this delete is used on purpose, to reset the insertion order
                    theMap.delete(author);
                    theMap.set(author, voteExpression);
                }
                else {
                    read(abort, next);
                    return;
                }
                cb(endOrErr, [...theMap]);
            });
        };
        return outputSource;
    };
}
module.exports = {
    name: 'votes',
    version: '1.0.0',
    manifest: {
        voterStream: 'source',
    },
    permissions: {
        master: {
            allow: ['voterStream'],
        },
    },
    init: function init(ssb) {
        return {
            voterStream: function voterStream(msgId) {
                if (!ref.isLink(msgId))
                    throw new Error('A message id must be specified');
                return pull(ssb.db.query(where(votesFor(msgId)), live({ old: true }), toPullStream()), collectUniqueAuthors());
            },
        };
    },
};
//# sourceMappingURL=votes.js.map
},
"4kPe2IgUGNpjZZAqP9pMFZZXky9hiXPjeJhPYZ/bkLQ=":
function (require, module, exports, __dirname, __filename) {
'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});

var _buffer = require('buffer');

var _create_buffer = require('./create_buffer');

var _create_buffer2 = _interopRequireDefault(_create_buffer);

var _define_crc = require('./define_crc');

var _define_crc2 = _interopRequireDefault(_define_crc);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

// Generated by `./pycrc.py --algorithm=table-driven --model=crc-32 --generate=c`
// prettier-ignore
var TABLE = [0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91, 0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b, 0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599, 0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924, 0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190, 0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433, 0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01, 0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950, 0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f, 0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1, 0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5, 0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236, 0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713, 0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777, 0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc, 0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9, 0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d];

if (typeof Int32Array !== 'undefined') TABLE = new Int32Array(TABLE);

var crc32 = (0, _define_crc2.default)('crc-32', function (buf, previous) {
  if (!_buffer.Buffer.isBuffer(buf)) buf = (0, _create_buffer2.default)(buf);

  var crc = previous === 0 ? 0 : ~~previous ^ -1;

  for (var index = 0; index < buf.length; index++) {
    var byte = buf[index];
    crc = TABLE[(crc ^ byte) & 0xff] ^ crc >>> 8;
  }

  return crc ^ -1;
});

exports.default = crc32;

},
"4z6gmKkdLEG+iG+7zsrLl5n+GD2KRG8TikeGyz2AmAI=":
function (require, module, exports, __dirname, __filename) {
var wrappy = require('wrappy')
var reqs = Object.create(null)
var once = require('once')

module.exports = wrappy(inflight)

function inflight (key, cb) {
  if (reqs[key]) {
    reqs[key].push(cb)
    return null
  } else {
    reqs[key] = [cb]
    return makeres(key)
  }
}

function makeres (key) {
  return once(function RES () {
    var cbs = reqs[key]
    var len = cbs.length
    var args = slice(arguments)

    // XXX It's somewhat ambiguous whether a new callback added in this
    // pass should be queued for later execution if something in the
    // list of callbacks throws, or if it should just be discarded.
    // However, it's such an edge case that it hardly matters, and either
    // choice is likely as surprising as the other.
    // As it happens, we do go ahead and schedule it for later execution.
    try {
      for (var i = 0; i < len; i++) {
        cbs[i].apply(null, args)
      }
    } finally {
      if (cbs.length > len) {
        // added more in the interim.
        // de-zalgo, just in case, but don't call again.
        cbs.splice(0, len)
        process.nextTick(function () {
          RES.apply(null, args)
        })
      } else {
        delete reqs[key]
      }
    }
  })
}

function slice (args) {
  var length = args.length
  var array = []

  for (var i = 0; i < length; i++) array[i] = args[i]
  return array
}

},
"5Izx0x/zPg453t8XlxmL0E8Igqu+NUJLgaMFp3rVBEI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fromBuffer = exports.fromStream = exports.EndOfStreamError = void 0;
const ReadStreamTokenizer_1 = require("./ReadStreamTokenizer");
const BufferTokenizer_1 = require("./BufferTokenizer");
var peek_readable_1 = require("peek-readable");
Object.defineProperty(exports, "EndOfStreamError", { enumerable: true, get: function () { return peek_readable_1.EndOfStreamError; } });
/**
 * Construct ReadStreamTokenizer from given Stream.
 * Will set fileSize, if provided given Stream has set the .path property/
 * @param stream - Read from Node.js Stream.Readable
 * @param fileInfo - Pass the file information, like size and MIME-type of the correspnding stream.
 * @returns ReadStreamTokenizer
 */
function fromStream(stream, fileInfo) {
    fileInfo = fileInfo ? fileInfo : {};
    return new ReadStreamTokenizer_1.ReadStreamTokenizer(stream, fileInfo);
}
exports.fromStream = fromStream;
/**
 * Construct ReadStreamTokenizer from given Buffer.
 * @param uint8Array - Uint8Array to tokenize
 * @param fileInfo - Pass additional file information to the tokenizer
 * @returns BufferTokenizer
 */
function fromBuffer(uint8Array, fileInfo) {
    return new BufferTokenizer_1.BufferTokenizer(uint8Array, fileInfo);
}
exports.fromBuffer = fromBuffer;

},
"5KnBJt9hi41Znz2CpbpdCEtdPcMbcsNjMCHI1RgKrow=":
function (require, module, exports, __dirname, __filename) {
var Blocks = require('aligned-block-file')
var createFrame = require('./frame/recoverable')
var Cache = require('hashlru')
var inject = require('./inject')
function id (e) { return e }
function isNumber(n) { return 'number' == typeof n && !isNaN(n) }

module.exports = function (file, opts) {
  if (!opts) opts = {}
  //file, blocks, frame, codec
  if (typeof opts !== 'object')
    opts = legacy.apply(null, arguments)

  var blockSize = opts.blockSize || 1024*16
  var codec = opts.codec || {encode: id, decode: id, buffer: true}
  var cache = opts.cache || Cache(1024)
  var offsetCodec = opts.offsetCodec || 32

  var blocks = Blocks(file, blockSize, opts.flags, cache)
  var frame = createFrame(blocks, blockSize, offsetCodec)
  return inject(blocks, frame, codec, file)
}

var warned = false
var msg = 'flumelog-offset: blockSize and codec params moved into an object. https://github.com/flumedb/flumelog-offset'
function legacy (file, blockSize, codec) {
  if (!warned) warned = true, console.warn(msg)
  if (!isNumber(blockSize)) codec = blockSize, blockSize = undefined
  return {blockSize: blockSize, codec: codec}
}



},
"5X5j7KPAcgFaVohmaU/64/2n+E9hM1rokDb3tZfWKxQ=":
function (require, module, exports, __dirname, __filename) {

module.exports = function split (data, max) {

  if(max <= 0) throw new Error('cannot split into zero (or smaller) length buffers')

  if(data.length <= max)
    return [data]
  var out = [], len = 0

  while(len < data.length) {
    out.push(data.slice(len, Math.min(len + max, data.length)))
    len += max
  }

  return out
}


},
"5XU3E7VBT7wkB2QI49GA6vwf8P/E4Hvgd7C9wBJktKA=":
function (require, module, exports, __dirname, __filename) {
var WriteError = require('level-errors').WriteError
var promisify = require('./promisify')
var getCallback = require('./common').getCallback
var getOptions = require('./common').getOptions

function Batch (levelup) {
  this._levelup = levelup
  this.batch = levelup.db.batch()
  this.ops = []
  this.length = 0
}

Batch.prototype.put = function (key, value) {
  try {
    this.batch.put(key, value)
  } catch (e) {
    throw new WriteError(e)
  }

  this.ops.push({ type: 'put', key: key, value: value })
  this.length++

  return this
}

Batch.prototype.del = function (key) {
  try {
    this.batch.del(key)
  } catch (err) {
    throw new WriteError(err)
  }

  this.ops.push({ type: 'del', key: key })
  this.length++

  return this
}

Batch.prototype.clear = function () {
  try {
    this.batch.clear()
  } catch (err) {
    throw new WriteError(err)
  }

  this.ops = []
  this.length = 0

  return this
}

Batch.prototype.write = function (options, callback) {
  var levelup = this._levelup
  var ops = this.ops
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  options = getOptions(options)

  try {
    this.batch.write(options, function (err) {
      if (err) { return callback(new WriteError(err)) }
      levelup.emit('batch', ops)
      callback()
    })
  } catch (err) {
    throw new WriteError(err)
  }

  return promise
}

module.exports = Batch

},
"5ZjD3xAHNQn+H09e2ZrAmPZ1341nHZB7BUQ9fTz7bTg=":
function (require, module, exports, __dirname, __filename) {
var EventEmitter = require('events').EventEmitter
var inherits = require('util').inherits
var extend = require('xtend')
var DeferredLevelDOWN = require('deferred-leveldown')
var IteratorStream = require('level-iterator-stream')
var Batch = require('./batch')
var errors = require('level-errors')
var supports = require('level-supports')
var assert = require('assert')
var promisify = require('./promisify')
var getCallback = require('./common').getCallback
var getOptions = require('./common').getOptions

var WriteError = errors.WriteError
var ReadError = errors.ReadError
var NotFoundError = errors.NotFoundError
var OpenError = errors.OpenError
var InitializationError = errors.InitializationError

// Possible AbstractLevelDOWN#status values:
//  - 'new'     - newly created, not opened or closed
//  - 'opening' - waiting for the database to be opened, post open()
//  - 'open'    - successfully opened the database, available for use
//  - 'closing' - waiting for the database to be closed, post close()
//  - 'closed'  - database has been successfully closed, should not be
//                 used except for another open() operation

function LevelUP (db, options, callback) {
  if (!(this instanceof LevelUP)) {
    return new LevelUP(db, options, callback)
  }

  var error
  var self = this

  EventEmitter.call(this)
  this.setMaxListeners(Infinity)

  if (typeof options === 'function') {
    callback = options
    options = {}
  }

  options = options || {}

  if (!db || typeof db !== 'object') {
    error = new InitializationError('First argument must be an abstract-leveldown compliant store')
    if (typeof callback === 'function') {
      return process.nextTick(callback, error)
    }
    throw error
  }

  assert.strictEqual(typeof db.status, 'string', '.status required, old abstract-leveldown')

  this.options = getOptions(options)
  this._db = db
  this.db = new DeferredLevelDOWN(db)
  this.open(callback || function (err) {
    if (err) self.emit('error', err)
  })

  // Create manifest based on deferred-leveldown's
  this.supports = supports(this.db.supports, {
    status: false,
    deferredOpen: true,
    openCallback: true,
    promises: true,
    streams: true
  })

  // Experimental: enrich levelup interface
  Object.keys(this.supports.additionalMethods).forEach(function (method) {
    if (this[method] != null) return

    // Don't do this.db[method].bind() because this.db is dynamic.
    this[method] = function () {
      return this.db[method].apply(this.db, arguments)
    }
  }, this)
}

LevelUP.prototype.emit = EventEmitter.prototype.emit
LevelUP.prototype.once = EventEmitter.prototype.once
inherits(LevelUP, EventEmitter)

LevelUP.prototype.open = function (opts, callback) {
  var self = this
  var promise

  if (typeof opts === 'function') {
    callback = opts
    opts = null
  }

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (!opts) {
    opts = this.options
  }

  if (this.isOpen()) {
    process.nextTick(callback, null, self)
    return promise
  }

  if (this._isOpening()) {
    this.once('open', function () { callback(null, self) })
    return promise
  }

  this.emit('opening')

  this.db.open(opts, function (err) {
    if (err) {
      return callback(new OpenError(err))
    }
    self.db = self._db
    callback(null, self)
    self.emit('open')
    self.emit('ready')
  })

  return promise
}

LevelUP.prototype.close = function (callback) {
  var self = this
  var promise

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (this.isOpen()) {
    this.db.close(function () {
      self.emit('closed')
      callback.apply(null, arguments)
    })
    this.emit('closing')
    this.db = new DeferredLevelDOWN(this._db)
  } else if (this.isClosed()) {
    process.nextTick(callback)
  } else if (this.db.status === 'closing') {
    this.once('closed', callback)
  } else if (this._isOpening()) {
    this.once('open', function () {
      self.close(callback)
    })
  }

  return promise
}

LevelUP.prototype.isOpen = function () {
  return this.db.status === 'open'
}

LevelUP.prototype._isOpening = function () {
  return this.db.status === 'opening'
}

LevelUP.prototype.isClosed = function () {
  return (/^clos|new/).test(this.db.status)
}

LevelUP.prototype.get = function (key, options, callback) {
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.get(key, options, function (err, value) {
    if (err) {
      if ((/notfound/i).test(err) || err.notFound) {
        err = new NotFoundError('Key not found in database [' + key + ']', err)
      } else {
        err = new ReadError(err)
      }
      return callback(err)
    }
    callback(null, value)
  })

  return promise
}

LevelUP.prototype.put = function (key, value, options, callback) {
  var self = this
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.put(key, value, options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('put', key, value)
    callback()
  })

  return promise
}

LevelUP.prototype.del = function (key, options, callback) {
  var self = this
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.del(key, options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('del', key)
    callback()
  })

  return promise
}

LevelUP.prototype.batch = function (arr, options, callback) {
  if (!arguments.length) {
    return new Batch(this)
  }

  var self = this
  var promise

  if (typeof arr === 'function') callback = arr
  else callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.batch(arr, options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('batch', arr)
    callback()
  })

  return promise
}

LevelUP.prototype.iterator = function (options) {
  return this.db.iterator(options)
}

LevelUP.prototype.clear = function (options, callback) {
  var self = this
  var promise

  callback = getCallback(options, callback)
  options = getOptions(options)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) {
    return promise
  }

  this.db.clear(options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('clear', options)
    callback()
  })

  return promise
}

LevelUP.prototype.readStream =
LevelUP.prototype.createReadStream = function (options) {
  options = extend({ keys: true, values: true }, options)
  if (typeof options.limit !== 'number') { options.limit = -1 }
  return new IteratorStream(this.db.iterator(options), options)
}

LevelUP.prototype.keyStream =
LevelUP.prototype.createKeyStream = function (options) {
  return this.createReadStream(extend(options, { keys: true, values: false }))
}

LevelUP.prototype.valueStream =
LevelUP.prototype.createValueStream = function (options) {
  return this.createReadStream(extend(options, { keys: false, values: true }))
}

LevelUP.prototype.toString = function () {
  return 'LevelUP'
}

LevelUP.prototype.type = 'levelup'

function maybeError (db, callback) {
  if (!db._isOpening() && !db.isOpen()) {
    process.nextTick(callback, new ReadError('Database is not open'))
    return true
  }
}

LevelUP.errors = errors
module.exports = LevelUP.default = LevelUP

},
"5cfvpgW0NF9XIpq727oLs8A9i4N5lZiBMtgMuvj2Ijk=":
function (require, module, exports, __dirname, __filename) {
var list = require('continuable-list')
var hash = require('continuable-hash')

module.exports = function (obj, cb) {
  if(Array.isArray(obj))
    return list(obj, cb)
  else if('object' === typeof obj)
    return hash(obj, cb)
  else
    return list([].slice.call(arguments))
}

},
"5g9p49oc/65drSUpDWPyOm4FClhynavE9ZzCRG2W63U=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var ip = exports;
var Buffer = require('buffer').Buffer;
var os = require('os');

ip.toBuffer = function(ip, buff, offset) {
  offset = ~~offset;

  var result;

  if (this.isV4Format(ip)) {
    result = buff || new Buffer(offset + 4);
    ip.split(/\./g).map(function(byte) {
      result[offset++] = parseInt(byte, 10) & 0xff;
    });
  } else if (this.isV6Format(ip)) {
    var sections = ip.split(':', 8);

    var i;
    for (i = 0; i < sections.length; i++) {
      var isv4 = this.isV4Format(sections[i]);
      var v4Buffer;

      if (isv4) {
        v4Buffer = this.toBuffer(sections[i]);
        sections[i] = v4Buffer.slice(0, 2).toString('hex');
      }

      if (v4Buffer && ++i < 8) {
        sections.splice(i, 0, v4Buffer.slice(2, 4).toString('hex'));
      }
    }

    if (sections[0] === '') {
      while (sections.length < 8) sections.unshift('0');
    } else if (sections[sections.length - 1] === '') {
      while (sections.length < 8) sections.push('0');
    } else if (sections.length < 8) {
      for (i = 0; i < sections.length && sections[i] !== ''; i++);
      var argv = [ i, 1 ];
      for (i = 9 - sections.length; i > 0; i--) {
        argv.push('0');
      }
      sections.splice.apply(sections, argv);
    }

    result = buff || new Buffer(offset + 16);
    for (i = 0; i < sections.length; i++) {
      var word = parseInt(sections[i], 16);
      result[offset++] = (word >> 8) & 0xff;
      result[offset++] = word & 0xff;
    }
  }

  if (!result) {
    throw Error('Invalid ip address: ' + ip);
  }

  return result;
};

ip.toString = function(buff, offset, length) {
  offset = ~~offset;
  length = length || (buff.length - offset);

  var result = [];
  if (length === 4) {
    // IPv4
    for (var i = 0; i < length; i++) {
      result.push(buff[offset + i]);
    }
    result = result.join('.');
  } else if (length === 16) {
    // IPv6
    for (var i = 0; i < length; i += 2) {
      result.push(buff.readUInt16BE(offset + i).toString(16));
    }
    result = result.join(':');
    result = result.replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3');
    result = result.replace(/:{3,4}/, '::');
  }

  return result;
};

var ipv4Regex = /^(\d{1,3}\.){3,3}\d{1,3}$/;
var ipv6Regex =
    /^(::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?$/i;

ip.isV4Format = function(ip) {
  return ipv4Regex.test(ip);
};

ip.isV6Format = function(ip) {
  return ipv6Regex.test(ip);
};
function _normalizeFamily(family) {
  return family ? family.toLowerCase() : 'ipv4';
}

ip.fromPrefixLen = function(prefixlen, family) {
  if (prefixlen > 32) {
    family = 'ipv6';
  } else {
    family = _normalizeFamily(family);
  }

  var len = 4;
  if (family === 'ipv6') {
    len = 16;
  }
  var buff = new Buffer(len);

  for (var i = 0, n = buff.length; i < n; ++i) {
    var bits = 8;
    if (prefixlen < 8) {
      bits = prefixlen;
    }
    prefixlen -= bits;

    buff[i] = ~(0xff >> bits) & 0xff;
  }

  return ip.toString(buff);
};

ip.mask = function(addr, mask) {
  addr = ip.toBuffer(addr);
  mask = ip.toBuffer(mask);

  var result = new Buffer(Math.max(addr.length, mask.length));

  var i = 0;
  // Same protocol - do bitwise and
  if (addr.length === mask.length) {
    for (i = 0; i < addr.length; i++) {
      result[i] = addr[i] & mask[i];
    }
  } else if (mask.length === 4) {
    // IPv6 address and IPv4 mask
    // (Mask low bits)
    for (i = 0; i < mask.length; i++) {
      result[i] = addr[addr.length - 4  + i] & mask[i];
    }
  } else {
    // IPv6 mask and IPv4 addr
    for (var i = 0; i < result.length - 6; i++) {
      result[i] = 0;
    }

    // ::ffff:ipv4
    result[10] = 0xff;
    result[11] = 0xff;
    for (i = 0; i < addr.length; i++) {
      result[i + 12] = addr[i] & mask[i + 12];
    }
    i = i + 12;
  }
  for (; i < result.length; i++)
    result[i] = 0;

  return ip.toString(result);
};

ip.cidr = function(cidrString) {
  var cidrParts = cidrString.split('/');

  var addr = cidrParts[0];
  if (cidrParts.length !== 2)
    throw new Error('invalid CIDR subnet: ' + addr);

  var mask = ip.fromPrefixLen(parseInt(cidrParts[1], 10));

  return ip.mask(addr, mask);
};

ip.subnet = function(addr, mask) {
  var networkAddress = ip.toLong(ip.mask(addr, mask));

  // Calculate the mask's length.
  var maskBuffer = ip.toBuffer(mask);
  var maskLength = 0;

  for (var i = 0; i < maskBuffer.length; i++) {
    if (maskBuffer[i] === 0xff) {
      maskLength += 8;
    } else {
      var octet = maskBuffer[i] & 0xff;
      while (octet) {
        octet = (octet << 1) & 0xff;
        maskLength++;
      }
    }
  }

  var numberOfAddresses = Math.pow(2, 32 - maskLength);

  return {
    networkAddress: ip.fromLong(networkAddress),
    firstAddress: numberOfAddresses <= 2 ?
                    ip.fromLong(networkAddress) :
                    ip.fromLong(networkAddress + 1),
    lastAddress: numberOfAddresses <= 2 ?
                    ip.fromLong(networkAddress + numberOfAddresses - 1) :
                    ip.fromLong(networkAddress + numberOfAddresses - 2),
    broadcastAddress: ip.fromLong(networkAddress + numberOfAddresses - 1),
    subnetMask: mask,
    subnetMaskLength: maskLength,
    numHosts: numberOfAddresses <= 2 ?
                numberOfAddresses : numberOfAddresses - 2,
    length: numberOfAddresses,
    contains: function(other) {
      return networkAddress === ip.toLong(ip.mask(other, mask));
    }
  };
};

ip.cidrSubnet = function(cidrString) {
  var cidrParts = cidrString.split('/');

  var addr = cidrParts[0];
  if (cidrParts.length !== 2)
    throw new Error('invalid CIDR subnet: ' + addr);

  var mask = ip.fromPrefixLen(parseInt(cidrParts[1], 10));

  return ip.subnet(addr, mask);
};

ip.not = function(addr) {
  var buff = ip.toBuffer(addr);
  for (var i = 0; i < buff.length; i++) {
    buff[i] = 0xff ^ buff[i];
  }
  return ip.toString(buff);
};

ip.or = function(a, b) {
  a = ip.toBuffer(a);
  b = ip.toBuffer(b);

  // same protocol
  if (a.length === b.length) {
    for (var i = 0; i < a.length; ++i) {
      a[i] |= b[i];
    }
    return ip.toString(a);

  // mixed protocols
  } else {
    var buff = a;
    var other = b;
    if (b.length > a.length) {
      buff = b;
      other = a;
    }

    var offset = buff.length - other.length;
    for (var i = offset; i < buff.length; ++i) {
      buff[i] |= other[i - offset];
    }

    return ip.toString(buff);
  }
};

ip.isEqual = function(a, b) {
  a = ip.toBuffer(a);
  b = ip.toBuffer(b);

  // Same protocol
  if (a.length === b.length) {
    for (var i = 0; i < a.length; i++) {
      if (a[i] !== b[i]) return false;
    }
    return true;
  }

  // Swap
  if (b.length === 4) {
    var t = b;
    b = a;
    a = t;
  }

  // a - IPv4, b - IPv6
  for (var i = 0; i < 10; i++) {
    if (b[i] !== 0) return false;
  }

  var word = b.readUInt16BE(10);
  if (word !== 0 && word !== 0xffff) return false;

  for (var i = 0; i < 4; i++) {
    if (a[i] !== b[i + 12]) return false;
  }

  return true;
};

ip.isPrivate = function(addr) {
  return /^(::f{4}:)?10\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/i
      .test(addr) ||
    /^(::f{4}:)?192\.168\.([0-9]{1,3})\.([0-9]{1,3})$/i.test(addr) ||
    /^(::f{4}:)?172\.(1[6-9]|2\d|30|31)\.([0-9]{1,3})\.([0-9]{1,3})$/i
      .test(addr) ||
    /^(::f{4}:)?127\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/i.test(addr) ||
    /^(::f{4}:)?169\.254\.([0-9]{1,3})\.([0-9]{1,3})$/i.test(addr) ||
    /^f[cd][0-9a-f]{2}:/i.test(addr) ||
    /^fe80:/i.test(addr) ||
    /^::1$/.test(addr) ||
    /^::$/.test(addr);
};

ip.isPublic = function(addr) {
  return !ip.isPrivate(addr);
};

ip.isLoopback = function(addr) {
  return /^(::f{4}:)?127\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})/
      .test(addr) ||
    /^fe80::1$/.test(addr) ||
    /^::1$/.test(addr) ||
    /^::$/.test(addr);
};

ip.loopback = function(family) {
  //
  // Default to `ipv4`
  //
  family = _normalizeFamily(family);

  if (family !== 'ipv4' && family !== 'ipv6') {
    throw new Error('family must be ipv4 or ipv6');
  }

  return family === 'ipv4' ? '127.0.0.1' : 'fe80::1';
};

//
// ### function address (name, family)
// #### @name {string|'public'|'private'} **Optional** Name or security
//      of the network interface.
// #### @family {ipv4|ipv6} **Optional** IP family of the address (defaults
//      to ipv4).
//
// Returns the address for the network interface on the current system with
// the specified `name`:
//   * String: First `family` address of the interface.
//             If not found see `undefined`.
//   * 'public': the first public ip address of family.
//   * 'private': the first private ip address of family.
//   * undefined: First address with `ipv4` or loopback address `127.0.0.1`.
//
ip.address = function(name, family) {
  var interfaces = os.networkInterfaces();
  var all;

  //
  // Default to `ipv4`
  //
  family = _normalizeFamily(family);

  //
  // If a specific network interface has been named,
  // return the address.
  //
  if (name && name !== 'private' && name !== 'public') {
    var res = interfaces[name].filter(function(details) {
      var itemFamily = details.family.toLowerCase();
      return itemFamily === family;
    });
    if (res.length === 0)
      return undefined;
    return res[0].address;
  }

  var all = Object.keys(interfaces).map(function (nic) {
    //
    // Note: name will only be `public` or `private`
    // when this is called.
    //
    var addresses = interfaces[nic].filter(function (details) {
      details.family = details.family.toLowerCase();
      if (details.family !== family || ip.isLoopback(details.address)) {
        return false;
      } else if (!name) {
        return true;
      }

      return name === 'public' ? ip.isPrivate(details.address) :
          ip.isPublic(details.address);
    });

    return addresses.length ? addresses[0].address : undefined;
  }).filter(Boolean);

  return !all.length ? ip.loopback(family) : all[0];
};

ip.toLong = function(ip) {
  var ipl = 0;
  ip.split('.').forEach(function(octet) {
    ipl <<= 8;
    ipl += parseInt(octet);
  });
  return(ipl >>> 0);
};

ip.fromLong = function(ipl) {
  return ((ipl >>> 24) + '.' +
      (ipl >> 16 & 255) + '.' +
      (ipl >> 8 & 255) + '.' +
      (ipl & 255) );
};

},
"5t3rfA/2J7Ac6pY5J2pu4blMNng8RNnmy3rJwK75f/I=":
function (require, module, exports, __dirname, __filename) {
'use strict';

//load websocket library if we are not in the browser
var WebSocket = require('./web-socket')
var duplex = require('./duplex')
var wsurl = require('./ws-url')

function isFunction (f) {
  return 'function' === typeof f
}

module.exports = function (addr, opts) {
  if (isFunction(opts)) opts = {onConnect: opts}

  var location = typeof window === 'undefined' ? {} : window.location

  var url = wsurl(addr, location)
  var socket = new WebSocket(url)

  var stream = duplex(socket, opts)
  stream.remoteAddress = url
  stream.close = function (cb) {
    if (isFunction(cb)) {
      socket.addEventListener('close', cb)
    }
    socket.close()
  }

  socket.addEventListener('open', function (e) {
    if (opts && isFunction(opts.onConnect)) {
      opts.onConnect(null, stream)
    }
  })

  return stream
}

module.exports.connect = module.exports

},
"5vFqCwpK2l4rGECYPd1b0hXUg9v0N3NaPCgTv770S8Y=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "abaisser",
    "abandon",
    "abdiquer",
    "abeille",
    "abolir",
    "aborder",
    "aboutir",
    "aboyer",
    "abrasif",
    "abreuver",
    "abriter",
    "abroger",
    "abrupt",
    "absence",
    "absolu",
    "absurde",
    "abusif",
    "abyssal",
    "académie",
    "acajou",
    "acarien",
    "accabler",
    "accepter",
    "acclamer",
    "accolade",
    "accroche",
    "accuser",
    "acerbe",
    "achat",
    "acheter",
    "aciduler",
    "acier",
    "acompte",
    "acquérir",
    "acronyme",
    "acteur",
    "actif",
    "actuel",
    "adepte",
    "adéquat",
    "adhésif",
    "adjectif",
    "adjuger",
    "admettre",
    "admirer",
    "adopter",
    "adorer",
    "adoucir",
    "adresse",
    "adroit",
    "adulte",
    "adverbe",
    "aérer",
    "aéronef",
    "affaire",
    "affecter",
    "affiche",
    "affreux",
    "affubler",
    "agacer",
    "agencer",
    "agile",
    "agiter",
    "agrafer",
    "agréable",
    "agrume",
    "aider",
    "aiguille",
    "ailier",
    "aimable",
    "aisance",
    "ajouter",
    "ajuster",
    "alarmer",
    "alchimie",
    "alerte",
    "algèbre",
    "algue",
    "aliéner",
    "aliment",
    "alléger",
    "alliage",
    "allouer",
    "allumer",
    "alourdir",
    "alpaga",
    "altesse",
    "alvéole",
    "amateur",
    "ambigu",
    "ambre",
    "aménager",
    "amertume",
    "amidon",
    "amiral",
    "amorcer",
    "amour",
    "amovible",
    "amphibie",
    "ampleur",
    "amusant",
    "analyse",
    "anaphore",
    "anarchie",
    "anatomie",
    "ancien",
    "anéantir",
    "angle",
    "angoisse",
    "anguleux",
    "animal",
    "annexer",
    "annonce",
    "annuel",
    "anodin",
    "anomalie",
    "anonyme",
    "anormal",
    "antenne",
    "antidote",
    "anxieux",
    "apaiser",
    "apéritif",
    "aplanir",
    "apologie",
    "appareil",
    "appeler",
    "apporter",
    "appuyer",
    "aquarium",
    "aqueduc",
    "arbitre",
    "arbuste",
    "ardeur",
    "ardoise",
    "argent",
    "arlequin",
    "armature",
    "armement",
    "armoire",
    "armure",
    "arpenter",
    "arracher",
    "arriver",
    "arroser",
    "arsenic",
    "artériel",
    "article",
    "aspect",
    "asphalte",
    "aspirer",
    "assaut",
    "asservir",
    "assiette",
    "associer",
    "assurer",
    "asticot",
    "astre",
    "astuce",
    "atelier",
    "atome",
    "atrium",
    "atroce",
    "attaque",
    "attentif",
    "attirer",
    "attraper",
    "aubaine",
    "auberge",
    "audace",
    "audible",
    "augurer",
    "aurore",
    "automne",
    "autruche",
    "avaler",
    "avancer",
    "avarice",
    "avenir",
    "averse",
    "aveugle",
    "aviateur",
    "avide",
    "avion",
    "aviser",
    "avoine",
    "avouer",
    "avril",
    "axial",
    "axiome",
    "badge",
    "bafouer",
    "bagage",
    "baguette",
    "baignade",
    "balancer",
    "balcon",
    "baleine",
    "balisage",
    "bambin",
    "bancaire",
    "bandage",
    "banlieue",
    "bannière",
    "banquier",
    "barbier",
    "baril",
    "baron",
    "barque",
    "barrage",
    "bassin",
    "bastion",
    "bataille",
    "bateau",
    "batterie",
    "baudrier",
    "bavarder",
    "belette",
    "bélier",
    "belote",
    "bénéfice",
    "berceau",
    "berger",
    "berline",
    "bermuda",
    "besace",
    "besogne",
    "bétail",
    "beurre",
    "biberon",
    "bicycle",
    "bidule",
    "bijou",
    "bilan",
    "bilingue",
    "billard",
    "binaire",
    "biologie",
    "biopsie",
    "biotype",
    "biscuit",
    "bison",
    "bistouri",
    "bitume",
    "bizarre",
    "blafard",
    "blague",
    "blanchir",
    "blessant",
    "blinder",
    "blond",
    "bloquer",
    "blouson",
    "bobard",
    "bobine",
    "boire",
    "boiser",
    "bolide",
    "bonbon",
    "bondir",
    "bonheur",
    "bonifier",
    "bonus",
    "bordure",
    "borne",
    "botte",
    "boucle",
    "boueux",
    "bougie",
    "boulon",
    "bouquin",
    "bourse",
    "boussole",
    "boutique",
    "boxeur",
    "branche",
    "brasier",
    "brave",
    "brebis",
    "brèche",
    "breuvage",
    "bricoler",
    "brigade",
    "brillant",
    "brioche",
    "brique",
    "brochure",
    "broder",
    "bronzer",
    "brousse",
    "broyeur",
    "brume",
    "brusque",
    "brutal",
    "bruyant",
    "buffle",
    "buisson",
    "bulletin",
    "bureau",
    "burin",
    "bustier",
    "butiner",
    "butoir",
    "buvable",
    "buvette",
    "cabanon",
    "cabine",
    "cachette",
    "cadeau",
    "cadre",
    "caféine",
    "caillou",
    "caisson",
    "calculer",
    "calepin",
    "calibre",
    "calmer",
    "calomnie",
    "calvaire",
    "camarade",
    "caméra",
    "camion",
    "campagne",
    "canal",
    "caneton",
    "canon",
    "cantine",
    "canular",
    "capable",
    "caporal",
    "caprice",
    "capsule",
    "capter",
    "capuche",
    "carabine",
    "carbone",
    "caresser",
    "caribou",
    "carnage",
    "carotte",
    "carreau",
    "carton",
    "cascade",
    "casier",
    "casque",
    "cassure",
    "causer",
    "caution",
    "cavalier",
    "caverne",
    "caviar",
    "cédille",
    "ceinture",
    "céleste",
    "cellule",
    "cendrier",
    "censurer",
    "central",
    "cercle",
    "cérébral",
    "cerise",
    "cerner",
    "cerveau",
    "cesser",
    "chagrin",
    "chaise",
    "chaleur",
    "chambre",
    "chance",
    "chapitre",
    "charbon",
    "chasseur",
    "chaton",
    "chausson",
    "chavirer",
    "chemise",
    "chenille",
    "chéquier",
    "chercher",
    "cheval",
    "chien",
    "chiffre",
    "chignon",
    "chimère",
    "chiot",
    "chlorure",
    "chocolat",
    "choisir",
    "chose",
    "chouette",
    "chrome",
    "chute",
    "cigare",
    "cigogne",
    "cimenter",
    "cinéma",
    "cintrer",
    "circuler",
    "cirer",
    "cirque",
    "citerne",
    "citoyen",
    "citron",
    "civil",
    "clairon",
    "clameur",
    "claquer",
    "classe",
    "clavier",
    "client",
    "cligner",
    "climat",
    "clivage",
    "cloche",
    "clonage",
    "cloporte",
    "cobalt",
    "cobra",
    "cocasse",
    "cocotier",
    "coder",
    "codifier",
    "coffre",
    "cogner",
    "cohésion",
    "coiffer",
    "coincer",
    "colère",
    "colibri",
    "colline",
    "colmater",
    "colonel",
    "combat",
    "comédie",
    "commande",
    "compact",
    "concert",
    "conduire",
    "confier",
    "congeler",
    "connoter",
    "consonne",
    "contact",
    "convexe",
    "copain",
    "copie",
    "corail",
    "corbeau",
    "cordage",
    "corniche",
    "corpus",
    "correct",
    "cortège",
    "cosmique",
    "costume",
    "coton",
    "coude",
    "coupure",
    "courage",
    "couteau",
    "couvrir",
    "coyote",
    "crabe",
    "crainte",
    "cravate",
    "crayon",
    "créature",
    "créditer",
    "crémeux",
    "creuser",
    "crevette",
    "cribler",
    "crier",
    "cristal",
    "critère",
    "croire",
    "croquer",
    "crotale",
    "crucial",
    "cruel",
    "crypter",
    "cubique",
    "cueillir",
    "cuillère",
    "cuisine",
    "cuivre",
    "culminer",
    "cultiver",
    "cumuler",
    "cupide",
    "curatif",
    "curseur",
    "cyanure",
    "cycle",
    "cylindre",
    "cynique",
    "daigner",
    "damier",
    "danger",
    "danseur",
    "dauphin",
    "débattre",
    "débiter",
    "déborder",
    "débrider",
    "débutant",
    "décaler",
    "décembre",
    "déchirer",
    "décider",
    "déclarer",
    "décorer",
    "décrire",
    "décupler",
    "dédale",
    "déductif",
    "déesse",
    "défensif",
    "défiler",
    "défrayer",
    "dégager",
    "dégivrer",
    "déglutir",
    "dégrafer",
    "déjeuner",
    "délice",
    "déloger",
    "demander",
    "demeurer",
    "démolir",
    "dénicher",
    "dénouer",
    "dentelle",
    "dénuder",
    "départ",
    "dépenser",
    "déphaser",
    "déplacer",
    "déposer",
    "déranger",
    "dérober",
    "désastre",
    "descente",
    "désert",
    "désigner",
    "désobéir",
    "dessiner",
    "destrier",
    "détacher",
    "détester",
    "détourer",
    "détresse",
    "devancer",
    "devenir",
    "deviner",
    "devoir",
    "diable",
    "dialogue",
    "diamant",
    "dicter",
    "différer",
    "digérer",
    "digital",
    "digne",
    "diluer",
    "dimanche",
    "diminuer",
    "dioxyde",
    "directif",
    "diriger",
    "discuter",
    "disposer",
    "dissiper",
    "distance",
    "divertir",
    "diviser",
    "docile",
    "docteur",
    "dogme",
    "doigt",
    "domaine",
    "domicile",
    "dompter",
    "donateur",
    "donjon",
    "donner",
    "dopamine",
    "dortoir",
    "dorure",
    "dosage",
    "doseur",
    "dossier",
    "dotation",
    "douanier",
    "double",
    "douceur",
    "douter",
    "doyen",
    "dragon",
    "draper",
    "dresser",
    "dribbler",
    "droiture",
    "duperie",
    "duplexe",
    "durable",
    "durcir",
    "dynastie",
    "éblouir",
    "écarter",
    "écharpe",
    "échelle",
    "éclairer",
    "éclipse",
    "éclore",
    "écluse",
    "école",
    "économie",
    "écorce",
    "écouter",
    "écraser",
    "écrémer",
    "écrivain",
    "écrou",
    "écume",
    "écureuil",
    "édifier",
    "éduquer",
    "effacer",
    "effectif",
    "effigie",
    "effort",
    "effrayer",
    "effusion",
    "égaliser",
    "égarer",
    "éjecter",
    "élaborer",
    "élargir",
    "électron",
    "élégant",
    "éléphant",
    "élève",
    "éligible",
    "élitisme",
    "éloge",
    "élucider",
    "éluder",
    "emballer",
    "embellir",
    "embryon",
    "émeraude",
    "émission",
    "emmener",
    "émotion",
    "émouvoir",
    "empereur",
    "employer",
    "emporter",
    "emprise",
    "émulsion",
    "encadrer",
    "enchère",
    "enclave",
    "encoche",
    "endiguer",
    "endosser",
    "endroit",
    "enduire",
    "énergie",
    "enfance",
    "enfermer",
    "enfouir",
    "engager",
    "engin",
    "englober",
    "énigme",
    "enjamber",
    "enjeu",
    "enlever",
    "ennemi",
    "ennuyeux",
    "enrichir",
    "enrobage",
    "enseigne",
    "entasser",
    "entendre",
    "entier",
    "entourer",
    "entraver",
    "énumérer",
    "envahir",
    "enviable",
    "envoyer",
    "enzyme",
    "éolien",
    "épaissir",
    "épargne",
    "épatant",
    "épaule",
    "épicerie",
    "épidémie",
    "épier",
    "épilogue",
    "épine",
    "épisode",
    "épitaphe",
    "époque",
    "épreuve",
    "éprouver",
    "épuisant",
    "équerre",
    "équipe",
    "ériger",
    "érosion",
    "erreur",
    "éruption",
    "escalier",
    "espadon",
    "espèce",
    "espiègle",
    "espoir",
    "esprit",
    "esquiver",
    "essayer",
    "essence",
    "essieu",
    "essorer",
    "estime",
    "estomac",
    "estrade",
    "étagère",
    "étaler",
    "étanche",
    "étatique",
    "éteindre",
    "étendoir",
    "éternel",
    "éthanol",
    "éthique",
    "ethnie",
    "étirer",
    "étoffer",
    "étoile",
    "étonnant",
    "étourdir",
    "étrange",
    "étroit",
    "étude",
    "euphorie",
    "évaluer",
    "évasion",
    "éventail",
    "évidence",
    "éviter",
    "évolutif",
    "évoquer",
    "exact",
    "exagérer",
    "exaucer",
    "exceller",
    "excitant",
    "exclusif",
    "excuse",
    "exécuter",
    "exemple",
    "exercer",
    "exhaler",
    "exhorter",
    "exigence",
    "exiler",
    "exister",
    "exotique",
    "expédier",
    "explorer",
    "exposer",
    "exprimer",
    "exquis",
    "extensif",
    "extraire",
    "exulter",
    "fable",
    "fabuleux",
    "facette",
    "facile",
    "facture",
    "faiblir",
    "falaise",
    "fameux",
    "famille",
    "farceur",
    "farfelu",
    "farine",
    "farouche",
    "fasciner",
    "fatal",
    "fatigue",
    "faucon",
    "fautif",
    "faveur",
    "favori",
    "fébrile",
    "féconder",
    "fédérer",
    "félin",
    "femme",
    "fémur",
    "fendoir",
    "féodal",
    "fermer",
    "féroce",
    "ferveur",
    "festival",
    "feuille",
    "feutre",
    "février",
    "fiasco",
    "ficeler",
    "fictif",
    "fidèle",
    "figure",
    "filature",
    "filetage",
    "filière",
    "filleul",
    "filmer",
    "filou",
    "filtrer",
    "financer",
    "finir",
    "fiole",
    "firme",
    "fissure",
    "fixer",
    "flairer",
    "flamme",
    "flasque",
    "flatteur",
    "fléau",
    "flèche",
    "fleur",
    "flexion",
    "flocon",
    "flore",
    "fluctuer",
    "fluide",
    "fluvial",
    "folie",
    "fonderie",
    "fongible",
    "fontaine",
    "forcer",
    "forgeron",
    "formuler",
    "fortune",
    "fossile",
    "foudre",
    "fougère",
    "fouiller",
    "foulure",
    "fourmi",
    "fragile",
    "fraise",
    "franchir",
    "frapper",
    "frayeur",
    "frégate",
    "freiner",
    "frelon",
    "frémir",
    "frénésie",
    "frère",
    "friable",
    "friction",
    "frisson",
    "frivole",
    "froid",
    "fromage",
    "frontal",
    "frotter",
    "fruit",
    "fugitif",
    "fuite",
    "fureur",
    "furieux",
    "furtif",
    "fusion",
    "futur",
    "gagner",
    "galaxie",
    "galerie",
    "gambader",
    "garantir",
    "gardien",
    "garnir",
    "garrigue",
    "gazelle",
    "gazon",
    "géant",
    "gélatine",
    "gélule",
    "gendarme",
    "général",
    "génie",
    "genou",
    "gentil",
    "géologie",
    "géomètre",
    "géranium",
    "germe",
    "gestuel",
    "geyser",
    "gibier",
    "gicler",
    "girafe",
    "givre",
    "glace",
    "glaive",
    "glisser",
    "globe",
    "gloire",
    "glorieux",
    "golfeur",
    "gomme",
    "gonfler",
    "gorge",
    "gorille",
    "goudron",
    "gouffre",
    "goulot",
    "goupille",
    "gourmand",
    "goutte",
    "graduel",
    "graffiti",
    "graine",
    "grand",
    "grappin",
    "gratuit",
    "gravir",
    "grenat",
    "griffure",
    "griller",
    "grimper",
    "grogner",
    "gronder",
    "grotte",
    "groupe",
    "gruger",
    "grutier",
    "gruyère",
    "guépard",
    "guerrier",
    "guide",
    "guimauve",
    "guitare",
    "gustatif",
    "gymnaste",
    "gyrostat",
    "habitude",
    "hachoir",
    "halte",
    "hameau",
    "hangar",
    "hanneton",
    "haricot",
    "harmonie",
    "harpon",
    "hasard",
    "hélium",
    "hématome",
    "herbe",
    "hérisson",
    "hermine",
    "héron",
    "hésiter",
    "heureux",
    "hiberner",
    "hibou",
    "hilarant",
    "histoire",
    "hiver",
    "homard",
    "hommage",
    "homogène",
    "honneur",
    "honorer",
    "honteux",
    "horde",
    "horizon",
    "horloge",
    "hormone",
    "horrible",
    "houleux",
    "housse",
    "hublot",
    "huileux",
    "humain",
    "humble",
    "humide",
    "humour",
    "hurler",
    "hydromel",
    "hygiène",
    "hymne",
    "hypnose",
    "idylle",
    "ignorer",
    "iguane",
    "illicite",
    "illusion",
    "image",
    "imbiber",
    "imiter",
    "immense",
    "immobile",
    "immuable",
    "impact",
    "impérial",
    "implorer",
    "imposer",
    "imprimer",
    "imputer",
    "incarner",
    "incendie",
    "incident",
    "incliner",
    "incolore",
    "indexer",
    "indice",
    "inductif",
    "inédit",
    "ineptie",
    "inexact",
    "infini",
    "infliger",
    "informer",
    "infusion",
    "ingérer",
    "inhaler",
    "inhiber",
    "injecter",
    "injure",
    "innocent",
    "inoculer",
    "inonder",
    "inscrire",
    "insecte",
    "insigne",
    "insolite",
    "inspirer",
    "instinct",
    "insulter",
    "intact",
    "intense",
    "intime",
    "intrigue",
    "intuitif",
    "inutile",
    "invasion",
    "inventer",
    "inviter",
    "invoquer",
    "ironique",
    "irradier",
    "irréel",
    "irriter",
    "isoler",
    "ivoire",
    "ivresse",
    "jaguar",
    "jaillir",
    "jambe",
    "janvier",
    "jardin",
    "jauger",
    "jaune",
    "javelot",
    "jetable",
    "jeton",
    "jeudi",
    "jeunesse",
    "joindre",
    "joncher",
    "jongler",
    "joueur",
    "jouissif",
    "journal",
    "jovial",
    "joyau",
    "joyeux",
    "jubiler",
    "jugement",
    "junior",
    "jupon",
    "juriste",
    "justice",
    "juteux",
    "juvénile",
    "kayak",
    "kimono",
    "kiosque",
    "label",
    "labial",
    "labourer",
    "lacérer",
    "lactose",
    "lagune",
    "laine",
    "laisser",
    "laitier",
    "lambeau",
    "lamelle",
    "lampe",
    "lanceur",
    "langage",
    "lanterne",
    "lapin",
    "largeur",
    "larme",
    "laurier",
    "lavabo",
    "lavoir",
    "lecture",
    "légal",
    "léger",
    "légume",
    "lessive",
    "lettre",
    "levier",
    "lexique",
    "lézard",
    "liasse",
    "libérer",
    "libre",
    "licence",
    "licorne",
    "liège",
    "lièvre",
    "ligature",
    "ligoter",
    "ligue",
    "limer",
    "limite",
    "limonade",
    "limpide",
    "linéaire",
    "lingot",
    "lionceau",
    "liquide",
    "lisière",
    "lister",
    "lithium",
    "litige",
    "littoral",
    "livreur",
    "logique",
    "lointain",
    "loisir",
    "lombric",
    "loterie",
    "louer",
    "lourd",
    "loutre",
    "louve",
    "loyal",
    "lubie",
    "lucide",
    "lucratif",
    "lueur",
    "lugubre",
    "luisant",
    "lumière",
    "lunaire",
    "lundi",
    "luron",
    "lutter",
    "luxueux",
    "machine",
    "magasin",
    "magenta",
    "magique",
    "maigre",
    "maillon",
    "maintien",
    "mairie",
    "maison",
    "majorer",
    "malaxer",
    "maléfice",
    "malheur",
    "malice",
    "mallette",
    "mammouth",
    "mandater",
    "maniable",
    "manquant",
    "manteau",
    "manuel",
    "marathon",
    "marbre",
    "marchand",
    "mardi",
    "maritime",
    "marqueur",
    "marron",
    "marteler",
    "mascotte",
    "massif",
    "matériel",
    "matière",
    "matraque",
    "maudire",
    "maussade",
    "mauve",
    "maximal",
    "méchant",
    "méconnu",
    "médaille",
    "médecin",
    "méditer",
    "méduse",
    "meilleur",
    "mélange",
    "mélodie",
    "membre",
    "mémoire",
    "menacer",
    "mener",
    "menhir",
    "mensonge",
    "mentor",
    "mercredi",
    "mérite",
    "merle",
    "messager",
    "mesure",
    "métal",
    "météore",
    "méthode",
    "métier",
    "meuble",
    "miauler",
    "microbe",
    "miette",
    "mignon",
    "migrer",
    "milieu",
    "million",
    "mimique",
    "mince",
    "minéral",
    "minimal",
    "minorer",
    "minute",
    "miracle",
    "miroiter",
    "missile",
    "mixte",
    "mobile",
    "moderne",
    "moelleux",
    "mondial",
    "moniteur",
    "monnaie",
    "monotone",
    "monstre",
    "montagne",
    "monument",
    "moqueur",
    "morceau",
    "morsure",
    "mortier",
    "moteur",
    "motif",
    "mouche",
    "moufle",
    "moulin",
    "mousson",
    "mouton",
    "mouvant",
    "multiple",
    "munition",
    "muraille",
    "murène",
    "murmure",
    "muscle",
    "muséum",
    "musicien",
    "mutation",
    "muter",
    "mutuel",
    "myriade",
    "myrtille",
    "mystère",
    "mythique",
    "nageur",
    "nappe",
    "narquois",
    "narrer",
    "natation",
    "nation",
    "nature",
    "naufrage",
    "nautique",
    "navire",
    "nébuleux",
    "nectar",
    "néfaste",
    "négation",
    "négliger",
    "négocier",
    "neige",
    "nerveux",
    "nettoyer",
    "neurone",
    "neutron",
    "neveu",
    "niche",
    "nickel",
    "nitrate",
    "niveau",
    "noble",
    "nocif",
    "nocturne",
    "noirceur",
    "noisette",
    "nomade",
    "nombreux",
    "nommer",
    "normatif",
    "notable",
    "notifier",
    "notoire",
    "nourrir",
    "nouveau",
    "novateur",
    "novembre",
    "novice",
    "nuage",
    "nuancer",
    "nuire",
    "nuisible",
    "numéro",
    "nuptial",
    "nuque",
    "nutritif",
    "obéir",
    "objectif",
    "obliger",
    "obscur",
    "observer",
    "obstacle",
    "obtenir",
    "obturer",
    "occasion",
    "occuper",
    "océan",
    "octobre",
    "octroyer",
    "octupler",
    "oculaire",
    "odeur",
    "odorant",
    "offenser",
    "officier",
    "offrir",
    "ogive",
    "oiseau",
    "oisillon",
    "olfactif",
    "olivier",
    "ombrage",
    "omettre",
    "onctueux",
    "onduler",
    "onéreux",
    "onirique",
    "opale",
    "opaque",
    "opérer",
    "opinion",
    "opportun",
    "opprimer",
    "opter",
    "optique",
    "orageux",
    "orange",
    "orbite",
    "ordonner",
    "oreille",
    "organe",
    "orgueil",
    "orifice",
    "ornement",
    "orque",
    "ortie",
    "osciller",
    "osmose",
    "ossature",
    "otarie",
    "ouragan",
    "ourson",
    "outil",
    "outrager",
    "ouvrage",
    "ovation",
    "oxyde",
    "oxygène",
    "ozone",
    "paisible",
    "palace",
    "palmarès",
    "palourde",
    "palper",
    "panache",
    "panda",
    "pangolin",
    "paniquer",
    "panneau",
    "panorama",
    "pantalon",
    "papaye",
    "papier",
    "papoter",
    "papyrus",
    "paradoxe",
    "parcelle",
    "paresse",
    "parfumer",
    "parler",
    "parole",
    "parrain",
    "parsemer",
    "partager",
    "parure",
    "parvenir",
    "passion",
    "pastèque",
    "paternel",
    "patience",
    "patron",
    "pavillon",
    "pavoiser",
    "payer",
    "paysage",
    "peigne",
    "peintre",
    "pelage",
    "pélican",
    "pelle",
    "pelouse",
    "peluche",
    "pendule",
    "pénétrer",
    "pénible",
    "pensif",
    "pénurie",
    "pépite",
    "péplum",
    "perdrix",
    "perforer",
    "période",
    "permuter",
    "perplexe",
    "persil",
    "perte",
    "peser",
    "pétale",
    "petit",
    "pétrir",
    "peuple",
    "pharaon",
    "phobie",
    "phoque",
    "photon",
    "phrase",
    "physique",
    "piano",
    "pictural",
    "pièce",
    "pierre",
    "pieuvre",
    "pilote",
    "pinceau",
    "pipette",
    "piquer",
    "pirogue",
    "piscine",
    "piston",
    "pivoter",
    "pixel",
    "pizza",
    "placard",
    "plafond",
    "plaisir",
    "planer",
    "plaque",
    "plastron",
    "plateau",
    "pleurer",
    "plexus",
    "pliage",
    "plomb",
    "plonger",
    "pluie",
    "plumage",
    "pochette",
    "poésie",
    "poète",
    "pointe",
    "poirier",
    "poisson",
    "poivre",
    "polaire",
    "policier",
    "pollen",
    "polygone",
    "pommade",
    "pompier",
    "ponctuel",
    "pondérer",
    "poney",
    "portique",
    "position",
    "posséder",
    "posture",
    "potager",
    "poteau",
    "potion",
    "pouce",
    "poulain",
    "poumon",
    "pourpre",
    "poussin",
    "pouvoir",
    "prairie",
    "pratique",
    "précieux",
    "prédire",
    "préfixe",
    "prélude",
    "prénom",
    "présence",
    "prétexte",
    "prévoir",
    "primitif",
    "prince",
    "prison",
    "priver",
    "problème",
    "procéder",
    "prodige",
    "profond",
    "progrès",
    "proie",
    "projeter",
    "prologue",
    "promener",
    "propre",
    "prospère",
    "protéger",
    "prouesse",
    "proverbe",
    "prudence",
    "pruneau",
    "psychose",
    "public",
    "puceron",
    "puiser",
    "pulpe",
    "pulsar",
    "punaise",
    "punitif",
    "pupitre",
    "purifier",
    "puzzle",
    "pyramide",
    "quasar",
    "querelle",
    "question",
    "quiétude",
    "quitter",
    "quotient",
    "racine",
    "raconter",
    "radieux",
    "ragondin",
    "raideur",
    "raisin",
    "ralentir",
    "rallonge",
    "ramasser",
    "rapide",
    "rasage",
    "ratisser",
    "ravager",
    "ravin",
    "rayonner",
    "réactif",
    "réagir",
    "réaliser",
    "réanimer",
    "recevoir",
    "réciter",
    "réclamer",
    "récolter",
    "recruter",
    "reculer",
    "recycler",
    "rédiger",
    "redouter",
    "refaire",
    "réflexe",
    "réformer",
    "refrain",
    "refuge",
    "régalien",
    "région",
    "réglage",
    "régulier",
    "réitérer",
    "rejeter",
    "rejouer",
    "relatif",
    "relever",
    "relief",
    "remarque",
    "remède",
    "remise",
    "remonter",
    "remplir",
    "remuer",
    "renard",
    "renfort",
    "renifler",
    "renoncer",
    "rentrer",
    "renvoi",
    "replier",
    "reporter",
    "reprise",
    "reptile",
    "requin",
    "réserve",
    "résineux",
    "résoudre",
    "respect",
    "rester",
    "résultat",
    "rétablir",
    "retenir",
    "réticule",
    "retomber",
    "retracer",
    "réunion",
    "réussir",
    "revanche",
    "revivre",
    "révolte",
    "révulsif",
    "richesse",
    "rideau",
    "rieur",
    "rigide",
    "rigoler",
    "rincer",
    "riposter",
    "risible",
    "risque",
    "rituel",
    "rival",
    "rivière",
    "rocheux",
    "romance",
    "rompre",
    "ronce",
    "rondin",
    "roseau",
    "rosier",
    "rotatif",
    "rotor",
    "rotule",
    "rouge",
    "rouille",
    "rouleau",
    "routine",
    "royaume",
    "ruban",
    "rubis",
    "ruche",
    "ruelle",
    "rugueux",
    "ruiner",
    "ruisseau",
    "ruser",
    "rustique",
    "rythme",
    "sabler",
    "saboter",
    "sabre",
    "sacoche",
    "safari",
    "sagesse",
    "saisir",
    "salade",
    "salive",
    "salon",
    "saluer",
    "samedi",
    "sanction",
    "sanglier",
    "sarcasme",
    "sardine",
    "saturer",
    "saugrenu",
    "saumon",
    "sauter",
    "sauvage",
    "savant",
    "savonner",
    "scalpel",
    "scandale",
    "scélérat",
    "scénario",
    "sceptre",
    "schéma",
    "science",
    "scinder",
    "score",
    "scrutin",
    "sculpter",
    "séance",
    "sécable",
    "sécher",
    "secouer",
    "sécréter",
    "sédatif",
    "séduire",
    "seigneur",
    "séjour",
    "sélectif",
    "semaine",
    "sembler",
    "semence",
    "séminal",
    "sénateur",
    "sensible",
    "sentence",
    "séparer",
    "séquence",
    "serein",
    "sergent",
    "sérieux",
    "serrure",
    "sérum",
    "service",
    "sésame",
    "sévir",
    "sevrage",
    "sextuple",
    "sidéral",
    "siècle",
    "siéger",
    "siffler",
    "sigle",
    "signal",
    "silence",
    "silicium",
    "simple",
    "sincère",
    "sinistre",
    "siphon",
    "sirop",
    "sismique",
    "situer",
    "skier",
    "social",
    "socle",
    "sodium",
    "soigneux",
    "soldat",
    "soleil",
    "solitude",
    "soluble",
    "sombre",
    "sommeil",
    "somnoler",
    "sonde",
    "songeur",
    "sonnette",
    "sonore",
    "sorcier",
    "sortir",
    "sosie",
    "sottise",
    "soucieux",
    "soudure",
    "souffle",
    "soulever",
    "soupape",
    "source",
    "soutirer",
    "souvenir",
    "spacieux",
    "spatial",
    "spécial",
    "sphère",
    "spiral",
    "stable",
    "station",
    "sternum",
    "stimulus",
    "stipuler",
    "strict",
    "studieux",
    "stupeur",
    "styliste",
    "sublime",
    "substrat",
    "subtil",
    "subvenir",
    "succès",
    "sucre",
    "suffixe",
    "suggérer",
    "suiveur",
    "sulfate",
    "superbe",
    "supplier",
    "surface",
    "suricate",
    "surmener",
    "surprise",
    "sursaut",
    "survie",
    "suspect",
    "syllabe",
    "symbole",
    "symétrie",
    "synapse",
    "syntaxe",
    "système",
    "tabac",
    "tablier",
    "tactile",
    "tailler",
    "talent",
    "talisman",
    "talonner",
    "tambour",
    "tamiser",
    "tangible",
    "tapis",
    "taquiner",
    "tarder",
    "tarif",
    "tartine",
    "tasse",
    "tatami",
    "tatouage",
    "taupe",
    "taureau",
    "taxer",
    "témoin",
    "temporel",
    "tenaille",
    "tendre",
    "teneur",
    "tenir",
    "tension",
    "terminer",
    "terne",
    "terrible",
    "tétine",
    "texte",
    "thème",
    "théorie",
    "thérapie",
    "thorax",
    "tibia",
    "tiède",
    "timide",
    "tirelire",
    "tiroir",
    "tissu",
    "titane",
    "titre",
    "tituber",
    "toboggan",
    "tolérant",
    "tomate",
    "tonique",
    "tonneau",
    "toponyme",
    "torche",
    "tordre",
    "tornade",
    "torpille",
    "torrent",
    "torse",
    "tortue",
    "totem",
    "toucher",
    "tournage",
    "tousser",
    "toxine",
    "traction",
    "trafic",
    "tragique",
    "trahir",
    "train",
    "trancher",
    "travail",
    "trèfle",
    "tremper",
    "trésor",
    "treuil",
    "triage",
    "tribunal",
    "tricoter",
    "trilogie",
    "triomphe",
    "tripler",
    "triturer",
    "trivial",
    "trombone",
    "tronc",
    "tropical",
    "troupeau",
    "tuile",
    "tulipe",
    "tumulte",
    "tunnel",
    "turbine",
    "tuteur",
    "tutoyer",
    "tuyau",
    "tympan",
    "typhon",
    "typique",
    "tyran",
    "ubuesque",
    "ultime",
    "ultrason",
    "unanime",
    "unifier",
    "union",
    "unique",
    "unitaire",
    "univers",
    "uranium",
    "urbain",
    "urticant",
    "usage",
    "usine",
    "usuel",
    "usure",
    "utile",
    "utopie",
    "vacarme",
    "vaccin",
    "vagabond",
    "vague",
    "vaillant",
    "vaincre",
    "vaisseau",
    "valable",
    "valise",
    "vallon",
    "valve",
    "vampire",
    "vanille",
    "vapeur",
    "varier",
    "vaseux",
    "vassal",
    "vaste",
    "vecteur",
    "vedette",
    "végétal",
    "véhicule",
    "veinard",
    "véloce",
    "vendredi",
    "vénérer",
    "venger",
    "venimeux",
    "ventouse",
    "verdure",
    "vérin",
    "vernir",
    "verrou",
    "verser",
    "vertu",
    "veston",
    "vétéran",
    "vétuste",
    "vexant",
    "vexer",
    "viaduc",
    "viande",
    "victoire",
    "vidange",
    "vidéo",
    "vignette",
    "vigueur",
    "vilain",
    "village",
    "vinaigre",
    "violon",
    "vipère",
    "virement",
    "virtuose",
    "virus",
    "visage",
    "viseur",
    "vision",
    "visqueux",
    "visuel",
    "vital",
    "vitesse",
    "viticole",
    "vitrine",
    "vivace",
    "vivipare",
    "vocation",
    "voguer",
    "voile",
    "voisin",
    "voiture",
    "volaille",
    "volcan",
    "voltiger",
    "volume",
    "vorace",
    "vortex",
    "voter",
    "vouloir",
    "voyage",
    "voyelle",
    "wagon",
    "xénon",
    "yacht",
    "zèbre",
    "zénith",
    "zeste",
    "zoologie"
]

},
"6+0EJUY6cZ+zYs2V8FcjxPdpC0MQXyTWQqJ40hix9aU=":
function (require, module, exports, __dirname, __filename) {
'use strict';
var os = require('os');

function homedir() {
	var env = process.env;
	var home = env.HOME;
	var user = env.LOGNAME || env.USER || env.LNAME || env.USERNAME;

	if (process.platform === 'win32') {
		return env.USERPROFILE || env.HOMEDRIVE + env.HOMEPATH || home || null;
	}

	if (process.platform === 'darwin') {
		return home || (user ? '/Users/' + user : null);
	}

	if (process.platform === 'linux') {
		return home || (process.getuid() === 0 ? '/root' : (user ? '/home/' + user : null));
	}

	return home || null;
}

module.exports = typeof os.homedir === 'function' ? os.homedir : homedir;

},
"6+BxrYHbhymYY1ZogfZ7psXyJBTFvc4LnvHwuYIFAWE=":
function (require, module, exports, __dirname, __filename) {
var Reader = require('pull-reader')
var Writer = require('pull-pushable')
var cat = require('pull-cat')
var pair = require('pull-pair')

function once (cb) {
  var called = 0
  return function (a, b, c) {
    if(called++) return
    cb(a, b, c)
  }
}

function isFunction (f) {
  return 'function' === typeof f
}

module.exports = function (opts, _cb) {
  if(isFunction(opts)) _cb = opts, opts = {}
  _cb = once(_cb || function noop () {})
  var reader = Reader(opts && opts.timeout || 5e3)
  var writer = Writer(function (err) {
    if(err) _cb(err)
  })

  var p = pair()

  return {
    handshake: {
      read: reader.read,
      abort: function (err) {
        writer.end(err)
        reader.abort(err, function (err) {
        })
        _cb(err)
      },
      write: writer.push,
      rest: function () {
        writer.end()
        return {
          source: reader.read(),
          sink: p.sink
        }
      }
    },
    sink: reader,
    source: cat([writer, p.source])
  }
}

},
"61r6Yx1OtPVKfCZEiHA76brp45pjKGL6lad+JCRlmug=":
function (require, module, exports, __dirname, __filename) {
'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var common = require('@minireq/common');
var http = require('http');
var https = require('https');

function _interopNamespace(e) {
    if (e && e.__esModule) return e;
    var n = Object.create(null);
    if (e) {
        Object.keys(e).forEach(function (k) {
            if (k !== 'default') {
                var d = Object.getOwnPropertyDescriptor(e, k);
                Object.defineProperty(n, k, d.get ? d : {
                    enumerable: true,
                    get: function () {
                        return e[k];
                    }
                });
            }
        });
    }
    n['default'] = e;
    return Object.freeze(n);
}

var http__namespace = /*#__PURE__*/_interopNamespace(http);
var https__namespace = /*#__PURE__*/_interopNamespace(https);

function makeRequest(serializers = common.defaultSerializers, defaultOptions = {}) {
    return function request(options) {
        var _a;
        const opts = Object.assign(Object.assign(Object.assign({}, common.defaults), defaultOptions), options);
        const url = opts.url + common.makeQueryString(opts.query);
        const h = /^http:\/\//.test(opts.url) ? http__namespace : https__namespace;
        if (opts.uploadProgress) {
            throw new Error('Node.js does not support reporting upload progress');
        }
        const headers = Object.assign({}, opts.headers);
        if (opts.contentType) {
            headers['Content-Type'] = opts.contentType;
        }
        if (opts.accept) {
            headers['Accept'] = opts.accept;
        }
        if (opts.auth) {
            const base64 = Buffer.from(opts.auth.user + ':' + opts.auth.password).toString('base64');
            headers.Authorization = `Basic ${base64}`;
        }
        let data = '';
        const req = h.request(url, {
            method: opts.method,
            timeout: opts.timeout,
            headers,
        });
        let id = undefined;
        if (opts.timeout) {
            id = setTimeout(() => {
                req.abort();
                if (opts.onTimeout) {
                    opts.onTimeout(makeProgress(data, undefined));
                }
            }, opts.timeout);
        }
        const promise = new Promise((resolve, reject) => {
            req.on('response', res => {
                if (opts.responseType !== 'binary') {
                    res.setEncoding('utf-8');
                }
                res.on('data', chunk => {
                    if (typeof chunk === 'string') {
                        data += chunk;
                    }
                    else {
                        if (data === '') {
                            data = [];
                        }
                        else {
                            data.push(chunk);
                        }
                    }
                    if (opts.progress) {
                        opts.progress(makeProgress(data, res.headers['content-length']));
                    }
                });
                res.on('end', () => {
                    var _a, _b;
                    if (id)
                        clearTimeout(id);
                    let response = data;
                    if (Array.isArray(data)) {
                        const buffer = Buffer.concat(data);
                        response = buffer.buffer.slice(buffer.byteOffset, buffer.byteOffset + buffer.byteLength);
                    }
                    if (typeof response === 'string' &&
                        opts.responseType === 'parsed') {
                        const mimeType = (_a = res.headers['content-type']) === null || _a === void 0 ? void 0 : _a.split(';')[0];
                        if (mimeType && ((_b = serializers[mimeType]) === null || _b === void 0 ? void 0 : _b.parse)) {
                            response = serializers[mimeType].parse(response);
                        }
                    }
                    resolve({
                        status: res.statusCode,
                        data: response,
                    });
                });
            });
            req.on('error', err => {
                if (!req.aborted) {
                    reject(err);
                }
            });
        });
        if (opts.send) {
            if (typeof opts.send === 'string' ||
                opts.send instanceof ArrayBuffer ||
                opts.send instanceof ArrayBuffer ||
                opts.send instanceof Int8Array ||
                opts.send instanceof Uint8Array ||
                opts.send instanceof Uint8ClampedArray ||
                opts.send instanceof Int16Array ||
                opts.send instanceof Uint16Array ||
                opts.send instanceof Int32Array ||
                opts.send instanceof Uint32Array ||
                opts.send instanceof Float32Array ||
                opts.send instanceof Float64Array ||
                opts.send instanceof DataView ||
                opts.send instanceof URLSearchParams) {
                req.write(opts.send);
            }
            else if ((_a = serializers[opts.contentType]) === null || _a === void 0 ? void 0 : _a.convert) {
                req.write(serializers[opts.contentType].convert(opts.send));
            }
            else {
                req.abort();
                throw new Error(`Could not find a serializer for content type ${opts.contentType}`);
            }
        }
        req.end();
        return {
            promise,
            abort: () => req.abort(),
        };
    };
}
function makeProgress(data, contentLength) {
    const lengthComputable = contentLength !== undefined;
    const loaded = typeof data === 'string'
        ? Buffer.byteLength(data)
        : data.reduce((acc, curr) => acc + curr.length, 0);
    let total = 0;
    if (lengthComputable) {
        total = parseInt(contentLength);
    }
    return {
        lengthComputable,
        loaded,
        total,
    };
}

exports.makeRequest = makeRequest;

},
"6Guyk+kvFKXes2B5gVa1V2Ss2ATwgx5FVJBKUPHx1yk=":
function (require, module, exports, __dirname, __filename) {

var pull = require('pull-stream/pull')
var Through = require('pull-stream/throughs/through')
var Abortable = require('pull-abortable')
var Rate = require('./rate')

module.exports = function (duplex, min, onEnd) {
  if('function' === typeof min)
    onEnd = min, min = null

  var n = 2, error, interval

  function done (err) {
    error = error || err
    if(--n) return
    clearInterval(interval)
    onEnd && onEnd(error)
  }

  min = min || 1000 //close after 1 second inactivity.

  var sourceAbort = Abortable(done)
  var sinkAbort   = Abortable(done)
  var sourceRate  = Rate()
  var sinkRate    = Rate()

  function rate () {
    return sourceRate.rate() + sinkRate.rate()
  }

  function abort () {
    clearInterval(interval)
    sourceAbort.abort()
    sinkAbort.abort()
  }

  interval = setInterval(function () {
    if(!min) return
    if(Math.max(sourceRate.ts, sinkRate.ts) + min < Date.now())
      abort()
  }, 200)
  interval.unref && interval.unref()

  return {
    source: pull(duplex.source, sourceRate, sourceAbort),
    sink  : pull(sinkRate, sinkAbort, duplex.sink),
    rate  : rate,
    setTTL: function (_min) {
      if(!_min) clearInterval(interval)
      min = _min
      return this
    },
    abort : abort
  }

}

module.exports.through = function (min, onEnd) {
  min = min || 0.002 //2k per second
  var abortable = Abortable(onEnd)
  var flow = Rate()
  var interval = setInterval(function () {
    if(flow.rate() < min) {
      clearInterval(interval)
      abortable.abort()
    }
  }, 500)

  var stream = pull(
    flow,
    abortable,
    Through(null, function () {
      clearInterval(interval)
    })
  )

  stream.rate = flow.rate

  return stream
}


},
"6HUpfuflJtR37rsR5RKgn9k38g1B7cxcNVretSlbeVw=":
function (require, module, exports, __dirname, __filename) {
var path = require('path')
var home = require('os-homedir')
var merge = require('deep-extend')
var ssbCaps = require('ssb-caps')
var ssbKeys = require('ssb-keys')

var incomingConnections = require('./util/incoming-connections')
var fixConnections = require('./util/fix-connections')

var SEC = 1e3
var MIN = 60 * SEC

module.exports = function setDefaults (name, config) {
  var baseDefaults = {
    path: path.join(home() || 'browser', '.' + name),
    party: true,
    timeout: 0,
    pub: true,
    local: true,
    friends: {
      dunbar: 150,
      hops: 2
    },
    gossip: {
      connections: 3
    },
    connections: {
      outgoing: {
        net: [{ transform: 'shs' }],
        onion: [{ transform: 'shs' }]
      }
    },
    timers: {
      connection: 0,
      reconnect: 5 * SEC,
      ping: 5 * MIN,
      handshake: 5 * SEC
    },
    // change these to make a test network that will not connect to the main network.
    caps: ssbCaps,
    master: [],
    logging: { level: 'notice' }
  }
  config = merge(baseDefaults, config || {})

  if (!config.connections.incoming) {
    // if no incoming connections have been set,
    // populate this with some rad-comprehensive defaults!
    config.connections.incoming = incomingConnections(config)
  }

  config = fixConnections(config)

  if (config.keys == null) {
    config.keys = ssbKeys.loadOrCreateSync(path.join(config.path, 'secret'))
  }

  return config
}

},
"6K/6q6UGvfzIGStk02e5qR/h+jzFMOeSEtL0nRJkq/k=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var implementation = require('./implementation');

var supportsDescriptors = require('define-properties').supportsDescriptors;
var $gOPD = Object.getOwnPropertyDescriptor;
var $TypeError = TypeError;

module.exports = function getPolyfill() {
	if (!supportsDescriptors) {
		throw new $TypeError('RegExp.prototype.flags requires a true ES5 environment that supports property descriptors');
	}
	if ((/a/mig).flags === 'gim') {
		var descriptor = $gOPD(RegExp.prototype, 'flags');
		if (descriptor && typeof descriptor.get === 'function' && typeof (/a/).dotAll === 'boolean') {
			return descriptor.get;
		}
	}
	return implementation;
};

},
"6MXKYXv2yybhg7BqMk6aetUaL8ARfB5rRb2GcXRRWQg=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
Object.defineProperty(exports, "__esModule", { value: true });
const fs = require("fs");
const path = require("path");
const mkdirp = require('mkdirp');
const caps = require('ssb-caps');
const ssbKeys = require('ssb-keys');
const makeConfig = require('ssb-config/inject');
const SecretStack = require('secret-stack');
const settingsUtils = require("./plugins/settingsUtils");
const bluetoothTransport = require("./plugins/bluetooth");
const oneTimeFixes = require("./one-time-fixes");
// Make sure SSB_DIR exists
if (!process.env.APP_DATA_DIR || !process.env.SSB_DIR) {
    throw new Error('misconfigured default paths for the backend');
}
if (!fs.existsSync(process.env.SSB_DIR)) {
    mkdirp.sync(process.env.SSB_DIR);
}
oneTimeFixes().then(() => {
    var _a;
    const KEYS_PATH = path.join(process.env.SSB_DIR, 'secret');
    const keys = ssbKeys.loadOrCreateSync(KEYS_PATH);
    const config = makeConfig('ssb', {
        caps,
        keys,
        path: process.env.SSB_DIR,
        db2: {
            maxCpu: 91,
            maxCpuWait: 80,
            maxCpuMaxPause: 120,
            automigrate: true,
            dangerouslyKillFlumeWhenMigrated: process.env.MANYVERSE_PLATFORM === 'mobile',
        },
        blobs: {
            sympathy: 2,
        },
        blobsPurge: {
            cpuMax: 90, // %
        },
        conn: {
            autostart: false,
            firewall: {
                rejectBlocked: true,
                rejectUnknown: true,
            },
        },
        friends: {
            hops: (_a = settingsUtils.readSync().hops) !== null && _a !== void 0 ? _a : 2,
            hookAuth: false, // because we use ssb-conn-firewall
        },
        suggest: {
            autostart: false,
        },
        connections: {
            incoming: {
                net: [{ scope: 'private', transform: 'shs', port: 26831 }],
                channel: [{ scope: 'device', transform: 'noauth' }],
                bluetooth: [{ scope: 'public', transform: 'shs' }],
                tunnel: [{ scope: 'public', transform: 'shs' }],
            },
            outgoing: {
                net: [{ transform: 'shs' }],
                ws: [{ transform: 'shs' }],
                bluetooth: [{ scope: 'public', transform: 'shs' }],
                tunnel: [{ transform: 'shs' }],
            },
        },
    });
    process._ssb = SecretStack()
        // Core
        .use(require('ssb-master'))
        .use(require('ssb-db2'))
        .use(require('ssb-db2/compat/db'))
        .use(require('ssb-db2/compat/ebt'))
        .use(require('ssb-db2/compat/log-stream'))
        .use(require('ssb-db2/compat/history-stream'))
        .use(require('ssb-deweird/producer'))
        // Replication
        .use(require('ssb-ebt')) // needs: db2/compat
        .use(require('ssb-friends')) // needs: db2
        .use(require('ssb-replication-scheduler')) // needs: friends, ebt
        // Connections
        .use(require('./plugins/multiserver-addons'))
        .use(require('ssb-lan'))
        .use(bluetoothTransport(keys, process.env.APP_DATA_DIR))
        .use(require('ssb-conn')) // needs: db2, friends, lan, bluetooth
        .use(require('ssb-conn-firewall')) // needs: friends
        .use(require('ssb-room-client')) // needs: conn
        .use(require('ssb-http-auth-client')) // needs: conn
        .use(require('ssb-http-invite-client'))
        .use(require('ssb-invite-client')) // needs: db2, conn
        // Queries
        .use(require('ssb-db2/about-self')) // needs: db2
        .use(require('ssb-suggest-lite')) // needs: db2, about-self, friends
        .use(require('ssb-threads')) // needs: db, db2, friends
        .use(require('ssb-db2/full-mentions')) // needs: db2
        .use(require('ssb-search2')) // needs: db2
        // Blobs
        .use(require('ssb-blobs'))
        .use(require('ssb-serve-blobs')) // needs: blobs
        .use(require('ssb-blobs-purge')) // needs: blobs, db2/full-mentions
        // Customizations
        .use(require('./plugins/aboutSelf')) // needs: db2
        .use(require('./plugins/blobsUtils')) // needs: blobs
        .use(require('./plugins/connUtils')) // needs: conn, aboutSelf
        .use(require('./plugins/aliasUtils')) // needs: db2
        .use(require('./plugins/resyncUtils')) // needs: db2, connFirewall
        .use(require('./plugins/publishUtilsBack')) // needs: db, blobs, blobsUtils
        .use(require('./plugins/searchUtils')) // needs: db2
        .use(require('./plugins/keysUtils'))
        .use(settingsUtils) // needs: blobs-purge
        .use(require('./plugins/syncing')) // needs: db2
        .use(require('./plugins/dbUtils')) // needs: db2, syncing
        .use(require('./plugins/votes')) // needs: db2
        .call(null, config);
});
//# sourceMappingURL=ssb.js.map
},
"6aXzeHgmb0QQaVVupBGmDWWL37FqqZ07KbU/1jmlqjo=":
function (require, module, exports, __dirname, __filename) {
exports.alphasort = alphasort
exports.alphasorti = alphasorti
exports.setopts = setopts
exports.ownProp = ownProp
exports.makeAbs = makeAbs
exports.finish = finish
exports.mark = mark
exports.isIgnored = isIgnored
exports.childrenIgnored = childrenIgnored

function ownProp (obj, field) {
  return Object.prototype.hasOwnProperty.call(obj, field)
}

var path = require("path")
var minimatch = require("minimatch")
var isAbsolute = require("path-is-absolute")
var Minimatch = minimatch.Minimatch

function alphasorti (a, b) {
  return a.toLowerCase().localeCompare(b.toLowerCase())
}

function alphasort (a, b) {
  return a.localeCompare(b)
}

function setupIgnores (self, options) {
  self.ignore = options.ignore || []

  if (!Array.isArray(self.ignore))
    self.ignore = [self.ignore]

  if (self.ignore.length) {
    self.ignore = self.ignore.map(ignoreMap)
  }
}

// ignore patterns are always in dot:true mode.
function ignoreMap (pattern) {
  var gmatcher = null
  if (pattern.slice(-3) === '/**') {
    var gpattern = pattern.replace(/(\/\*\*)+$/, '')
    gmatcher = new Minimatch(gpattern, { dot: true })
  }

  return {
    matcher: new Minimatch(pattern, { dot: true }),
    gmatcher: gmatcher
  }
}

function setopts (self, pattern, options) {
  if (!options)
    options = {}

  // base-matching: just use globstar for that.
  if (options.matchBase && -1 === pattern.indexOf("/")) {
    if (options.noglobstar) {
      throw new Error("base matching requires globstar")
    }
    pattern = "**/" + pattern
  }

  self.silent = !!options.silent
  self.pattern = pattern
  self.strict = options.strict !== false
  self.realpath = !!options.realpath
  self.realpathCache = options.realpathCache || Object.create(null)
  self.follow = !!options.follow
  self.dot = !!options.dot
  self.mark = !!options.mark
  self.nodir = !!options.nodir
  if (self.nodir)
    self.mark = true
  self.sync = !!options.sync
  self.nounique = !!options.nounique
  self.nonull = !!options.nonull
  self.nosort = !!options.nosort
  self.nocase = !!options.nocase
  self.stat = !!options.stat
  self.noprocess = !!options.noprocess
  self.absolute = !!options.absolute

  self.maxLength = options.maxLength || Infinity
  self.cache = options.cache || Object.create(null)
  self.statCache = options.statCache || Object.create(null)
  self.symlinks = options.symlinks || Object.create(null)

  setupIgnores(self, options)

  self.changedCwd = false
  var cwd = process.cwd()
  if (!ownProp(options, "cwd"))
    self.cwd = cwd
  else {
    self.cwd = path.resolve(options.cwd)
    self.changedCwd = self.cwd !== cwd
  }

  self.root = options.root || path.resolve(self.cwd, "/")
  self.root = path.resolve(self.root)
  if (process.platform === "win32")
    self.root = self.root.replace(/\\/g, "/")

  // TODO: is an absolute `cwd` supposed to be resolved against `root`?
  // e.g. { cwd: '/test', root: __dirname } === path.join(__dirname, '/test')
  self.cwdAbs = isAbsolute(self.cwd) ? self.cwd : makeAbs(self, self.cwd)
  if (process.platform === "win32")
    self.cwdAbs = self.cwdAbs.replace(/\\/g, "/")
  self.nomount = !!options.nomount

  // disable comments and negation in Minimatch.
  // Note that they are not supported in Glob itself anyway.
  options.nonegate = true
  options.nocomment = true

  self.minimatch = new Minimatch(pattern, options)
  self.options = self.minimatch.options
}

function finish (self) {
  var nou = self.nounique
  var all = nou ? [] : Object.create(null)

  for (var i = 0, l = self.matches.length; i < l; i ++) {
    var matches = self.matches[i]
    if (!matches || Object.keys(matches).length === 0) {
      if (self.nonull) {
        // do like the shell, and spit out the literal glob
        var literal = self.minimatch.globSet[i]
        if (nou)
          all.push(literal)
        else
          all[literal] = true
      }
    } else {
      // had matches
      var m = Object.keys(matches)
      if (nou)
        all.push.apply(all, m)
      else
        m.forEach(function (m) {
          all[m] = true
        })
    }
  }

  if (!nou)
    all = Object.keys(all)

  if (!self.nosort)
    all = all.sort(self.nocase ? alphasorti : alphasort)

  // at *some* point we statted all of these
  if (self.mark) {
    for (var i = 0; i < all.length; i++) {
      all[i] = self._mark(all[i])
    }
    if (self.nodir) {
      all = all.filter(function (e) {
        var notDir = !(/\/$/.test(e))
        var c = self.cache[e] || self.cache[makeAbs(self, e)]
        if (notDir && c)
          notDir = c !== 'DIR' && !Array.isArray(c)
        return notDir
      })
    }
  }

  if (self.ignore.length)
    all = all.filter(function(m) {
      return !isIgnored(self, m)
    })

  self.found = all
}

function mark (self, p) {
  var abs = makeAbs(self, p)
  var c = self.cache[abs]
  var m = p
  if (c) {
    var isDir = c === 'DIR' || Array.isArray(c)
    var slash = p.slice(-1) === '/'

    if (isDir && !slash)
      m += '/'
    else if (!isDir && slash)
      m = m.slice(0, -1)

    if (m !== p) {
      var mabs = makeAbs(self, m)
      self.statCache[mabs] = self.statCache[abs]
      self.cache[mabs] = self.cache[abs]
    }
  }

  return m
}

// lotta situps...
function makeAbs (self, f) {
  var abs = f
  if (f.charAt(0) === '/') {
    abs = path.join(self.root, f)
  } else if (isAbsolute(f) || f === '') {
    abs = f
  } else if (self.changedCwd) {
    abs = path.resolve(self.cwd, f)
  } else {
    abs = path.resolve(f)
  }

  if (process.platform === 'win32')
    abs = abs.replace(/\\/g, '/')

  return abs
}


// Return true, if pattern ends with globstar '**', for the accompanying parent directory.
// Ex:- If node_modules/** is the pattern, add 'node_modules' to ignore list along with it's contents
function isIgnored (self, path) {
  if (!self.ignore.length)
    return false

  return self.ignore.some(function(item) {
    return item.matcher.match(path) || !!(item.gmatcher && item.gmatcher.match(path))
  })
}

function childrenIgnored (self, path) {
  if (!self.ignore.length)
    return false

  return self.ignore.some(function(item) {
    return !!(item.gmatcher && item.gmatcher.match(path))
  })
}

},
"6ervpJovy46ChznRJlGQkYDZQCGIHufyCMecluGBgWY=":
function (require, module, exports, __dirname, __filename) {
var stringify = require('pull-stringify')
var split = require('pull-split')
var pull = require('pull-stream/pull')
var map = require('pull-stream/throughs/map')
var filter = require('pull-stream/throughs/filter')

var p = require('is-pull-stream')

function duplex (stream) {
  return {
    source: pull(stream.source, stringify()),
    sink: pull(parse(), stream.sink)
  }
}

function parse () {
  return pull(
    split('\n\n'),
    filter(), // filter empty lines
    map(JSON.parse)
  )
}

exports = module.exports = function (stream) {
  return (
    p.isSource(stream) ? pull(stream, parse())
  : p.isSink(stream)   ? pull(stringify(), stream)
  :                      duplex(stream)
  )
}

exports.stringify = stringify
exports.parse = parse

},
"6wjlMgmCb9E/v0dWOkSxeO7dnLftUJ1f1O3fPpL8vhI=":
function (require, module, exports, __dirname, __filename) {
var WriteError = require('level-errors').WriteError
var promisify = require('./promisify')
var getCallback = require('./common').getCallback
var getOptions = require('./common').getOptions

function Batch (levelup) {
  // TODO (next major): remove this._levelup alias
  this.db = this._levelup = levelup
  this.batch = levelup.db.batch()
  this.ops = []
  this.length = 0
}

Batch.prototype.put = function (key, value) {
  try {
    this.batch.put(key, value)
  } catch (e) {
    throw new WriteError(e)
  }

  this.ops.push({ type: 'put', key: key, value: value })
  this.length++

  return this
}

Batch.prototype.del = function (key) {
  try {
    this.batch.del(key)
  } catch (err) {
    throw new WriteError(err)
  }

  this.ops.push({ type: 'del', key: key })
  this.length++

  return this
}

Batch.prototype.clear = function () {
  try {
    this.batch.clear()
  } catch (err) {
    throw new WriteError(err)
  }

  this.ops = []
  this.length = 0

  return this
}

Batch.prototype.write = function (options, callback) {
  var levelup = this._levelup
  var ops = this.ops
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  options = getOptions(options)

  try {
    this.batch.write(options, function (err) {
      if (err) { return callback(new WriteError(err)) }
      levelup.emit('batch', ops)
      callback()
    })
  } catch (err) {
    throw new WriteError(err)
  }

  return promise
}

module.exports = Batch

},
"72XVPy+VsgaBUFvX4hmVSkng1lKVA5wGIBkU87syh+U=":
function (require, module, exports, __dirname, __filename) {

module.exports = function () {
  var _read, _cb, abortCb, _end

  var read = function (end, cb) {
    if(!_read) {
      if(end) {
        _end = end
        abortCb = cb
      }
      else
        _cb = cb
    }
    else _read(end, cb)
  }
  read.resolve = function (read) {
    if(_read) throw new Error('already resolved')
    _read = read
    if(!_read) throw new Error('no read cannot resolve!' + _read)
    if(_cb) read(null, _cb)
    if(abortCb) read(_end, abortCb)
  }
  read.abort = function(err) {
    read.resolve(function (_, cb) {
      cb(err || true)
    })
  }
  return read
}


},
"76efcC3urfDlCDz3IT0NFLojITm6bvPREC7kd0vrCqk=":
function (require, module, exports, __dirname, __filename) {

function Z(n) {
  return Buffer.alloc(n)
}

module.exports = function (na) {
  var exports = {}

  // *** Signatures ***

  exports.crypto_sign_seed_keypair = function (seed) {
    var pk = Z(na.crypto_sign_PUBLICKEYBYTES)
    var sk = Z(na.crypto_sign_SECRETKEYBYTES)
    na.crypto_sign_seed_keypair(pk, sk, seed)
    return {publicKey: pk, secretKey: sk}
  }

  exports.crypto_sign_keypair = function () {
    var pk = Z(na.crypto_sign_PUBLICKEYBYTES)
    var sk = Z(na.crypto_sign_SECRETKEYBYTES)
    na.crypto_sign_keypair(pk, sk)
    return {publicKey: pk, secretKey: sk}
  }

  exports.crypto_sign = function (message, sk) {
    var signed = Z(message.length + na.crypto_sign_BYTES)
    na.crypto_sign(signed, message, sk)
    return signed
  }

  exports.crypto_sign_open = function (signed, pk) {
    var message = Z(signed.length - na.crypto_sign_BYTES)
    if(na.crypto_sign_open(message, signed, pk))
      return message
  }

  exports.crypto_sign_detached = function (message, sk) {
    var signed = Z(na.crypto_sign_BYTES)
    na.crypto_sign_detached(signed, message, sk)
    return signed
  }

  exports.crypto_sign_verify_detached = function (sig, msg, pk) {
    return na.crypto_sign_verify_detached(sig, msg, pk)
  }
  // *** Box ***

  exports.crypto_box_seed_keypair = function (seed) {
    var pk = Z(na.crypto_box_PUBLICKEYBYTES)
    var sk = Z(na.crypto_box_SECRETKEYBYTES)
    na.crypto_box_seed_keypair(pk, sk, seed)
    return {publicKey: pk, secretKey: sk}
  }

  exports.crypto_box_keypair = function () {
    var pk = Z(na.crypto_box_PUBLICKEYBYTES)
    var sk = Z(na.crypto_box_SECRETKEYBYTES)
    na.crypto_box_keypair(pk, sk)
    return {publicKey: pk, secretKey: sk}
  }


  exports.crypto_box_easy = function (ptxt, nonce, pk, sk) {
    var ctxt = Z(ptxt.length + na.crypto_box_MACBYTES)
    na.crypto_box_easy(ctxt, ptxt, nonce, pk, sk)
    return ctxt
  }

  exports.crypto_box_open_easy = function (ctxt, nonce, pk, sk) {
    var ptxt = Z(ctxt.length - na.crypto_box_MACBYTES)
    if(na.crypto_box_open_easy(ptxt, ctxt, nonce, pk, sk))
      return ptxt
  }

  // *** SecretBox ***

  exports.crypto_secretbox_easy = function (ptxt, nonce, key) {
    var ctxt = Z(ptxt.length + na.crypto_secretbox_MACBYTES)
    na.crypto_secretbox_easy(ctxt, ptxt, nonce, key)
    return ctxt
  }

  exports.crypto_secretbox_open_easy = function (ctxt, nonce, key) {
    var ptxt = Z(ctxt.length - na.crypto_secretbox_MACBYTES)
    if(na.crypto_secretbox_open_easy(ptxt, ctxt, nonce, key))
      return ptxt
  }

  // *** Auth (hmac) ***

  exports.crypto_auth = function (input, key) {
    var output = Z(na.crypto_auth_BYTES)
    na.crypto_auth(output, input, key)
    return output
  }

  exports.crypto_auth_verify = function (output, input, key) {
    return na.crypto_auth_verify(output, input, key) ? 0 : 1
  }
  // *** Hash (sha512)

  exports.crypto_hash = function (ptxt) {
    var hash = Z(na.crypto_hash_BYTES)
    na.crypto_hash_sha512(hash, ptxt)
    return hash
  }

  exports.crypto_hash_sha256 = function (ptxt) {
    var hash = Z(na.crypto_hash_sha256_BYTES)
    na.crypto_hash_sha256(hash, ptxt)
    return hash
  }

  // *** scalarmult ***

  exports.crypto_scalarmult = function (sk, pk) {
    var secret = Z(na.crypto_scalarmult_BYTES)
    na.crypto_scalarmult(secret, sk, pk)
    return secret
  }

  // *** Conversions ***

  exports.crypto_sign_ed25519_pk_to_curve25519 = function (ed_pk) {
    var curve_pk = Z(na.crypto_box_PUBLICKEYBYTES)
    try {
      //in chloridedown, it just returns something no matter what
      //but in sodium-native it throws if you try to convert
      //a random buffer, that isn't a pk.
      na.crypto_sign_ed25519_pk_to_curve25519(curve_pk, ed_pk)
    } catch (err) {
      return null
    }
    return curve_pk
  }

  exports.crypto_sign_ed25519_sk_to_curve25519 = function (ed_sk) {
    var curve_sk = Z(na.crypto_box_SECRETKEYBYTES)
    na.crypto_sign_ed25519_sk_to_curve25519(curve_sk, ed_sk)
    return curve_sk

  }

  // *** Randomness **

  exports.randombytes = function (length) {
    return na.randombytes_buf(length)
  }

  return exports
}




},
"7K0UBOixDGPoRkf9omfHi5tsCtkcmWWCsNIb3lHsuhg=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = {
  unescape: unescape,
  escape: escape,
  encode: encode,
  decode: decode
}

function unescape (str) {
  return (str + '==='.slice((str.length + 3) % 4))
    .replace(/-/g, '+')
    .replace(/_/g, '/')
}

function escape (str) {
  return str.replace(/\+/g, '-')
    .replace(/\//g, '_')
    .replace(/=/g, '')
}

function encode (str, encoding) {
  return escape(Buffer.from(str, encoding || 'utf8').toString('base64'))
}

function decode (str, encoding) {
  return Buffer.from(unescape(str), 'base64').toString(encoding || 'utf8')
}

},
"7LceS+qAzU+tDOfC68RLs+EK6L2OcwVChem7Koha3+s=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var reduce = require('./reduce')

module.exports = function concat (cb) {
  return reduce(function (a, b) {
    return a + b
  }, '', cb)
}

},
"7SR4vSZ8a5HmkiCYF5CNYb7mrFRpRdck5miW0gqgjL4=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var Looper = require('looper')
var offsetCodecs = require('./offset-codecs')

module.exports = function (blocks, blockSize, offsetCodec) {
  if (typeof offsetCodec === 'number') {
    offsetCodec = offsetCodecs[offsetCodec]
    if (!offsetCodec) throw Error('Invalid number of bits to encode file offsets. Must be one of ' + Object.keys(offsetCodecs).join(' '))
  }
  offsetCodec = offsetCodec || offsetCodecs[32]
  var fsw = offsetCodec.byteWidth

  function frame(data, start) {
    var _start = start
    var length = data.reduce(function (total, value) { return total + value.length }, 0)
    var b = Buffer.alloc(length + data.length * (8+fsw))
    var offset = 0
    for(var i = 0; i < data.length; i++) {
      var buf = data[i]
      b.writeUInt32BE(buf.length, 0 + offset) //start
      buf.copy(b, 4+offset, 0, buf.length)
      b.writeUInt32BE(buf.length, 4+buf.length + offset) //end
      offsetCodec.encode(b, start+=buf.length+(8+fsw), 8+buf.length + offset) //length of the file, if valid
      frame.offset = _start + offset
      offset += buf.length + (8 + fsw)
    }
    return b
  }

  function getMeta (offset, cb) {
    blocks.readUInt32BE(offset, function (err, len) {
      if(err) return cb(err)

      //read the length of the previous item.
      //unless this falls right on the overlap between
      //two blocks, this will already be in the cache,
      //so will be just a mem read.
      if(offset === 0)
        next(4, 4+len, -1, (fsw+len+8))
      else
        blocks.readUInt32BE(offset - (4+fsw), function (err, prev_len) {
          if(err) return cb(err)
          next(offset+4, offset+4+len, offset-(prev_len+8+fsw), offset+(len+8+fsw))
        })

      function next (start, end, prev, next) {
        blocks.read(start, end, function (err, value) {
          cb(err, value, prev, next)
        })
      }
    })
  }

  function restore (cb) {
    blocks.offset.once(function (offset) {
      if(offset === 0) return cb(null, -1) //the file is just empty!
      
      var end = offset //the very end of the file!
      var again = Looper(function () {
        offsetCodec.decodeAsync(blocks, end-fsw, function (err, _end) {
          if(_end != end) {
            if((--end) >= 0) again()
            //completely corrupted file!
            else blocks.truncate(0, next)
          }
          else {
            if(end != offset) {
              blocks.truncate(end, next)
            } else
              next()
          }
        })
      })
      again()
      function next () {
        blocks.readUInt32BE(end-(4+fsw), function (err, length) {
          if(err) cb(err)
          else cb(null, end-(length+8+fsw)) //start of the last record
        })
      }
    })
  }

  /**
   * Overwrites an item at `offset` with null bytes.
   *
   * @param {number} offset - the offset of the item to overwrite
   * @param {function} cb - callback that returns any error as an argument
   */
  const overwrite = (offset, cb) => {
    blocks.readUInt32BE(offset, function (err, len) {
      if (err) return cb(err)

      const bookend = Buffer.alloc(4)
      bookend.writeUInt32BE(len, 0)

      const nullBytes = Buffer.alloc(len)
      const full = Buffer.concat([bookend, nullBytes, bookend])

      blocks.write(full, offset, cb)
    })
  }

  return {
    frame, getMeta, restore, overwrite
  }
}



},
"7Xs21mvB3jBFa6LdigPzqD5mo3en4/fpZ7gtqwY3GZQ=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('crypto').randomBytes

},
"7ZoUb78Dv5MKH2Uj9+R+WkT9kcIKCYC8jN3ihAKB390=":
function (require, module, exports, __dirname, __filename) {
'use strict'

//read a number of items and then stop.
module.exports = function take (test, opts) {
  opts = opts || {}
  var last = opts.last || false // whether the first item for which !test(item) should still pass
  var ended = false
  if('number' === typeof test) {
    last = true
    var n = test; test = function () {
      return --n
    }
  }

  return function (read) {

    function terminate (cb) {
      read(true, function (err) {
        last = false; cb(err || true)
      })
    }

    return function (end, cb) {
      if(ended && !end) last ? terminate(cb) : cb(ended)
      else if(ended = end) read(ended, cb)
      else
        read(null, function (end, data) {
          if(ended = ended || end) {
            //last ? terminate(cb) :
            cb(ended)
          }
          else if(!test(data)) {
            ended = true
            last ? cb(null, data) : terminate(cb)
          }
          else
            cb(null, data)
        })
    }
  }
}

},
"7iEjpT3z0zbRKb98t87frdFy/JmB05tW8ZosMaFthtQ=":
function (require, module, exports, __dirname, __filename) {
'use strict';
const strtok3 = require('strtok3');
const core = require('./core');

async function fromFile(path) {
	const tokenizer = await strtok3.fromFile(path);
	try {
		return await core.fromTokenizer(tokenizer);
	} finally {
		await tokenizer.close();
	}
}

const fileType = {
	fromFile
};

Object.assign(fileType, core);

Object.defineProperty(fileType, 'extensions', {
	get() {
		return core.extensions;
	}
});

Object.defineProperty(fileType, 'mimeTypes', {
	get() {
		return core.mimeTypes;
	}
});

module.exports = fileType;

},
"7ir8sinprP5XygFU50ay/O86Zn/b3DUHcPQ3ccIKFI4=":
function (require, module, exports, __dirname, __filename) {
var int53 = {}

var MAX_UINT32 = 0x00000000FFFFFFFF
var MAX_INT53 =  0x001FFFFFFFFFFFFF

function assert (test, message) {
	if(!test) throw new Error(message)
}

function onesComplement(number) {
	number = ~number
	if (number < 0) {
		number = (number & 0x7FFFFFFF) + 0x80000000
	}
	return number
}

function uintHighLow(number) {
	assert(number > -1 && number <= MAX_INT53, "number out of range")
	assert(Math.floor(number) === number, "number must be an integer")
	var high = 0
	var signbit = number & 0xFFFFFFFF
	var low = signbit < 0 ? (number & 0x7FFFFFFF) + 0x80000000 : signbit
	if (number > MAX_UINT32) {
		high = (number - low) / (MAX_UINT32 + 1)
	}
	return [high, low]
}

function intHighLow(number) {
	if (number > -1) {
		return uintHighLow(number)
	}
	var hl = uintHighLow(-number)
	var high = onesComplement(hl[0])
	var low = onesComplement(hl[1])
	if (low === MAX_UINT32) {
		high += 1
		low = 0
	}
	else {
		low += 1
	}
	return [high, low]
}

function toDouble(high, low, signed) {
	if (signed && (high & 0x80000000) !== 0) {
		high = onesComplement(high)
		low = onesComplement(low)
		assert(high < 0x00200000, "number too small")
		return -((high * (MAX_UINT32 + 1)) + low + 1)
	}
	else { //positive
		assert(high < 0x00200000, "number too large")
		return (high * (MAX_UINT32 + 1)) + low
	}
}

int53.readInt64BE = function (buffer, offset) {
	offset = offset || 0
	var high = buffer.readUInt32BE(offset)
	var low = buffer.readUInt32BE(offset + 4)
	return toDouble(high, low, true)
}

int53.readInt64LE = function (buffer, offset) {
	offset = offset || 0
	var low = buffer.readUInt32LE(offset)
	var high = buffer.readUInt32LE(offset + 4)
	return toDouble(high, low, true)
}

int53.readUInt64BE = function (buffer, offset) {
	offset = offset || 0
	var high = buffer.readUInt32BE(offset)
	var low = buffer.readUInt32BE(offset + 4)
	return toDouble(high, low, false)
}

int53.readUInt64LE = function (buffer, offset) {
	offset = offset || 0
	var low = buffer.readUInt32LE(offset)
	var high = buffer.readUInt32LE(offset + 4)
	return toDouble(high, low, false)
}

int53.writeInt64BE = function (number, buffer, offset) {
	offset = offset || 0
	var hl = intHighLow(number)
	buffer.writeUInt32BE(hl[0], offset)
	buffer.writeUInt32BE(hl[1], offset + 4)
}

int53.writeInt64LE = function (number, buffer, offset) {
	offset = offset || 0
	var hl = intHighLow(number)
	buffer.writeUInt32LE(hl[1], offset)
	buffer.writeUInt32LE(hl[0], offset + 4)
}

int53.writeUInt64BE = function (number, buffer, offset) {
	offset = offset || 0
	var hl = uintHighLow(number)
	buffer.writeUInt32BE(hl[0], offset)
	buffer.writeUInt32BE(hl[1], offset + 4)
}

int53.writeUInt64LE = function (number, buffer, offset) {
	offset = offset || 0
	var hl = uintHighLow(number)
	buffer.writeUInt32LE(hl[1], offset)
	buffer.writeUInt32LE(hl[0], offset + 4)
}

module.exports = int53

},
"7nx6M/8jYI/tPQVAOIMyQPi7B7tMpUSziHghUjPfKMA=":
function (require, module, exports, __dirname, __filename) {
var quickInsert = require('quick-insert');

module.exports = function toDuplex(channel) {
  var buffer = [];
  var cbs = [];
  var isReceiving = false;
  var outSeq = 0;
  var waitingForInSeq = 1;
  var isSending = false;

  function close() {
    setTimeout(function tryToClose() {
      if (!isReceiving && !isSending) {
        if (channel.removeListener) {
          channel.removeListener('message', onMsg);
        } else if (channel.off) {
          channel.off('message', onMsg);
        }
      } else {
        setTimeout(tryToClose);
      }
    });
  }

  function consumeReads() {
    var cb, msg;
    while (buffer.length && cbs.length && buffer[0].seq === waitingForInSeq) {
      msg = buffer.shift();
      cb = cbs.shift();
      waitingForInSeq += 1;
      switch (msg.type) {
        case 'data':
          if (msg.format === 'buffer') {
            cb(null, Buffer.from(msg.data, 'base64'));
          } else {
            cb(null, msg.data);
          }
          break;

        case 'error':
          cb(msg.data);
          isReceiving = false;
          close();
          return;

        case 'end':
          cb(true);
          isReceiving = false;
          close();
          return;

        default:
          (console.warn | console.log)(
            'pull-rn-channel cannot recognize message',
            msg
          );
          break;
      }
    }
  }

  function onMsg(raw) {
    const msg = JSON.parse(raw);
    quickInsert(msg, buffer, function(m1, m2) {
      if (m1.seq === m2.seq) return 0;
      return m1.seq < m2.seq ? -1 : 1;
    });
    consumeReads();
  }

  if (channel.addListener) {
    channel.addListener('message', onMsg);
  } else if (channel.on) {
    channel.on('message', onMsg);
  } else {
    throw new Error(
      'pull-rn-channel cannot call neither `on` nor `addListener`'
    );
  }

  function read(abort, cb) {
    isReceiving = true;
    if (!cb) throw new Error('*must* provide cb to pull-rn-channel source');
    if (abort) {
      while (cbs.length) {
        cbs.shift()(abort);
      }
      cb(abort);
      isReceiving = false;
      close();
    } else {
      cbs.push(cb);
      consumeReads();
    }
  }

  function write(read) {
    isSending = true;
    read(null, function next(end, data) {
      outSeq += 1;
      if (end === true) {
        channel.send(JSON.stringify({type: 'end', seq: outSeq}));
        isSending = false;
        close();
      } else if (end) {
        channel.send(JSON.stringify({type: 'error', data: end, seq: outSeq}));
        isSending = false;
        close();
      } else {
        const send = Buffer.isBuffer(data) ? data.toString('base64') : data;
        const format = Buffer.isBuffer(data) ? 'buffer' : 'json';
        const payload = {type: 'data', format, data: send, seq: outSeq};
        channel.send(JSON.stringify(payload));
        read(null, next);
      }
    });
  }

  return {
    source: read,
    sink: write,
  };
};

},
"7q7LlTQEks9Myg/SZIMnoEC0HgzjCqoRDBnyrs8gCSc=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.hasPinged = exports.hasSuccessfulAttempts = exports.hasOnlyFailedAttempts = exports.hasNoAttempts = void 0;
function hasNoAttempts([_addr, p]) {
    return !p.stateChange;
}
exports.hasNoAttempts = hasNoAttempts;
function hasOnlyFailedAttempts([_addr, p]) {
    return !!p.stateChange && (!p.duration || p.duration.mean == 0);
}
exports.hasOnlyFailedAttempts = hasOnlyFailedAttempts;
function hasSuccessfulAttempts([_addr, p]) {
    return !!p.duration && p.duration.mean > 0;
}
exports.hasSuccessfulAttempts = hasSuccessfulAttempts;
function hasPinged([_addr, p]) {
    return !!p.ping && !!p.ping.rtt && p.ping.rtt.mean > 0;
}
exports.hasPinged = hasPinged;

},
"7zjesWGed4jKtuDXva9K3esbuy9Xu86TIfVIovsi01E=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('crypto').createHmac

},
"84wOzamum2jP+/5fIqg6RNZF+/nib1rh845LX3EpSg8=":
function (require, module, exports, __dirname, __filename) {
var sodium = require('bindings')({
  bindings: 'sodium.node',
  name: 'sodium-native-nodejs-mobile',
});

module.exports = sodium;

},
"88chY/ziKx3yfC1mhfx/HLAvhyOFSFmvaTQG9QACJMw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2020 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const noauthTransformPlugin = require('multiserver/plugins/noauth');
const wsTransportPlugin = require('multiserver/plugins/ws');
module.exports = function multiserverAddons(ssb, cfg) {
    ssb.multiserver.transform({
        name: 'noauth',
        create: () => noauthTransformPlugin({
            keys: { publicKey: Buffer.from(cfg.keys.public, 'base64') },
        }),
    });
    ssb.multiserver.transport({
        name: 'ws',
        create: () => wsTransportPlugin({}),
    });
    if (process.env.MANYVERSE_PLATFORM === 'mobile') {
        try {
            const rnBridge = require('rn-bridge');
            const rnChannelPlugin = require('multiserver-rn-channel');
            ssb.multiserver.transport({
                name: 'channel',
                create: () => rnChannelPlugin(rnBridge.channel),
            });
        }
        catch (err) { }
    }
    else {
        try {
            const { ipcMain } = require('electron');
            const electronIpcPlugin = require('multiserver-electron-ipc');
            const webContentsPromise = process.webContentsP;
            ssb.multiserver.transport({
                name: 'channel',
                create: () => electronIpcPlugin({ ipcMain, webContentsPromise }),
            });
        }
        catch (err) {
            console.error(err);
        }
    }
};
//# sourceMappingURL=multiserver-addons.js.map
},
"8EwE6eQOoa2peh5BStJthx+qB3jjsfsNX8Zuxqy8JD8=":
function (require, module, exports, __dirname, __filename) {
module.exports = globSync
globSync.GlobSync = GlobSync

var fs = require('fs')
var rp = require('fs.realpath')
var minimatch = require('minimatch')
var Minimatch = minimatch.Minimatch
var Glob = require('./glob.js').Glob
var util = require('util')
var path = require('path')
var assert = require('assert')
var isAbsolute = require('path-is-absolute')
var common = require('./common.js')
var alphasort = common.alphasort
var alphasorti = common.alphasorti
var setopts = common.setopts
var ownProp = common.ownProp
var childrenIgnored = common.childrenIgnored
var isIgnored = common.isIgnored

function globSync (pattern, options) {
  if (typeof options === 'function' || arguments.length === 3)
    throw new TypeError('callback provided to sync glob\n'+
                        'See: https://github.com/isaacs/node-glob/issues/167')

  return new GlobSync(pattern, options).found
}

function GlobSync (pattern, options) {
  if (!pattern)
    throw new Error('must provide pattern')

  if (typeof options === 'function' || arguments.length === 3)
    throw new TypeError('callback provided to sync glob\n'+
                        'See: https://github.com/isaacs/node-glob/issues/167')

  if (!(this instanceof GlobSync))
    return new GlobSync(pattern, options)

  setopts(this, pattern, options)

  if (this.noprocess)
    return this

  var n = this.minimatch.set.length
  this.matches = new Array(n)
  for (var i = 0; i < n; i ++) {
    this._process(this.minimatch.set[i], i, false)
  }
  this._finish()
}

GlobSync.prototype._finish = function () {
  assert(this instanceof GlobSync)
  if (this.realpath) {
    var self = this
    this.matches.forEach(function (matchset, index) {
      var set = self.matches[index] = Object.create(null)
      for (var p in matchset) {
        try {
          p = self._makeAbs(p)
          var real = rp.realpathSync(p, self.realpathCache)
          set[real] = true
        } catch (er) {
          if (er.syscall === 'stat')
            set[self._makeAbs(p)] = true
          else
            throw er
        }
      }
    })
  }
  common.finish(this)
}


GlobSync.prototype._process = function (pattern, index, inGlobStar) {
  assert(this instanceof GlobSync)

  // Get the first [n] parts of pattern that are all strings.
  var n = 0
  while (typeof pattern[n] === 'string') {
    n ++
  }
  // now n is the index of the first one that is *not* a string.

  // See if there's anything else
  var prefix
  switch (n) {
    // if not, then this is rather simple
    case pattern.length:
      this._processSimple(pattern.join('/'), index)
      return

    case 0:
      // pattern *starts* with some non-trivial item.
      // going to readdir(cwd), but not include the prefix in matches.
      prefix = null
      break

    default:
      // pattern has some string bits in the front.
      // whatever it starts with, whether that's 'absolute' like /foo/bar,
      // or 'relative' like '../baz'
      prefix = pattern.slice(0, n).join('/')
      break
  }

  var remain = pattern.slice(n)

  // get the list of entries.
  var read
  if (prefix === null)
    read = '.'
  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {
    if (!prefix || !isAbsolute(prefix))
      prefix = '/' + prefix
    read = prefix
  } else
    read = prefix

  var abs = this._makeAbs(read)

  //if ignored, skip processing
  if (childrenIgnored(this, read))
    return

  var isGlobStar = remain[0] === minimatch.GLOBSTAR
  if (isGlobStar)
    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar)
  else
    this._processReaddir(prefix, read, abs, remain, index, inGlobStar)
}


GlobSync.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar) {
  var entries = this._readdir(abs, inGlobStar)

  // if the abs isn't a dir, then nothing can match!
  if (!entries)
    return

  // It will only match dot entries if it starts with a dot, or if
  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.
  var pn = remain[0]
  var negate = !!this.minimatch.negate
  var rawGlob = pn._glob
  var dotOk = this.dot || rawGlob.charAt(0) === '.'

  var matchedEntries = []
  for (var i = 0; i < entries.length; i++) {
    var e = entries[i]
    if (e.charAt(0) !== '.' || dotOk) {
      var m
      if (negate && !prefix) {
        m = !e.match(pn)
      } else {
        m = e.match(pn)
      }
      if (m)
        matchedEntries.push(e)
    }
  }

  var len = matchedEntries.length
  // If there are no matched entries, then nothing matches.
  if (len === 0)
    return

  // if this is the last remaining pattern bit, then no need for
  // an additional stat *unless* the user has specified mark or
  // stat explicitly.  We know they exist, since readdir returned
  // them.

  if (remain.length === 1 && !this.mark && !this.stat) {
    if (!this.matches[index])
      this.matches[index] = Object.create(null)

    for (var i = 0; i < len; i ++) {
      var e = matchedEntries[i]
      if (prefix) {
        if (prefix.slice(-1) !== '/')
          e = prefix + '/' + e
        else
          e = prefix + e
      }

      if (e.charAt(0) === '/' && !this.nomount) {
        e = path.join(this.root, e)
      }
      this._emitMatch(index, e)
    }
    // This was the last one, and no stats were needed
    return
  }

  // now test all matched entries as stand-ins for that part
  // of the pattern.
  remain.shift()
  for (var i = 0; i < len; i ++) {
    var e = matchedEntries[i]
    var newPattern
    if (prefix)
      newPattern = [prefix, e]
    else
      newPattern = [e]
    this._process(newPattern.concat(remain), index, inGlobStar)
  }
}


GlobSync.prototype._emitMatch = function (index, e) {
  if (isIgnored(this, e))
    return

  var abs = this._makeAbs(e)

  if (this.mark)
    e = this._mark(e)

  if (this.absolute) {
    e = abs
  }

  if (this.matches[index][e])
    return

  if (this.nodir) {
    var c = this.cache[abs]
    if (c === 'DIR' || Array.isArray(c))
      return
  }

  this.matches[index][e] = true

  if (this.stat)
    this._stat(e)
}


GlobSync.prototype._readdirInGlobStar = function (abs) {
  // follow all symlinked directories forever
  // just proceed as if this is a non-globstar situation
  if (this.follow)
    return this._readdir(abs, false)

  var entries
  var lstat
  var stat
  try {
    lstat = fs.lstatSync(abs)
  } catch (er) {
    if (er.code === 'ENOENT') {
      // lstat failed, doesn't exist
      return null
    }
  }

  var isSym = lstat && lstat.isSymbolicLink()
  this.symlinks[abs] = isSym

  // If it's not a symlink or a dir, then it's definitely a regular file.
  // don't bother doing a readdir in that case.
  if (!isSym && lstat && !lstat.isDirectory())
    this.cache[abs] = 'FILE'
  else
    entries = this._readdir(abs, false)

  return entries
}

GlobSync.prototype._readdir = function (abs, inGlobStar) {
  var entries

  if (inGlobStar && !ownProp(this.symlinks, abs))
    return this._readdirInGlobStar(abs)

  if (ownProp(this.cache, abs)) {
    var c = this.cache[abs]
    if (!c || c === 'FILE')
      return null

    if (Array.isArray(c))
      return c
  }

  try {
    return this._readdirEntries(abs, fs.readdirSync(abs))
  } catch (er) {
    this._readdirError(abs, er)
    return null
  }
}

GlobSync.prototype._readdirEntries = function (abs, entries) {
  // if we haven't asked to stat everything, then just
  // assume that everything in there exists, so we can avoid
  // having to stat it a second time.
  if (!this.mark && !this.stat) {
    for (var i = 0; i < entries.length; i ++) {
      var e = entries[i]
      if (abs === '/')
        e = abs + e
      else
        e = abs + '/' + e
      this.cache[e] = true
    }
  }

  this.cache[abs] = entries

  // mark and cache dir-ness
  return entries
}

GlobSync.prototype._readdirError = function (f, er) {
  // handle errors, and cache the information
  switch (er.code) {
    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205
    case 'ENOTDIR': // totally normal. means it *does* exist.
      var abs = this._makeAbs(f)
      this.cache[abs] = 'FILE'
      if (abs === this.cwdAbs) {
        var error = new Error(er.code + ' invalid cwd ' + this.cwd)
        error.path = this.cwd
        error.code = er.code
        throw error
      }
      break

    case 'ENOENT': // not terribly unusual
    case 'ELOOP':
    case 'ENAMETOOLONG':
    case 'UNKNOWN':
      this.cache[this._makeAbs(f)] = false
      break

    default: // some unusual error.  Treat as failure.
      this.cache[this._makeAbs(f)] = false
      if (this.strict)
        throw er
      if (!this.silent)
        console.error('glob error', er)
      break
  }
}

GlobSync.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar) {

  var entries = this._readdir(abs, inGlobStar)

  // no entries means not a dir, so it can never have matches
  // foo.txt/** doesn't match foo.txt
  if (!entries)
    return

  // test without the globstar, and with every child both below
  // and replacing the globstar.
  var remainWithoutGlobStar = remain.slice(1)
  var gspref = prefix ? [ prefix ] : []
  var noGlobStar = gspref.concat(remainWithoutGlobStar)

  // the noGlobStar pattern exits the inGlobStar state
  this._process(noGlobStar, index, false)

  var len = entries.length
  var isSym = this.symlinks[abs]

  // If it's a symlink, and we're in a globstar, then stop
  if (isSym && inGlobStar)
    return

  for (var i = 0; i < len; i++) {
    var e = entries[i]
    if (e.charAt(0) === '.' && !this.dot)
      continue

    // these two cases enter the inGlobStar state
    var instead = gspref.concat(entries[i], remainWithoutGlobStar)
    this._process(instead, index, true)

    var below = gspref.concat(entries[i], remain)
    this._process(below, index, true)
  }
}

GlobSync.prototype._processSimple = function (prefix, index) {
  // XXX review this.  Shouldn't it be doing the mounting etc
  // before doing stat?  kinda weird?
  var exists = this._stat(prefix)

  if (!this.matches[index])
    this.matches[index] = Object.create(null)

  // If it doesn't exist, then just mark the lack of results
  if (!exists)
    return

  if (prefix && isAbsolute(prefix) && !this.nomount) {
    var trail = /[\/\\]$/.test(prefix)
    if (prefix.charAt(0) === '/') {
      prefix = path.join(this.root, prefix)
    } else {
      prefix = path.resolve(this.root, prefix)
      if (trail)
        prefix += '/'
    }
  }

  if (process.platform === 'win32')
    prefix = prefix.replace(/\\/g, '/')

  // Mark this as a match
  this._emitMatch(index, prefix)
}

// Returns either 'DIR', 'FILE', or false
GlobSync.prototype._stat = function (f) {
  var abs = this._makeAbs(f)
  var needDir = f.slice(-1) === '/'

  if (f.length > this.maxLength)
    return false

  if (!this.stat && ownProp(this.cache, abs)) {
    var c = this.cache[abs]

    if (Array.isArray(c))
      c = 'DIR'

    // It exists, but maybe not how we need it
    if (!needDir || c === 'DIR')
      return c

    if (needDir && c === 'FILE')
      return false

    // otherwise we have to stat, because maybe c=true
    // if we know it exists, but not what it is.
  }

  var exists
  var stat = this.statCache[abs]
  if (!stat) {
    var lstat
    try {
      lstat = fs.lstatSync(abs)
    } catch (er) {
      if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {
        this.statCache[abs] = false
        return false
      }
    }

    if (lstat && lstat.isSymbolicLink()) {
      try {
        stat = fs.statSync(abs)
      } catch (er) {
        stat = lstat
      }
    } else {
      stat = lstat
    }
  }

  this.statCache[abs] = stat

  var c = true
  if (stat)
    c = stat.isDirectory() ? 'DIR' : 'FILE'

  this.cache[abs] = this.cache[abs] || c

  if (needDir && c === 'FILE')
    return false

  return c
}

GlobSync.prototype._mark = function (p) {
  return common.mark(this, p)
}

GlobSync.prototype._makeAbs = function (f) {
  return common.makeAbs(this, f)
}

},
"8It9l0trLHjLwFy+Qv3oPWTAEoErwSDL9wH5UIDmgGE=":
function (require, module, exports, __dirname, __filename) {
'use strict'

//a pair of pull streams where one drains from the other
module.exports = function () {
  var _read, waiting
  function sink (read) {
    if('function' !== typeof read)
      throw new Error('read must be function')

    if(_read)
      throw new Error('already piped')
    _read = read
    if(waiting) {
      var _waiting = waiting
      waiting = null
      _read.apply(null, _waiting)
    }
  }
  function source (abort, cb) {
    if(_read)
      _read(abort, cb)
    else
      waiting = [abort, cb]
  }

  return {
    source: source, sink: sink
  }
}


},
"8SYPXAO0L6iNyK/xgwoUh2bxaiMc3UUxydqVS903fHY=":
function (require, module, exports, __dirname, __filename) {
var create = require('./create')
var path = require('path')
var Inject = require('./inject')
var Set = require('./set')
var Level = require('level')

exports.manifest = {
  get: 'source',
  getSlice: 'source',
  add: 'sink',
  rm: 'async',
  ls: 'source',
  has: 'async',
  size: 'async',
  meta: 'async',
  want: 'async',
  push: 'async',
  changes: 'source',
  createWants: 'source',
  help: 'sync'
}

exports.name = 'blobs'

exports.version = require('./package.json').version

exports.permissions = {
    anonymous: {allow: ['has', 'get', 'getSlice', 'changes', 'createWants']},
}

exports.init = function (sbot, config) {
  var blobs = Inject(
    create(path.join(config.path, 'blobs')),
    Set(Level(path.join(config.path, 'blobs_push'), {valueEncoding: 'json'})),
    sbot.id,
    config.blobs
  )

  sbot.on('rpc:connect', function (rpc) {
    if (rpc.id === sbot.id) return
    blobs._onConnect(rpc, rpc.id)
  })
  return blobs
}


},
"8a51bL3pVppKr5W1HMFs1nx8iryH6TaqPNjZNwiFcaI=":
function (require, module, exports, __dirname, __filename) {
'use strict'
module.exports = function(socket, callback) {
  var remove = socket && (socket.removeEventListener || socket.removeListener);

  function cleanup () {
    if (typeof remove == 'function') {
      remove.call(socket, 'open', handleOpen);
      remove.call(socket, 'error', handleErr);
    }
  }

  function handleOpen(evt) {
    cleanup(); callback();
  }

  function handleErr (evt) {
    cleanup(); callback(evt);
  }

  // if the socket is closing or closed, return end
  if (socket.readyState >= 2) {
    return callback(true);
  }

  // if open, trigger the callback
  if (socket.readyState === 1) {
    return callback();
  }

  socket.addEventListener('open', handleOpen);
  socket.addEventListener('error', handleErr);
};

},
"8awuKc7pKqrk8gvE3q1Yl+IrB12AY+YJoKIyW9haNcI=":
function (require, module, exports, __dirname, __filename) {
function abortable(onEnd) {
  var aborted = false, reading = false, ended = false, _cb, _read

  function terminate (err) {
    if(onEnd) onEnd(ended === true ? null :  ended)
    var cb = _cb; _cb = null
    if(cb) cb(ended)
  }

  function cancel () {
    ended = ended || true
    terminate(aborted || ended)
    _read(aborted, function (err) {
      if(_cb) _cb(err)
    })
  }

  function reader (read) {
    _read = read
    return function (abort, cb) {
      _cb = cb
      if(abort)   aborted = abort
      if(ended)   return cb(ended)
      if(aborted) return
      reading = true
      read(abort, function (end, data) {
        reading = false
        if(aborted) return !abort && read(aborted, function () {})
        if(!_cb) return
        var cb = _cb
        _cb = null
        if(end) {
          ended = end
          onEnd && onEnd(ended === true ? null :  ended)
          cb(end)
        }
        else {
          cb(end, data)
        }
      })
    }
  }

  reader.abort = function () {
    aborted = true
    if(ended) return
    cancel()
  }

  return reader
}

module.exports = abortable


},
"8dNtR7LFeQYzksGmiWNGfy1PUaBprwnrBo2XTGPuOzc=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

/*<replacement>*/

var Buffer = require('safe-buffer').Buffer;
/*</replacement>*/

var isEncoding = Buffer.isEncoding || function (encoding) {
  encoding = '' + encoding;
  switch (encoding && encoding.toLowerCase()) {
    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
      return true;
    default:
      return false;
  }
};

function _normalizeEncoding(enc) {
  if (!enc) return 'utf8';
  var retried;
  while (true) {
    switch (enc) {
      case 'utf8':
      case 'utf-8':
        return 'utf8';
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return 'utf16le';
      case 'latin1':
      case 'binary':
        return 'latin1';
      case 'base64':
      case 'ascii':
      case 'hex':
        return enc;
      default:
        if (retried) return; // undefined
        enc = ('' + enc).toLowerCase();
        retried = true;
    }
  }
};

// Do not cache `Buffer.isEncoding` when checking encoding names as some
// modules monkey-patch it to support additional encodings
function normalizeEncoding(enc) {
  var nenc = _normalizeEncoding(enc);
  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
  return nenc || enc;
}

// StringDecoder provides an interface for efficiently splitting a series of
// buffers into a series of JS strings without breaking apart multi-byte
// characters.
exports.StringDecoder = StringDecoder;
function StringDecoder(encoding) {
  this.encoding = normalizeEncoding(encoding);
  var nb;
  switch (this.encoding) {
    case 'utf16le':
      this.text = utf16Text;
      this.end = utf16End;
      nb = 4;
      break;
    case 'utf8':
      this.fillLast = utf8FillLast;
      nb = 4;
      break;
    case 'base64':
      this.text = base64Text;
      this.end = base64End;
      nb = 3;
      break;
    default:
      this.write = simpleWrite;
      this.end = simpleEnd;
      return;
  }
  this.lastNeed = 0;
  this.lastTotal = 0;
  this.lastChar = Buffer.allocUnsafe(nb);
}

StringDecoder.prototype.write = function (buf) {
  if (buf.length === 0) return '';
  var r;
  var i;
  if (this.lastNeed) {
    r = this.fillLast(buf);
    if (r === undefined) return '';
    i = this.lastNeed;
    this.lastNeed = 0;
  } else {
    i = 0;
  }
  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
  return r || '';
};

StringDecoder.prototype.end = utf8End;

// Returns only complete characters in a Buffer
StringDecoder.prototype.text = utf8Text;

// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
StringDecoder.prototype.fillLast = function (buf) {
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
  this.lastNeed -= buf.length;
};

// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
// continuation byte. If an invalid byte is detected, -2 is returned.
function utf8CheckByte(byte) {
  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
  return byte >> 6 === 0x02 ? -1 : -2;
}

// Checks at most 3 bytes at the end of a Buffer in order to detect an
// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
// needed to complete the UTF-8 character (if applicable) are returned.
function utf8CheckIncomplete(self, buf, i) {
  var j = buf.length - 1;
  if (j < i) return 0;
  var nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 1;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 2;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) {
      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
    }
    return nb;
  }
  return 0;
}

// Validates as many continuation bytes for a multi-byte UTF-8 character as
// needed or are available. If we see a non-continuation byte where we expect
// one, we "replace" the validated continuation bytes we've seen so far with
// a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
// behavior. The continuation byte check is included three times in the case
// where all of the continuation bytes for a character exist in the same buffer.
// It is also done this way as a slight performance increase instead of using a
// loop.
function utf8CheckExtraBytes(self, buf, p) {
  if ((buf[0] & 0xC0) !== 0x80) {
    self.lastNeed = 0;
    return '\ufffd';
  }
  if (self.lastNeed > 1 && buf.length > 1) {
    if ((buf[1] & 0xC0) !== 0x80) {
      self.lastNeed = 1;
      return '\ufffd';
    }
    if (self.lastNeed > 2 && buf.length > 2) {
      if ((buf[2] & 0xC0) !== 0x80) {
        self.lastNeed = 2;
        return '\ufffd';
      }
    }
  }
}

// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
function utf8FillLast(buf) {
  var p = this.lastTotal - this.lastNeed;
  var r = utf8CheckExtraBytes(this, buf, p);
  if (r !== undefined) return r;
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, p, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, p, 0, buf.length);
  this.lastNeed -= buf.length;
}

// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
// partial character, the character's bytes are buffered until the required
// number of bytes are available.
function utf8Text(buf, i) {
  var total = utf8CheckIncomplete(this, buf, i);
  if (!this.lastNeed) return buf.toString('utf8', i);
  this.lastTotal = total;
  var end = buf.length - (total - this.lastNeed);
  buf.copy(this.lastChar, 0, end);
  return buf.toString('utf8', i, end);
}

// For UTF-8, a replacement character is added when ending on a partial
// character.
function utf8End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + '\ufffd';
  return r;
}

// UTF-16LE typically needs two bytes per character, but even if we have an even
// number of bytes available, we need to check if we end on a leading/high
// surrogate. In that case, we need to wait for the next two bytes in order to
// decode the last character properly.
function utf16Text(buf, i) {
  if ((buf.length - i) % 2 === 0) {
    var r = buf.toString('utf16le', i);
    if (r) {
      var c = r.charCodeAt(r.length - 1);
      if (c >= 0xD800 && c <= 0xDBFF) {
        this.lastNeed = 2;
        this.lastTotal = 4;
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
        return r.slice(0, -1);
      }
    }
    return r;
  }
  this.lastNeed = 1;
  this.lastTotal = 2;
  this.lastChar[0] = buf[buf.length - 1];
  return buf.toString('utf16le', i, buf.length - 1);
}

// For UTF-16LE we do not explicitly append special replacement characters if we
// end on a partial character, we simply let v8 handle that.
function utf16End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) {
    var end = this.lastTotal - this.lastNeed;
    return r + this.lastChar.toString('utf16le', 0, end);
  }
  return r;
}

function base64Text(buf, i) {
  var n = (buf.length - i) % 3;
  if (n === 0) return buf.toString('base64', i);
  this.lastNeed = 3 - n;
  this.lastTotal = 3;
  if (n === 1) {
    this.lastChar[0] = buf[buf.length - 1];
  } else {
    this.lastChar[0] = buf[buf.length - 2];
    this.lastChar[1] = buf[buf.length - 1];
  }
  return buf.toString('base64', i, buf.length - n);
}

function base64End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
  return r;
}

// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
function simpleWrite(buf) {
  return buf.toString(this.encoding);
}

function simpleEnd(buf) {
  return buf && buf.length ? this.write(buf) : '';
}
},
"8evRgp8A3qK9k7z9EwZDTCw7zH/85Fz16c9sAsXDMg0=":
function (require, module, exports, __dirname, __filename) {
const IsCanonicalBase64 = require('is-canonical-base64')
const { isFeedType, isMsgType, isBlobType } = require('ssb-ref')

const encryptedTypeRegex = IsCanonicalBase64('', '\\.box\\d*')
const sigTypeRegex = IsCanonicalBase64('', '\\.sig\\.[a-zA-Z0-9]+')

const isEncryptedType = (input) => encryptedTypeRegex.test(input)
const isSigType = (input) => sigTypeRegex.test(input)

function decorateBFE(types) {
  const sigilSuffixRegexp = (type, format) => {
    if (!format.sigil && !format.suffix) return

    return IsCanonicalBase64(
      format.sigil || '',
      (format.suffix && format.suffix.replace('.', '\\.')) || '',
      format.key_length
    )
    // NOTE this assumes all sigil / suffic encodings are base64
  }

  return types.map((type) => {
    return {
      ...type,
      code: Buffer.from([type.code]),
      formats: type.formats.map((format) => {
        return {
          ...format,
          code: Buffer.from([format.code]),
          // TFCode: Buffer.from([type.code, format.code]),
          sigilSuffixRegexp: sigilSuffixRegexp(type, format),
        }
      }),
    }
  })
}

function findTypeFormatForSigilSuffix(input, types) {
  // NOTE tests guarentee that sigil is unique across types
  let type
  let format
  if (typeof input !== 'string') return { type, format }

  if (isFeedType(input)) type = types[0]
  else if (isMsgType(input)) type = types[1]
  else if (isBlobType(input)) type = types[2]
  else if (isEncryptedType(input)) type = types[5]
  else if (isSigType(input)) type = types[4]
  // first regexp match to narrow type

  if (type) {
    try {
      format = type.formats.find((format) =>
        format.sigilSuffixRegexp.test(input)
      )
      // second regexp check to be 100% sure of match
    } catch {
      format = undefined
    }

    return { type, format }
  }

  return { type, format }
}

function definitionsToDict(types) {
  const NAMED_TYPES = {}

  function convertFormats(type) {
    const formats = {}
    for (const format of type.formats) {
      formats[format.format] = format
    }

    return { ...type, formats }
  }

  for (const type of types) {
    NAMED_TYPES[type.type] = convertFormats(type)
  }

  return NAMED_TYPES
}

module.exports = {
  decorateBFE,
  findTypeFormatForSigilSuffix,
  definitionsToDict,
}

},
"8jety1KEnefBKPV+BGi1I1PFKabINBgQR3wOcUQ1lVk=":
function (require, module, exports, __dirname, __filename) {
/**
 * Module dependencies.
 */

const tty = require('tty');
const util = require('util');

/**
 * This is the Node.js implementation of `debug()`.
 */

exports.init = init;
exports.log = log;
exports.formatArgs = formatArgs;
exports.save = save;
exports.load = load;
exports.useColors = useColors;
exports.destroy = util.deprecate(
	() => {},
	'Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.'
);

/**
 * Colors.
 */

exports.colors = [6, 2, 3, 4, 5, 1];

try {
	// Optional dependency (as in, doesn't need to be installed, NOT like optionalDependencies in package.json)
	// eslint-disable-next-line import/no-extraneous-dependencies
	const supportsColor = require('supports-color');

	if (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {
		exports.colors = [
			20,
			21,
			26,
			27,
			32,
			33,
			38,
			39,
			40,
			41,
			42,
			43,
			44,
			45,
			56,
			57,
			62,
			63,
			68,
			69,
			74,
			75,
			76,
			77,
			78,
			79,
			80,
			81,
			92,
			93,
			98,
			99,
			112,
			113,
			128,
			129,
			134,
			135,
			148,
			149,
			160,
			161,
			162,
			163,
			164,
			165,
			166,
			167,
			168,
			169,
			170,
			171,
			172,
			173,
			178,
			179,
			184,
			185,
			196,
			197,
			198,
			199,
			200,
			201,
			202,
			203,
			204,
			205,
			206,
			207,
			208,
			209,
			214,
			215,
			220,
			221
		];
	}
} catch (error) {
	// Swallow - we only care if `supports-color` is available; it doesn't have to be.
}

/**
 * Build up the default `inspectOpts` object from the environment variables.
 *
 *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js
 */

exports.inspectOpts = Object.keys(process.env).filter(key => {
	return /^debug_/i.test(key);
}).reduce((obj, key) => {
	// Camel-case
	const prop = key
		.substring(6)
		.toLowerCase()
		.replace(/_([a-z])/g, (_, k) => {
			return k.toUpperCase();
		});

	// Coerce string value into JS value
	let val = process.env[key];
	if (/^(yes|on|true|enabled)$/i.test(val)) {
		val = true;
	} else if (/^(no|off|false|disabled)$/i.test(val)) {
		val = false;
	} else if (val === 'null') {
		val = null;
	} else {
		val = Number(val);
	}

	obj[prop] = val;
	return obj;
}, {});

/**
 * Is stdout a TTY? Colored output is enabled when `true`.
 */

function useColors() {
	return 'colors' in exports.inspectOpts ?
		Boolean(exports.inspectOpts.colors) :
		tty.isatty(process.stderr.fd);
}

/**
 * Adds ANSI color escape codes if enabled.
 *
 * @api public
 */

function formatArgs(args) {
	const {namespace: name, useColors} = this;

	if (useColors) {
		const c = this.color;
		const colorCode = '\u001B[3' + (c < 8 ? c : '8;5;' + c);
		const prefix = `  ${colorCode};1m${name} \u001B[0m`;

		args[0] = prefix + args[0].split('\n').join('\n' + prefix);
		args.push(colorCode + 'm+' + module.exports.humanize(this.diff) + '\u001B[0m');
	} else {
		args[0] = getDate() + name + ' ' + args[0];
	}
}

function getDate() {
	if (exports.inspectOpts.hideDate) {
		return '';
	}
	return new Date().toISOString() + ' ';
}

/**
 * Invokes `util.format()` with the specified arguments and writes to stderr.
 */

function log(...args) {
	return process.stderr.write(util.format(...args) + '\n');
}

/**
 * Save `namespaces`.
 *
 * @param {String} namespaces
 * @api private
 */
function save(namespaces) {
	if (namespaces) {
		process.env.DEBUG = namespaces;
	} else {
		// If you set a process.env field to null or undefined, it gets cast to the
		// string 'null' or 'undefined'. Just delete instead.
		delete process.env.DEBUG;
	}
}

/**
 * Load `namespaces`.
 *
 * @return {String} returns the previously persisted debug modes
 * @api private
 */

function load() {
	return process.env.DEBUG;
}

/**
 * Init logic for `debug` instances.
 *
 * Create a new `inspectOpts` object in case `useColors` is set
 * differently for a particular `debug` instance.
 */

function init(debug) {
	debug.inspectOpts = {};

	const keys = Object.keys(exports.inspectOpts);
	for (let i = 0; i < keys.length; i++) {
		debug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];
	}
}

module.exports = require('./common')(exports);

const {formatters} = module.exports;

/**
 * Map %o to `util.inspect()`, all on a single line.
 */

formatters.o = function (v) {
	this.inspectOpts.colors = this.useColors;
	return util.inspect(v, this.inspectOpts)
		.split('\n')
		.map(str => str.trim())
		.join(' ');
};

/**
 * Map %O to `util.inspect()`, allowing multiple lines if needed.
 */

formatters.O = function (v) {
	this.inspectOpts.colors = this.useColors;
	return util.inspect(v, this.inspectOpts);
};

},
"8oVQAh3PHo5mQo4nNZARZxbXyIiufUbrNzi1vx0D53w=":
function (require, module, exports, __dirname, __filename) {
module.exports = map

// map := (Continuable<A>, (A) => B) => Continuable<B>
function map(source, lambda) {
    return function continuable(callback) {
        source(function continuation(err, value) {
            if (err) {
                return callback(err)
            }

            callback(null, lambda(value))
        })
    }
}

},
"8vxRGsq1DtgN3QLXryHGZxIJZ7Et6C+dF1MYssntWsE=":
function (require, module, exports, __dirname, __filename) {

module.exports = function (cont) {
  return function (read) {
    cont(function again (err, value) {
      if(err) read(err, function () {
        value(function (abort, cb) { cb(err) })
      })
      else value(read)
    })
  }
}


},
"9+Nl4PO/Aeysg9Z/HWpXKn2CTtKNmBDCkgkl/lk0i3w=":
function (require, module, exports, __dirname, __filename) {
var pull = require('pull-stream')
var fs   = require('fs')
var path = require('path')
var Read = require('pull-file')
var Write = require('pull-write-file')

var readdir =
exports.readdir =
function (dir, match, ignore) {
  var ls, ended = false
  match = (
    !match                           ? null
  : 'function' === typeof match      ? match
  : 'function' === typeof match.test ? match.test.bind(match)
  :                                    null
  )
  return function (abort, cb) {
    if(ended || abort) {
      cb(ended = ended || abort)
    }
    else if(!ls)
      fs.readdir(dir, function (err, _ls) {
        if(err && err.code == 'ENOTDIR') cb(ended = true)
        else if(err)             cb(ended = err)
        else if(!_ls.length) cb(ended = true)
        else {
          if(match)
            _ls = _ls.filter(match)
          ls = _ls.map(function (f) {
            return path.resolve(dir, f)
          })
          if(ls.length)
            cb(null, ls.shift())
          else
            cb(true)
        }
      })
    else if(!ls.length) cb(ended = true)
    else                cb(null, ls.shift())
  }
}

var blocksize = 512

var read = exports.read = Read
var write = exports.write = Write

var exists =
exports.exists =
function (test) {
  test = test || function (e) {
    return !!e
  }
  return pull(
    pull.asyncMap(function (e, cb) {
      fs.stat(e, function (err, stat) {
        if(stat && test(stat))
          cb(null, e)
        else
          cb(null, null)
      })
    }),
    pull.filter(Boolean)
  )
}

function testStat(test) {
  return function () {
    return exists(test)
  }
}


var isFile = 
exports.isFile =
testStat(function (e) { return e.isFile() })

var isDirectory = 
exports.isDirectory =
testStat(function (e) { return e.isDirectory() })

var isBlockDevice = 
exports.isBlockDevice =
testStat(function (e) { return e.isBlockDevice() })

var isCharacterDevice = 
exports.isCharacterDevice =
testStat(function (e) { return e.isCharacterDevice() })

var isSymbolicLink = 
exports.isSymbolicLink =
testStat(function (e) { return e.isSymbolicLink() })

var isFIFO = 
exports.isFIFO =
testStat(function (e) { return e.isFIFO() })

var isSocket = 
exports.isSocket =
testStat(function (e) { return e.isSocket() })



},
"96b9o3I74bYOFfyHfwhgHPvBjrjbvnmYPHRT+QJ0Ktw=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const { Writable } = require('stream');

const PerMessageDeflate = require('./permessage-deflate');
const {
  BINARY_TYPES,
  EMPTY_BUFFER,
  kStatusCode,
  kWebSocket
} = require('./constants');
const { concat, toArrayBuffer, unmask } = require('./buffer-util');
const { isValidStatusCode, isValidUTF8 } = require('./validation');

const GET_INFO = 0;
const GET_PAYLOAD_LENGTH_16 = 1;
const GET_PAYLOAD_LENGTH_64 = 2;
const GET_MASK = 3;
const GET_DATA = 4;
const INFLATING = 5;

/**
 * HyBi Receiver implementation.
 *
 * @extends stream.Writable
 */
class Receiver extends Writable {
  /**
   * Creates a Receiver instance.
   *
   * @param {String} [binaryType=nodebuffer] The type for binary data
   * @param {Object} [extensions] An object containing the negotiated extensions
   * @param {Boolean} [isServer=false] Specifies whether to operate in client or
   *     server mode
   * @param {Number} [maxPayload=0] The maximum allowed message length
   */
  constructor(binaryType, extensions, isServer, maxPayload) {
    super();

    this._binaryType = binaryType || BINARY_TYPES[0];
    this[kWebSocket] = undefined;
    this._extensions = extensions || {};
    this._isServer = !!isServer;
    this._maxPayload = maxPayload | 0;

    this._bufferedBytes = 0;
    this._buffers = [];

    this._compressed = false;
    this._payloadLength = 0;
    this._mask = undefined;
    this._fragmented = 0;
    this._masked = false;
    this._fin = false;
    this._opcode = 0;

    this._totalPayloadLength = 0;
    this._messageLength = 0;
    this._fragments = [];

    this._state = GET_INFO;
    this._loop = false;
  }

  /**
   * Implements `Writable.prototype._write()`.
   *
   * @param {Buffer} chunk The chunk of data to write
   * @param {String} encoding The character encoding of `chunk`
   * @param {Function} cb Callback
   * @private
   */
  _write(chunk, encoding, cb) {
    if (this._opcode === 0x08 && this._state == GET_INFO) return cb();

    this._bufferedBytes += chunk.length;
    this._buffers.push(chunk);
    this.startLoop(cb);
  }

  /**
   * Consumes `n` bytes from the buffered data.
   *
   * @param {Number} n The number of bytes to consume
   * @return {Buffer} The consumed bytes
   * @private
   */
  consume(n) {
    this._bufferedBytes -= n;

    if (n === this._buffers[0].length) return this._buffers.shift();

    if (n < this._buffers[0].length) {
      const buf = this._buffers[0];
      this._buffers[0] = buf.slice(n);
      return buf.slice(0, n);
    }

    const dst = Buffer.allocUnsafe(n);

    do {
      const buf = this._buffers[0];
      const offset = dst.length - n;

      if (n >= buf.length) {
        dst.set(this._buffers.shift(), offset);
      } else {
        dst.set(new Uint8Array(buf.buffer, buf.byteOffset, n), offset);
        this._buffers[0] = buf.slice(n);
      }

      n -= buf.length;
    } while (n > 0);

    return dst;
  }

  /**
   * Starts the parsing loop.
   *
   * @param {Function} cb Callback
   * @private
   */
  startLoop(cb) {
    let err;
    this._loop = true;

    do {
      switch (this._state) {
        case GET_INFO:
          err = this.getInfo();
          break;
        case GET_PAYLOAD_LENGTH_16:
          err = this.getPayloadLength16();
          break;
        case GET_PAYLOAD_LENGTH_64:
          err = this.getPayloadLength64();
          break;
        case GET_MASK:
          this.getMask();
          break;
        case GET_DATA:
          err = this.getData(cb);
          break;
        default:
          // `INFLATING`
          this._loop = false;
          return;
      }
    } while (this._loop);

    cb(err);
  }

  /**
   * Reads the first two bytes of a frame.
   *
   * @return {(RangeError|undefined)} A possible error
   * @private
   */
  getInfo() {
    if (this._bufferedBytes < 2) {
      this._loop = false;
      return;
    }

    const buf = this.consume(2);

    if ((buf[0] & 0x30) !== 0x00) {
      this._loop = false;
      return error(RangeError, 'RSV2 and RSV3 must be clear', true, 1002);
    }

    const compressed = (buf[0] & 0x40) === 0x40;

    if (compressed && !this._extensions[PerMessageDeflate.extensionName]) {
      this._loop = false;
      return error(RangeError, 'RSV1 must be clear', true, 1002);
    }

    this._fin = (buf[0] & 0x80) === 0x80;
    this._opcode = buf[0] & 0x0f;
    this._payloadLength = buf[1] & 0x7f;

    if (this._opcode === 0x00) {
      if (compressed) {
        this._loop = false;
        return error(RangeError, 'RSV1 must be clear', true, 1002);
      }

      if (!this._fragmented) {
        this._loop = false;
        return error(RangeError, 'invalid opcode 0', true, 1002);
      }

      this._opcode = this._fragmented;
    } else if (this._opcode === 0x01 || this._opcode === 0x02) {
      if (this._fragmented) {
        this._loop = false;
        return error(RangeError, `invalid opcode ${this._opcode}`, true, 1002);
      }

      this._compressed = compressed;
    } else if (this._opcode > 0x07 && this._opcode < 0x0b) {
      if (!this._fin) {
        this._loop = false;
        return error(RangeError, 'FIN must be set', true, 1002);
      }

      if (compressed) {
        this._loop = false;
        return error(RangeError, 'RSV1 must be clear', true, 1002);
      }

      if (this._payloadLength > 0x7d) {
        this._loop = false;
        return error(
          RangeError,
          `invalid payload length ${this._payloadLength}`,
          true,
          1002
        );
      }
    } else {
      this._loop = false;
      return error(RangeError, `invalid opcode ${this._opcode}`, true, 1002);
    }

    if (!this._fin && !this._fragmented) this._fragmented = this._opcode;
    this._masked = (buf[1] & 0x80) === 0x80;

    if (this._isServer) {
      if (!this._masked) {
        this._loop = false;
        return error(RangeError, 'MASK must be set', true, 1002);
      }
    } else if (this._masked) {
      this._loop = false;
      return error(RangeError, 'MASK must be clear', true, 1002);
    }

    if (this._payloadLength === 126) this._state = GET_PAYLOAD_LENGTH_16;
    else if (this._payloadLength === 127) this._state = GET_PAYLOAD_LENGTH_64;
    else return this.haveLength();
  }

  /**
   * Gets extended payload length (7+16).
   *
   * @return {(RangeError|undefined)} A possible error
   * @private
   */
  getPayloadLength16() {
    if (this._bufferedBytes < 2) {
      this._loop = false;
      return;
    }

    this._payloadLength = this.consume(2).readUInt16BE(0);
    return this.haveLength();
  }

  /**
   * Gets extended payload length (7+64).
   *
   * @return {(RangeError|undefined)} A possible error
   * @private
   */
  getPayloadLength64() {
    if (this._bufferedBytes < 8) {
      this._loop = false;
      return;
    }

    const buf = this.consume(8);
    const num = buf.readUInt32BE(0);

    //
    // The maximum safe integer in JavaScript is 2^53 - 1. An error is returned
    // if payload length is greater than this number.
    //
    if (num > Math.pow(2, 53 - 32) - 1) {
      this._loop = false;
      return error(
        RangeError,
        'Unsupported WebSocket frame: payload length > 2^53 - 1',
        false,
        1009
      );
    }

    this._payloadLength = num * Math.pow(2, 32) + buf.readUInt32BE(4);
    return this.haveLength();
  }

  /**
   * Payload length has been read.
   *
   * @return {(RangeError|undefined)} A possible error
   * @private
   */
  haveLength() {
    if (this._payloadLength && this._opcode < 0x08) {
      this._totalPayloadLength += this._payloadLength;
      if (this._totalPayloadLength > this._maxPayload && this._maxPayload > 0) {
        this._loop = false;
        return error(RangeError, 'Max payload size exceeded', false, 1009);
      }
    }

    if (this._masked) this._state = GET_MASK;
    else this._state = GET_DATA;
  }

  /**
   * Reads mask bytes.
   *
   * @private
   */
  getMask() {
    if (this._bufferedBytes < 4) {
      this._loop = false;
      return;
    }

    this._mask = this.consume(4);
    this._state = GET_DATA;
  }

  /**
   * Reads data bytes.
   *
   * @param {Function} cb Callback
   * @return {(Error|RangeError|undefined)} A possible error
   * @private
   */
  getData(cb) {
    let data = EMPTY_BUFFER;

    if (this._payloadLength) {
      if (this._bufferedBytes < this._payloadLength) {
        this._loop = false;
        return;
      }

      data = this.consume(this._payloadLength);
      if (this._masked) unmask(data, this._mask);
    }

    if (this._opcode > 0x07) return this.controlMessage(data);

    if (this._compressed) {
      this._state = INFLATING;
      this.decompress(data, cb);
      return;
    }

    if (data.length) {
      //
      // This message is not compressed so its lenght is the sum of the payload
      // length of all fragments.
      //
      this._messageLength = this._totalPayloadLength;
      this._fragments.push(data);
    }

    return this.dataMessage();
  }

  /**
   * Decompresses data.
   *
   * @param {Buffer} data Compressed data
   * @param {Function} cb Callback
   * @private
   */
  decompress(data, cb) {
    const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];

    perMessageDeflate.decompress(data, this._fin, (err, buf) => {
      if (err) return cb(err);

      if (buf.length) {
        this._messageLength += buf.length;
        if (this._messageLength > this._maxPayload && this._maxPayload > 0) {
          return cb(
            error(RangeError, 'Max payload size exceeded', false, 1009)
          );
        }

        this._fragments.push(buf);
      }

      const er = this.dataMessage();
      if (er) return cb(er);

      this.startLoop(cb);
    });
  }

  /**
   * Handles a data message.
   *
   * @return {(Error|undefined)} A possible error
   * @private
   */
  dataMessage() {
    if (this._fin) {
      const messageLength = this._messageLength;
      const fragments = this._fragments;

      this._totalPayloadLength = 0;
      this._messageLength = 0;
      this._fragmented = 0;
      this._fragments = [];

      if (this._opcode === 2) {
        let data;

        if (this._binaryType === 'nodebuffer') {
          data = concat(fragments, messageLength);
        } else if (this._binaryType === 'arraybuffer') {
          data = toArrayBuffer(concat(fragments, messageLength));
        } else {
          data = fragments;
        }

        this.emit('message', data);
      } else {
        const buf = concat(fragments, messageLength);

        if (!isValidUTF8(buf)) {
          this._loop = false;
          return error(Error, 'invalid UTF-8 sequence', true, 1007);
        }

        this.emit('message', buf.toString());
      }
    }

    this._state = GET_INFO;
  }

  /**
   * Handles a control message.
   *
   * @param {Buffer} data Data to handle
   * @return {(Error|RangeError|undefined)} A possible error
   * @private
   */
  controlMessage(data) {
    if (this._opcode === 0x08) {
      this._loop = false;

      if (data.length === 0) {
        this.emit('conclude', 1005, '');
        this.end();
      } else if (data.length === 1) {
        return error(RangeError, 'invalid payload length 1', true, 1002);
      } else {
        const code = data.readUInt16BE(0);

        if (!isValidStatusCode(code)) {
          return error(RangeError, `invalid status code ${code}`, true, 1002);
        }

        const buf = data.slice(2);

        if (!isValidUTF8(buf)) {
          return error(Error, 'invalid UTF-8 sequence', true, 1007);
        }

        this.emit('conclude', code, buf.toString());
        this.end();
      }
    } else if (this._opcode === 0x09) {
      this.emit('ping', data);
    } else {
      this.emit('pong', data);
    }

    this._state = GET_INFO;
  }
}

module.exports = Receiver;

/**
 * Builds an error object.
 *
 * @param {(Error|RangeError)} ErrorCtor The error constructor
 * @param {String} message The error message
 * @param {Boolean} prefix Specifies whether or not to add a default prefix to
 *     `message`
 * @param {Number} statusCode The status code
 * @return {(Error|RangeError)} The error
 * @private
 */
function error(ErrorCtor, message, prefix, statusCode) {
  const err = new ErrorCtor(
    prefix ? `Invalid WebSocket frame: ${message}` : message
  );

  Error.captureStackTrace(err, error);
  err[kStatusCode] = statusCode;
  return err;
}

},
"9JSqMrDasmeWQ3N9YmglujCqV6TIYmGSCyKSBd0vl3k=":
function (require, module, exports, __dirname, __filename) {
var source = require('./source')
var sink = require('./sink')

module.exports = duplex

function duplex (ws, opts) {
  var req = ws.upgradeReq || {}
  if(opts && opts.binaryType)
    ws.binaryType = opts.binaryType
  else if(opts && opts.binary)
    ws.binaryType = 'arraybuffer'
  return {
    source: source(ws, opts && opts.onConnect),
    sink: sink(ws, opts),

    //http properties - useful for routing or auth.
    headers: req.headers,
    url: req.url,
    upgrade: req.upgrade,
    method: req.method
  };
};


},
"9TNsQDI3nqQdPgb/sKQvU1f79rlQ5SyTo695X3SivaE=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const { seekKey } = require('bipf')

const B_KEY = Buffer.from('key')
const B_VALUE = Buffer.from('value')
const B_AUTHOR = Buffer.from('author')
const B_CONTENT = Buffer.from('content')
const B_TYPE = Buffer.from('type')
const B_ROOT = Buffer.from('root')
const B_FORK = Buffer.from('fork')
const B_ABOUT = Buffer.from('about')
const B_BRANCH = Buffer.from('branch')
const B_VOTE = Buffer.from('vote')
const B_CONTACT = Buffer.from('contact')
const B_LINK = Buffer.from('link')
const B_META = Buffer.from('meta')
const B_PRIVATE = Buffer.from('private')
const B_CHANNEL = Buffer.from('channel')
const B_MENTIONS = Buffer.from('mentions')

module.exports = {
  seekAuthor: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    return seekKey(buffer, p, B_AUTHOR)
  },

  seekType: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_TYPE)
  },

  seekRoot: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_ROOT)
  },

  seekFork: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_FORK)
  },

  seekBranch: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_BRANCH)
  },

  seekVoteLink: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    p = seekKey(buffer, p, B_VOTE)
    if (p < 0) return
    return seekKey(buffer, p, B_LINK)
  },

  seekContact: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_CONTACT)
  },

  seekMentions: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_MENTIONS)
  },

  seekAbout: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_ABOUT)
  },

  pluckLink: function (buffer, start) {
    let p = start
    return seekKey(buffer, p, B_LINK)
  },

  seekPrivate: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_META)
    if (p < 0) return
    return seekKey(buffer, p, B_PRIVATE)
  },

  seekMeta: function (buffer) {
    let p = 0 // note you pass in p!
    return seekKey(buffer, p, B_META)
  },

  seekChannel: function (buffer) {
    let p = 0 // note you pass in p!
    p = seekKey(buffer, p, B_VALUE)
    if (p < 0) return
    p = seekKey(buffer, p, B_CONTENT)
    if (p < 0) return
    return seekKey(buffer, p, B_CHANNEL)
  },

  seekKey: function (buffer) {
    var p = 0 // note you pass in p!
    return seekKey(buffer, p, B_KEY)
  },
}

},
"9aC+WkcEkgFYz8gxKzAfRc7bicX7LCnDHZVHQ5JpUdw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.interpoolGlue = void 0;
const pull = require('pull-stream');
const stats = require('statistics');
const ping = require('pull-ping');
function interpoolGlue(db, hub, staging) {
    function setupPing(address, rpc) {
        const PING_TIMEOUT = 5 * 6e4;
        const pp = ping({ serve: true, timeout: PING_TIMEOUT }, () => { });
        db.update(address, { ping: { rtt: pp.rtt, skew: pp.skew } });
        pull(pp, rpc.gossip.ping({ timeout: PING_TIMEOUT }, (err) => {
            if ((err === null || err === void 0 ? void 0 : err.name) === 'TypeError') {
                db.update(address, (prev) => {
                    var _a;
                    return ({
                        ping: { ...((_a = prev.ping) !== null && _a !== void 0 ? _a : {}), fail: true },
                    });
                });
            }
        }), pp);
    }
    function onConnecting(ev) {
        const address = ev.address;
        const stagedData = staging.get(address);
        staging.unstage(address);
        for (const [addr, data] of staging.entries()) {
            if (data.key && data.key === ev.key)
                staging.unstage(addr);
        }
        db.update(address, { stateChange: Date.now() });
        const dbData = db.get(address);
        hub.update(address, { ...dbData, ...stagedData });
    }
    function onConnectingFailed(ev) {
        db.update(ev.address, (prev) => {
            var _a;
            return ({
                failure: ((_a = prev.failure) !== null && _a !== void 0 ? _a : 0) + 1,
                stateChange: Date.now(),
                duration: stats(prev.duration, 0),
            });
        });
    }
    function onConnected(ev) {
        const address = ev.address;
        const stagedData = staging.get(address);
        staging.unstage(address);
        for (const [addr, data] of staging.entries()) {
            if (data.key && data.key === ev.key)
                staging.unstage(addr);
        }
        db.update(address, { stateChange: Date.now(), failure: 0 });
        const dbData = db.get(address);
        hub.update(address, { ...dbData, ...stagedData });
        if (ev.details.isClient)
            setupPing(address, ev.details.rpc);
    }
    function onDisconnecting(ev) {
        db.update(ev.address, { stateChange: Date.now() });
    }
    function onDisconnectingFailed(ev) {
        db.update(ev.address, { stateChange: Date.now() });
    }
    function onDisconnected(ev) {
        db.update(ev.address, (prev) => ({
            stateChange: Date.now(),
            duration: stats(prev.duration, Date.now() - prev.stateChange),
        }));
    }
    pull(hub.listen(), pull.drain((ev) => {
        if (ev.type === 'connecting')
            onConnecting(ev);
        if (ev.type === 'connecting-failed')
            onConnectingFailed(ev);
        if (ev.type === 'connected')
            onConnected(ev);
        if (ev.type === 'disconnecting')
            onDisconnecting(ev);
        if (ev.type === 'disconnecting-failed')
            onDisconnectingFailed(ev);
        if (ev.type === 'disconnected')
            onDisconnected(ev);
    }));
}
exports.interpoolGlue = interpoolGlue;

},
"9fd1k5ZkeTwPk3R00CrHjPFwfqfnoN2YXmDjJiyUzgE=":
function (require, module, exports, __dirname, __filename) {
var inherits = require('inherits')
var Readable = require('readable-stream').Readable
var extend = require('xtend')

module.exports = ReadStream
inherits(ReadStream, Readable)

function ReadStream (iterator, options) {
  if (!(this instanceof ReadStream)) return new ReadStream(iterator, options)
  options = options || {}
  Readable.call(this, extend(options, {
    objectMode: true
  }))
  this._iterator = iterator
  this._options = options
  this.on('end', this.destroy.bind(this, null, null))
}

ReadStream.prototype._read = function () {
  var self = this
  var options = this._options
  if (this.destroyed) return

  this._iterator.next(function (err, key, value) {
    if (self.destroyed) return
    if (err) return self.destroy(err)

    if (key === undefined && value === undefined) {
      self.push(null)
    } else if (options.keys !== false && options.values === false) {
      self.push(key)
    } else if (options.keys === false && options.values !== false) {
      self.push(value)
    } else {
      self.push({ key: key, value: value })
    }
  })
}

ReadStream.prototype._destroy = function (err, callback) {
  this._iterator.end(function (err2) {
    callback(err || err2)
  })
}

},
"9xVP90iyBmMd1dXKEgWfEDdwvjIeAWxI5nXFe3ucaRg=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var has = Object.prototype.hasOwnProperty
  , undef;

/**
 * Decode a URI encoded string.
 *
 * @param {String} input The URI encoded string.
 * @returns {String|Null} The decoded string.
 * @api private
 */
function decode(input) {
  try {
    return decodeURIComponent(input.replace(/\+/g, ' '));
  } catch (e) {
    return null;
  }
}

/**
 * Attempts to encode a given input.
 *
 * @param {String} input The string that needs to be encoded.
 * @returns {String|Null} The encoded string.
 * @api private
 */
function encode(input) {
  try {
    return encodeURIComponent(input);
  } catch (e) {
    return null;
  }
}

/**
 * Simple query string parser.
 *
 * @param {String} query The query string that needs to be parsed.
 * @returns {Object}
 * @api public
 */
function querystring(query) {
  var parser = /([^=?#&]+)=?([^&]*)/g
    , result = {}
    , part;

  while (part = parser.exec(query)) {
    var key = decode(part[1])
      , value = decode(part[2]);

    //
    // Prevent overriding of existing properties. This ensures that build-in
    // methods like `toString` or __proto__ are not overriden by malicious
    // querystrings.
    //
    // In the case if failed decoding, we want to omit the key/value pairs
    // from the result.
    //
    if (key === null || value === null || key in result) continue;
    result[key] = value;
  }

  return result;
}

/**
 * Transform a query string to an object.
 *
 * @param {Object} obj Object that should be transformed.
 * @param {String} prefix Optional prefix.
 * @returns {String}
 * @api public
 */
function querystringify(obj, prefix) {
  prefix = prefix || '';

  var pairs = []
    , value
    , key;

  //
  // Optionally prefix with a '?' if needed
  //
  if ('string' !== typeof prefix) prefix = '?';

  for (key in obj) {
    if (has.call(obj, key)) {
      value = obj[key];

      //
      // Edge cases where we actually want to encode the value to an empty
      // string instead of the stringified value.
      //
      if (!value && (value === null || value === undef || isNaN(value))) {
        value = '';
      }

      key = encode(key);
      value = encode(value);

      //
      // If we failed to encode the strings, we should bail out as we don't
      // want to add invalid strings to the query.
      //
      if (key === null || value === null) continue;
      pairs.push(key +'='+ value);
    }
  }

  return pairs.length ? prefix + pairs.join('&') : '';
}

//
// Expose the module.
//
exports.stringify = querystringify;
exports.parse = querystring;

},
"A8vg/dLVpwCJt5YxfoftVupQufIBkasQ8k2vyxQHJLI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Ref = require('ssb-ref');
const minireq = typeof window !== 'undefined'
    ? require('@minireq/browser').makeRequest()
    : require('@minireq/node').makeRequest();
const INVITE_URI_ACTION = 'claim-http-invite';
module.exports = {
    name: 'httpInviteClient',
    version: '1.0.0',
    manifest: {
        claim: 'async',
    },
    permissions: {
        anonymous: {},
    },
    init(ssb, _config) {
        function jsonResponseFailed(data) {
            return (typeof data.status === 'string' &&
                data.status !== 'successful' &&
                data.error);
        }
        async function executePostTo(invite, url) {
            if (!invite || typeof invite !== 'string') {
                throw new Error(`invalid invite code: ${invite}`);
            }
            if (!url || typeof url !== 'string') {
                throw new Error(`invalid postTo: ${url}`);
            }
            const { status, data } = await minireq({
                url: url,
                method: 'POST',
                accept: 'application/json',
                send: {
                    id: ssb.id,
                    invite,
                },
                timeout: 10e3,
            }).promise;
            if (!(status >= 200 && status < 300)) {
                throw new Error(`failed (${status}) to claim invite at ${url}`);
            }
            if (jsonResponseFailed(data)) {
                throw new Error(data.error);
            }
            const multiserverAddress = data.multiserverAddress;
            if (!Ref.isAddress(multiserverAddress)) {
                throw new Error(`bad multiserverAddress: ${multiserverAddress}`);
            }
            return multiserverAddress;
        }
        async function claim(input, cb) {
            if (!input) {
                cb(new Error('missing URI input'));
                return;
            }
            if (typeof input !== 'string') {
                cb(new Error('URI input should be a string'));
                return;
            }
            let url;
            try {
                url = new URL(input);
            }
            catch (err) {
                cb(err);
                return;
            }
            if (url.protocol.startsWith('http')) {
                url.searchParams.set('encoding', 'json');
                const jsonUrl = url.toString();
                try {
                    const { status, data } = await minireq({
                        url: jsonUrl,
                        method: 'GET',
                        accept: 'application/json',
                        timeout: 10e3,
                    }).promise;
                    if (!(status >= 200 && status < 300)) {
                        cb(new Error(`failed (${status}) to get invite from ${jsonUrl}`));
                        return;
                    }
                    if (jsonResponseFailed(data)) {
                        cb(new Error(data.error));
                        return;
                    }
                    const { invite, postTo } = data;
                    try {
                        const multiserverAddress = await executePostTo(invite, postTo);
                        cb(null, multiserverAddress);
                        return;
                    }
                    catch (err) {
                        cb(err);
                        return;
                    }
                }
                catch (err) {
                    cb(err);
                    return;
                }
            }
            else if (url.protocol === 'ssb:') {
                if (url.pathname !== 'experimental' && url.host !== 'experimental') {
                    cb(new Error('SSB URI input isnt experimental'));
                    return;
                }
                const action = url.searchParams.get('action');
                if (action !== INVITE_URI_ACTION) {
                    cb(new Error(`SSB URI input isnt ${INVITE_URI_ACTION}: ${input}`));
                    return;
                }
                const invite = url.searchParams.get('invite');
                const postTo = url.searchParams.get('postTo');
                try {
                    const multiserverAddress = await executePostTo(invite, postTo);
                    cb(null, multiserverAddress);
                    return;
                }
                catch (err) {
                    cb(err);
                    return;
                }
            }
            else {
                cb(new Error(`unsupported URI input: ${input}`));
                return;
            }
        }
        return {
            claim,
        };
    },
};

},
"AINTHrGMiW9dchJOHX1AoGEo7qDBiT1vE+EEgjZTTM8=":
function (require, module, exports, __dirname, __filename) {
'use strict'

function id (e) { return e }
var prop = require('../util/prop')

module.exports = function map (mapper) {
  if(!mapper) return id
  mapper = prop(mapper)
  return function (read) {
    return function (abort, cb) {
      read(abort, function (end, data) {
        try {
        data = !end ? mapper(data) : null
        } catch (err) {
          return read(err, function () {
            return cb(err)
          })
        }
        cb(end, data)
      })
    }
  }
}

},
"AWec1grcPLhUXRka4eduyljgIGlmFAHBkEsgrWrAsSk=":
function (require, module, exports, __dirname, __filename) {

module.exports = {
  encode: JSON.stringify,
  decode: function (data) { return JSON.parse(data.toString()) },
  buffer: false
}




},
"AhGM13F38Ugmo+1/psfxxr/69gITlpyAFudfqUhCubg=":
function (require, module, exports, __dirname, __filename) {
module.exports = of

// of := (Value) => Continuable<Value>
function of(value) {
    return function continuable(callback) {
        callback(null, value)
    }
}

},
"AhjxB+Xjyxkt9RjYoBCkWAsmHOG+2xx1Y8YxsWNSsWU=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var pull = require('pull-stream')
var boxes = require('pull-box-stream')
var explain = require('explain-error')
var errors = require('./errors')
var Handshake = require('pull-handshake')
var random = require('./random')

function isBuffer(buf, len) {
  return Buffer.isBuffer(buf) && buf.length === len
}

module.exports = function (stateless) {
  var exports = {}
  //client is Alice
  //create the client stream with the public key you expect to connect to.
  exports.createClientStream = function (alice, app_key, timeout) {

    return function (bob_pub, seed, cb) {
      if('function' == typeof seed)
        cb = seed, seed = null

      //alice may be null.
      var state = stateless.initialize({
        app_key: app_key,
        local: alice,
        remote: {publicKey: bob_pub},
        seed: seed,
        random: random(32)
      })

      var stream = Handshake({timeout: timeout}, cb)
      var shake = stream.handshake
      stream.handshake = null

      function abort(err, reason) {
        if(err && err !== true) shake.abort(explain(err, reason), cb)
        else                    shake.abort(new Error(reason), cb)
      }

      shake.write(stateless.createChallenge(state))

      shake.read(stateless.challenge_length, function (err, msg) {
        if(err) return abort(err, errors.serverErrorOnChallenge)
        //create the challenge first, because we need to generate a local key
        if(!(state = stateless.clientVerifyChallenge(state, msg)))
          return abort(null, errors.serverInvalidChallenge)

        shake.write(stateless.clientCreateAuth(state))

        shake.read(stateless.server_auth_length, function (err, boxed_sig) {
          if(err) return abort(err, errors.serverHungUp)

          if(!(state = stateless.clientVerifyAccept(state, boxed_sig)))
            return abort(null, errors.serverAcceptInvalid)

          cb(null, shake.rest(), state = stateless.clean(state))
        })
      })

      return stream
    }
  }

  //server is Bob.
  exports.createServerStream = function (bob, authorize, app_key, timeout) {

    return function (cb) {
      var state = stateless.initialize({
        app_key: app_key,
        local: bob,
        //note, the server doesn't know the remote until it receives ClientAuth
        random: random(32)
      })
      var stream = Handshake({timeout: timeout}, cb)

      var shake = stream.handshake
      stream.handshake = null

      function abort (err, reason) {
        if(err && err !== true) shake.abort(err)
        else                    shake.abort(new Error(reason))
        // shake.abort(err) triggers cb(err)
      }

      shake.read(stateless.challenge_length, function (err, challenge) {
        if(err) return abort(err, errors.clientErrorOnChallenge)
        if(!(state = stateless.verifyChallenge(state, challenge)))
          return shake.abort(new Error(errors.clientInvalidChallenge))

        shake.write(stateless.createChallenge(state))
        shake.read(stateless.client_auth_length, function (err, hello) {
          if(err) return abort(err, errors.clientErrorOnHello)

          if(!(state = stateless.serverVerifyAuth(state, hello)))
            return abort(null, errors.clientInvalidHello)

          //check if the user wants to speak to alice.
          authorize(state.remote.publicKey, function (err, auth) {
            if(err) return abort(err, errors.serverErrorOnAuthorization)
            if(!auth) return abort(null, errors.clientUnauthorized)
            state.auth = auth
            shake.write(stateless.serverCreateAccept(state))
            cb(null, shake.rest(), state = stateless.clean(state))
          })
        })
      })
      return stream
    }
  }

  //wrap the above into an actual handshake + encrypted session

  exports.toKeys = stateless.toKeys

  function secure (cb) {
    return function (err, stream, state) {
      if(err) return cb(err)

      var encryptNonce = state.remote.app_mac.slice(0, 24)
      var decryptNonce = state.local.app_mac.slice(0, 24)

      cb(null, {
        remote: state.remote.publicKey,
        //on the server, attach any metadata gathered
        //during `authorize` call
        auth: state.auth,
        crypto: {
          encryptKey: state.encryptKey,
          decryptKey: state.decryptKey,
          encryptNonce: encryptNonce,
          decryptNonce: decryptNonce
        },
        source: pull(
          stream.source,
          boxes.createUnboxStream(state.decryptKey, decryptNonce)
        ),
        sink: pull(
          boxes.createBoxStream(state.encryptKey, encryptNonce),
          stream.sink
        )
      })
    }
  }

  exports.client =
  exports.createClient = function (alice, app_key, timeout) {
    var create = exports.createClientStream(alice, app_key, timeout)

    return function (bob, seed, cb) {
      if(!isBuffer(bob, 32))
        throw new Error('createClient *must* be passed a public key')
      if('function' === typeof seed)
        return create(bob, secure(seed))
      else
        return create(bob, seed, secure(cb))
    }
  }

  exports.server =
  exports.createServer = function (bob, authorize, app_key, timeout) {
    var create = exports.createServerStream(bob, authorize, app_key, timeout)

    return function (cb) {
      return create(secure(cb))
    }
  }

  return exports
}

},
"AkufsqbhzOeEcKg5R0EcaYJpQ2QkC8Xk7XasY0Nl0Ew=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", { value: true });
const run = require("promisify-tuple");
const secret_stack_decorators_1 = require("secret-stack-decorators");
var explain = require('explain-error');
var Ref = require('ssb-ref');
let invite = class invite {
    constructor(ssb) {
        this.accept = async (invite, cb) => {
            if (!this.ssb.conn || !this.ssb.conn.connect || !this.ssb.conn.remember) {
                cb(new Error('ssb-invite-client requires ssb-conn'));
                return;
            }
            // parse the code
            const [e0, parsed] = this.parseInvite(invite);
            if (e0)
                return cb(explain(e0, 'Could not accept invalid invite code'));
            // connect via SSB CONN
            const addr = parsed.remote;
            const connData = { type: 'pub', autoconnect: true };
            const [e1, rpc] = await run(this.ssb.conn.connect)(addr, connData);
            if (e1)
                return cb(explain(e1, 'Could not connect to pub'));
            // command the peer to follow me
            const [e2] = await run(rpc.invite.use)({ feed: this.ssb.id });
            if (e2)
                return cb(explain(e2, 'Invite not accepted by the pub'));
            // follow the peer
            const [e3] = await run(this.ssb.publish)({
                type: 'contact',
                following: true,
                autofollow: true,
                contact: parsed.key,
            });
            if (e3)
                return cb(explain(e3, 'Unable to follow friend behind invite'));
            // announce the pub to my friends
            const [e4] = await run(this.ssb.publish)({
                type: 'pub',
                address: parsed,
            });
            if (e4)
                return cb(explain(e4, 'Unable to announce pub to my friends'));
            // remember in SSB CONN
            const [e5] = await run(this.ssb.conn.remember)(addr, connData);
            if (e5)
                return cb(explain(e5, 'Could not store the pub in ssb-conn'));
            cb(null, true);
        };
        this.use = (_opts, cb) => {
            cb(new Error('ssb.invite.use not supported by ' + this.ssb.id));
        };
        this.create = (_opts, cb) => {
            cb(new Error('ssb.invite.create not supported by ' + this.ssb.id));
        };
        this.ssb = ssb;
    }
    parseInvite(input) {
        let invite = input && typeof input === 'object' ? input.invite : input;
        if (typeof invite !== 'string' || !invite) {
            return [new Error('is not a string invite code: ' + invite)];
        }
        // remove surrounding whitespaces and quotes
        invite = invite.trim();
        if (invite.charAt(0) === '"' && invite.charAt(invite.length - 1) === '"') {
            invite = invite.slice(1, -1);
        }
        invite = invite.trim();
        if (!Ref.isInvite(invite)) {
            return [new Error('is not an invite code: ' + invite)];
        }
        if (Ref.isLegacyInvite(invite)) {
            var parts = invite.split('~');
            const parsed = Ref.parseAddress(parts[0]); //.split(':')
            //convert legacy code to multiserver invite code.
            var protocol = 'net:';
            if (parsed.host.endsWith('.onion'))
                protocol = 'onion:';
            parsed.remote =
                protocol +
                    parsed.host +
                    ':' +
                    parsed.port +
                    '~shs:' +
                    parsed.key.slice(1, -8) +
                    ':' +
                    parts[1];
            return [null, parsed];
        }
        else {
            const parsed = Ref.parseInvite(invite);
            return [null, parsed];
        }
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('async')
], invite.prototype, "accept", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('async')
], invite.prototype, "use", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('async')
], invite.prototype, "create", void 0);
invite = __decorate([
    secret_stack_decorators_1.plugin('1.0.0')
], invite);
module.exports = invite;

},
"AnlcEj/4pufJjUD4wN/HjKnYXqwoI6Nes7QmANhf9lo=":
function (require, module, exports, __dirname, __filename) {
'use strict'

//read a number of items and then stop.
module.exports = function take (test, opts) {
  opts = opts || {}
  var last = opts.last || false // whether the first item for which !test(item) should still pass
  var ended = false
  if('number' === typeof test) {
    last = true
    var n = test; test = function () {
      return --n
    }
  }

  return function (read) {

    function terminate (cb) {
      read(true, function (err) {
        last = false; cb(err || true)
      })
    }

    return function (end, cb) {
      if(ended)            last ? terminate(cb) : cb(ended)
      else if(ended = end) read(ended, cb)
      else
        read(null, function (end, data) {
          if(ended = ended || end) {
            //last ? terminate(cb) :
            cb(ended)
          }
          else if(!test(data)) {
            ended = true
            last ? cb(null, data) : terminate(cb)
          }
          else
            cb(null, data)
        })
    }
  }
}

},
"AoZLaFBvqQ0x+URmYcRwzEkGuDdK92Uwpbsup93AdOs=":
function (require, module, exports, __dirname, __filename) {
const net = require('net');
const toPull = require('stream-to-pull-stream');
const fs = require('fs');
const pull = require('pull-stream');

const Pushable = require('pull-pushable');
const pullJson = require('pull-json-doubleline');
const pullDefer = require('pull-defer');

const zip  = require('pull-zip')

const uuidv4 = require('uuid/v4');

const debug = require('debug')('ssb-mobile-bluetooth-manager');

const EventEmitter = require('events');

const delayedDeviceScanSource = pullDefer.source();

let scanActive = false;

function makeManager (opts) {

  const bluetoothScanStateEmitter = new EventEmitter();

  if (!opts || !opts.socketFolderPath) {
    throw new Error("ssb-mobile-bluetooth-manager must be configured with a socketFolderPath option.");
  }

  if (!opts || !opts.myIdent) {
    throw new Error("ssb-mobile-bluetooth-manager must be configured with the myIdent option.")
  }

  if (!opts || !opts.metadataServiceUUID) {
    throw new Error("ssb-mobile-bluetooth-manager must be configured with a metadataServiceUUID option.");
  }

  if (!opts || !opts.controlSocketFilename) {
    throw new Error("ssb-mobile-bluetooth-manager must be configured with a controlSocketFilename option.");
  }

  if (!opts || !opts.incomingSocketFilename) {
    throw new Error("ssb-mobile-bluetooth-manager must be configured with a incomingSocketFilename option.");
  }

  if (!opts || !opts.outgoingSocketFilename) {
    throw new Error("ssb-mobile-bluetooth-manager must be configured with a outgoingSocketFilename option.");
  }

  /* Scanning while connected to another bluetooth device slows down the connection, increases latency and makes it
   * periodically disconnect, so we slow down the scan interval if we're gossiping with at least one other device.
   *
   * As per the android docs: https://developer.android.com/guide/topics/connectivity/bluetooth#QueryPairedDevices
   */
  const scanRefreshIntervalWhenConnected = opts.scanRefreshIntervalWhenConnected || 60000;
  let connectedDevices = 0;

  const EVENT_STARTED_SCAN = "startedBluetoothScan";
  const EVENT_FOUND_BLUETOOTH_DEVICES = "btDevicesFound";
  const EVENT_FINISHED_FINDING_BLUETOOTH_DEVICES = "endedBluetoothScan";
  const EVENT_CHECKING_DEVICES = "checkingForScuttlebutt";
  const EVENT_ENDED_CHECKING = "endedChecking";

  const awaitingConnection = Pushable();
  const outgoingConnectionsEstablished = Pushable();
  const outgoingAddressEstablished = Pushable();

  const incomingConnectionEstablished = Pushable();
  const incomingAddressEstablished = Pushable();

  let controlSocketSource = Pushable();

  let awaitingDevicesCb = null;
  let awaitingDiscoverableResponse = null;
  let awaitingIsEnabledResponse = null;
  let onIncomingConnection = null;
  let awaitingOwnMacAddressResponse = null;

  let awaitingMetadata = {

  }

  const metadataServiceUUID = opts.metadataServiceUUID;

  function connect(bluetoothAddress, cb) {
    debug("Attempting outgoing connection to bluetooth address: " + bluetoothAddress);

    awaitingConnection.push(cb);

    // Tell the native android code to make the outgoing bluetooth connection and then connect back
    // on the socket

    controlSocketSource.push({
      "command": "connect",
      "arguments": {
        "remoteAddress": bluetoothAddress
      }
    })

  }

  let controlSocketEstablished = false;

  function makeControlSocket() {
    if (controlSocketEstablished) return;

    var address = opts.socketFolderPath + "/" + opts.controlSocketFilename;

    try {
      fs.unlinkSync(address);
    } catch (error) {
    }

    var controlSocket = net.createServer(function(stream){

      var duplexConnection = toPull.duplex(stream);

      // Send commands to the control server
      pull(controlSocketSource,
        pullJson.stringify(),
        pull.map(logOutgoingCommand),
        duplexConnection.sink
      );

      // Receive and process commands from the control server
      pull(duplexConnection.source, pullJson.parse(), pull.drain(doCommand));

    }).listen(address);

    controlSocketEstablished = true;

    controlSocket.on('closed', function() {
      debug("Control socket closed");
    })

    debug("Created control socket");
  }

  function makeFullyEstablishConnectionsHandler() {

    // It's unpredictable when each of these things happen, but they do happen sequentially
    // within their stream, so we zip them together and do the necessary action when ready

    pull(
      zip(awaitingConnection, outgoingConnectionsEstablished, outgoingAddressEstablished),
      pull.drain( results => {

        let cb = results[0];
        let stream = results[1].stream;
        let connectionOutcome = results[2];

        let outgoingAddress = connectionOutcome.address;
        stream.address = outgoingAddress;

        if (connectionOutcome.success) {
          debug("Calling back multiserve with successful outgoing connection to " + outgoingAddress);
          cb(null, stream);
        } else {
          debug("Calling back with unsuccessful connection to multiserver for address: " + outgoingAddress)
          cb(new Error(connectionOutcome.failureReason));
        }
      })
    );

    pull(
      zip(incomingConnectionEstablished, incomingAddressEstablished),
      pull.drain(results => {
        let stream = results[0].stream;
        let address = results[1].address;

        stream.address = address;

        debug("Calling back to multiserve with incoming bluetooth connection from " + address);
        onIncomingConnection(null, stream);
      })
    )

  }

  function logOutgoingCommand(command) {
    debug("Sending outgoing command to control server");
    debug(command);

    return command;
  }

  function doCommand (command) {

    debug("Received command: ");
    debug(command);

    let commandName = command.command;

    if (commandName === "connected" && !command.arguments.isIncoming) {
      // The initial stream connection is just to the Unix socket. We don't know if that socket is proxying
      // the bluetooth connection successfully until we receive an event to tell us it's connected.

      var addr = "bt:" + command.arguments.remoteAddress.split(":").join("");
      debug("Setting outgoing stream address to " + addr);

      var result = {
        success: true,
        address: addr
      }

      outgoingAddressEstablished.push(result);

      connectedDevices = connectedDevices + 1;
      debug("Connected bluetooth devices is now: " + connectedDevices);

    } else if (commandName === "connected" && command.arguments.isIncoming) {
      var incomingAddr = "bt:" + command.arguments.remoteAddress.split(":").join("");
      debug("Setting incoming connection stream address to: " + incomingAddr);

      incomingAddressEstablished.push({
        address: incomingAddr
      });

      connectedDevices = connectedDevices + 1;
      debug("Connected bluetooth devices is now: " + connectedDevices);

    } else if (commandName === "connectionFailure" && !command.arguments.isIncoming) {
      var reason = command.arguments.reason;

      var result = {
        success: false,
        address: command.arguments.remoteAddress.split(":").join(""),
        failureReason: reason
      }

      outgoingAddressEstablished.push(result);

    } else if (commandName === "disconnected") {
      connectedDevices = connectedDevices - 1;
      debug("Connected bluetooth devices is now: " + connectedDevices);

    } else if (commandName === "discovered") {
      var currentTime = Date.now();
      var args = command.arguments;

      debug("Updating nearby source");
      debug(args);

      if (args.error && args.errorCode === "bluetoothDisabled") {
        debug("Wanted nearby bluetooth devices but bluetooth is disabled. Will call back once bluetooth is enabled again.");
      }
      else if (args.error === true) {
        awaitingDevicesCb(new Error(args.description), null);
      } else {
        var nearBy = {
          lastUpdate: currentTime,
          discovered: args.devices
        }

        bluetoothScanStateEmitter.emit(EVENT_FOUND_BLUETOOTH_DEVICES, nearBy);
        bluetoothScanStateEmitter.emit(EVENT_FINISHED_FINDING_BLUETOOTH_DEVICES);

        awaitingDevicesCb(null, nearBy);
      }

    } else if (commandName === "discoverable") {
      var args = command.arguments;
      if (args.error === true) {
        awaitingDiscoverableResponse(command.arguments);
      }
      else {
        awaitingDiscoverableResponse(null, command.arguments);
      }

      awaitingDiscoverableResponse = null;
    } else if (commandName === "isEnabled") {
      var args = command.arguments;
      awaitingIsEnabledResponse(null, args.enabled);
    } else if (commandName === "ownMacAddress") {
      var args = command.arguments;
      awaitingOwnMacAddressResponse(null, args.address);
    } else if (commandName === "getMetadata") {
      var args = command.arguments;

      var requestId = command.requestId;

      var cb = awaitingMetadata[requestId];

      if (args.error === true) {
        cb(new Error(args.error.description), null);
      } else {
        cb(null, args.metadata);
      }

      delete awaitingMetadata[requestId];

    } else if (commandName === "bluetoothState" && command.arguments.isEnabled) {

      debug("Bluetooth has been enabled.");

      if (awaitingDevicesCb) {
        debug("Was awaiting nearby devices callback but bluetooth was previously disabled. Making request again now.");
        getLatestNearbyDevices(awaitingDevicesCb);
      }

    }

  }

  function listenForOutgoingEstablished() {
    var address = opts.socketFolderPath + "/" + opts.outgoingSocketFilename;

    try {
      fs.unlinkSync(address);
    } catch (error) {

    }

    var server = net.createServer(function(stream){
      debug("bluetooth: Outgoing connection established proxy connection.")

      var item = {
        stream: logDuplexStreams(toPull.duplex(stream))
      }

      outgoingConnectionsEstablished.push(item);

    });

    server.on('listening', () => {
      debug("Server listening for outgoing connections. Starting control unix socket.");
      makeControlSocket();
    });

    return server.listen(address);
  }

  // For some reason, .server gets called twice...
  var started = false

  function listenForIncomingConnections(onConnection) {

    onIncomingConnection = onConnection;

    if(started) return

    var socket = opts.socketFolderPath + "/" + opts.incomingSocketFilename;
    try {
      fs.unlinkSync(socket);
    } catch (error) {

    }

    var server = net.createServer(function (incomingStream) {

      // We only call back with the connection when we later receive the address over the control
      // bridge. See the 'onCommand' function.

      incomingConnectionEstablished.push({
        stream: logDuplexStreams( toPull.duplex(incomingStream) )
      })

    }).listen(socket);

    server.on('close', function (e) {
      debug("bt_bridge socket closed: " + e);
    });

    started = true;

    return function () {
      debug("Server close?");
    }
  }

  function refreshNearbyDevices() {
    // Tell the native android code to discover nearby devices. When it responds, we'll update the
    // 'nearBy devices' pull-stream source

    controlSocketSource.push({
      "command": "discoverDevices",
      "arguments": {

      }
    });
  }

  function getLatestNearbyDevices(cb) {
    awaitingDevicesCb = cb;

    refreshNearbyDevices();
  }

  function getValidAddresses(devices, cb) {

    var results = [];
    var count = 0;

    if (devices.length === 0) {
      debug("No nearby devices to check for scuttlebutt metadata service.");
      cb(null, {
        "discovered": results,
        "lastUpdate": Date.now()
      });

      return;
    }

    devices.forEach( (device, num) => {

      getMetadataForDevice(device.remoteAddress, (err, res) => {

        count = count + 1;
        debug("getValidAddresses count: " + count);

        if (!err) {
          debug(device.remoteAddress + " is available for scuttlebutt bluetooth connections");
          device.id = res.id;
          results.push(device);
        }

        if (count === devices.length) {
          debug("Calling back (get valid addresses)...");
          debug("Valid addresses:");
          debug(results);

          bluetoothScanStateEmitter.emit(EVENT_CHECKING_DEVICES, {
            "checked": count,
            "total": devices.length,
            "discovered": results,
            "found": results.length,
            "remaining": (devices.length - count),
            "lastUpdate": Date.now()
          });

          cb(null, {
            "discovered": results,
            "lastUpdate": Date.now()
          });
        } else {
          bluetoothScanStateEmitter.emit(EVENT_CHECKING_DEVICES, {
            "checked": count,
            "total": devices.length,
            "discovered": results,
            "found": results.length,
            "remaining": (devices.length - count),
            "lastUpdate": Date.now()
          });
        }

      });
    })
  }

  function nearbyScuttlebuttDevices(refreshInterval) {

    return pull(
      nearbyDevices(refreshInterval),
      pull.asyncMap( (result, cb) => {

        debug("Nearby bluetooth devices.");
        debug(result);

        getValidAddresses(result.discovered, cb)
      }),
      pull.map(result => {
        bluetoothScanStateEmitter.emit(EVENT_ENDED_CHECKING, result);
        return result;
      })
    )
  }

  function nearbyDevices(refreshInterval) {

    return pull(
      // We don't start scanning until the user has made their own device discoverable, signalling they wish
      // to use the bluetooth functionality.
      delayedDeviceScanSource,
      pull.asyncMap((next, cb) => {

        var nextScanAfter = refreshInterval;

        if (connectedDevices > 0) {
          debug("Connected device count is " + connectedDevices + ". Next scan will start after " + scanRefreshIntervalWhenConnected + " milliseconds");
          nextScanAfter = scanRefreshIntervalWhenConnected;
        } else {
          debug("Starting next scan after: " + nextScanAfter);
        }

        setTimeout(() => {
          bluetoothScanStateEmitter.emit(EVENT_STARTED_SCAN);
          getLatestNearbyDevices(cb)
        }, nextScanAfter)
      })
    )
  }

  function makeDeviceDiscoverable(forTime, cb) {
    debug("Making device discoverable");

    if (awaitingDiscoverableResponse != null) {
      cb(new Error("Already requesting to make device discoverable."), null)
    } else {
      awaitingDiscoverableResponse = (err, result) => {

        if (!scanActive) {
          delayedDeviceScanSource.resolve(pull.infinite());
          scanActive = true;
        }

        if (err) {
          cb(new Error(err.description), null);
        } else {

          var payload = {
            "id": opts.myIdent
          };

          // The service should stop when the device is no longer discoverable
          var serviceNeededForSeconds = Math.ceil((result.discoverableUntil - Date.now()) / 1000);

          // Only start the metadata service once the device is discoverable
          controlSocketSource.push({
            "command": "startMetadataService",
            "arguments": {
              "serviceName": "scuttlebuttMetadata",
              "service": metadataServiceUUID,
              "payload": payload,
              "timeSeconds": serviceNeededForSeconds
            }
          });

          cb(null, result);
        }

      };

      controlSocketSource.push({
        "command": "makeDiscoverable",
        "arguments": {
          "forTime": forTime
        }
      });
    }
  }

  function isEnabled(cb) {
    if (awaitingIsEnabledResponse) {
      cb(new Error("Already awaiting 'isEnabled' response."), null);
    } else {
      awaitingIsEnabledResponse = cb;

      controlSocketSource.push({
        "command": "isEnabled",
        "arguments": {

        }
      })
    }
  }

  function getMetadataForDevice(deviceMacAddress, cb) {
    var requestId = uuidv4();

    awaitingMetadata[requestId] = cb;

    controlSocketSource.push({
      "command": "getMetadata",
      "requestId": requestId,
      "arguments": {
        "remoteDevice": deviceMacAddress,
        "service": metadataServiceUUID
      }
    });

  }

  function bluetoothScanState() {

    var source = Pushable(function (closed) {

      debug("Closing bluetooth scan lifecycle event listeners.");

      bluetoothScanStateEmitter.removeListener(EVENT_STARTED_SCAN, onScanStarted);
      bluetoothScanStateEmitter.removeListener(EVENT_FOUND_BLUETOOTH_DEVICES, onBtDevicesFound);
      bluetoothScanStateEmitter.removeListener(EVENT_FINISHED_FINDING_BLUETOOTH_DEVICES, onFinishedFindingBluetoothDevices);
      bluetoothScanStateEmitter.removeListener(EVENT_CHECKING_DEVICES, onCheckingDevices);
      bluetoothScanStateEmitter.removeListener(EVENT_ENDED_CHECKING, onFinishedCheckingDevices);
    });

    function onScanStarted()  {
      var event = {
        "state": EVENT_STARTED_SCAN
      }

      source.push(event);
    };

    function onBtDevicesFound (devices) {
      var event = {
        "state": EVENT_FOUND_BLUETOOTH_DEVICES,
        "update": devices
      }

      source.push(event);
    }

    function onFinishedFindingBluetoothDevices() {
      var event = {
        "state": EVENT_FINISHED_FINDING_BLUETOOTH_DEVICES
      }

      source.push(event);
    }

    function onCheckingDevices (update) {
      var event = {
        "state": EVENT_CHECKING_DEVICES,
        "update": update
      }

      source.push(event);
    }

    function onFinishedCheckingDevices() {
      var event = {
        "state": EVENT_ENDED_CHECKING
      }

      source.push(event);
    }

    bluetoothScanStateEmitter.on(EVENT_STARTED_SCAN, onScanStarted);
    bluetoothScanStateEmitter.on(EVENT_FOUND_BLUETOOTH_DEVICES, onBtDevicesFound);
    bluetoothScanStateEmitter.on(EVENT_FINISHED_FINDING_BLUETOOTH_DEVICES, onFinishedFindingBluetoothDevices);
    bluetoothScanStateEmitter.on(EVENT_CHECKING_DEVICES, onCheckingDevices);
    bluetoothScanStateEmitter.on(EVENT_ENDED_CHECKING, onFinishedCheckingDevices);

    return source;
  }

  function getOwnMacAddress(cb) {
    if (awaitingOwnMacAddressResponse) {
      return makeError("alreadyAwaitingMacAddress", "Already awaiting 'ownMacAddress' response");
    } else {
      awaitingOwnMacAddressResponse = cb;

      controlSocketSource.push({
        "command": "ownMacAddress",
        "arguments": {

        }
      })

    }
  }

  function makeError(errorCode, description) {
    return {
        "error": true,
        "errorCode": errorCode,
        "description": description
      }
  }

  /**
   * If 'opts.logStreams' is true, logs out incoming and outgoing data streams.
   * @param {} duplexStream
   */
  function logDuplexStreams(duplexStream) {
    if (!opts.logStreams) {
      return duplexStream;
    } else {

      duplexStream.source = pull(duplexStream.source, pull.map(
        buff => {
          debug( "[source] " + buff.toString() )
          return buff;
        }
      ));

      duplexStream.sink = pull(
        pull.map(outgoingBuff => {
          debug( "[sink] " + outgoingBuff.toString() )
          return outgoingBuff;
        }),
        duplexStream.sink
      )

      return duplexStream;
    }
  }


  listenForOutgoingEstablished();
  makeFullyEstablishConnectionsHandler();

  return {
    connect,
    listenForIncomingConnections,
    nearbyDevices,
    bluetoothScanState,
    nearbyScuttlebuttDevices,
    makeDeviceDiscoverable,
    getMetadataForDevice,
    isEnabled,
    getOwnMacAddress
  }

}

module.exports = makeManager;

},
"AotSg8OFi+45XXQYOo3BG6J46u4PQvjSv8Syr5ga4p4=":
function (require, module, exports, __dirname, __filename) {
const http = require('http');
const urlParse = require('url-parse');
const pull = require('pull-stream');
const FileType = require('file-type');
const {createUnboxStream} = require('pull-box-stream');
const BlobsHttp = require('multiblob-http');
const DEFAULT_PORT = require('./port');

const zeros = Buffer.alloc(24, 0);
const FAKE_HOST = 'http://makeurlparseright.com';

function ServeBlobs(sbot, config) {
  const corsEnabled =
    config && config.serveBlobs && typeof config.serveBlobs.cors === 'boolean'
      ? config.serveBlobs.cors
      : false;
  const csp = config && config.serveBlobs && typeof config.serveBlobs.csp === 'string'
    ? config.serveBlobs.csp
    : 'default-src none; sandbox'

  const handler = BlobsHttp(sbot.blobs, /* prefix */ '', {
    size: false,
    cors: corsEnabled,
    csp,
    readonly: true,
    transform: function (q) {
      if (q.unbox) {
        const keyBase64 = Buffer.from(q.unbox.replace(/\s/g, '+'), 'base64');
        if (keyBase64.length !== 32)
          return function (read) {
            return function (abort, cb) {
              read(new Error('key must be 32 bytes long'), cb);
            };
          };
        const keyBytes = Buffer.from(keyBase64, 'base64');
        return createUnboxStream(keyBytes, zeros);
      }
      return pull.through();
    },
  });

  function ensureHasBlob(hash, cb) {
    //check if we don't already have this, tell blobs we want it, if necessary.
    sbot.blobs.has(hash, function (err, has) {
      if (has) {
        cb(null, true);
      } else {
        sbot.blobs.want(hash, function (err, has) {
          cb(err, has);
        });
      }
    });
  }

  function getBlobHead(hash, cb) {
    pull(
      sbot.blobs.getSlice({hash, start: 0, end: 4100}),
      pull.take(1),
      pull.collect((err, [buf]) => {
        if (err) cb(err);
        else cb(null, buf);
      }),
    );
  }

  function getContentType(buf, cb) {
    FileType.fromBuffer(buf).then(
      (result) => {
        if (result && result.mime) cb(null, result.mime);
        else cb(null, null);
      },
      (err) => {
        cb(err);
      },
    );
  }

  function setContentTypeOnReqURL(contentType, req) {
    const u = urlParse(FAKE_HOST + req.url, true);
    u.set('query', {...u.query, contentType});
    req.url = u.toString().replace(FAKE_HOST, '');
  }

  return function (req, res, next) {
    if (!(req.method === 'GET' || req.method === 'HEAD')) return next();

    const hash = decodeURIComponent(
      urlParse(FAKE_HOST + req.url, true).pathname.substr('/get/'.length),
    );

    ensureHasBlob(hash, (err, has) => {
      if (err || !has) return handler(req, res, next);
      getBlobHead(hash, (err, buf) => {
        if (err || !buf) return handler(req, res, next);
        getContentType(buf, (err, contentType) => {
          if (err || !contentType) return handler(req, res, next);
          setContentTypeOnReqURL(contentType, req);
          handler(req, res, next);
        });
      });
    });
  };
}

module.exports = function init(sbot, config) {
  const port =
    config && config.serveBlobs && typeof config.serveBlobs.port === 'number'
      ? config.serveBlobs.port
      : DEFAULT_PORT;

  const server = http.createServer(ServeBlobs(sbot, config)).listen(port);

  // Ensure that HTTP server is closed when the SSB server closes.
  sbot.close.hook(function (fn, args) {
    server.close();
    fn.apply(this, args);
  });
};

module.exports.init = module.exports;

},
"AthTRY10OgBLAlaG/beXl4z5FCAlPocbMnJaqKLBJIw=":
function (require, module, exports, __dirname, __filename) {
var WS = require('pull-websocket')
var URL = require('url')
var pull = require('pull-stream/pull')
var Map = require('pull-stream/throughs/map')
var scopes = require('multiserver-scopes')
var http = require('http')
var https = require('https')
var fs = require('fs')
var debug = require('debug')('multiserver:ws')

function safe_origin (origin, address, port) {

  //if the connection is not localhost, we shouldn't trust
  //the origin header. So, use address instead of origin
  //if origin not set, then it's definitely not a browser.
  if(!(address === '::1' || address === '127.0.0.1') || origin == undefined)
    return 'ws:' + address + (port ? ':' + port : '')

  //note: origin "null" (as string) can happen a bunch of ways
  //      it can be a html opened as a file
  //      or certain types of CORS
  //      https://www.w3.org/TR/cors/#resource-sharing-check-0
  //      and webworkers if loaded from data-url?
  if(origin === 'null')
    return 'ws:null'

  //a connection from the browser on localhost,
  //we choose to trust this came from a browser.
  return origin.replace(/^http/, 'ws')

}

// Choose a dynamic port between 49152 and 65535
// https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers#Dynamic,_private_or_ephemeral_ports
const getRandomPort = () =>
  Math.floor(49152 + (65535 - 49152 + 1) * Math.random())

module.exports = function (opts = {}) {
  // This takes options for `WebSocket.Server()`:
  // https://github.com/websockets/ws/blob/master/doc/ws.md#new-websocketserveroptions-callback

  opts.binaryType = opts.binaryType || 'arraybuffer'
  const scope = opts.scope || 'device'

  function isAllowedScope (s) {
    return s === scope || Array.isArray(scope) && ~scope.indexOf(s)
  }

  var secure = opts.server && !!opts.server.key || (!!opts.key && !!opts.cert)
  return {
    name: 'ws',
    scope: () => scope,
    server: function (onConnect, startedCb) {
      if (WS.createServer == null) return null

      // Maybe weird: this sets a random port each time that `server()` is run
      // whereas the net plugin sets the port when the outer function is run.
      //
      // This server has a random port generated at runtime rather than when
      // the interface is instantiated. Is that the way it should work?
      opts.port = opts.port || getRandomPort()

      if (typeof opts.key === 'string')
        opts.key = fs.readFileSync(opts.key)
      if (typeof opts.cert === 'string')
        opts.cert = fs.readFileSync(opts.cert)

      var server = opts.server ||
          (opts.key && opts.cert ? https.createServer({ key: opts.key, cert: opts.cert }, opts.handler) : http.createServer(opts.handler))

      const serverOpts = Object.assign({}, opts, {server: server})
      let wsServer = WS.createServer(serverOpts, function (stream) {
        stream.address = safe_origin(
          stream.headers.origin,
          stream.remoteAddress,
          stream.remotePort
        )
        onConnect(stream)
      })

      if(!opts.server) {
        debug('Listening on %s:%d', opts.host, opts.port)
        server.listen(opts.port, opts.host, function () {
          startedCb && startedCb(null, true)
        })
      }
      else
        startedCb && startedCb(null, true)

      return function (cb) {
        debug('Closing server on %s:%d', opts.host, opts.port)
        wsServer.close((err) => {
          debug('after WS close', err)
          if (err) console.error(err)
          else debug('No longer listening on %s:%d', opts.host, opts.port)
          if (cb) cb(err)
        })
      }
    },
    client: function (addr, cb) {
      if(!addr.host) {
        addr.hostname = addr.hostname || opts.host || 'localhost'
        addr.slashes = true
        addr = URL.format(addr)
      }
      if('string' !== typeof addr)
        addr = URL.format(addr)

      var stream = WS.connect(addr, {
        binaryType: opts.binaryType,
        onConnect: function (err) {
          //ensure stream is a stream of node buffers
          stream.source = pull(stream.source, Map(Buffer.from.bind(Buffer)))
          cb(err, stream)
        }
      })
      stream.address = addr

      return function () {
        stream.close()
      }
    },
    stringify: function (targetScope = 'device') {
      if (WS.createServer == null) {
        return null
      }
      if (isAllowedScope(targetScope) === false) {
        return null
      }

      const port = opts.server ? opts.server.address().port : opts.port
      const externalHost = targetScope === 'public' && opts.external
      let resultHost = externalHost || opts.host || scopes.host(targetScope)

      if (resultHost == null) {
        // The device has no network interface for a given `targetScope`.
        return null
      }

      if (typeof resultHost === 'string') {
        resultHost = [resultHost]
      }

      return resultHost.map((h) => {
        return URL.format({
          protocol: secure ? 'wss' : 'ws',
          slashes: true,
          hostname: h,
          port: (secure ? port == 443 : port == 80) ? undefined : port
        })
      }).join(';')
    },
    parse: function (str) {
      var addr = URL.parse(str)
      if(!/^wss?\:$/.test(addr.protocol)) return null
      return addr
    }
  }
}

},
"BAb8PtZjQg38fOfdP6kJel/Askmzk4LekGrQIq39Zbo=":
function (require, module, exports, __dirname, __filename) {
module.exports = mapAsync

// mapAsync := (Continuable<A>, lambda: (A, Callback<B>)) => Continuable<B>
function mapAsync(source, lambda) {
    return function continuable(callback) {
        source(function continuation(err, value) {
            if (err) {
                return callback(err)
            }

            lambda(value, callback)
        })
    }
}

},
"BJhvFouPFvTyUjfQYIzfV7bKFPEA/tYsApW9olWasks=":
function (require, module, exports, __dirname, __filename) {
module.exports = extend

var hasOwnProperty = Object.prototype.hasOwnProperty;

function extend() {
    var target = {}

    for (var i = 0; i < arguments.length; i++) {
        var source = arguments[i]

        for (var key in source) {
            if (hasOwnProperty.call(source, key)) {
                target[key] = source[key]
            }
        }
    }

    return target
}

},
"BPW+ohGOj+1TlKqaWFsfFn7zUbaW6USLAAF5Ln1+CLI=":
function (require, module, exports, __dirname, __filename) {
var maybeCallback = require("./maybe-callback.js")
maybeCallback.both = require("./both.js")
maybeCallback.chain = require("./chain.js")
maybeCallback.either = require("./either.js")
maybeCallback.error = require("./error.js")
maybeCallback.join = require("./join.js")
maybeCallback.mapAsync = require("./map-async.js")
maybeCallback.map = require("./map.js")
maybeCallback.of = require("./of.js")
maybeCallback.to = require("./to.js")

module.exports = maybeCallback


},
"BUZhdKi5Zm9hvtj/jhsOtNkcFGMNoivpgyWgq5g5xS4=":
function (require, module, exports, __dirname, __filename) {


module.exports = require('level-codec/lib/encodings').json

},
"BV2kG6VEVFcyNv+HpxDyLhk0Rs8wmuHW234wYy8pcjg=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Andre Staltz
//
// SPDX-License-Identifier: LGPL-3.0-only

const v = require('ssb-validate');

const convertError = (err) => {
  if (!err.message) return err;
  if (err.message.includes('invalid signature')) {
    err.message = 'Signature was invalid';
  } else if (err.message.includes('initial message must have sequence: 1,')) {
    err.message = 'The first message of a feed must have seq of 1';
  } else if (err.message.includes('invalid HMAC key')) {
    err.message = 'string must be base64 encoded';
  }
  return err;
};

const verifySignatures = (hmacKey, msgVals, cb) => {
  if (!Array.isArray(msgVals)) {
    cb(new Error('input must be an array of message objects'));
    return;
  }
  for (const msgVal of msgVals) {
    const err = v.checkInvalidOOO(msgVal, hmacKey);
    if (err) {
      cb(convertError(err));
      return;
    }
  }
  const keys = msgVals.map(v.id);
  cb(null, keys);
};

const validateSingle = (hmacKey, msgVal, previous, cb) => {
  validateBatch(hmacKey, [msgVal], previous, (err, keys) => {
    if (err) cb(err);
    else cb(err, keys[0]);
  });
};

const validateBatch = (hmacKey, msgVals, previous, cb) => {
  if (!Array.isArray(msgVals)) {
    cb(new Error('input must be an array of message objects'));
    return;
  }
  let state = v.initial();
  try {
    if (previous) {
      const previousKVT = v.toKeyValueTimestamp(previous);
      state = {
        validated: 1,
        queued: 0,
        queue: [previousKVT],
        feeds: {
          [previous.author]: {
            id: previousKVT.key,
            sequence: previous.sequence,
            timestamp: previousKVT.timestamp,
            queue: [],
          },
        },
      };
    }
    for (const msgVal of msgVals) {
      state = v.append(state, hmacKey, msgVal);
      if (state.error) {
        cb(convertError(state.error));
        return;
      }
    }
  } catch (err) {
    cb(convertError(err));
    return;
  }
  const keys = msgVals.map(v.id);
  cb(null, keys);
};

const validateOOOBatch = (hmacKey, msgVals, cb) => {
  verifySignatures(hmacKey, msgVals, cb);
};

const validateMultiAuthorBatch = (hmacKey, msgVals, cb) => {
  verifySignatures(hmacKey, msgVals, cb);
};

// Mirrors the `ready` function for the `web` version of `ssb-validate2-rsjs`.
// The function initializes WASM and WebWorkers in `web`. We define it here with
// a callback so that both libraries can be safely called with the same code.
const ready = (cb) => {
  cb();
};

module.exports.ready = ready;
module.exports.verifySignatures = verifySignatures;
module.exports.validateSingle = validateSingle;
module.exports.validateBatch = validateBatch;
module.exports.validateOOOBatch = validateOOOBatch;
module.exports.validateMultiAuthorBatch = validateMultiAuthorBatch;

},
"BbJ+AHGSnoS13OpDSkWGHhM+CJATmn9px1+2E8kOdtg=":
function (require, module, exports, __dirname, __filename) {

var ThroughStream = require('./through')

function AsyncMapStream(fn) {
  ThroughStream.call(this)
  this.fn = fn
  this.async = false
}

AsyncMapStream.prototype = new ThroughStream()

AsyncMapStream.prototype.write = function (data) {
  var self = this
  if(this.paused) throw new Error('received write while paused')
  this.async = true
  this.fn(data, function (err, data) {
    self.async = false
    if(err) self.source.abort(self.ended = err)
    else {
      self.sink.write(data)
      if(self.ended) self.sink.end(self.ended)
      else if(self.paused) self.resume()
    }
  })
  this.paused = this.async || this.sink.paused
}

AsyncMapStream.prototype.end = function (err) {
  if(this.async) this.ended = err || true
  else this.sink.end(err)
}

module.exports = function (fn) {
  return new AsyncMapStream(fn)
}

},
"ByRagnF/m/oqY7l4QoSht/xD/1/LSvKpS85fg2EdSi8=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

var pathModule = require('path');
var isWindows = process.platform === 'win32';
var fs = require('fs');

// JavaScript implementation of realpath, ported from node pre-v6

var DEBUG = process.env.NODE_DEBUG && /fs/.test(process.env.NODE_DEBUG);

function rethrow() {
  // Only enable in debug mode. A backtrace uses ~1000 bytes of heap space and
  // is fairly slow to generate.
  var callback;
  if (DEBUG) {
    var backtrace = new Error;
    callback = debugCallback;
  } else
    callback = missingCallback;

  return callback;

  function debugCallback(err) {
    if (err) {
      backtrace.message = err.message;
      err = backtrace;
      missingCallback(err);
    }
  }

  function missingCallback(err) {
    if (err) {
      if (process.throwDeprecation)
        throw err;  // Forgot a callback but don't know where? Use NODE_DEBUG=fs
      else if (!process.noDeprecation) {
        var msg = 'fs: missing callback ' + (err.stack || err.message);
        if (process.traceDeprecation)
          console.trace(msg);
        else
          console.error(msg);
      }
    }
  }
}

function maybeCallback(cb) {
  return typeof cb === 'function' ? cb : rethrow();
}

var normalize = pathModule.normalize;

// Regexp that finds the next partion of a (partial) path
// result is [base_with_slash, base], e.g. ['somedir/', 'somedir']
if (isWindows) {
  var nextPartRe = /(.*?)(?:[\/\\]+|$)/g;
} else {
  var nextPartRe = /(.*?)(?:[\/]+|$)/g;
}

// Regex to find the device root, including trailing slash. E.g. 'c:\\'.
if (isWindows) {
  var splitRootRe = /^(?:[a-zA-Z]:|[\\\/]{2}[^\\\/]+[\\\/][^\\\/]+)?[\\\/]*/;
} else {
  var splitRootRe = /^[\/]*/;
}

exports.realpathSync = function realpathSync(p, cache) {
  // make p is absolute
  p = pathModule.resolve(p);

  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {
    return cache[p];
  }

  var original = p,
      seenLinks = {},
      knownHard = {};

  // current character position in p
  var pos;
  // the partial path so far, including a trailing slash if any
  var current;
  // the partial path without a trailing slash (except when pointing at a root)
  var base;
  // the partial path scanned in the previous round, with slash
  var previous;

  start();

  function start() {
    // Skip over roots
    var m = splitRootRe.exec(p);
    pos = m[0].length;
    current = m[0];
    base = m[0];
    previous = '';

    // On windows, check that the root exists. On unix there is no need.
    if (isWindows && !knownHard[base]) {
      fs.lstatSync(base);
      knownHard[base] = true;
    }
  }

  // walk down the path, swapping out linked pathparts for their real
  // values
  // NB: p.length changes.
  while (pos < p.length) {
    // find the next part
    nextPartRe.lastIndex = pos;
    var result = nextPartRe.exec(p);
    previous = current;
    current += result[0];
    base = previous + result[1];
    pos = nextPartRe.lastIndex;

    // continue if not a symlink
    if (knownHard[base] || (cache && cache[base] === base)) {
      continue;
    }

    var resolvedLink;
    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {
      // some known symbolic link.  no need to stat again.
      resolvedLink = cache[base];
    } else {
      var stat = fs.lstatSync(base);
      if (!stat.isSymbolicLink()) {
        knownHard[base] = true;
        if (cache) cache[base] = base;
        continue;
      }

      // read the link if it wasn't read before
      // dev/ino always return 0 on windows, so skip the check.
      var linkTarget = null;
      if (!isWindows) {
        var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);
        if (seenLinks.hasOwnProperty(id)) {
          linkTarget = seenLinks[id];
        }
      }
      if (linkTarget === null) {
        fs.statSync(base);
        linkTarget = fs.readlinkSync(base);
      }
      resolvedLink = pathModule.resolve(previous, linkTarget);
      // track this, if given a cache.
      if (cache) cache[base] = resolvedLink;
      if (!isWindows) seenLinks[id] = linkTarget;
    }

    // resolve the link, then start over
    p = pathModule.resolve(resolvedLink, p.slice(pos));
    start();
  }

  if (cache) cache[original] = p;

  return p;
};


exports.realpath = function realpath(p, cache, cb) {
  if (typeof cb !== 'function') {
    cb = maybeCallback(cache);
    cache = null;
  }

  // make p is absolute
  p = pathModule.resolve(p);

  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {
    return process.nextTick(cb.bind(null, null, cache[p]));
  }

  var original = p,
      seenLinks = {},
      knownHard = {};

  // current character position in p
  var pos;
  // the partial path so far, including a trailing slash if any
  var current;
  // the partial path without a trailing slash (except when pointing at a root)
  var base;
  // the partial path scanned in the previous round, with slash
  var previous;

  start();

  function start() {
    // Skip over roots
    var m = splitRootRe.exec(p);
    pos = m[0].length;
    current = m[0];
    base = m[0];
    previous = '';

    // On windows, check that the root exists. On unix there is no need.
    if (isWindows && !knownHard[base]) {
      fs.lstat(base, function(err) {
        if (err) return cb(err);
        knownHard[base] = true;
        LOOP();
      });
    } else {
      process.nextTick(LOOP);
    }
  }

  // walk down the path, swapping out linked pathparts for their real
  // values
  function LOOP() {
    // stop if scanned past end of path
    if (pos >= p.length) {
      if (cache) cache[original] = p;
      return cb(null, p);
    }

    // find the next part
    nextPartRe.lastIndex = pos;
    var result = nextPartRe.exec(p);
    previous = current;
    current += result[0];
    base = previous + result[1];
    pos = nextPartRe.lastIndex;

    // continue if not a symlink
    if (knownHard[base] || (cache && cache[base] === base)) {
      return process.nextTick(LOOP);
    }

    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {
      // known symbolic link.  no need to stat again.
      return gotResolvedLink(cache[base]);
    }

    return fs.lstat(base, gotStat);
  }

  function gotStat(err, stat) {
    if (err) return cb(err);

    // if not a symlink, skip to the next path part
    if (!stat.isSymbolicLink()) {
      knownHard[base] = true;
      if (cache) cache[base] = base;
      return process.nextTick(LOOP);
    }

    // stat & read the link if not read before
    // call gotTarget as soon as the link target is known
    // dev/ino always return 0 on windows, so skip the check.
    if (!isWindows) {
      var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);
      if (seenLinks.hasOwnProperty(id)) {
        return gotTarget(null, seenLinks[id], base);
      }
    }
    fs.stat(base, function(err) {
      if (err) return cb(err);

      fs.readlink(base, function(err, target) {
        if (!isWindows) seenLinks[id] = target;
        gotTarget(err, target);
      });
    });
  }

  function gotTarget(err, target, base) {
    if (err) return cb(err);

    var resolvedLink = pathModule.resolve(previous, target);
    if (cache) cache[base] = resolvedLink;
    gotResolvedLink(resolvedLink);
  }

  function gotResolvedLink(resolvedLink) {
    // resolve the link, then start over
    p = pathModule.resolve(resolvedLink, p.slice(pos));
    start();
  }
};

},
"C6DEo8Hzu8WvthGYGces7M5RraPde/RtjiZwMV15HMs=":
function (require, module, exports, __dirname, __filename) {
const Events = require('./events')
const v3 = require('./v3')
const StreamModule = require('./stream')
const progress = require('./progress')

function timestamp () {
  return Date.now()
}

module.exports = function (opts) {
  const events = Events(v3)
  const Stream = StreamModule(events)

  var state = events.initialize(opts.id, opts.getMsgAuthor, opts.getMsgSequence)
  state.timeout = opts.timeout || 3000
  state.clock = {}

  if (!opts.isMsg) {
    opts.isMsg = function(m) {
      return Number.isInteger(m.sequence) && m.sequence > 0 &&
        typeof m.author == 'string' && m.content
    }
  }

  var self = {
    id: opts.id,
    streams: {},
    state: state,
    logging: opts.logging,
    progress: function () {
      return progress(state)
    },
    request: function (id, follows) {
      if (opts.isFeed && !opts.isFeed(id)) return
      self.state = events.follow(self.state, {id: id, value: follows !== false, ts: timestamp()})
      self.update()
    },
    pause: function (id, paused) {
      self.state = events.pause(self.state, {id, paused: paused !== false})
      self.update()
    },
    block: function (id, target, value) {
      self.state = events.block(self.state, {id, target, value: value !== false, ts: timestamp()})
      self.update()
    },
    createStream: function (remoteId, version, client) {
      if (self.streams[remoteId])
        self.streams[remoteId].end(new Error('reconnected to peer'))
      if (self.logging) console.log('EBT:conn', remoteId)
      function onClose(peerState) {
        opts.setClock(remoteId, peerState.clock)
      }
      var stream = new Stream(this, remoteId, version, client, opts.isMsg, onClose)
      self.streams[remoteId] = stream

      opts.getClock(remoteId, (err, clock) => {
        //check if peer exists in state, because we may
        //have disconect in the meantime
        if (self.state.peers[remoteId])
          stream.clock(err ? {} : clock)
      })

      return stream
    },
    _retrive: function (err, msg) {
      if (msg) {
        self.state = events.retrive(self.state, msg)
        self.update()
      } else {
        //this should never happen.
        //replication for this feed is in bad state now.
        console.log('could not retrive msg:', err)
      }
    },
    onAppend: function (msg) {
      self.state = events.append(self.state, msg)
      self.update()
    },
    update: function () {
      //retrive next messages.
      //TODO: respond to back pressure from streams to each peer.
      //if a given stream is paused, don't retrive more msgs
      //for that peer/stream.
      for (var peer in self.state.peers) {
        var state = self.state.peers[peer]
        while (state.retrive.length) {
          var id = state.retrive.shift()
          if (state.replicating[id])
            opts.getAt({
              id,
              sequence: state.replicating[id].sent+1
            }, self._retrive)
        }
      }

      if (self.state.receive.length) {
        var ev = self.state.receive.shift()
        opts.append(ev.value, function (err) {
          if (err) {
            if (self.logging) console.error('EBT:err', err)
            self.block(ev.value.author, ev.id, true)
          }
        })
      }

      for (var k in self.streams)
        self.streams[k].resume()
    },
  }

  var int = setInterval(() => {
    self.state = events.timeout(self.state, {ts: timestamp()})
    self.update()
  }, state.timeout)
  if (int.unref) int.unref()

  return self
}

},
"C6qADXMOE7DHqXoeZbqzqpKXlk9us1wDsGTxetNAV68=":
function (require, module, exports, __dirname, __filename) {
var xtend = require('xtend')
var AbstractIterator = require('./abstract-iterator')
var AbstractChainedBatch = require('./abstract-chained-batch')
var hasOwnProperty = Object.prototype.hasOwnProperty
var rangeOptions = 'start end gt gte lt lte'.split(' ')

function AbstractLevelDOWN () {
  this.status = 'new'
}

AbstractLevelDOWN.prototype.open = function (options, callback) {
  var self = this
  var oldStatus = this.status

  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('open() requires a callback argument')
  }

  if (typeof options !== 'object' || options === null) options = {}

  options.createIfMissing = options.createIfMissing !== false
  options.errorIfExists = !!options.errorIfExists

  this.status = 'opening'
  this._open(options, function (err) {
    if (err) {
      self.status = oldStatus
      return callback(err)
    }
    self.status = 'open'
    callback()
  })
}

AbstractLevelDOWN.prototype._open = function (options, callback) {
  process.nextTick(callback)
}

AbstractLevelDOWN.prototype.close = function (callback) {
  var self = this
  var oldStatus = this.status

  if (typeof callback !== 'function') {
    throw new Error('close() requires a callback argument')
  }

  this.status = 'closing'
  this._close(function (err) {
    if (err) {
      self.status = oldStatus
      return callback(err)
    }
    self.status = 'closed'
    callback()
  })
}

AbstractLevelDOWN.prototype._close = function (callback) {
  process.nextTick(callback)
}

AbstractLevelDOWN.prototype.get = function (key, options, callback) {
  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('get() requires a callback argument')
  }

  var err = this._checkKey(key)
  if (err) return process.nextTick(callback, err)

  key = this._serializeKey(key)

  if (typeof options !== 'object' || options === null) options = {}

  options.asBuffer = options.asBuffer !== false

  this._get(key, options, callback)
}

AbstractLevelDOWN.prototype._get = function (key, options, callback) {
  process.nextTick(function () { callback(new Error('NotFound')) })
}

AbstractLevelDOWN.prototype.put = function (key, value, options, callback) {
  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('put() requires a callback argument')
  }

  var err = this._checkKey(key) || this._checkValue(value)
  if (err) return process.nextTick(callback, err)

  key = this._serializeKey(key)
  value = this._serializeValue(value)

  if (typeof options !== 'object' || options === null) options = {}

  this._put(key, value, options, callback)
}

AbstractLevelDOWN.prototype._put = function (key, value, options, callback) {
  process.nextTick(callback)
}

AbstractLevelDOWN.prototype.del = function (key, options, callback) {
  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('del() requires a callback argument')
  }

  var err = this._checkKey(key)
  if (err) return process.nextTick(callback, err)

  key = this._serializeKey(key)

  if (typeof options !== 'object' || options === null) options = {}

  this._del(key, options, callback)
}

AbstractLevelDOWN.prototype._del = function (key, options, callback) {
  process.nextTick(callback)
}

AbstractLevelDOWN.prototype.batch = function (array, options, callback) {
  if (!arguments.length) return this._chainedBatch()

  if (typeof options === 'function') callback = options

  if (typeof array === 'function') callback = array

  if (typeof callback !== 'function') {
    throw new Error('batch(array) requires a callback argument')
  }

  if (!Array.isArray(array)) {
    return process.nextTick(callback, new Error('batch(array) requires an array argument'))
  }

  if (array.length === 0) {
    return process.nextTick(callback)
  }

  if (typeof options !== 'object' || options === null) options = {}

  var serialized = new Array(array.length)

  for (var i = 0; i < array.length; i++) {
    if (typeof array[i] !== 'object' || array[i] === null) {
      return process.nextTick(callback, new Error('batch(array) element must be an object and not `null`'))
    }

    var e = xtend(array[i])

    if (e.type !== 'put' && e.type !== 'del') {
      return process.nextTick(callback, new Error("`type` must be 'put' or 'del'"))
    }

    var err = this._checkKey(e.key)
    if (err) return process.nextTick(callback, err)

    e.key = this._serializeKey(e.key)

    if (e.type === 'put') {
      var valueErr = this._checkValue(e.value)
      if (valueErr) return process.nextTick(callback, valueErr)

      e.value = this._serializeValue(e.value)
    }

    serialized[i] = e
  }

  this._batch(serialized, options, callback)
}

AbstractLevelDOWN.prototype._batch = function (array, options, callback) {
  process.nextTick(callback)
}

AbstractLevelDOWN.prototype._setupIteratorOptions = function (options) {
  options = cleanRangeOptions(this, options)

  options.reverse = !!options.reverse
  options.keys = options.keys !== false
  options.values = options.values !== false
  options.limit = 'limit' in options ? options.limit : -1
  options.keyAsBuffer = options.keyAsBuffer !== false
  options.valueAsBuffer = options.valueAsBuffer !== false

  return options
}

function cleanRangeOptions (db, options) {
  var result = {}

  for (var k in options) {
    if (!hasOwnProperty.call(options, k)) continue

    var opt = options[k]

    if (isRangeOption(k)) {
      // Note that we don't reject nullish and empty options here. While
      // those types are invalid as keys, they are valid as range options.
      opt = db._serializeKey(opt)
    }

    result[k] = opt
  }

  return result
}

function isRangeOption (k) {
  return rangeOptions.indexOf(k) !== -1
}

AbstractLevelDOWN.prototype.iterator = function (options) {
  if (typeof options !== 'object' || options === null) options = {}
  options = this._setupIteratorOptions(options)
  return this._iterator(options)
}

AbstractLevelDOWN.prototype._iterator = function (options) {
  return new AbstractIterator(this)
}

AbstractLevelDOWN.prototype._chainedBatch = function () {
  return new AbstractChainedBatch(this)
}

AbstractLevelDOWN.prototype._serializeKey = function (key) {
  return key
}

AbstractLevelDOWN.prototype._serializeValue = function (value) {
  return value
}

AbstractLevelDOWN.prototype._checkKey = function (key) {
  if (key === null || key === undefined) {
    return new Error('key cannot be `null` or `undefined`')
  } else if (Buffer.isBuffer(key) && key.length === 0) {
    return new Error('key cannot be an empty Buffer')
  } else if (key === '') {
    return new Error('key cannot be an empty String')
  } else if (Array.isArray(key) && key.length === 0) {
    return new Error('key cannot be an empty Array')
  }
}

AbstractLevelDOWN.prototype._checkValue = function (value) {
  if (value === null || value === undefined) {
    return new Error('value cannot be `null` or `undefined`')
  }
}

module.exports = AbstractLevelDOWN

},
"CCV/8KXzWyHw5p1xKk33zQBu1/gzi/adDMDZU27EUUw=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var abortCb = require('../util/abort-cb')

module.exports = function values (array, onAbort) {
  if(!array)
    return function (abort, cb) {
      if(abort) return abortCb(cb, abort, onAbort)
      return cb(true)
    }
  if(!Array.isArray(array))
    array = Object.keys(array).map(function (k) {
      return array[k]
    })
  var i = 0
  return function (abort, cb) {
    if(abort)
      return abortCb(cb, abort, onAbort)
    if(i >= array.length)
      cb(true)
    else
      cb(null, array[i++])
  }
}

},
"CHLIk0Y1f6e8W0C/NVOxpVzjwwrZJZAsw4dZtWW3PQM=":
function (require, module, exports, __dirname, __filename) {
module.exports = pullPushable

function pullPushable (separated, onClose) {
  if (typeof separated === 'function') {
    onClose = separated
    separated = false
  }

  // create a buffer for data
  // that have been pushed
  // but not yet pulled.
  var buffer = []

  // a pushable is a source stream
  // (abort, cb) => cb(end, data)
  //
  // when pushable is pulled,
  // keep references to abort and cb
  // so we can call back after
  // .end(end) or .push(data)
  var abort, cb
  function read (_abort, _cb) {
    if (_abort) {
      abort = _abort
      // if there is already a cb waiting, abort it.
      if (cb) callback(abort)
    }
    cb = _cb
    drain()
  }

  var ended
  function end (end) {
    ended = ended || end || true
    // attempt to drain
    drain()
  }

  function push (data) {
    if (ended) return
    // if sink already waiting,
    // we can call back directly.
    if (cb) {
      callback(abort, data)
      return
    }
    // otherwise buffer data
    buffer.push(data)
  }

  // Return functions separated from source { push, end, source }
  if (separated) {
    return { push: push, end: end, source: read, buffer: buffer }
  }

  // Return normal
  read.push = push
  read.end = end
  read.buffer = buffer
  return read

  // `drain` calls back to (if any) waiting
  // sink with abort, end, or next data.
  function drain () {
    if (!cb) return

    if (abort) callback(abort)
    else if (!buffer.length && ended) callback(ended)
    else if (buffer.length) callback(null, buffer.shift())
  }

  // `callback` calls back to waiting sink,
  // and removes references to sink cb.
  function callback (err, val) {
    var _cb = cb
    // if error and pushable passed onClose, call it
    // the first time this stream ends or errors.
    if (err && onClose) {
      var c = onClose
      onClose = null
      c(err === true ? null : err)
    }
    cb = null
    _cb(err, val)
  }
}

},
"CJNsZUArFMqbpvNekePV8wrLiyXq7lpku1o2wuhOfkg=":
function (require, module, exports, __dirname, __filename) {
const Store = require('./store/fs')
const Inject = require('./inject')

module.exports = function (filename, suffix, codec) {
  return Inject(Store(filename, suffix, codec && codec.buffer), codec)
}

},
"CJRzKtw/9vxtqI98BQn7AfADtTsseF5YuNPb45fea3E=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var Api = require("./api");
module.exports = function SecretStack(config) {
    var create = Api([], config !== null && config !== void 0 ? config : {});
    return (create
        .use(require('./core'))
        .use(require('./plugins/net'))
        .use(require('./plugins/shs')));
};

},
"CRtl13gzdZnQFAs11TwDhgPRcy0nwzv+OeA4calpJrI=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (xs, fn) {
    var res = [];
    for (var i = 0; i < xs.length; i++) {
        var x = fn(xs[i], i);
        if (isArray(x)) res.push.apply(res, x);
        else res.push(x);
    }
    return res;
};

var isArray = Array.isArray || function (xs) {
    return Object.prototype.toString.call(xs) === '[object Array]';
};

},
"CYFjk0MA9cqunsqirN4JfopZp1rC3FTB21giVtLNJLQ=":
function (require, module, exports, __dirname, __filename) {
var slice = Array.prototype.slice

module.exports = to

function to(asyncFn) {
    return function () {
        var args = slice.call(arguments)
        var callback = args[args.length - 1]
        var self = this

        if (typeof callback === "function") {
            return asyncFn.apply(this, args)
        }

        return function continuable(callback) {
            var _args = args.slice()
            _args.push(callback)
            return asyncFn.apply(self, _args)
        }
    }
}

},
"ClhFVOW3yaObcO/tfOvOKabbzPMcJozDwU/wXT1kJ3A=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const path = require('path')

exports.BLOCK_SIZE = 64 * 1024
exports.flumePath = (dir) => path.join(dir, 'flume')
exports.oldLogPath = (dir) => path.join(dir, 'flume', 'log.offset')
exports.newLogPath = (dir) => path.join(dir, 'db2', 'log.bipf')
exports.indexesPath = (dir) => path.join(dir, 'db2', 'indexes')
exports.tooHotOpts = (config) =>
  config.db2
    ? {
        ceiling: config.db2.maxCpu || Infinity,
        wait: config.db2.maxCpuWait || 90,
        maxPause: config.db2.maxCpuMaxPause || 300,
      }
    : { ceiling: Infinity, wait: 90, maxPause: 300 }

},
"CyqPv4HVo4ehT+I/WLEF1D9l1H38iVlGBNvEwM/p508=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const debug = require('debug')('ssb:room-client');
const pull = require('pull-stream');
const Ref = require('ssb-ref');
const run = require("promisify-tuple");
const room_observer_1 = require("./room-observer");
const utils_1 = require("./utils");
exports.default = (rooms, ssb) => (msConfig) => {
    const self = {
        name: 'tunnel',
        scope() {
            return msConfig.scope;
        },
        server(onConnect, startedCB) {
            pull(ssb.conn.hub().listen(), pull.filter(({ type }) => type === 'connected'), pull.drain(async ({ address, key, details }) => {
                if (!key)
                    return;
                if (rooms.has(key))
                    return;
                if (!(details === null || details === void 0 ? void 0 : details.rpc))
                    return;
                if (address.startsWith('tunnel:'))
                    return;
                const rpc = details.rpc;
                debug('will try to call room.metadata() on the peer %s', key);
                var [err, res] = await run(rpc.room.metadata)();
                if (utils_1.muxrpcMissing(err)) {
                    debug('will try to call tunnel.isRoom() on the peer %s', key);
                    [err, res] = await run(rpc.tunnel.isRoom)();
                    if (!err && res && typeof res === 'object')
                        res._isRoom1 = true;
                }
                if (err || !res)
                    return;
                debug('is connected to an actual ssb-room');
                if (rooms.has(key)) {
                    rooms.get(key).cancel();
                    rooms.delete(key);
                }
                const obs = new room_observer_1.default(ssb, key, address, rpc, res, onConnect);
                rooms.set(key, obs);
            }));
            pull(ssb.conn.hub().listen(), pull.filter(({ type }) => type === 'disconnected'), pull.drain(({ key }) => {
                if (!key)
                    return;
                if (!rooms.has(key))
                    return;
                rooms.get(key).close();
                rooms.delete(key);
            }));
            startedCB();
            return () => {
                rooms.forEach((roomObserver) => {
                    roomObserver.close();
                });
                rooms.clear();
            };
        },
        async client(addr, cb) {
            var _a, _b;
            debug(`we wish to connect to %o`, addr);
            const opts = self.parse(addr);
            if (!opts) {
                cb(new Error(`invalid tunnel address ${addr}`));
                return;
            }
            const { portal, target } = opts;
            const addrStr = JSON.stringify(addr);
            let roomRPC = null;
            if (rooms.has(portal)) {
                roomRPC = rooms.get(portal).rpc;
            }
            if (!roomRPC) {
                for (const [msaddr] of ssb.conn.db().entries()) {
                    const key = Ref.getKeyFromAddress(msaddr);
                    if (key === portal) {
                        debug(`to connect to ${addrStr} we first have to connect to ${portal}`);
                        const [err, rpc] = await run(ssb.conn.connect)(msaddr);
                        if (err) {
                            cb(new Error((_a = `cant connect to ${addrStr} because ` +
                                `cant reach the room ${portal} due to: ` +
                                err.message) !== null && _a !== void 0 ? _a : err));
                            return;
                        }
                        roomRPC = rpc;
                    }
                }
            }
            if (!roomRPC) {
                const addrPlusShs = utils_1.toTunnelAddress(portal, target);
                const peerData = ssb.conn.db().get(addrPlusShs);
                if ((peerData === null || peerData === void 0 ? void 0 : peerData.room) === portal && (peerData === null || peerData === void 0 ? void 0 : peerData.roomAddress)) {
                    debug(`to connect to ${addrStr} we first have to connect to ${portal}`);
                    const [err, rpc] = await run(ssb.conn.connect)(peerData.roomAddress);
                    if (err) {
                        cb(new Error((_b = `cant connect to ${addrStr} because ` +
                            `cant reach the room ${portal} due to: ` +
                            err.message) !== null && _b !== void 0 ? _b : err));
                        return;
                    }
                    roomRPC = rpc;
                }
            }
            if (!roomRPC) {
                cb(new Error(`cant connect to ${addrStr} because ` +
                    `room ${portal} is offline or unknown`));
                return;
            }
            debug(`will call tunnel.connect at ${target} via room ${portal}`);
            const duplex = roomRPC.tunnel.connect({ target, portal }, (err) => {
                var _a;
                if (err) {
                    debug('tunnel duplex broken with %o because %s', addr, (_a = err.message) !== null && _a !== void 0 ? _a : err);
                }
            });
            cb(null, duplex);
        },
        parse(addr) {
            let opts;
            if (typeof addr === 'object') {
                opts = addr;
            }
            else {
                const [name, portal, target] = addr.split(':');
                if (name !== 'tunnel')
                    return;
                opts = { name, portal, target };
            }
            if (!Ref.isFeed(opts.portal))
                return;
            if (!Ref.isFeed(opts.target))
                return;
            return opts;
        },
        stringify() {
            return undefined;
        },
    };
    return self;
};

},
"D0nA59GBhKIX7Sc5Kwjc5GZ5UCdU/INt/J2cmRjCIAQ=":
function (require, module, exports, __dirname, __filename) {
module.exports = join

// join := (Continuable<Continuable<T>>) => Continuable<T>
function join(source) {
    return function continuable(callback) {
        source(function continuation(err, next) {
            if (err) {
                return callback(err)
            }

            next(callback)
        })
    }
}

},
"D6nHxB06ZsH6a/+aiIBcTcmNMvDiLVScaxthn734INo=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = function count (max) {
  var i = 0; max = max || Infinity
  return function (end, cb) {
    if(end) return cb && cb(end)
    if(i > max)
      return cb(true)
    cb(null, i++)
  }
}



},
"DC/O0jJuWWfpbmSs/ShGBs4vh0OHZnFLFFTPmI1cXW0=":
function (require, module, exports, __dirname, __filename) {

module.exports = function (cb) {
  return new CollectStream(cb)
}

function CollectStream (cb) {
  this.paused = false
  this.buffer = []
  this._cb = cb
}

CollectStream.prototype.write = function (data) {
  this.buffer.push(data)
}

CollectStream.prototype.end = function (err) {
  if(err && err !== true) this._cb(err, this.buffer)
  else this._cb(null, this.buffer)
}

//this is a writable so it doesn't have pipe or resume

},
"DIlVPZ6OdBPO6pHIGw/Wsf1kH4kl4ZS+p0rVyffyut8=":
function (require, module, exports, __dirname, __filename) {

/**
 * Export.
 */

module.exports = toNoCase

/**
 * Test whether a string is camel-case.
 */

var hasSpace = /\s/
var hasSeparator = /(_|-|\.|:)/
var hasCamel = /([a-z][A-Z]|[A-Z][a-z])/

/**
 * Remove any starting case from a `string`, like camel or snake, but keep
 * spaces and punctuation that may be important otherwise.
 *
 * @param {String} string
 * @return {String}
 */

function toNoCase(string) {
  if (hasSpace.test(string)) return string.toLowerCase()
  if (hasSeparator.test(string)) return (unseparate(string) || string).toLowerCase()
  if (hasCamel.test(string)) return uncamelize(string).toLowerCase()
  return string.toLowerCase()
}

/**
 * Separator splitter.
 */

var separatorSplitter = /[\W_]+(.|$)/g

/**
 * Un-separate a `string`.
 *
 * @param {String} string
 * @return {String}
 */

function unseparate(string) {
  return string.replace(separatorSplitter, function (m, next) {
    return next ? ' ' + next : ''
  })
}

/**
 * Camelcase splitter.
 */

var camelSplitter = /(.)([A-Z]+)/g

/**
 * Un-camelcase a `string`.
 *
 * @param {String} string
 * @return {String}
 */

function uncamelize(string) {
  return string.replace(camelSplitter, function (m, previous, uppers) {
    return previous + ' ' + uppers.toLowerCase().split('').join(' ')
  })
}

},
"DQHE38gxJVYt4+XeWBYawsgpXXeHYeIUWDMVSjgMYF8=":
function (require, module, exports, __dirname, __filename) {
const util = module.exports

util.digitCount = function digitCount (value) {
  // Add a digit for negative numbers, as the sign will be prefixed
  const sign = value < 0 ? 1 : 0
  // Guard against negative numbers & zero going into log10(),
  // as that would return -Infinity
  value = Math.abs(Number(value || 1))
  return Math.floor(Math.log10(value)) + 1 + sign
}

util.getType = function getType (value) {
  if (Buffer.isBuffer(value)) return 'buffer'
  if (ArrayBuffer.isView(value)) return 'arraybufferview'
  if (Array.isArray(value)) return 'array'
  if (value instanceof Number) return 'number'
  if (value instanceof Boolean) return 'boolean'
  if (value instanceof Set) return 'set'
  if (value instanceof Map) return 'map'
  if (value instanceof String) return 'string'
  if (value instanceof ArrayBuffer) return 'arraybuffer'
  return typeof value
}

},
"DR0vy+NgqrmJOPJkI6Hw4SLB8ox2DZOJ9T1ygtpAMNw=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const pDefer = () => {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
};

module.exports = pDefer;

},
"DTehFUDCbxaSJgY9TgwKyCicaKundCfJ9Wu7vuSsqKI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var Net = require('multiserver/plugins/net');
var debug = require('debug')('secret-stack net plugin');
module.exports = {
    name: 'multiserver-net',
    version: '1.0.0',
    init: function (api) {
        api.multiserver.transport({
            name: 'net',
            create: function (opts) {
                debug('creating transport host=%s port=%d scope=%s', opts.host, opts.port, opts.scope);
                return Net(opts);
            }
        });
    }
};

},
"DyIrMBtSdZUpgdkxj46x8WboxEO6lUAd6lVSQb6wefA=":
function (require, module, exports, __dirname, __filename) {
exports.utf8 = exports['utf-8'] = {
  encode: function (data) {
    return isBinary(data) ? data : String(data)
  },
  decode: identity,
  buffer: false,
  type: 'utf8'
}

exports.json = {
  encode: JSON.stringify,
  decode: JSON.parse,
  buffer: false,
  type: 'json'
}

exports.binary = {
  encode: function (data) {
    return isBinary(data) ? data : Buffer.from(data)
  },
  decode: identity,
  buffer: true,
  type: 'binary'
}

exports.none = {
  encode: identity,
  decode: identity,
  buffer: false,
  type: 'id'
}

exports.id = exports.none

var bufferEncodings = [
  'hex',
  'ascii',
  'base64',
  'ucs2',
  'ucs-2',
  'utf16le',
  'utf-16le'
]

bufferEncodings.forEach(function (type) {
  exports[type] = {
    encode: function (data) {
      return isBinary(data) ? data : Buffer.from(data, type)
    },
    decode: function (buffer) {
      return buffer.toString(type)
    },
    buffer: true,
    type: type
  }
})

function identity (value) {
  return value
}

function isBinary (data) {
  return data === undefined || data === null || Buffer.isBuffer(data)
}

},
"E+Lg/sIylbaDQTsYgpLQb6VqQhci414hp0+Ok/Qtvg8=":
function (require, module, exports, __dirname, __filename) {
module.exports = function(allopts) {
  var n = 0, m = 0, _cb, results = [], _err;
  function o (k, d) { return allopts && allopts[k] !== void 0 ? allopts[k] : d }

  return function(cb) {
    if (cb) {
      results.length = m

      if(_err) {
        var err = _err; _err = null
        return cb(err)
      }
      if(n == m) {
        if (o('spread'))
          return cb.apply(null, [null].concat(results))
        else
        return cb(null, results)
      }

      _cb = cb
      return
    }

    var i = m++
    return function (err) {
      if (err) {
        if (_err) return
        _err = err
        n = -1 // stop
        if (_cb) _cb(err)
      } else {
        n++
        if (o('pluck'))
          results[i] = arguments[o('pluck')]
        else
          results[i] = Array.prototype.slice.call(arguments)
        if (n === m && _cb) {
          if (o('spread'))
            _cb.apply(null, [null].concat(results))
          else
            _cb(null, results)
        }
      }
    }
  }
}

},
"E7IoqS0trZ0b/9Cfqq5rZL/B9xPdlmAQrUeakBwkOoY=":
function (require, module, exports, __dirname, __filename) {
'use strict';

//
// Allowed token characters:
//
// '!', '#', '$', '%', '&', ''', '*', '+', '-',
// '.', 0-9, A-Z, '^', '_', '`', a-z, '|', '~'
//
// tokenChars[32] === 0 // ' '
// tokenChars[33] === 1 // '!'
// tokenChars[34] === 0 // '"'
// ...
//
// prettier-ignore
const tokenChars = [
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0 - 15
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 16 - 31
  0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, // 32 - 47
  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, // 48 - 63
  0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 64 - 79
  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, // 80 - 95
  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 96 - 111
  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0 // 112 - 127
];

/**
 * Adds an offer to the map of extension offers or a parameter to the map of
 * parameters.
 *
 * @param {Object} dest The map of extension offers or parameters
 * @param {String} name The extension or parameter name
 * @param {(Object|Boolean|String)} elem The extension parameters or the
 *     parameter value
 * @private
 */
function push(dest, name, elem) {
  if (dest[name] === undefined) dest[name] = [elem];
  else dest[name].push(elem);
}

/**
 * Parses the `Sec-WebSocket-Extensions` header into an object.
 *
 * @param {String} header The field value of the header
 * @return {Object} The parsed object
 * @public
 */
function parse(header) {
  const offers = Object.create(null);

  if (header === undefined || header === '') return offers;

  let params = Object.create(null);
  let mustUnescape = false;
  let isEscaping = false;
  let inQuotes = false;
  let extensionName;
  let paramName;
  let start = -1;
  let end = -1;
  let i = 0;

  for (; i < header.length; i++) {
    const code = header.charCodeAt(i);

    if (extensionName === undefined) {
      if (end === -1 && tokenChars[code] === 1) {
        if (start === -1) start = i;
      } else if (code === 0x20 /* ' ' */ || code === 0x09 /* '\t' */) {
        if (end === -1 && start !== -1) end = i;
      } else if (code === 0x3b /* ';' */ || code === 0x2c /* ',' */) {
        if (start === -1) {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }

        if (end === -1) end = i;
        const name = header.slice(start, end);
        if (code === 0x2c) {
          push(offers, name, params);
          params = Object.create(null);
        } else {
          extensionName = name;
        }

        start = end = -1;
      } else {
        throw new SyntaxError(`Unexpected character at index ${i}`);
      }
    } else if (paramName === undefined) {
      if (end === -1 && tokenChars[code] === 1) {
        if (start === -1) start = i;
      } else if (code === 0x20 || code === 0x09) {
        if (end === -1 && start !== -1) end = i;
      } else if (code === 0x3b || code === 0x2c) {
        if (start === -1) {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }

        if (end === -1) end = i;
        push(params, header.slice(start, end), true);
        if (code === 0x2c) {
          push(offers, extensionName, params);
          params = Object.create(null);
          extensionName = undefined;
        }

        start = end = -1;
      } else if (code === 0x3d /* '=' */ && start !== -1 && end === -1) {
        paramName = header.slice(start, i);
        start = end = -1;
      } else {
        throw new SyntaxError(`Unexpected character at index ${i}`);
      }
    } else {
      //
      // The value of a quoted-string after unescaping must conform to the
      // token ABNF, so only token characters are valid.
      // Ref: https://tools.ietf.org/html/rfc6455#section-9.1
      //
      if (isEscaping) {
        if (tokenChars[code] !== 1) {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }
        if (start === -1) start = i;
        else if (!mustUnescape) mustUnescape = true;
        isEscaping = false;
      } else if (inQuotes) {
        if (tokenChars[code] === 1) {
          if (start === -1) start = i;
        } else if (code === 0x22 /* '"' */ && start !== -1) {
          inQuotes = false;
          end = i;
        } else if (code === 0x5c /* '\' */) {
          isEscaping = true;
        } else {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }
      } else if (code === 0x22 && header.charCodeAt(i - 1) === 0x3d) {
        inQuotes = true;
      } else if (end === -1 && tokenChars[code] === 1) {
        if (start === -1) start = i;
      } else if (start !== -1 && (code === 0x20 || code === 0x09)) {
        if (end === -1) end = i;
      } else if (code === 0x3b || code === 0x2c) {
        if (start === -1) {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }

        if (end === -1) end = i;
        let value = header.slice(start, end);
        if (mustUnescape) {
          value = value.replace(/\\/g, '');
          mustUnescape = false;
        }
        push(params, paramName, value);
        if (code === 0x2c) {
          push(offers, extensionName, params);
          params = Object.create(null);
          extensionName = undefined;
        }

        paramName = undefined;
        start = end = -1;
      } else {
        throw new SyntaxError(`Unexpected character at index ${i}`);
      }
    }
  }

  if (start === -1 || inQuotes) {
    throw new SyntaxError('Unexpected end of input');
  }

  if (end === -1) end = i;
  const token = header.slice(start, end);
  if (extensionName === undefined) {
    push(offers, token, params);
  } else {
    if (paramName === undefined) {
      push(params, token, true);
    } else if (mustUnescape) {
      push(params, paramName, token.replace(/\\/g, ''));
    } else {
      push(params, paramName, token);
    }
    push(offers, extensionName, params);
  }

  return offers;
}

/**
 * Builds the `Sec-WebSocket-Extensions` header field value.
 *
 * @param {Object} extensions The map of extensions and parameters to format
 * @return {String} A string representing the given object
 * @public
 */
function format(extensions) {
  return Object.keys(extensions)
    .map((extension) => {
      let configurations = extensions[extension];
      if (!Array.isArray(configurations)) configurations = [configurations];
      return configurations
        .map((params) => {
          return [extension]
            .concat(
              Object.keys(params).map((k) => {
                let values = params[k];
                if (!Array.isArray(values)) values = [values];
                return values
                  .map((v) => (v === true ? k : `${k}=${v}`))
                  .join('; ');
              })
            )
            .join('; ');
        })
        .join(', ');
    })
    .join(', ');
}

module.exports = { format, parse };

},
"EFyelVMiBsGQgnD2oWobg/BdPLIaM0NHbl1N1bXv/rI=":
function (require, module, exports, __dirname, __filename) {
var AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN
var inherits = require('inherits')
var DeferredIterator = require('./deferred-iterator')
var deferrables = 'put get del batch'.split(' ')

function DeferredLevelDOWN (db) {
  AbstractLevelDOWN.call(this, '')
  this._db = db
  this._operations = []
  this._iterators = []
  closed(this)
}

inherits(DeferredLevelDOWN, AbstractLevelDOWN)

DeferredLevelDOWN.prototype._open = function (options, callback) {
  var self = this

  this._db.open(options, function (err) {
    if (err) return callback(err)

    self._operations.forEach(function (op) {
      self._db[op.method].apply(self._db, op.args)
    })
    self._operations = []
    self._iterators.forEach(function (it) {
      it.setDb(self._db)
    })
    self._iterators = []
    open(self)
    callback()
  })
}

DeferredLevelDOWN.prototype._close = function (callback) {
  var self = this

  this._db.close(function (err) {
    if (err) return callback(err)
    closed(self)
    callback()
  })
}

function open (self) {
  deferrables.concat('iterator').forEach(function (m) {
    self['_' + m] = function () {
      return this._db[m].apply(this._db, arguments)
    }
  })
  if (self._db.approximateSize) {
    self.approximateSize = function () {
      return this._db.approximateSize.apply(this._db, arguments)
    }
  }
}

function closed (self) {
  deferrables.forEach(function (m) {
    self['_' + m] = function () {
      this._operations.push({ method: m, args: arguments })
    }
  })
  if (typeof self._db.approximateSize === 'function') {
    self.approximateSize = function () {
      this._operations.push({
        method: 'approximateSize',
        args: arguments
      })
    }
  }
  self._iterator = function (options) {
    var it = new DeferredIterator(options)
    this._iterators.push(it)
    return it
  }
}

DeferredLevelDOWN.prototype._serializeKey = function (key) {
  return key
}

DeferredLevelDOWN.prototype._serializeValue = function (value) {
  return value
}

module.exports = DeferredLevelDOWN
module.exports.DeferredIterator = DeferredIterator

},
"EMLFOaIW0fk53cnh5aOxEIB47HIMSEbYDvwicWIDHO0=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bipf = require('bipf')
const pl = require('pull-level')
const pull = require('pull-stream')
const Plugin = require('./plugin')

const B_VALUE = Buffer.from('value')
const B_AUTHOR = Buffer.from('author')
const B_SEQUENCE = Buffer.from('sequence')

// authorId => latestMsg { offset, sequence }
//
// Necessary for feed validation and for EBT
module.exports = function makeBaseIndex(privateIndex) {
  return class BaseIndex extends Plugin {
    constructor(log, dir) {
      super(log, dir, 'base', 2, undefined, 'json')
      this.privateIndex = privateIndex
      this.authorLatest = new Map()
    }

    onLoaded(cb) {
      pull(
        this.getAllLatest(),
        pull.drain(
          ({ key, value }) => {
            this.authorLatest.set(key, value)
          },
          (err) => {
            cb()
          }
        )
      )
    }

    processRecord(record, seq) {
      const buf = record.value
      const pValue = bipf.seekKey(buf, 0, B_VALUE)
      if (pValue < 0) return
      const author = bipf.decode(buf, bipf.seekKey(buf, pValue, B_AUTHOR))
      const sequence = bipf.decode(buf, bipf.seekKey(buf, pValue, B_SEQUENCE))
      const latestSequence = this.authorLatest.has(author)
        ? this.authorLatest.get(author).sequence
        : 0
      if (sequence > latestSequence) {
        const latest = { offset: record.offset, sequence }
        this.authorLatest.set(author, latest)
        this.batch.push({
          type: 'put',
          key: author,
          value: latest,
        })
      }
    }

    indexesContent() {
      return false
    }

    onFlush(cb) {
      this.privateIndex.saveIndexes(cb)
    }

    // pull-stream where each item is { key, value }
    // where key is the authorId and value is { offset, sequence }
    getAllLatest() {
      const META = '\x00'
      return pl.read(this.level, {
        gt: META,
        valueEncoding: this.valueEncoding,
      })
    }

    // returns { offset, sequence }
    getLatest(feedId, cb) {
      this.level.get(feedId, { valueEncoding: this.valueEncoding }, cb)
    }

    removeFeedFromLatest(feedId, cb) {
      this.flush((err) => {
        if (err) cb(err)
        else
          this.level.del(feedId, (err2) => {
            if (err2) cb(err2)
            else cb()
          })
      })
    }
  }
}

},
"ERhvJEVPubIZkxgc5IQr52HPWuFxZxnJOHg1aKejGoQ=":
function (require, module, exports, __dirname, __filename) {
module.exports = {"com.ac":true,"net.ac":true,"gov.ac":true,"org.ac":true,"mil.ac":true,"co.ae":true,"net.ae":true,"gov.ae":true,"ac.ae":true,"sch.ae":true,"org.ae":true,"mil.ae":true,"pro.ae":true,"name.ae":true,"com.af":true,"edu.af":true,"gov.af":true,"net.af":true,"org.af":true,"com.al":true,"edu.al":true,"gov.al":true,"mil.al":true,"net.al":true,"org.al":true,"ed.ao":true,"gv.ao":true,"og.ao":true,"co.ao":true,"pb.ao":true,"it.ao":true,"com.ar":true,"edu.ar":true,"gob.ar":true,"gov.ar":true,"int.ar":true,"mil.ar":true,"net.ar":true,"org.ar":true,"tur.ar":true,"gv.at":true,"ac.at":true,"co.at":true,"or.at":true,"com.au":true,"net.au":true,"org.au":true,"edu.au":true,"gov.au":true,"csiro.au":true,"asn.au":true,"id.au":true,"vic.au":true,"sa.au":true,"wa.au":true,"nt.au":true,"tas.au":true,"qld.au":true,"act.au":true,"conf.au":true,"oz.au":true,"org.ba":true,"net.ba":true,"edu.ba":true,"gov.ba":true,"mil.ba":true,"unsa.ba":true,"untz.ba":true,"unmo.ba":true,"unbi.ba":true,"unze.ba":true,"co.ba":true,"com.ba":true,"rs.ba":true,"co.bb":true,"com.bb":true,"net.bb":true,"org.bb":true,"gov.bb":true,"edu.bb":true,"info.bb":true,"store.bb":true,"tv.bb":true,"biz.bb":true,"com.bh":true,"info.bh":true,"cc.bh":true,"edu.bh":true,"biz.bh":true,"net.bh":true,"org.bh":true,"gov.bh":true,"com.bn":true,"edu.bn":true,"gov.bn":true,"net.bn":true,"org.bn":true,"com.bo":true,"net.bo":true,"org.bo":true,"tv.bo":true,"mil.bo":true,"int.bo":true,"gob.bo":true,"gov.bo":true,"edu.bo":true,"adm.br":true,"adv.br":true,"agr.br":true,"am.br":true,"arq.br":true,"art.br":true,"ato.br":true,"b.br":true,"bio.br":true,"blog.br":true,"bmd.br":true,"cim.br":true,"cng.br":true,"cnt.br":true,"com.br":true,"coop.br":true,"ecn.br":true,"edu.br":true,"eng.br":true,"esp.br":true,"etc.br":true,"eti.br":true,"far.br":true,"flog.br":true,"fm.br":true,"fnd.br":true,"fot.br":true,"fst.br":true,"g12.br":true,"ggf.br":true,"gov.br":true,"imb.br":true,"ind.br":true,"inf.br":true,"jor.br":true,"jus.br":true,"lel.br":true,"mat.br":true,"med.br":true,"mil.br":true,"mus.br":true,"net.br":true,"nom.br":true,"not.br":true,"ntr.br":true,"odo.br":true,"org.br":true,"ppg.br":true,"pro.br":true,"psc.br":true,"psi.br":true,"qsl.br":true,"rec.br":true,"slg.br":true,"srv.br":true,"tmp.br":true,"trd.br":true,"tur.br":true,"tv.br":true,"vet.br":true,"vlog.br":true,"wiki.br":true,"zlg.br":true,"com.bs":true,"net.bs":true,"org.bs":true,"edu.bs":true,"gov.bs":true,"om.bz":true,"du.bz":true,"ov.bz":true,"et.bz":true,"rg.bz":true,"ab.ca":true,"bc.ca":true,"mb.ca":true,"nb.ca":true,"nf.ca":true,"nl.ca":true,"ns.ca":true,"nt.ca":true,"nu.ca":true,"on.ca":true,"pe.ca":true,"qc.ca":true,"sk.ca":true,"yk.ca":true,"co.ck":true,"org.ck":true,"edu.ck":true,"gov.ck":true,"net.ck":true,"gen.ck":true,"biz.ck":true,"info.ck":true,"ac.cn":true,"com.cn":true,"edu.cn":true,"gov.cn":true,"mil.cn":true,"net.cn":true,"org.cn":true,"ah.cn":true,"bj.cn":true,"cq.cn":true,"fj.cn":true,"gd.cn":true,"gs.cn":true,"gz.cn":true,"gx.cn":true,"ha.cn":true,"hb.cn":true,"he.cn":true,"hi.cn":true,"hl.cn":true,"hn.cn":true,"jl.cn":true,"js.cn":true,"jx.cn":true,"ln.cn":true,"nm.cn":true,"nx.cn":true,"qh.cn":true,"sc.cn":true,"sd.cn":true,"sh.cn":true,"sn.cn":true,"sx.cn":true,"tj.cn":true,"tw.cn":true,"xj.cn":true,"xz.cn":true,"yn.cn":true,"zj.cn":true,"com.co":true,"org.co":true,"edu.co":true,"gov.co":true,"net.co":true,"mil.co":true,"nom.co":true,"ac.cr":true,"co.cr":true,"ed.cr":true,"fi.cr":true,"go.cr":true,"or.cr":true,"sa.cr":true,"cr":true,"ac.cy":true,"net.cy":true,"gov.cy":true,"org.cy":true,"pro.cy":true,"name.cy":true,"ekloges.cy":true,"tm.cy":true,"ltd.cy":true,"biz.cy":true,"press.cy":true,"parliament.cy":true,"com.cy":true,"edu.do":true,"gob.do":true,"gov.do":true,"com.do":true,"sld.do":true,"org.do":true,"net.do":true,"web.do":true,"mil.do":true,"art.do":true,"com.dz":true,"org.dz":true,"net.dz":true,"gov.dz":true,"edu.dz":true,"asso.dz":true,"pol.dz":true,"art.dz":true,"com.ec":true,"info.ec":true,"net.ec":true,"fin.ec":true,"med.ec":true,"pro.ec":true,"org.ec":true,"edu.ec":true,"gov.ec":true,"mil.ec":true,"com.eg":true,"edu.eg":true,"eun.eg":true,"gov.eg":true,"mil.eg":true,"name.eg":true,"net.eg":true,"org.eg":true,"sci.eg":true,"com.er":true,"edu.er":true,"gov.er":true,"mil.er":true,"net.er":true,"org.er":true,"ind.er":true,"rochest.er":true,"w.er":true,"com.es":true,"nom.es":true,"org.es":true,"gob.es":true,"edu.es":true,"com.et":true,"gov.et":true,"org.et":true,"edu.et":true,"net.et":true,"biz.et":true,"name.et":true,"info.et":true,"ac.fj":true,"biz.fj":true,"com.fj":true,"info.fj":true,"mil.fj":true,"name.fj":true,"net.fj":true,"org.fj":true,"pro.fj":true,"co.fk":true,"org.fk":true,"gov.fk":true,"ac.fk":true,"nom.fk":true,"net.fk":true,"fr":true,"tm.fr":true,"asso.fr":true,"nom.fr":true,"prd.fr":true,"presse.fr":true,"com.fr":true,"gouv.fr":true,"co.gg":true,"net.gg":true,"org.gg":true,"com.gh":true,"edu.gh":true,"gov.gh":true,"org.gh":true,"mil.gh":true,"com.gn":true,"ac.gn":true,"gov.gn":true,"org.gn":true,"net.gn":true,"com.gr":true,"edu.gr":true,"net.gr":true,"org.gr":true,"gov.gr":true,"mil.gr":true,"com.gt":true,"edu.gt":true,"net.gt":true,"gob.gt":true,"org.gt":true,"mil.gt":true,"ind.gt":true,"com.gu":true,"net.gu":true,"gov.gu":true,"org.gu":true,"edu.gu":true,"com.hk":true,"edu.hk":true,"gov.hk":true,"idv.hk":true,"net.hk":true,"org.hk":true,"2000.hu":true,"agrar.hu":true,"bolt.hu":true,"casino.hu":true,"city.hu":true,"co.hu":true,"erotica.hu":true,"erotika.hu":true,"film.hu":true,"forum.hu":true,"games.hu":true,"hotel.hu":true,"info.hu":true,"ingatlan.hu":true,"jogasz.hu":true,"konyvelo.hu":true,"lakas.hu":true,"media.hu":true,"news.hu":true,"org.hu":true,"priv.hu":true,"reklam.hu":true,"sex.hu":true,"shop.hu":true,"sport.hu":true,"suli.huv":true,"szex.hu":true,"tm.hu":true,"tozsde.hu":true,"utazas.hu":true,"video.hu":true,"ac.id":true,"co.id":true,"net.id":true,"or.id":true,"web.id":true,"sch.id":true,"mil.id":true,"go.id":true,"war.net.id":true,"ac.il":true,"co.il":true,"org.il":true,"net.il":true,"k12.il":true,"gov.il":true,"muni.il":true,"idf.il":true,"in":true,"4fd.in":true,"co.in":true,"firm.in":true,"net.in":true,"org.in":true,"gen.in":true,"ind.in":true,"ac.in":true,"edu.in":true,"res.in":true,"ernet.in":true,"gov.in":true,"mil.in":true,"nic.in":true,"iq":true,"gov.iq":true,"edu.iq":true,"com.iq":true,"mil.iq":true,"org.iq":true,"net.iq":true,"ir":true,"ac.ir":true,"co.ir":true,"gov.ir":true,"id.ir":true,"net.ir":true,"org.ir":true,"sch.ir":true,"dnssec.ir":true,"gov.it":true,"edu.it":true,"co.je":true,"net.je":true,"org.je":true,"com.jo":true,"net.jo":true,"gov.jo":true,"edu.jo":true,"org.jo":true,"mil.jo":true,"name.jo":true,"sch.jo":true,"ac.jp":true,"ad.jp":true,"co.jp":true,"ed.jp":true,"go.jp":true,"gr.jp":true,"lg.jp":true,"ne.jp":true,"or.jp":true,"co.ke":true,"or.ke":true,"ne.ke":true,"go.ke":true,"ac.ke":true,"sc.ke":true,"me.ke":true,"mobi.ke":true,"info.ke":true,"per.kh":true,"com.kh":true,"edu.kh":true,"gov.kh":true,"mil.kh":true,"net.kh":true,"org.kh":true,"com.ki":true,"biz.ki":true,"de.ki":true,"net.ki":true,"info.ki":true,"org.ki":true,"gov.ki":true,"edu.ki":true,"mob.ki":true,"tel.ki":true,"km":true,"com.km":true,"coop.km":true,"asso.km":true,"nom.km":true,"presse.km":true,"tm.km":true,"medecin.km":true,"notaires.km":true,"pharmaciens.km":true,"veterinaire.km":true,"edu.km":true,"gouv.km":true,"mil.km":true,"net.kn":true,"org.kn":true,"edu.kn":true,"gov.kn":true,"kr":true,"co.kr":true,"ne.kr":true,"or.kr":true,"re.kr":true,"pe.kr":true,"go.kr":true,"mil.kr":true,"ac.kr":true,"hs.kr":true,"ms.kr":true,"es.kr":true,"sc.kr":true,"kg.kr":true,"seoul.kr":true,"busan.kr":true,"daegu.kr":true,"incheon.kr":true,"gwangju.kr":true,"daejeon.kr":true,"ulsan.kr":true,"gyeonggi.kr":true,"gangwon.kr":true,"chungbuk.kr":true,"chungnam.kr":true,"jeonbuk.kr":true,"jeonnam.kr":true,"gyeongbuk.kr":true,"gyeongnam.kr":true,"jeju.kr":true,"edu.kw":true,"com.kw":true,"net.kw":true,"org.kw":true,"gov.kw":true,"com.ky":true,"org.ky":true,"net.ky":true,"edu.ky":true,"gov.ky":true,"com.kz":true,"edu.kz":true,"gov.kz":true,"mil.kz":true,"net.kz":true,"org.kz":true,"com.lb":true,"edu.lb":true,"gov.lb":true,"net.lb":true,"org.lb":true,"gov.lk":true,"sch.lk":true,"net.lk":true,"int.lk":true,"com.lk":true,"org.lk":true,"edu.lk":true,"ngo.lk":true,"soc.lk":true,"web.lk":true,"ltd.lk":true,"assn.lk":true,"grp.lk":true,"hotel.lk":true,"com.lr":true,"edu.lr":true,"gov.lr":true,"org.lr":true,"net.lr":true,"com.lv":true,"edu.lv":true,"gov.lv":true,"org.lv":true,"mil.lv":true,"id.lv":true,"net.lv":true,"asn.lv":true,"conf.lv":true,"com.ly":true,"net.ly":true,"gov.ly":true,"plc.ly":true,"edu.ly":true,"sch.ly":true,"med.ly":true,"org.ly":true,"id.ly":true,"ma":true,"net.ma":true,"ac.ma":true,"org.ma":true,"gov.ma":true,"press.ma":true,"co.ma":true,"tm.mc":true,"asso.mc":true,"co.me":true,"net.me":true,"org.me":true,"edu.me":true,"ac.me":true,"gov.me":true,"its.me":true,"priv.me":true,"org.mg":true,"nom.mg":true,"gov.mg":true,"prd.mg":true,"tm.mg":true,"edu.mg":true,"mil.mg":true,"com.mg":true,"com.mk":true,"org.mk":true,"net.mk":true,"edu.mk":true,"gov.mk":true,"inf.mk":true,"name.mk":true,"pro.mk":true,"com.ml":true,"net.ml":true,"org.ml":true,"edu.ml":true,"gov.ml":true,"presse.ml":true,"gov.mn":true,"edu.mn":true,"org.mn":true,"com.mo":true,"edu.mo":true,"gov.mo":true,"net.mo":true,"org.mo":true,"com.mt":true,"org.mt":true,"net.mt":true,"edu.mt":true,"gov.mt":true,"aero.mv":true,"biz.mv":true,"com.mv":true,"coop.mv":true,"edu.mv":true,"gov.mv":true,"info.mv":true,"int.mv":true,"mil.mv":true,"museum.mv":true,"name.mv":true,"net.mv":true,"org.mv":true,"pro.mv":true,"ac.mw":true,"co.mw":true,"com.mw":true,"coop.mw":true,"edu.mw":true,"gov.mw":true,"int.mw":true,"museum.mw":true,"net.mw":true,"org.mw":true,"com.mx":true,"net.mx":true,"org.mx":true,"edu.mx":true,"gob.mx":true,"com.my":true,"net.my":true,"org.my":true,"gov.my":true,"edu.my":true,"sch.my":true,"mil.my":true,"name.my":true,"com.nf":true,"net.nf":true,"arts.nf":true,"store.nf":true,"web.nf":true,"firm.nf":true,"info.nf":true,"other.nf":true,"per.nf":true,"rec.nf":true,"com.ng":true,"org.ng":true,"gov.ng":true,"edu.ng":true,"net.ng":true,"sch.ng":true,"name.ng":true,"mobi.ng":true,"biz.ng":true,"mil.ng":true,"gob.ni":true,"co.ni":true,"com.ni":true,"ac.ni":true,"edu.ni":true,"org.ni":true,"nom.ni":true,"net.ni":true,"mil.ni":true,"com.np":true,"edu.np":true,"gov.np":true,"org.np":true,"mil.np":true,"net.np":true,"edu.nr":true,"gov.nr":true,"biz.nr":true,"info.nr":true,"net.nr":true,"org.nr":true,"com.nr":true,"com.om":true,"co.om":true,"edu.om":true,"ac.om":true,"sch.om":true,"gov.om":true,"net.om":true,"org.om":true,"mil.om":true,"museum.om":true,"biz.om":true,"pro.om":true,"med.om":true,"edu.pe":true,"gob.pe":true,"nom.pe":true,"mil.pe":true,"sld.pe":true,"org.pe":true,"com.pe":true,"net.pe":true,"com.ph":true,"net.ph":true,"org.ph":true,"mil.ph":true,"ngo.ph":true,"i.ph":true,"gov.ph":true,"edu.ph":true,"com.pk":true,"net.pk":true,"edu.pk":true,"org.pk":true,"fam.pk":true,"biz.pk":true,"web.pk":true,"gov.pk":true,"gob.pk":true,"gok.pk":true,"gon.pk":true,"gop.pk":true,"gos.pk":true,"pwr.pl":true,"com.pl":true,"biz.pl":true,"net.pl":true,"art.pl":true,"edu.pl":true,"org.pl":true,"ngo.pl":true,"gov.pl":true,"info.pl":true,"mil.pl":true,"waw.pl":true,"warszawa.pl":true,"wroc.pl":true,"wroclaw.pl":true,"krakow.pl":true,"katowice.pl":true,"poznan.pl":true,"lodz.pl":true,"gda.pl":true,"gdansk.pl":true,"slupsk.pl":true,"radom.pl":true,"szczecin.pl":true,"lublin.pl":true,"bialystok.pl":true,"olsztyn.pl":true,"torun.pl":true,"gorzow.pl":true,"zgora.pl":true,"biz.pr":true,"com.pr":true,"edu.pr":true,"gov.pr":true,"info.pr":true,"isla.pr":true,"name.pr":true,"net.pr":true,"org.pr":true,"pro.pr":true,"est.pr":true,"prof.pr":true,"ac.pr":true,"com.ps":true,"net.ps":true,"org.ps":true,"edu.ps":true,"gov.ps":true,"plo.ps":true,"sec.ps":true,"co.pw":true,"ne.pw":true,"or.pw":true,"ed.pw":true,"go.pw":true,"belau.pw":true,"arts.ro":true,"com.ro":true,"firm.ro":true,"info.ro":true,"nom.ro":true,"nt.ro":true,"org.ro":true,"rec.ro":true,"store.ro":true,"tm.ro":true,"www.ro":true,"co.rs":true,"org.rs":true,"edu.rs":true,"ac.rs":true,"gov.rs":true,"in.rs":true,"com.sb":true,"net.sb":true,"edu.sb":true,"org.sb":true,"gov.sb":true,"com.sc":true,"net.sc":true,"edu.sc":true,"gov.sc":true,"org.sc":true,"co.sh":true,"com.sh":true,"org.sh":true,"gov.sh":true,"edu.sh":true,"net.sh":true,"nom.sh":true,"com.sl":true,"net.sl":true,"org.sl":true,"edu.sl":true,"gov.sl":true,"gov.st":true,"saotome.st":true,"principe.st":true,"consulado.st":true,"embaixada.st":true,"org.st":true,"edu.st":true,"net.st":true,"com.st":true,"store.st":true,"mil.st":true,"co.st":true,"edu.sv":true,"gob.sv":true,"com.sv":true,"org.sv":true,"red.sv":true,"co.sz":true,"ac.sz":true,"org.sz":true,"com.tr":true,"gen.tr":true,"org.tr":true,"biz.tr":true,"info.tr":true,"av.tr":true,"dr.tr":true,"pol.tr":true,"bel.tr":true,"tsk.tr":true,"bbs.tr":true,"k12.tr":true,"edu.tr":true,"name.tr":true,"net.tr":true,"gov.tr":true,"web.tr":true,"tel.tr":true,"tv.tr":true,"co.tt":true,"com.tt":true,"org.tt":true,"net.tt":true,"biz.tt":true,"info.tt":true,"pro.tt":true,"int.tt":true,"coop.tt":true,"jobs.tt":true,"mobi.tt":true,"travel.tt":true,"museum.tt":true,"aero.tt":true,"cat.tt":true,"tel.tt":true,"name.tt":true,"mil.tt":true,"edu.tt":true,"gov.tt":true,"edu.tw":true,"gov.tw":true,"mil.tw":true,"com.tw":true,"net.tw":true,"org.tw":true,"idv.tw":true,"game.tw":true,"ebiz.tw":true,"club.tw":true,"com.mu":true,"gov.mu":true,"net.mu":true,"org.mu":true,"ac.mu":true,"co.mu":true,"or.mu":true,"ac.mz":true,"co.mz":true,"edu.mz":true,"org.mz":true,"gov.mz":true,"com.na":true,"co.na":true,"ac.nz":true,"co.nz":true,"cri.nz":true,"geek.nz":true,"gen.nz":true,"govt.nz":true,"health.nz":true,"iwi.nz":true,"maori.nz":true,"mil.nz":true,"net.nz":true,"org.nz":true,"parliament.nz":true,"school.nz":true,"abo.pa":true,"ac.pa":true,"com.pa":true,"edu.pa":true,"gob.pa":true,"ing.pa":true,"med.pa":true,"net.pa":true,"nom.pa":true,"org.pa":true,"sld.pa":true,"com.pt":true,"edu.pt":true,"gov.pt":true,"int.pt":true,"net.pt":true,"nome.pt":true,"org.pt":true,"publ.pt":true,"com.py":true,"edu.py":true,"gov.py":true,"mil.py":true,"net.py":true,"org.py":true,"com.qa":true,"edu.qa":true,"gov.qa":true,"mil.qa":true,"net.qa":true,"org.qa":true,"asso.re":true,"com.re":true,"nom.re":true,"ac.ru":true,"adygeya.ru":true,"altai.ru":true,"amur.ru":true,"arkhangelsk.ru":true,"astrakhan.ru":true,"bashkiria.ru":true,"belgorod.ru":true,"bir.ru":true,"bryansk.ru":true,"buryatia.ru":true,"cbg.ru":true,"chel.ru":true,"chelyabinsk.ru":true,"chita.ru":true,"chukotka.ru":true,"chuvashia.ru":true,"com.ru":true,"dagestan.ru":true,"e-burg.ru":true,"edu.ru":true,"gov.ru":true,"grozny.ru":true,"int.ru":true,"irkutsk.ru":true,"ivanovo.ru":true,"izhevsk.ru":true,"jar.ru":true,"joshkar-ola.ru":true,"kalmykia.ru":true,"kaluga.ru":true,"kamchatka.ru":true,"karelia.ru":true,"kazan.ru":true,"kchr.ru":true,"kemerovo.ru":true,"khabarovsk.ru":true,"khakassia.ru":true,"khv.ru":true,"kirov.ru":true,"koenig.ru":true,"komi.ru":true,"kostroma.ru":true,"kranoyarsk.ru":true,"kuban.ru":true,"kurgan.ru":true,"kursk.ru":true,"lipetsk.ru":true,"magadan.ru":true,"mari.ru":true,"mari-el.ru":true,"marine.ru":true,"mil.ru":true,"mordovia.ru":true,"mosreg.ru":true,"msk.ru":true,"murmansk.ru":true,"nalchik.ru":true,"net.ru":true,"nnov.ru":true,"nov.ru":true,"novosibirsk.ru":true,"nsk.ru":true,"omsk.ru":true,"orenburg.ru":true,"org.ru":true,"oryol.ru":true,"penza.ru":true,"perm.ru":true,"pp.ru":true,"pskov.ru":true,"ptz.ru":true,"rnd.ru":true,"ryazan.ru":true,"sakhalin.ru":true,"samara.ru":true,"saratov.ru":true,"simbirsk.ru":true,"smolensk.ru":true,"spb.ru":true,"stavropol.ru":true,"stv.ru":true,"surgut.ru":true,"tambov.ru":true,"tatarstan.ru":true,"tom.ru":true,"tomsk.ru":true,"tsaritsyn.ru":true,"tsk.ru":true,"tula.ru":true,"tuva.ru":true,"tver.ru":true,"tyumen.ru":true,"udm.ru":true,"udmurtia.ru":true,"ulan-ude.ru":true,"vladikavkaz.ru":true,"vladimir.ru":true,"vladivostok.ru":true,"volgograd.ru":true,"vologda.ru":true,"voronezh.ru":true,"vrn.ru":true,"vyatka.ru":true,"yakutia.ru":true,"yamal.ru":true,"yekaterinburg.ru":true,"yuzhno-sakhalinsk.ru":true,"ac.rw":true,"co.rw":true,"com.rw":true,"edu.rw":true,"gouv.rw":true,"gov.rw":true,"int.rw":true,"mil.rw":true,"net.rw":true,"com.sa":true,"edu.sa":true,"gov.sa":true,"med.sa":true,"net.sa":true,"org.sa":true,"pub.sa":true,"sch.sa":true,"com.sd":true,"edu.sd":true,"gov.sd":true,"info.sd":true,"med.sd":true,"net.sd":true,"org.sd":true,"tv.sd":true,"a.se":true,"ac.se":true,"b.se":true,"bd.se":true,"c.se":true,"d.se":true,"e.se":true,"f.se":true,"g.se":true,"h.se":true,"i.se":true,"k.se":true,"l.se":true,"m.se":true,"n.se":true,"o.se":true,"org.se":true,"p.se":true,"parti.se":true,"pp.se":true,"press.se":true,"r.se":true,"s.se":true,"t.se":true,"tm.se":true,"u.se":true,"w.se":true,"x.se":true,"y.se":true,"z.se":true,"com.sg":true,"edu.sg":true,"gov.sg":true,"idn.sg":true,"net.sg":true,"org.sg":true,"per.sg":true,"art.sn":true,"com.sn":true,"edu.sn":true,"gouv.sn":true,"org.sn":true,"perso.sn":true,"univ.sn":true,"com.sy":true,"edu.sy":true,"gov.sy":true,"mil.sy":true,"net.sy":true,"news.sy":true,"org.sy":true,"ac.th":true,"co.th":true,"go.th":true,"in.th":true,"mi.th":true,"net.th":true,"or.th":true,"ac.tj":true,"biz.tj":true,"co.tj":true,"com.tj":true,"edu.tj":true,"go.tj":true,"gov.tj":true,"info.tj":true,"int.tj":true,"mil.tj":true,"name.tj":true,"net.tj":true,"nic.tj":true,"org.tj":true,"test.tj":true,"web.tj":true,"agrinet.tn":true,"com.tn":true,"defense.tn":true,"edunet.tn":true,"ens.tn":true,"fin.tn":true,"gov.tn":true,"ind.tn":true,"info.tn":true,"intl.tn":true,"mincom.tn":true,"nat.tn":true,"net.tn":true,"org.tn":true,"perso.tn":true,"rnrt.tn":true,"rns.tn":true,"rnu.tn":true,"tourism.tn":true,"ac.tz":true,"co.tz":true,"go.tz":true,"ne.tz":true,"or.tz":true,"biz.ua":true,"cherkassy.ua":true,"chernigov.ua":true,"chernovtsy.ua":true,"ck.ua":true,"cn.ua":true,"co.ua":true,"com.ua":true,"crimea.ua":true,"cv.ua":true,"dn.ua":true,"dnepropetrovsk.ua":true,"donetsk.ua":true,"dp.ua":true,"edu.ua":true,"gov.ua":true,"if.ua":true,"in.ua":true,"ivano-frankivsk.ua":true,"kh.ua":true,"kharkov.ua":true,"kherson.ua":true,"khmelnitskiy.ua":true,"kiev.ua":true,"kirovograd.ua":true,"km.ua":true,"kr.ua":true,"ks.ua":true,"kv.ua":true,"lg.ua":true,"lugansk.ua":true,"lutsk.ua":true,"lviv.ua":true,"me.ua":true,"mk.ua":true,"net.ua":true,"nikolaev.ua":true,"od.ua":true,"odessa.ua":true,"org.ua":true,"pl.ua":true,"poltava.ua":true,"pp.ua":true,"rovno.ua":true,"rv.ua":true,"sebastopol.ua":true,"sumy.ua":true,"te.ua":true,"ternopil.ua":true,"uzhgorod.ua":true,"vinnica.ua":true,"vn.ua":true,"zaporizhzhe.ua":true,"zhitomir.ua":true,"zp.ua":true,"zt.ua":true,"ac.ug":true,"co.ug":true,"go.ug":true,"ne.ug":true,"or.ug":true,"org.ug":true,"sc.ug":true,"ac.uk":true,"bl.uk":true,"british-library.uk":true,"co.uk":true,"cym.uk":true,"gov.uk":true,"govt.uk":true,"icnet.uk":true,"jet.uk":true,"lea.uk":true,"ltd.uk":true,"me.uk":true,"mil.uk":true,"mod.uk":true,"national-library-scotland.uk":true,"nel.uk":true,"net.uk":true,"nhs.uk":true,"nic.uk":true,"nls.uk":true,"org.uk":true,"orgn.uk":true,"parliament.uk":true,"plc.uk":true,"police.uk":true,"sch.uk":true,"scot.uk":true,"soc.uk":true,"4fd.us":true,"dni.us":true,"fed.us":true,"isa.us":true,"kids.us":true,"nsn.us":true,"com.uy":true,"edu.uy":true,"gub.uy":true,"mil.uy":true,"net.uy":true,"org.uy":true,"co.ve":true,"com.ve":true,"edu.ve":true,"gob.ve":true,"info.ve":true,"mil.ve":true,"net.ve":true,"org.ve":true,"web.ve":true,"co.vi":true,"com.vi":true,"k12.vi":true,"net.vi":true,"org.vi":true,"ac.vn":true,"biz.vn":true,"com.vn":true,"edu.vn":true,"gov.vn":true,"health.vn":true,"info.vn":true,"int.vn":true,"name.vn":true,"net.vn":true,"org.vn":true,"pro.vn":true,"co.ye":true,"com.ye":true,"gov.ye":true,"ltd.ye":true,"me.ye":true,"net.ye":true,"org.ye":true,"plc.ye":true,"ac.yu":true,"co.yu":true,"edu.yu":true,"gov.yu":true,"org.yu":true,"ac.za":true,"agric.za":true,"alt.za":true,"bourse.za":true,"city.za":true,"co.za":true,"cybernet.za":true,"db.za":true,"ecape.school.za":true,"edu.za":true,"fs.school.za":true,"gov.za":true,"gp.school.za":true,"grondar.za":true,"iaccess.za":true,"imt.za":true,"inca.za":true,"kzn.school.za":true,"landesign.za":true,"law.za":true,"lp.school.za":true,"mil.za":true,"mpm.school.za":true,"ncape.school.za":true,"net.za":true,"ngo.za":true,"nis.za":true,"nom.za":true,"nw.school.za":true,"olivetti.za":true,"org.za":true,"pix.za":true,"school.za":true,"tm.za":true,"wcape.school.za":true,"web.za":true,"ac.zm":true,"co.zm":true,"com.zm":true,"edu.zm":true,"gov.zm":true,"net.zm":true,"org.zm":true,"sch.zm":true}

},
"ESLtdoCU2GYADhPMtZOF83EMRia+I9HVAV94JPwQlZA=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (max) {

  if (!max) throw Error('hashlru must have a max value, of type number, greater than 0')

  var size = 0, cache = Object.create(null), _cache = Object.create(null)

  function update (key, value) {
    cache[key] = value
    size ++
    if(size >= max) {
      size = 0
      _cache = cache
      cache = Object.create(null)
    }
  }

  return {
    has: function (key) {
      return cache[key] !== undefined || _cache[key] !== undefined
    },
    remove: function (key) {
      if(cache[key] !== undefined)
        cache[key] = undefined
      if(_cache[key] !== undefined)
        _cache[key] = undefined
    },
    get: function (key) {
      var v = cache[key]
      if(v !== undefined) return v
      if((v = _cache[key]) !== undefined) {
        update(key, v)
        return v
      }
    },
    set: function (key, value) {
      if(cache[key] !== undefined) cache[key] = value
      else update(key, value)
    },
    clear: function () {
      cache = Object.create(null)
      _cache = Object.create(null)
    }
  }
}








},
"ET16jD2WhTMT06Kw15vXP1DBSGm9iwDnkfq4R3EFxKI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fromFile = exports.FileTokenizer = void 0;
const AbstractTokenizer_1 = require("./AbstractTokenizer");
const peek_readable_1 = require("peek-readable");
const fs = require("./FsPromise");
class FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {
    constructor(fd, fileInfo) {
        super(fileInfo);
        this.fd = fd;
    }
    /**
     * Read buffer from file
     * @param uint8Array - Uint8Array to write result to
     * @param options - Read behaviour options
     * @returns Promise number of bytes read
     */
    async readBuffer(uint8Array, options) {
        const normOptions = this.normalizeOptions(uint8Array, options);
        this.position = normOptions.position;
        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);
        this.position += res.bytesRead;
        if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {
            throw new peek_readable_1.EndOfStreamError();
        }
        return res.bytesRead;
    }
    /**
     * Peek buffer from file
     * @param uint8Array - Uint8Array (or Buffer) to write data to
     * @param options - Read behaviour options
     * @returns Promise number of bytes read
     */
    async peekBuffer(uint8Array, options) {
        const normOptions = this.normalizeOptions(uint8Array, options);
        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);
        if ((!normOptions.mayBeLess) && res.bytesRead < normOptions.length) {
            throw new peek_readable_1.EndOfStreamError();
        }
        return res.bytesRead;
    }
    async close() {
        return fs.close(this.fd);
    }
}
exports.FileTokenizer = FileTokenizer;
async function fromFile(sourceFilePath) {
    const stat = await fs.stat(sourceFilePath);
    if (!stat.isFile) {
        throw new Error(`File not a file: ${sourceFilePath}`);
    }
    const fd = await fs.open(sourceFilePath, 'r');
    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });
}
exports.fromFile = fromFile;

},
"EUYfxyAHlH65uL4RrUnkstYjV7itgf8+PmpAXT33jnM=":
function (require, module, exports, __dirname, __filename) {
module.exports = function () {
  return {
    mean: 0, stdev: 0,
    count: 0, sum: 0, sqsum: 0
  }
}

},
"Ec94syWZ8ZehXUFpWXfxPzgEuSAFW53cQ5rrsxA9vDg=":
function (require, module, exports, __dirname, __filename) {

exports.source = require('./source')
exports.through = require('./through')
exports.sink = require('./sink')
exports.duplex = require('./duplex')

},
"EomJ7TjYLyjhbkdm05GMX7Egp9A2wWiVQzzf04E6QWI=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const SSBURI = require('ssb-uri2')
const jitdbOperators = require('jitdb/operators')
const {
  seekType,
  seekAuthor,
  seekChannel,
  seekRoot,
  seekFork,
  seekPrivate,
  seekMeta,
  seekVoteLink,
  seekMentions,
  pluckLink,
  seekContact,
  seekBranch,
  seekAbout,
} = require('../seekers')
const { and, equal, predicate, includes, deferred } = jitdbOperators

function key(msgId) {
  return deferred((meta, cb) => {
    meta.db.onDrain('keys', () => {
      meta.db.getIndex('keys').getMsgByKey(msgId, cb)
    })
  })
}

function type(value, opts = { dedicated: true }) {
  if (opts && opts.dedicated) {
    return equal(seekType, value, {
      indexType: 'value_content_type',
    })
  } else {
    return equal(seekType, value, {
      prefix: 32,
      indexType: 'value_content_type',
    })
  }
}

// We don't need the author "prefix" to be an actual prefix, it can just be any
// predefined positions in the "information" part of the author ID.
//
// WARNING: when updating this, be extra careful that the resulting number isn't
// larger than the smallest ID's length. E.g. classic feed IDs are 53 characters
// long, and the base64 part ends at character 44, so AUTHOR_PREFIX_OFFSET must
// be smaller than 40 (i.e. 44 - 4).
const AUTHOR_PREFIX_OFFSET = Math.max(
  '@'.length,
  'ssb:feed/bendybutt-v1/'.length
)

function author(value, opts = { dedicated: false }) {
  if (opts && opts.dedicated) {
    return equal(seekAuthor, value, {
      indexType: 'value_author',
    })
  } else {
    return equal(seekAuthor, value, {
      prefix: 32,
      prefixOffset: AUTHOR_PREFIX_OFFSET,
      indexType: 'value_author',
      version: 2,
    })
  }
}

function channel(value) {
  return equal(seekChannel, value, {
    indexType: 'value_content_channel',
  })
}

function votesFor(msgKey) {
  return and(
    type('vote'),
    equal(seekVoteLink, msgKey, {
      prefix: 32,
      prefixOffset: 1,
      useMap: true,
      indexType: 'value_content_vote_link',
    })
  )
}

function contact(feedId) {
  return and(
    type('contact'),
    equal(seekContact, feedId, {
      prefix: 32,
      prefixOffset: 1,
      useMap: true,
      indexType: 'value_content_contact',
    })
  )
}

function mentions(key) {
  return includes(seekMentions, key, {
    pluck: pluckLink,
    indexType: 'value_content_mentions_link',
  })
}

function about(feedId) {
  return and(
    type('about'),
    equal(seekAbout, feedId, {
      prefix: 32,
      prefixOffset: 1,
      useMap: true,
      indexType: 'value_content_about',
    })
  )
}

function hasRoot(msgKey) {
  return equal(seekRoot, msgKey, {
    prefix: 32,
    prefixOffset: 1,
    useMap: true,
    indexType: 'value_content_root',
  })
}

function hasFork(msgKey) {
  return equal(seekFork, msgKey, {
    prefix: 32,
    prefixOffset: 1,
    useMap: true,
    indexType: 'value_content_fork',
  })
}

function hasBranch(msgKey) {
  return equal(seekBranch, msgKey, {
    prefix: 32,
    prefixOffset: 1,
    useMap: true,
    indexType: 'value_content_branch',
  })
}

function authorIsBendyButtV1() {
  return predicate(seekAuthor, SSBURI.isBendyButtV1FeedSSBURI, {
    indexType: 'value_author',
    name: 'bendybutt-v1',
  })
}

function isRoot() {
  return equal(seekRoot, undefined, {
    indexType: 'value_content_root',
  })
}

function isPrivate() {
  return equal(seekPrivate, true, { indexType: 'meta_private' })
}

function isPublic() {
  return equal(seekMeta, undefined, { indexType: 'meta' })
}

module.exports = Object.assign({}, jitdbOperators, {
  type,
  author,
  channel,
  key,
  votesFor,
  contact,
  mentions,
  about,
  hasRoot,
  hasFork,
  hasBranch,
  authorIsBendyButtV1,
  isRoot,
  isPrivate,
  isPublic,
})

},
"EvobkkKdslWZ9v4RjLu4d/f2K4PLm/4vyJay1qgRBkc=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var implementation = require('./implementation');

module.exports = Function.prototype.bind || implementation;

},
"F+Gv1QrpWW5VIU/ob1qFr8bkvWmgvJeOy7vapiycETM=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var _Heap = require('heap')
var Heap = function (cmp) { return new _Heap(cmp) }

module.exports = function (opts) {
  var exports = {}

  function getValueFromEdge(hops, j, v) {
    return opts.add(hops[j], v)
  }

  function getNewValue(hops, j, k, v) {
    return opts.min(hops[k], getValueFromEdge(hops, j, v))
  }

  function isUnchangedByEdge (hops, j, k, v) {
    return hops[k] === opts.add(hops[j], v)
  }

  function isUnchanged (hops, j, k, v) {
    return hops[k] === getNewValue(hops, j, k, v)
  }

  //"increment" is an edge that shortens graph distances
  //adding a new edge always decreases hops, or decreasing
  //the weight of an edge. (see the literature on dynamic graphs)
  function isIncrement (value, old_value) {
    return (
      opts.isAdd(value) && (
        opts.isRemove(old_value) || (opts.min(value, old_value) == value)
      )
    )
  }

  //take a graph, and return it's inverse
  exports.reverse = function (g) {
    var _g = {}
    for(var k in g) {
      for(var j in g[k]) {
        _g[j] = _g[j] || {}
        _g[j][k] = g[k][j]
      }
    }
    return _g
  }

  function _loop (g, max, hops, next, _hops) {
    if(!_hops) throw new Error('_hops must be provided')
    while(!next.empty()) {
      var j = next.pop()
      if(opts.expand(hops[j], max))
        for(var k in g[j]) {
          var _h = getNewValue(hops, j, k, g[j][k])
          if(isNaN(_h)) throw new Error('NaN')
          if(_h != hops[k]) {
            _hops[k] = hops[k] = _h
            next.push(k)
          }
        }
    }
    return _hops
  }

  exports.traverse = exports.brute = function (g, _g, max, from) {
    var hops = {}
    hops[from] = opts.initial()
    var next = Heap(function (a, b) {
       return hops[a] - hops[b]
    }, function (k) { return hops[k] })
    next.push(from)
    return _loop(g, max, hops, next, hops)
  }

  //find all nodes reachable via `from` with hops at > was
  exports.uncertain = function (g, hops, max, start) {
    var was = hops[start]
    var maybe = {}
    maybe[start] = true
    var next = Heap(function (a, b) {
      return hops[a] - hops[b]
    })
    next.push(start)
    while(!next.empty()) {
      var j = next.pop()
      for(var k in g[j])
        if(
          isUnchangedByEdge(hops, j,k,g[j][k])
        //hops[k] === opts.add(hops[j], g[j][k])
        ) {
          if(!maybe[k]) {
            maybe[k] = true
            next.push(k)
          }
        }
    }
    return maybe
  }

  exports.sources = function (_g, hops, maybe) {
    if(!_g) throw new Error('backlink graph must be provided')
    var update = {}
    for(var k in maybe)
      if(hops[k])
        for(var j in _g[k])
          if(!maybe[j] && hops[j] != null)
            update[j] = true
    return update
  }

  function update_graphs(g, _g, from, to, value) {
    g[from] = g[from] || {}
    _g[to] = _g[to] || {}
    g[from][to] = _g[to][from] = value
  }

  exports.update = function (g, _g, hops, max, start, from,to,value) {
    var _hops = {}
    if(hops[start] == null) hops[start] = opts.initial()

    var old_value = g[from] && g[from][to]

//    if(from == to) {
//      update_graphs(g, _g, from, to, value)
//      return null
//    }
//    else

    if(isIncrement(value, old_value)) {
      update_graphs(g, _g, from, to, value)

      //if from isn't within hops, then to won't be in hops either.
      if(hops[from] == null || from == to) return null


      var h = getNewValue(hops, from, to, value)
      //if source is max or more, do not add edge
      if(!opts.expand(hops[from], max)) return null

      //check if there is another edge that keeps this value alive.
      if(h == hops[to] && opts.add(hops[from], old_value) == hops[to]) {
        for(var _from in _g[to])
          if(_from != from && opts.expand(hops[_from], max) && opts.add(hops[_from], g[_from][to]) === hops[to])
            return null
        var _h = null
        for(var _from in _g[to])
          if(hops[_from] != null && opts.expand(hops[_from], max)) {
            _h = opts.min(_h, opts.add(hops[_from], g[_from][to]))
          }
        h = _h
      }

      //hops will change
      if(h != hops[to]) {
        _hops[to] = hops[to] = h
        //if this edge is at the limit, we are done.
        if(!opts.expand(hops[to], max)) return _hops

        //setup heap and run dijkstra's algorithm
        var next = Heap(function (a, b) { return hops[a] - hops[b] })
        next.push(to)
        return _loop(g, max, hops, next, _hops)
      }
      //undefined!
      return null
    }
    //handle unfollow and block (aka decrements)
    else {
      if(!value && !_g) throw new Error('expected increment:'+value)
      var j = from, k = to, v = value, _v = g[from] && g[from][to]

      //shortcut 1: detect cases that won't change the hops
      if(
        to === start || //can't block yourself, so don't update hops.
        //if from isn't within hops, then to won't be in hops either.
        from == to ||
        //they are already blocked, stop tracking hops from them
        (!opts.expand(hops[j], max)) ||
        ( //already closer
          //if previous value was null, or previous didn't set the hops value anyway.
          //and the hops value will be the same, then don't update hops.
          (_v == null  || !isUnchangedByEdge(hops, j, k, _v)) &&
          isUnchanged(hops, j, k, v)
        ) || (
          //if this edge _did_ set the hops value, check if there is another edge which also sets it.
          //this catches the case when someone unfollows, but there is another follow path the same length.
          //only applies when there was a previous edge.
            (_v == null || isUnchangedByEdge(hops, j, k, _v)) &&
            isUnchanged(hops, j, k, v) &&
            //quickly check if any other edges set hops
            (function () {
              for(var _j in _g[k])
                if(_j !== j && hops[_j] != null && isUnchangedByEdge(hops, _j, k, g[_j][k]))
                  return true
            }())
        )
      ) {
        //won't change hops, so update graph and return
        update_graphs(g, _g, from, to, value)
        return null
      }
      //shortcut 2. detect cases that will add exactly 1 element to hops
      //adding negative edge to someone not already in hops.
      else if (opts.isRemove(v) && hops[j] >= 0 && hops[k] == null) {
        //only adds the new item, but won't expand since this is a block.
        update_graphs(g, _g, j,k,v)
        if(opts.expand(hops[j], 3)) //XXX is this really where the default is set?
          _hops[k] = hops[k] = opts.add(hops[j], v)
        return _hops
      }
      //the long way. calculate all hops that may be changed by this edge and recalculate them.
      else {
        var next = Heap(function (a, b) {
          return hops[a] - hops[b]
        }, function (k) { return hops[k] })

        var maybe = exports.uncertain(g, hops, max, to)
        var sources = exports.sources(_g, hops, maybe)

        update_graphs(g, _g, from, to, value)

        sources[from] = true
        var pre = {}
        for(var _k in maybe) {
          pre[_k] = hops[_k]
          delete hops[_k]
        }

        var diff = exports.updateAll(g, hops, max, sources, _hops)

        for(var k in pre)
          if(diff[k] == pre[k])
            delete diff[k]

        return diff
      }
    }
  }

  exports.updateAll = function (g, hops, max, sources, _hops) {
    var next = Heap(function (a, b) { return hops[a] - hops[b] })

    for(var k in sources) next.push(k)

    return _loop(g, max, hops, next, _hops)
  }

  return exports
}


},
"FEdWQewdhdy/leJVX+2wS/AvhILgiCKloJsB3cY4n18=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a passthrough stream.
// basically just the most minimal sort of Transform stream.
// Every written chunk gets output as-is.
'use strict';

module.exports = PassThrough;

var Transform = require('./_stream_transform');

require('inherits')(PassThrough, Transform);

function PassThrough(options) {
  if (!(this instanceof PassThrough)) return new PassThrough(options);
  Transform.call(this, options);
}

PassThrough.prototype._transform = function (chunk, encoding, cb) {
  cb(null, chunk);
};
},
"FHRdfMkgTG8UH99hmFIdkPoU3w+al9Ro6LYuMM0dNDY=":
function (require, module, exports, __dirname, __filename) {
var fs = require('fs')
var mkdirp = require('mkdirp')
var Obv = require('obv')
var path = require('path')
const ReadWriteLock = require('rwlock');

module.exports = function (file, block_size, flags) {
  flags = flags || 'r+'
  var fd
  var offset = Obv()

  // Positional read and write operations may be hazardous. We want to avoid:
  //
  // - Concurrent writes to the same part of the file.
  // - Reading and writing from the same part of the file.
  //
  // It's likely that Node.js is handling this deeper in the stack with libuv
  // operations like `pread()` and `pwrite()`, but they haven't explicitly
  // committed to this behavior:
  //
  // https://github.com/nodejs/node/issues/18634#issuecomment-363981993
  //
  // > This is not safe on all platforms, no.
  //

  const lock = new ReadWriteLock();

  mkdirp(path.dirname(file), function () {
    //r+ opens the file for reading and writing, but errors if file does not exist.
    //to open the file for reading and writing and not error if it does not exist.
    //we need to open and close the file for append first.
    fs.open(file, 'a', function (_, _fd) {
      fs.close(_fd, function (_) {
        fs.open(file, flags, function (err, _fd) {
          fd = _fd
          fs.stat(file, function (err, stat) {
            offset.set(err ? 0 : stat.size)
          })
        })
      })
    })
  })

  // This variable *only* tracks appends, not positional writes.
  var appending = 0

  return {
    get: function (i, cb) {
      offset.once(function (_offset) {
        lock.readLock((release) => {
          var max = ~~(_offset / block_size)
          if(i > max)
            return cb(new Error('aligned-block-file/file.get: requested block index was greater than max, got:'+i+', expected less than or equal to:'+max))

          var buf = Buffer.alloc(block_size)

          fs.read(fd, buf, 0, block_size, i*block_size, function (err, bytes_read) {
            release()
            if(err) cb(err)
            else if(
              //if bytes_read is wrong
              i < max &&
              buf.length !== bytes_read &&
              //unless this is the very last block and it is incomplete.
              !((i*block_size + bytes_read) == offset.value)
            )
              cb(new Error(
                'aligned-block-file/file.get: did not read whole block, expected length:'+
                block_size+' but got:'+bytes_read
              ))
            else
              cb(null, buf, bytes_read)
          })
        })
      })
    },
    offset: offset,
    size: function () { return offset.value },
    append: function (buf, cb) {
      if(appending++) throw new Error('already appending to this file')
      offset.once(function (_offset) {
        fs.write(fd, buf, 0, buf.length, _offset, function (err, written) {
          appending = 0
          if(err) return cb(err)
          if(written !== buf.length) return cb(new Error('wrote less bytes than expected:'+written+', but wanted:'+buf.length))
          offset.set(_offset+written)
          cb(null, _offset+written)
        })
      })
    },
    /**
     * Writes a buffer directly to a position in the file. This opens the file
     * with another file descriptor so that the main file descriptor can just
     * append and read without doing any positional writes.
     *
     * @param {buffer} buf - the data to write to the file
     * @param {number} pos - position in the file to write the buffer
     * @param {function} cb - callback that returns any error as an argument
     */
    write: (buf, pos, cb) => {
      if(flags !== 'r+') throw new Error('file opened with flags:'+flags+' refusing to write unless flags are:r+')
      offset.once((_offset) => {
        const endPos = pos + buf.length
        const isPastOffset = endPos > _offset

        if (isPastOffset) {
          return cb(new Error(`cannot write past offset: ${endPos} > ${_offset}`))
        }

        lock.writeLock((release) => {
          fs.write(fd, buf, 0, buf.length, pos, (err, written) => {
            release()
            if (err == null && written !== buf.length) {
              cb(new Error('wrote less bytes than expected:'+written+', but wanted:'+buf.length))
            } else {
              cb(err)
            }
          })
        })
      })
    },
    truncate: function (len, cb) {
      if(appending) throw new Error('already appending, cannot truncate')
      offset.once(function (_offset) {
        if(_offset <= len) return cb()
        fs.ftruncate(fd, len, function (err) {
          if(err) cb(err)
          else {
            offset.set(len)
            cb(null, offset.value)
          }
        })
      })
    }
  }
}



},
"FIYopa/BrX7/XSovHppXiydkcqV9t64IWW6WREHXwwI=":
function (require, module, exports, __dirname, __filename) {
const Reduce = require('flumeview-reduce')
const isFeed = require('ssb-ref').isFeed
// track contact messages, follow, unfollow, block

module.exports = function (sbot, createLayer) {
  const updatePublicLayer = createLayer('contactsPublic')
  const updatePrivateLayer = createLayer('contactsPrivate')
  let initial = false

  const INDEX_VERSION = 11
  const index = sbot._flumeUse('contacts2', Reduce(INDEX_VERSION, (g, data) => {
    if (!g) g = {}

    const source = data.value.author
    const dest = data.value.content.contact
    const edgeValue =
      data.value.content.blocking || data.value.content.flagged
        ? -1
        : data.value.content.following === true
          ? 1
          : -2
    const privately = data.value.meta && data.value.meta.private

    if (isFeed(source) && isFeed(dest)) {
      if (initial) {
        if (privately) {
          updatePrivateLayer(source, dest, edgeValue)
        } else {
          updatePublicLayer(source, dest, edgeValue)
        }
      }
      g[source] = g[source] || {}
      if (privately) {
        g[source][dest] = 'p' + edgeValue
      } else {
        g[source][dest] = edgeValue
      }
    }
    return g
  }))

  // trigger flume machinery to wait until index is ready,
  // otherwise there is a race condition when rebuilding the graph.
  index.get((err, g) => {
    if (err) throw err
    initial = true

    if (!g) {
      updatePublicLayer({})
      updatePrivateLayer({})
      return
    }

    // Split g into public and private layers
    const publicLayer = {}
    const privateLayer = {}
    for (const source of Object.keys(g)) {
      for (const dest of Object.keys(g[source])) {
        const val = g[source][dest]
        const privately = val[0] === 'p'
        if (privately) {
          const edgeValue = parseInt(val.slice(1), 10)
          privateLayer[source] = privateLayer[source] || {}
          privateLayer[source][dest] = edgeValue
        } else {
          publicLayer[source] = publicLayer[source] || {}
          publicLayer[source][dest] = val
        }
      }
    }

    updatePublicLayer(publicLayer)
    updatePrivateLayer(privateLayer)
  })
}

},
"FTRTxNhKPC8TWJw3BVp9r/YdSEddzOVU9+7a0V/Hs+U=":
function (require, module, exports, __dirname, __filename) {
// Returns a wrapper function that returns a wrapped callback
// The wrapper function should do some stuff, and return a
// presumably different callback function.
// This makes sure that own properties are retained, so that
// decorations and such are not lost along the way.
module.exports = wrappy
function wrappy (fn, cb) {
  if (fn && cb) return wrappy(fn)(cb)

  if (typeof fn !== 'function')
    throw new TypeError('need wrapper function')

  Object.keys(fn).forEach(function (k) {
    wrapper[k] = fn[k]
  })

  return wrapper

  function wrapper() {
    var args = new Array(arguments.length)
    for (var i = 0; i < args.length; i++) {
      args[i] = arguments[i]
    }
    var ret = fn.apply(this, args)
    var cb = args[args.length-1]
    if (typeof ret === 'function' && ret !== cb) {
      Object.keys(cb).forEach(function (k) {
        ret[k] = cb[k]
      })
    }
    return ret
  }
}

},
"FW/xh7nWutA0GJjxC2igK9GSk2i7dnXDATFrGGztQ6A=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var define = require('define-properties');
var callBind = require('call-bind');

var implementation = require('./implementation');
var getPolyfill = require('./polyfill');
var shim = require('./shim');

var flagsBound = callBind(implementation);

define(flagsBound, {
	getPolyfill: getPolyfill,
	implementation: implementation,
	shim: shim
});

module.exports = flagsBound;

},
"FldrIBHHjQxc7M3rp0Ueg+G9hvLD8xwF3n30zPsUnCo=":
function (require, module, exports, __dirname, __filename) {
// Ported from https://github.com/mafintosh/pump with
// permission from the author, Mathias Buus (@mafintosh).
'use strict';

var eos;

function once(callback) {
  var called = false;
  return function () {
    if (called) return;
    called = true;
    callback.apply(void 0, arguments);
  };
}

var _require$codes = require('../../../errors').codes,
    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;

function noop(err) {
  // Rethrow the error if it exists to avoid swallowing it
  if (err) throw err;
}

function isRequest(stream) {
  return stream.setHeader && typeof stream.abort === 'function';
}

function destroyer(stream, reading, writing, callback) {
  callback = once(callback);
  var closed = false;
  stream.on('close', function () {
    closed = true;
  });
  if (eos === undefined) eos = require('./end-of-stream');
  eos(stream, {
    readable: reading,
    writable: writing
  }, function (err) {
    if (err) return callback(err);
    closed = true;
    callback();
  });
  var destroyed = false;
  return function (err) {
    if (closed) return;
    if (destroyed) return;
    destroyed = true; // request.destroy just do .end - .abort is what we want

    if (isRequest(stream)) return stream.abort();
    if (typeof stream.destroy === 'function') return stream.destroy();
    callback(err || new ERR_STREAM_DESTROYED('pipe'));
  };
}

function call(fn) {
  fn();
}

function pipe(from, to) {
  return from.pipe(to);
}

function popCallback(streams) {
  if (!streams.length) return noop;
  if (typeof streams[streams.length - 1] !== 'function') return noop;
  return streams.pop();
}

function pipeline() {
  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {
    streams[_key] = arguments[_key];
  }

  var callback = popCallback(streams);
  if (Array.isArray(streams[0])) streams = streams[0];

  if (streams.length < 2) {
    throw new ERR_MISSING_ARGS('streams');
  }

  var error;
  var destroys = streams.map(function (stream, i) {
    var reading = i < streams.length - 1;
    var writing = i > 0;
    return destroyer(stream, reading, writing, function (err) {
      if (!error) error = err;
      if (err) destroys.forEach(call);
      if (reading) return;
      destroys.forEach(call);
      callback(error);
    });
  });
  return streams.reduce(pipe);
}

module.exports = pipeline;
},
"FvVL6bsXckM6GcPE/NkK2CKbrlAulfyCyQNAjsSRhew=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.selfHealingJSONCodec = void 0;
exports.selfHealingJSONCodec = {
    encode: function (obj) {
        return JSON.stringify(obj, null, 2);
    },
    decode: function (input) {
        if (!input)
            return {};
        const str = input.toString();
        const MAX_TRIM = 10;
        let foundCorruption = false;
        for (let i = 0; i < MAX_TRIM; i++) {
            try {
                return JSON.parse(str.substring(0, str.length - i));
            }
            catch (err) {
                if (!foundCorruption) {
                    foundCorruption = true;
                    console.warn('WARNING: ssb-conn-db found a corrupted conn.json file ' +
                        'and is attempting to heal it');
                }
                continue;
            }
        }
        console.error('ERROR! ssb-conn-db failed to heal corrupted conn.json file');
        return {};
    },
};

},
"G7KjyckHCop/vC6nJsQJHoGW/yQWNAeMeOJ5JGcKBg0=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var callBound = require('call-bind/callBound');
var hasSymbols = require('has-symbols/shams')();
var hasToStringTag = hasSymbols && !!Symbol.toStringTag;
var has;
var $exec;
var isRegexMarker;
var badStringifier;

if (hasToStringTag) {
	has = callBound('Object.prototype.hasOwnProperty');
	$exec = callBound('RegExp.prototype.exec');
	isRegexMarker = {};

	var throwRegexMarker = function () {
		throw isRegexMarker;
	};
	badStringifier = {
		toString: throwRegexMarker,
		valueOf: throwRegexMarker
	};

	if (typeof Symbol.toPrimitive === 'symbol') {
		badStringifier[Symbol.toPrimitive] = throwRegexMarker;
	}
}

var $toString = callBound('Object.prototype.toString');
var gOPD = Object.getOwnPropertyDescriptor;
var regexClass = '[object RegExp]';

module.exports = hasToStringTag
	// eslint-disable-next-line consistent-return
	? function isRegex(value) {
		if (!value || typeof value !== 'object') {
			return false;
		}

		var descriptor = gOPD(value, 'lastIndex');
		var hasLastIndexDataProperty = descriptor && has(descriptor, 'value');
		if (!hasLastIndexDataProperty) {
			return false;
		}

		try {
			$exec(value, badStringifier);
		} catch (e) {
			return e === isRegexMarker;
		}
	}
	: function isRegex(value) {
		// In older browsers, typeof regex incorrectly returns 'function'
		if (!value || (typeof value !== 'object' && typeof value !== 'function')) {
			return false;
		}

		return $toString(value) === regexClass;
	};

},
"GCqC0Z1TFuAA+NbEVWgs0y6Xmyi1oMU9tnzKnEbcYz0=":
function (require, module, exports, __dirname, __filename) {
module.exports = 26835;
},
"GNMWnP7cs2UL9sgR85SgiDUEhvn2CLMayZcND4cIDmg=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var mutexify = require('mutexify')

module.exports = function (store, _codec) {
  var codec = _codec || require('flumecodec/json')
  var lock = mutexify()
  var value

  return {
    get: function (cb) {
      if(value) return cb(null, value)
      else store.get(function (err, _value) {
        if(err) return cb(err)
        try {
          value = codec.decode(_value)
        } catch (err) {
          return cb(err)
        }
        cb(null, value)
      })
    },
    //only allow one update at a time.
    set: function (_value, cb) {
      lock(function (unlock) {
        store.set(codec.encode(_value), function (err) {
          if(!err) value=_value
          unlock(cb, err, _value)
        })
      })
    },
    destroy: function (cb) {
      lock(function (unlock) {
        store.destroy(function (err) {
          value=null
          unlock(cb, err)
        })
      })
    }
  }
}


},
"GR7qOXKw4G+SlbAoo+ThsHSQCZTrM+ED7k3wnsp8pMU=":
function (require, module, exports, __dirname, __filename) {
'use strict';

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

var _require = require('buffer'),
    Buffer = _require.Buffer;

var _require2 = require('util'),
    inspect = _require2.inspect;

var custom = inspect && inspect.custom || 'inspect';

function copyBuffer(src, target, offset) {
  Buffer.prototype.copy.call(src, target, offset);
}

module.exports =
/*#__PURE__*/
function () {
  function BufferList() {
    this.head = null;
    this.tail = null;
    this.length = 0;
  }

  var _proto = BufferList.prototype;

  _proto.push = function push(v) {
    var entry = {
      data: v,
      next: null
    };
    if (this.length > 0) this.tail.next = entry;else this.head = entry;
    this.tail = entry;
    ++this.length;
  };

  _proto.unshift = function unshift(v) {
    var entry = {
      data: v,
      next: this.head
    };
    if (this.length === 0) this.tail = entry;
    this.head = entry;
    ++this.length;
  };

  _proto.shift = function shift() {
    if (this.length === 0) return;
    var ret = this.head.data;
    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;
    --this.length;
    return ret;
  };

  _proto.clear = function clear() {
    this.head = this.tail = null;
    this.length = 0;
  };

  _proto.join = function join(s) {
    if (this.length === 0) return '';
    var p = this.head;
    var ret = '' + p.data;

    while (p = p.next) {
      ret += s + p.data;
    }

    return ret;
  };

  _proto.concat = function concat(n) {
    if (this.length === 0) return Buffer.alloc(0);
    var ret = Buffer.allocUnsafe(n >>> 0);
    var p = this.head;
    var i = 0;

    while (p) {
      copyBuffer(p.data, ret, i);
      i += p.data.length;
      p = p.next;
    }

    return ret;
  } // Consumes a specified amount of bytes or characters from the buffered data.
  ;

  _proto.consume = function consume(n, hasStrings) {
    var ret;

    if (n < this.head.data.length) {
      // `slice` is the same for buffers and strings.
      ret = this.head.data.slice(0, n);
      this.head.data = this.head.data.slice(n);
    } else if (n === this.head.data.length) {
      // First chunk is a perfect match.
      ret = this.shift();
    } else {
      // Result spans more than one buffer.
      ret = hasStrings ? this._getString(n) : this._getBuffer(n);
    }

    return ret;
  };

  _proto.first = function first() {
    return this.head.data;
  } // Consumes a specified amount of characters from the buffered data.
  ;

  _proto._getString = function _getString(n) {
    var p = this.head;
    var c = 1;
    var ret = p.data;
    n -= ret.length;

    while (p = p.next) {
      var str = p.data;
      var nb = n > str.length ? str.length : n;
      if (nb === str.length) ret += str;else ret += str.slice(0, n);
      n -= nb;

      if (n === 0) {
        if (nb === str.length) {
          ++c;
          if (p.next) this.head = p.next;else this.head = this.tail = null;
        } else {
          this.head = p;
          p.data = str.slice(nb);
        }

        break;
      }

      ++c;
    }

    this.length -= c;
    return ret;
  } // Consumes a specified amount of bytes from the buffered data.
  ;

  _proto._getBuffer = function _getBuffer(n) {
    var ret = Buffer.allocUnsafe(n);
    var p = this.head;
    var c = 1;
    p.data.copy(ret);
    n -= p.data.length;

    while (p = p.next) {
      var buf = p.data;
      var nb = n > buf.length ? buf.length : n;
      buf.copy(ret, ret.length - n, 0, nb);
      n -= nb;

      if (n === 0) {
        if (nb === buf.length) {
          ++c;
          if (p.next) this.head = p.next;else this.head = this.tail = null;
        } else {
          this.head = p;
          p.data = buf.slice(nb);
        }

        break;
      }

      ++c;
    }

    this.length -= c;
    return ret;
  } // Make sure the linked list only shows the minimal necessary information.
  ;

  _proto[custom] = function (_, options) {
    return inspect(this, _objectSpread({}, options, {
      // Only inspect one level.
      depth: 0,
      // It should not recurse.
      customInspect: false
    }));
  };

  return BufferList;
}();
},
"Gaaxa5sEElP72u1VUGK+FoI2p+EAMoMgrNYQElse3k4=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
function microtask() {
    if (typeof MutationObserver !== 'undefined') {
        var node_1 = document.createTextNode('');
        var queue_1 = [];
        var i_1 = 0;
        new MutationObserver(function () {
            while (queue_1.length) {
                queue_1.shift()();
            }
        }).observe(node_1, { characterData: true });
        return function (fn) {
            queue_1.push(fn);
            node_1.data = i_1 = 1 - i_1;
        };
    }
    else if (typeof process !== 'undefined') {
        return process.nextTick;
    }
    else {
        return setTimeout;
    }
}
exports.default = microtask;
//# sourceMappingURL=index.js.map
},
"Gxi6OFfjN4MMv2zODwnYfZkJeHsy8MSDWWhkxHv/DCY=":
function (require, module, exports, __dirname, __filename) {
'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var common = require('@minireq/common');

function makeRequest(serializers = common.defaultSerializers, defaultOptions = {}) {
    return function request(options) {
        var _a;
        const opts = Object.assign(Object.assign(Object.assign({}, common.defaults), defaultOptions), options);
        const url = opts.url + common.makeQueryString(opts.query);
        // Because fuck JavaScript Promises and their garbage error handing regarding throw
        let resolve;
        let reject;
        const request = new XMLHttpRequest();
        const abort = () => {
            request.abort();
        };
        if (opts.timeout)
            request.timeout = opts.timeout;
        if (opts.onTimeout) {
            request.addEventListener('timeout', opts.onTimeout);
        }
        request.addEventListener('load', () => {
            var _a, _b;
            let response = request.response;
            if (opts.responseType === 'parsed') {
                const mimeType = (_a = request
                    .getResponseHeader('Content-Type')) === null || _a === void 0 ? void 0 : _a.split(';')[0];
                if (mimeType && ((_b = serializers[mimeType]) === null || _b === void 0 ? void 0 : _b.parse)) {
                    response = serializers[mimeType].parse(response);
                }
            }
            resolve({
                status: request.status,
                data: response,
            });
        });
        request.addEventListener('error', reject);
        if (opts.progress) {
            request.onprogress = opts.progress;
        }
        if (opts.uploadProgress) {
            request.upload.onprogress = opts.uploadProgress;
        }
        request.open(opts.method, url, true);
        request.responseType =
            opts.responseType === 'binary' ? 'arraybuffer' : 'text';
        if (opts.headers) {
            for (const key in opts.headers) {
                request.setRequestHeader(key, opts.headers[key]);
            }
        }
        if (opts.contentType) {
            request.setRequestHeader('Content-Type', opts.contentType);
        }
        if (opts.accept) {
            request.setRequestHeader('Accept', opts.accept);
        }
        if (opts.auth) {
            request.setRequestHeader('Authorization', `Basic ${btoa(opts.auth.user + ':' + opts.auth.password)}`);
        }
        if (opts.send) {
            if (typeof opts.send === 'string' ||
                opts.send instanceof Blob ||
                opts.send instanceof ArrayBuffer ||
                opts.send instanceof Int8Array ||
                opts.send instanceof Uint8Array ||
                opts.send instanceof Uint8ClampedArray ||
                opts.send instanceof Int16Array ||
                opts.send instanceof Uint16Array ||
                opts.send instanceof Int32Array ||
                opts.send instanceof Uint32Array ||
                opts.send instanceof Float32Array ||
                opts.send instanceof Float64Array ||
                opts.send instanceof DataView ||
                opts.send instanceof FormData ||
                opts.send instanceof URLSearchParams) {
                request.send(opts.send);
            }
            else if ((_a = serializers[opts.contentType]) === null || _a === void 0 ? void 0 : _a.convert) {
                request.send(serializers[opts.contentType].convert(opts.send));
            }
            else {
                throw new Error(`Could not find a serializer for content type ${opts.contentType}`);
            }
        }
        else {
            request.send();
        }
        return {
            promise: new Promise((res, rej) => {
                resolve = res;
                reject = rej;
            }),
            abort,
        };
    };
}

exports.makeRequest = makeRequest;

},
"Gyxb1O+ZxazmoR3fJJ3GrHX1UxrNcxmqjSderytY4VQ=":
function (require, module, exports, __dirname, __filename) {
/*jshint node:true*/
'use strict';

/**
 * Replaces characters in strings that are illegal/unsafe for filenames.
 * Unsafe characters are either removed or replaced by a substitute set
 * in the optional `options` object.
 *
 * Illegal Characters on Various Operating Systems
 * / ? < > \ : * | "
 * https://kb.acronis.com/content/39790
 *
 * Unicode Control codes
 * C0 0x00-0x1f & C1 (0x80-0x9f)
 * http://en.wikipedia.org/wiki/C0_and_C1_control_codes
 *
 * Reserved filenames on Unix-based systems (".", "..")
 * Reserved filenames in Windows ("CON", "PRN", "AUX", "NUL", "COM1",
 * "COM2", "COM3", "COM4", "COM5", "COM6", "COM7", "COM8", "COM9",
 * "LPT1", "LPT2", "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", and
 * "LPT9") case-insesitively and with or without filename extensions.
 *
 * Capped at 255 characters in length.
 * http://unix.stackexchange.com/questions/32795/what-is-the-maximum-allowed-filename-and-folder-size-with-ecryptfs
 *
 * @param  {String} input   Original filename
 * @param  {Object} options {replacement: String | Function }
 * @return {String}         Sanitized filename
 */

var truncate = require("truncate-utf8-bytes");

var illegalRe = /[\/\?<>\\:\*\|"]/g;
var controlRe = /[\x00-\x1f\x80-\x9f]/g;
var reservedRe = /^\.+$/;
var windowsReservedRe = /^(con|prn|aux|nul|com[0-9]|lpt[0-9])(\..*)?$/i;
var windowsTrailingRe = /[\. ]+$/;

function sanitize(input, replacement) {
  if (typeof input !== 'string') {
    throw new Error('Input must be string');
  }
  var sanitized = input
    .replace(illegalRe, replacement)
    .replace(controlRe, replacement)
    .replace(reservedRe, replacement)
    .replace(windowsReservedRe, replacement)
    .replace(windowsTrailingRe, replacement);
  return truncate(sanitized, 255);
}

module.exports = function (input, options) {
  var replacement = (options && options.replacement) || '';
  var output = sanitize(input, replacement);
  if (replacement === '') {
    return output;
  }
  return sanitize(output, '');
};

},
"HHod+0xMVFBcp4b4clM0g0T/PKlL+xSWHrou2eEwI2s=":
function (require, module, exports, __dirname, __filename) {
const { getType } = require('./util.js')

/**
 * Encodes data in bencode.
 *
 * @param  {Buffer|Array|String|Object|Number|Boolean} data
 * @return {Buffer}
 */
function encode (data, buffer, offset) {
  const buffers = []
  let result = null

  encode._encode(buffers, data)
  result = Buffer.concat(buffers)
  encode.bytes = result.length

  if (Buffer.isBuffer(buffer)) {
    result.copy(buffer, offset)
    return buffer
  }

  return result
}

encode.bytes = -1
encode._floatConversionDetected = false

encode._encode = function (buffers, data) {
  if (data == null) { return }

  switch (getType(data)) {
    case 'buffer': encode.buffer(buffers, data); break
    case 'object': encode.dict(buffers, data); break
    case 'map': encode.dictMap(buffers, data); break
    case 'array': encode.list(buffers, data); break
    case 'set': encode.listSet(buffers, data); break
    case 'string': encode.string(buffers, data); break
    case 'number': encode.number(buffers, data); break
    case 'boolean': encode.number(buffers, data); break
    case 'arraybufferview': encode.buffer(buffers, Buffer.from(data.buffer, data.byteOffset, data.byteLength)); break
    case 'arraybuffer': encode.buffer(buffers, Buffer.from(data)); break
  }
}

const buffE = Buffer.from('e')
const buffD = Buffer.from('d')
const buffL = Buffer.from('l')

encode.buffer = function (buffers, data) {
  buffers.push(Buffer.from(data.length + ':'), data)
}

encode.string = function (buffers, data) {
  buffers.push(Buffer.from(Buffer.byteLength(data) + ':' + data))
}

encode.number = function (buffers, data) {
  const maxLo = 0x80000000
  const hi = (data / maxLo) << 0
  const lo = (data % maxLo) << 0
  const val = hi * maxLo + lo

  buffers.push(Buffer.from('i' + val + 'e'))

  if (val !== data && !encode._floatConversionDetected) {
    encode._floatConversionDetected = true
    console.warn(
      'WARNING: Possible data corruption detected with value "' + data + '":',
      'Bencoding only defines support for integers, value was converted to "' + val + '"'
    )
    console.trace()
  }
}

encode.dict = function (buffers, data) {
  buffers.push(buffD)

  let j = 0
  let k
  // fix for issue #13 - sorted dicts
  const keys = Object.keys(data).sort()
  const kl = keys.length

  for (; j < kl; j++) {
    k = keys[j]
    if (data[k] == null) continue
    encode.string(buffers, k)
    encode._encode(buffers, data[k])
  }

  buffers.push(buffE)
}

encode.dictMap = function (buffers, data) {
  buffers.push(buffD)

  const keys = Array.from(data.keys()).sort()

  for (const key of keys) {
    if (data.get(key) == null) continue
    Buffer.isBuffer(key)
      ? encode._encode(buffers, key)
      : encode.string(buffers, String(key))
    encode._encode(buffers, data.get(key))
  }

  buffers.push(buffE)
}

encode.list = function (buffers, data) {
  let i = 0
  const c = data.length
  buffers.push(buffL)

  for (; i < c; i++) {
    if (data[i] == null) continue
    encode._encode(buffers, data[i])
  }

  buffers.push(buffE)
}

encode.listSet = function (buffers, data) {
  buffers.push(buffL)

  for (const item of data) {
    if (item == null) continue
    encode._encode(buffers, item)
  }

  buffers.push(buffE)
}

module.exports = encode

},
"HNOwxrCMnZwenqSz+Qxx7JaQ4D1x2GnbwBWjUVJwh7U=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "abdikace",
    "abeceda",
    "adresa",
    "agrese",
    "akce",
    "aktovka",
    "alej",
    "alkohol",
    "amputace",
    "ananas",
    "andulka",
    "anekdota",
    "anketa",
    "antika",
    "anulovat",
    "archa",
    "arogance",
    "asfalt",
    "asistent",
    "aspirace",
    "astma",
    "astronom",
    "atlas",
    "atletika",
    "atol",
    "autobus",
    "azyl",
    "babka",
    "bachor",
    "bacil",
    "baculka",
    "badatel",
    "bageta",
    "bagr",
    "bahno",
    "bakterie",
    "balada",
    "baletka",
    "balkon",
    "balonek",
    "balvan",
    "balza",
    "bambus",
    "bankomat",
    "barbar",
    "baret",
    "barman",
    "baroko",
    "barva",
    "baterka",
    "batoh",
    "bavlna",
    "bazalka",
    "bazilika",
    "bazuka",
    "bedna",
    "beran",
    "beseda",
    "bestie",
    "beton",
    "bezinka",
    "bezmoc",
    "beztak",
    "bicykl",
    "bidlo",
    "biftek",
    "bikiny",
    "bilance",
    "biograf",
    "biolog",
    "bitva",
    "bizon",
    "blahobyt",
    "blatouch",
    "blecha",
    "bledule",
    "blesk",
    "blikat",
    "blizna",
    "blokovat",
    "bloudit",
    "blud",
    "bobek",
    "bobr",
    "bodlina",
    "bodnout",
    "bohatost",
    "bojkot",
    "bojovat",
    "bokorys",
    "bolest",
    "borec",
    "borovice",
    "bota",
    "boubel",
    "bouchat",
    "bouda",
    "boule",
    "bourat",
    "boxer",
    "bradavka",
    "brambora",
    "branka",
    "bratr",
    "brepta",
    "briketa",
    "brko",
    "brloh",
    "bronz",
    "broskev",
    "brunetka",
    "brusinka",
    "brzda",
    "brzy",
    "bublina",
    "bubnovat",
    "buchta",
    "buditel",
    "budka",
    "budova",
    "bufet",
    "bujarost",
    "bukvice",
    "buldok",
    "bulva",
    "bunda",
    "bunkr",
    "burza",
    "butik",
    "buvol",
    "buzola",
    "bydlet",
    "bylina",
    "bytovka",
    "bzukot",
    "capart",
    "carevna",
    "cedr",
    "cedule",
    "cejch",
    "cejn",
    "cela",
    "celer",
    "celkem",
    "celnice",
    "cenina",
    "cennost",
    "cenovka",
    "centrum",
    "cenzor",
    "cestopis",
    "cetka",
    "chalupa",
    "chapadlo",
    "charita",
    "chata",
    "chechtat",
    "chemie",
    "chichot",
    "chirurg",
    "chlad",
    "chleba",
    "chlubit",
    "chmel",
    "chmura",
    "chobot",
    "chochol",
    "chodba",
    "cholera",
    "chomout",
    "chopit",
    "choroba",
    "chov",
    "chrapot",
    "chrlit",
    "chrt",
    "chrup",
    "chtivost",
    "chudina",
    "chutnat",
    "chvat",
    "chvilka",
    "chvost",
    "chyba",
    "chystat",
    "chytit",
    "cibule",
    "cigareta",
    "cihelna",
    "cihla",
    "cinkot",
    "cirkus",
    "cisterna",
    "citace",
    "citrus",
    "cizinec",
    "cizost",
    "clona",
    "cokoliv",
    "couvat",
    "ctitel",
    "ctnost",
    "cudnost",
    "cuketa",
    "cukr",
    "cupot",
    "cvaknout",
    "cval",
    "cvik",
    "cvrkot",
    "cyklista",
    "daleko",
    "dareba",
    "datel",
    "datum",
    "dcera",
    "debata",
    "dechovka",
    "decibel",
    "deficit",
    "deflace",
    "dekl",
    "dekret",
    "demokrat",
    "deprese",
    "derby",
    "deska",
    "detektiv",
    "dikobraz",
    "diktovat",
    "dioda",
    "diplom",
    "disk",
    "displej",
    "divadlo",
    "divoch",
    "dlaha",
    "dlouho",
    "dluhopis",
    "dnes",
    "dobro",
    "dobytek",
    "docent",
    "dochutit",
    "dodnes",
    "dohled",
    "dohoda",
    "dohra",
    "dojem",
    "dojnice",
    "doklad",
    "dokola",
    "doktor",
    "dokument",
    "dolar",
    "doleva",
    "dolina",
    "doma",
    "dominant",
    "domluvit",
    "domov",
    "donutit",
    "dopad",
    "dopis",
    "doplnit",
    "doposud",
    "doprovod",
    "dopustit",
    "dorazit",
    "dorost",
    "dort",
    "dosah",
    "doslov",
    "dostatek",
    "dosud",
    "dosyta",
    "dotaz",
    "dotek",
    "dotknout",
    "doufat",
    "doutnat",
    "dovozce",
    "dozadu",
    "doznat",
    "dozorce",
    "drahota",
    "drak",
    "dramatik",
    "dravec",
    "draze",
    "drdol",
    "drobnost",
    "drogerie",
    "drozd",
    "drsnost",
    "drtit",
    "drzost",
    "duben",
    "duchovno",
    "dudek",
    "duha",
    "duhovka",
    "dusit",
    "dusno",
    "dutost",
    "dvojice",
    "dvorec",
    "dynamit",
    "ekolog",
    "ekonomie",
    "elektron",
    "elipsa",
    "email",
    "emise",
    "emoce",
    "empatie",
    "epizoda",
    "epocha",
    "epopej",
    "epos",
    "esej",
    "esence",
    "eskorta",
    "eskymo",
    "etiketa",
    "euforie",
    "evoluce",
    "exekuce",
    "exkurze",
    "expedice",
    "exploze",
    "export",
    "extrakt",
    "facka",
    "fajfka",
    "fakulta",
    "fanatik",
    "fantazie",
    "farmacie",
    "favorit",
    "fazole",
    "federace",
    "fejeton",
    "fenka",
    "fialka",
    "figurant",
    "filozof",
    "filtr",
    "finance",
    "finta",
    "fixace",
    "fjord",
    "flanel",
    "flirt",
    "flotila",
    "fond",
    "fosfor",
    "fotbal",
    "fotka",
    "foton",
    "frakce",
    "freska",
    "fronta",
    "fukar",
    "funkce",
    "fyzika",
    "galeje",
    "garant",
    "genetika",
    "geolog",
    "gilotina",
    "glazura",
    "glejt",
    "golem",
    "golfista",
    "gotika",
    "graf",
    "gramofon",
    "granule",
    "grep",
    "gril",
    "grog",
    "groteska",
    "guma",
    "hadice",
    "hadr",
    "hala",
    "halenka",
    "hanba",
    "hanopis",
    "harfa",
    "harpuna",
    "havran",
    "hebkost",
    "hejkal",
    "hejno",
    "hejtman",
    "hektar",
    "helma",
    "hematom",
    "herec",
    "herna",
    "heslo",
    "hezky",
    "historik",
    "hladovka",
    "hlasivky",
    "hlava",
    "hledat",
    "hlen",
    "hlodavec",
    "hloh",
    "hloupost",
    "hltat",
    "hlubina",
    "hluchota",
    "hmat",
    "hmota",
    "hmyz",
    "hnis",
    "hnojivo",
    "hnout",
    "hoblina",
    "hoboj",
    "hoch",
    "hodiny",
    "hodlat",
    "hodnota",
    "hodovat",
    "hojnost",
    "hokej",
    "holinka",
    "holka",
    "holub",
    "homole",
    "honitba",
    "honorace",
    "horal",
    "horda",
    "horizont",
    "horko",
    "horlivec",
    "hormon",
    "hornina",
    "horoskop",
    "horstvo",
    "hospoda",
    "hostina",
    "hotovost",
    "houba",
    "houf",
    "houpat",
    "houska",
    "hovor",
    "hradba",
    "hranice",
    "hravost",
    "hrazda",
    "hrbolek",
    "hrdina",
    "hrdlo",
    "hrdost",
    "hrnek",
    "hrobka",
    "hromada",
    "hrot",
    "hrouda",
    "hrozen",
    "hrstka",
    "hrubost",
    "hryzat",
    "hubenost",
    "hubnout",
    "hudba",
    "hukot",
    "humr",
    "husita",
    "hustota",
    "hvozd",
    "hybnost",
    "hydrant",
    "hygiena",
    "hymna",
    "hysterik",
    "idylka",
    "ihned",
    "ikona",
    "iluze",
    "imunita",
    "infekce",
    "inflace",
    "inkaso",
    "inovace",
    "inspekce",
    "internet",
    "invalida",
    "investor",
    "inzerce",
    "ironie",
    "jablko",
    "jachta",
    "jahoda",
    "jakmile",
    "jakost",
    "jalovec",
    "jantar",
    "jarmark",
    "jaro",
    "jasan",
    "jasno",
    "jatka",
    "javor",
    "jazyk",
    "jedinec",
    "jedle",
    "jednatel",
    "jehlan",
    "jekot",
    "jelen",
    "jelito",
    "jemnost",
    "jenom",
    "jepice",
    "jeseter",
    "jevit",
    "jezdec",
    "jezero",
    "jinak",
    "jindy",
    "jinoch",
    "jiskra",
    "jistota",
    "jitrnice",
    "jizva",
    "jmenovat",
    "jogurt",
    "jurta",
    "kabaret",
    "kabel",
    "kabinet",
    "kachna",
    "kadet",
    "kadidlo",
    "kahan",
    "kajak",
    "kajuta",
    "kakao",
    "kaktus",
    "kalamita",
    "kalhoty",
    "kalibr",
    "kalnost",
    "kamera",
    "kamkoliv",
    "kamna",
    "kanibal",
    "kanoe",
    "kantor",
    "kapalina",
    "kapela",
    "kapitola",
    "kapka",
    "kaple",
    "kapota",
    "kapr",
    "kapusta",
    "kapybara",
    "karamel",
    "karotka",
    "karton",
    "kasa",
    "katalog",
    "katedra",
    "kauce",
    "kauza",
    "kavalec",
    "kazajka",
    "kazeta",
    "kazivost",
    "kdekoliv",
    "kdesi",
    "kedluben",
    "kemp",
    "keramika",
    "kino",
    "klacek",
    "kladivo",
    "klam",
    "klapot",
    "klasika",
    "klaun",
    "klec",
    "klenba",
    "klepat",
    "klesnout",
    "klid",
    "klima",
    "klisna",
    "klobouk",
    "klokan",
    "klopa",
    "kloub",
    "klubovna",
    "klusat",
    "kluzkost",
    "kmen",
    "kmitat",
    "kmotr",
    "kniha",
    "knot",
    "koalice",
    "koberec",
    "kobka",
    "kobliha",
    "kobyla",
    "kocour",
    "kohout",
    "kojenec",
    "kokos",
    "koktejl",
    "kolaps",
    "koleda",
    "kolize",
    "kolo",
    "komando",
    "kometa",
    "komik",
    "komnata",
    "komora",
    "kompas",
    "komunita",
    "konat",
    "koncept",
    "kondice",
    "konec",
    "konfese",
    "kongres",
    "konina",
    "konkurs",
    "kontakt",
    "konzerva",
    "kopanec",
    "kopie",
    "kopnout",
    "koprovka",
    "korbel",
    "korektor",
    "kormidlo",
    "koroptev",
    "korpus",
    "koruna",
    "koryto",
    "korzet",
    "kosatec",
    "kostka",
    "kotel",
    "kotleta",
    "kotoul",
    "koukat",
    "koupelna",
    "kousek",
    "kouzlo",
    "kovboj",
    "koza",
    "kozoroh",
    "krabice",
    "krach",
    "krajina",
    "kralovat",
    "krasopis",
    "kravata",
    "kredit",
    "krejcar",
    "kresba",
    "kreveta",
    "kriket",
    "kritik",
    "krize",
    "krkavec",
    "krmelec",
    "krmivo",
    "krocan",
    "krok",
    "kronika",
    "kropit",
    "kroupa",
    "krovka",
    "krtek",
    "kruhadlo",
    "krupice",
    "krutost",
    "krvinka",
    "krychle",
    "krypta",
    "krystal",
    "kryt",
    "kudlanka",
    "kufr",
    "kujnost",
    "kukla",
    "kulajda",
    "kulich",
    "kulka",
    "kulomet",
    "kultura",
    "kuna",
    "kupodivu",
    "kurt",
    "kurzor",
    "kutil",
    "kvalita",
    "kvasinka",
    "kvestor",
    "kynolog",
    "kyselina",
    "kytara",
    "kytice",
    "kytka",
    "kytovec",
    "kyvadlo",
    "labrador",
    "lachtan",
    "ladnost",
    "laik",
    "lakomec",
    "lamela",
    "lampa",
    "lanovka",
    "lasice",
    "laso",
    "lastura",
    "latinka",
    "lavina",
    "lebka",
    "leckdy",
    "leden",
    "lednice",
    "ledovka",
    "ledvina",
    "legenda",
    "legie",
    "legrace",
    "lehce",
    "lehkost",
    "lehnout",
    "lektvar",
    "lenochod",
    "lentilka",
    "lepenka",
    "lepidlo",
    "letadlo",
    "letec",
    "letmo",
    "letokruh",
    "levhart",
    "levitace",
    "levobok",
    "libra",
    "lichotka",
    "lidojed",
    "lidskost",
    "lihovina",
    "lijavec",
    "lilek",
    "limetka",
    "linie",
    "linka",
    "linoleum",
    "listopad",
    "litina",
    "litovat",
    "lobista",
    "lodivod",
    "logika",
    "logoped",
    "lokalita",
    "loket",
    "lomcovat",
    "lopata",
    "lopuch",
    "lord",
    "losos",
    "lotr",
    "loudal",
    "louh",
    "louka",
    "louskat",
    "lovec",
    "lstivost",
    "lucerna",
    "lucifer",
    "lump",
    "lusk",
    "lustrace",
    "lvice",
    "lyra",
    "lyrika",
    "lysina",
    "madam",
    "madlo",
    "magistr",
    "mahagon",
    "majetek",
    "majitel",
    "majorita",
    "makak",
    "makovice",
    "makrela",
    "malba",
    "malina",
    "malovat",
    "malvice",
    "maminka",
    "mandle",
    "manko",
    "marnost",
    "masakr",
    "maskot",
    "masopust",
    "matice",
    "matrika",
    "maturita",
    "mazanec",
    "mazivo",
    "mazlit",
    "mazurka",
    "mdloba",
    "mechanik",
    "meditace",
    "medovina",
    "melasa",
    "meloun",
    "mentolka",
    "metla",
    "metoda",
    "metr",
    "mezera",
    "migrace",
    "mihnout",
    "mihule",
    "mikina",
    "mikrofon",
    "milenec",
    "milimetr",
    "milost",
    "mimika",
    "mincovna",
    "minibar",
    "minomet",
    "minulost",
    "miska",
    "mistr",
    "mixovat",
    "mladost",
    "mlha",
    "mlhovina",
    "mlok",
    "mlsat",
    "mluvit",
    "mnich",
    "mnohem",
    "mobil",
    "mocnost",
    "modelka",
    "modlitba",
    "mohyla",
    "mokro",
    "molekula",
    "momentka",
    "monarcha",
    "monokl",
    "monstrum",
    "montovat",
    "monzun",
    "mosaz",
    "moskyt",
    "most",
    "motivace",
    "motorka",
    "motyka",
    "moucha",
    "moudrost",
    "mozaika",
    "mozek",
    "mozol",
    "mramor",
    "mravenec",
    "mrkev",
    "mrtvola",
    "mrzet",
    "mrzutost",
    "mstitel",
    "mudrc",
    "muflon",
    "mulat",
    "mumie",
    "munice",
    "muset",
    "mutace",
    "muzeum",
    "muzikant",
    "myslivec",
    "mzda",
    "nabourat",
    "nachytat",
    "nadace",
    "nadbytek",
    "nadhoz",
    "nadobro",
    "nadpis",
    "nahlas",
    "nahnat",
    "nahodile",
    "nahradit",
    "naivita",
    "najednou",
    "najisto",
    "najmout",
    "naklonit",
    "nakonec",
    "nakrmit",
    "nalevo",
    "namazat",
    "namluvit",
    "nanometr",
    "naoko",
    "naopak",
    "naostro",
    "napadat",
    "napevno",
    "naplnit",
    "napnout",
    "naposled",
    "naprosto",
    "narodit",
    "naruby",
    "narychlo",
    "nasadit",
    "nasekat",
    "naslepo",
    "nastat",
    "natolik",
    "navenek",
    "navrch",
    "navzdory",
    "nazvat",
    "nebe",
    "nechat",
    "necky",
    "nedaleko",
    "nedbat",
    "neduh",
    "negace",
    "nehet",
    "nehoda",
    "nejen",
    "nejprve",
    "neklid",
    "nelibost",
    "nemilost",
    "nemoc",
    "neochota",
    "neonka",
    "nepokoj",
    "nerost",
    "nerv",
    "nesmysl",
    "nesoulad",
    "netvor",
    "neuron",
    "nevina",
    "nezvykle",
    "nicota",
    "nijak",
    "nikam",
    "nikdy",
    "nikl",
    "nikterak",
    "nitro",
    "nocleh",
    "nohavice",
    "nominace",
    "nora",
    "norek",
    "nositel",
    "nosnost",
    "nouze",
    "noviny",
    "novota",
    "nozdra",
    "nuda",
    "nudle",
    "nuget",
    "nutit",
    "nutnost",
    "nutrie",
    "nymfa",
    "obal",
    "obarvit",
    "obava",
    "obdiv",
    "obec",
    "obehnat",
    "obejmout",
    "obezita",
    "obhajoba",
    "obilnice",
    "objasnit",
    "objekt",
    "obklopit",
    "oblast",
    "oblek",
    "obliba",
    "obloha",
    "obluda",
    "obnos",
    "obohatit",
    "obojek",
    "obout",
    "obrazec",
    "obrna",
    "obruba",
    "obrys",
    "obsah",
    "obsluha",
    "obstarat",
    "obuv",
    "obvaz",
    "obvinit",
    "obvod",
    "obvykle",
    "obyvatel",
    "obzor",
    "ocas",
    "ocel",
    "ocenit",
    "ochladit",
    "ochota",
    "ochrana",
    "ocitnout",
    "odboj",
    "odbyt",
    "odchod",
    "odcizit",
    "odebrat",
    "odeslat",
    "odevzdat",
    "odezva",
    "odhadce",
    "odhodit",
    "odjet",
    "odjinud",
    "odkaz",
    "odkoupit",
    "odliv",
    "odluka",
    "odmlka",
    "odolnost",
    "odpad",
    "odpis",
    "odplout",
    "odpor",
    "odpustit",
    "odpykat",
    "odrazka",
    "odsoudit",
    "odstup",
    "odsun",
    "odtok",
    "odtud",
    "odvaha",
    "odveta",
    "odvolat",
    "odvracet",
    "odznak",
    "ofina",
    "ofsajd",
    "ohlas",
    "ohnisko",
    "ohrada",
    "ohrozit",
    "ohryzek",
    "okap",
    "okenice",
    "oklika",
    "okno",
    "okouzlit",
    "okovy",
    "okrasa",
    "okres",
    "okrsek",
    "okruh",
    "okupant",
    "okurka",
    "okusit",
    "olejnina",
    "olizovat",
    "omak",
    "omeleta",
    "omezit",
    "omladina",
    "omlouvat",
    "omluva",
    "omyl",
    "onehdy",
    "opakovat",
    "opasek",
    "operace",
    "opice",
    "opilost",
    "opisovat",
    "opora",
    "opozice",
    "opravdu",
    "oproti",
    "orbital",
    "orchestr",
    "orgie",
    "orlice",
    "orloj",
    "ortel",
    "osada",
    "oschnout",
    "osika",
    "osivo",
    "oslava",
    "oslepit",
    "oslnit",
    "oslovit",
    "osnova",
    "osoba",
    "osolit",
    "ospalec",
    "osten",
    "ostraha",
    "ostuda",
    "ostych",
    "osvojit",
    "oteplit",
    "otisk",
    "otop",
    "otrhat",
    "otrlost",
    "otrok",
    "otruby",
    "otvor",
    "ovanout",
    "ovar",
    "oves",
    "ovlivnit",
    "ovoce",
    "oxid",
    "ozdoba",
    "pachatel",
    "pacient",
    "padouch",
    "pahorek",
    "pakt",
    "palanda",
    "palec",
    "palivo",
    "paluba",
    "pamflet",
    "pamlsek",
    "panenka",
    "panika",
    "panna",
    "panovat",
    "panstvo",
    "pantofle",
    "paprika",
    "parketa",
    "parodie",
    "parta",
    "paruka",
    "paryba",
    "paseka",
    "pasivita",
    "pastelka",
    "patent",
    "patrona",
    "pavouk",
    "pazneht",
    "pazourek",
    "pecka",
    "pedagog",
    "pejsek",
    "peklo",
    "peloton",
    "penalta",
    "pendrek",
    "penze",
    "periskop",
    "pero",
    "pestrost",
    "petarda",
    "petice",
    "petrolej",
    "pevnina",
    "pexeso",
    "pianista",
    "piha",
    "pijavice",
    "pikle",
    "piknik",
    "pilina",
    "pilnost",
    "pilulka",
    "pinzeta",
    "pipeta",
    "pisatel",
    "pistole",
    "pitevna",
    "pivnice",
    "pivovar",
    "placenta",
    "plakat",
    "plamen",
    "planeta",
    "plastika",
    "platit",
    "plavidlo",
    "plaz",
    "plech",
    "plemeno",
    "plenta",
    "ples",
    "pletivo",
    "plevel",
    "plivat",
    "plnit",
    "plno",
    "plocha",
    "plodina",
    "plomba",
    "plout",
    "pluk",
    "plyn",
    "pobavit",
    "pobyt",
    "pochod",
    "pocit",
    "poctivec",
    "podat",
    "podcenit",
    "podepsat",
    "podhled",
    "podivit",
    "podklad",
    "podmanit",
    "podnik",
    "podoba",
    "podpora",
    "podraz",
    "podstata",
    "podvod",
    "podzim",
    "poezie",
    "pohanka",
    "pohnutka",
    "pohovor",
    "pohroma",
    "pohyb",
    "pointa",
    "pojistka",
    "pojmout",
    "pokazit",
    "pokles",
    "pokoj",
    "pokrok",
    "pokuta",
    "pokyn",
    "poledne",
    "polibek",
    "polknout",
    "poloha",
    "polynom",
    "pomalu",
    "pominout",
    "pomlka",
    "pomoc",
    "pomsta",
    "pomyslet",
    "ponechat",
    "ponorka",
    "ponurost",
    "popadat",
    "popel",
    "popisek",
    "poplach",
    "poprosit",
    "popsat",
    "popud",
    "poradce",
    "porce",
    "porod",
    "porucha",
    "poryv",
    "posadit",
    "posed",
    "posila",
    "poskok",
    "poslanec",
    "posoudit",
    "pospolu",
    "postava",
    "posudek",
    "posyp",
    "potah",
    "potkan",
    "potlesk",
    "potomek",
    "potrava",
    "potupa",
    "potvora",
    "poukaz",
    "pouto",
    "pouzdro",
    "povaha",
    "povidla",
    "povlak",
    "povoz",
    "povrch",
    "povstat",
    "povyk",
    "povzdech",
    "pozdrav",
    "pozemek",
    "poznatek",
    "pozor",
    "pozvat",
    "pracovat",
    "prahory",
    "praktika",
    "prales",
    "praotec",
    "praporek",
    "prase",
    "pravda",
    "princip",
    "prkno",
    "probudit",
    "procento",
    "prodej",
    "profese",
    "prohra",
    "projekt",
    "prolomit",
    "promile",
    "pronikat",
    "propad",
    "prorok",
    "prosba",
    "proton",
    "proutek",
    "provaz",
    "prskavka",
    "prsten",
    "prudkost",
    "prut",
    "prvek",
    "prvohory",
    "psanec",
    "psovod",
    "pstruh",
    "ptactvo",
    "puberta",
    "puch",
    "pudl",
    "pukavec",
    "puklina",
    "pukrle",
    "pult",
    "pumpa",
    "punc",
    "pupen",
    "pusa",
    "pusinka",
    "pustina",
    "putovat",
    "putyka",
    "pyramida",
    "pysk",
    "pytel",
    "racek",
    "rachot",
    "radiace",
    "radnice",
    "radon",
    "raft",
    "ragby",
    "raketa",
    "rakovina",
    "rameno",
    "rampouch",
    "rande",
    "rarach",
    "rarita",
    "rasovna",
    "rastr",
    "ratolest",
    "razance",
    "razidlo",
    "reagovat",
    "reakce",
    "recept",
    "redaktor",
    "referent",
    "reflex",
    "rejnok",
    "reklama",
    "rekord",
    "rekrut",
    "rektor",
    "reputace",
    "revize",
    "revma",
    "revolver",
    "rezerva",
    "riskovat",
    "riziko",
    "robotika",
    "rodokmen",
    "rohovka",
    "rokle",
    "rokoko",
    "romaneto",
    "ropovod",
    "ropucha",
    "rorejs",
    "rosol",
    "rostlina",
    "rotmistr",
    "rotoped",
    "rotunda",
    "roubenka",
    "roucho",
    "roup",
    "roura",
    "rovina",
    "rovnice",
    "rozbor",
    "rozchod",
    "rozdat",
    "rozeznat",
    "rozhodce",
    "rozinka",
    "rozjezd",
    "rozkaz",
    "rozloha",
    "rozmar",
    "rozpad",
    "rozruch",
    "rozsah",
    "roztok",
    "rozum",
    "rozvod",
    "rubrika",
    "ruchadlo",
    "rukavice",
    "rukopis",
    "ryba",
    "rybolov",
    "rychlost",
    "rydlo",
    "rypadlo",
    "rytina",
    "ryzost",
    "sadista",
    "sahat",
    "sako",
    "samec",
    "samizdat",
    "samota",
    "sanitka",
    "sardinka",
    "sasanka",
    "satelit",
    "sazba",
    "sazenice",
    "sbor",
    "schovat",
    "sebranka",
    "secese",
    "sedadlo",
    "sediment",
    "sedlo",
    "sehnat",
    "sejmout",
    "sekera",
    "sekta",
    "sekunda",
    "sekvoje",
    "semeno",
    "seno",
    "servis",
    "sesadit",
    "seshora",
    "seskok",
    "seslat",
    "sestra",
    "sesuv",
    "sesypat",
    "setba",
    "setina",
    "setkat",
    "setnout",
    "setrvat",
    "sever",
    "seznam",
    "shoda",
    "shrnout",
    "sifon",
    "silnice",
    "sirka",
    "sirotek",
    "sirup",
    "situace",
    "skafandr",
    "skalisko",
    "skanzen",
    "skaut",
    "skeptik",
    "skica",
    "skladba",
    "sklenice",
    "sklo",
    "skluz",
    "skoba",
    "skokan",
    "skoro",
    "skripta",
    "skrz",
    "skupina",
    "skvost",
    "skvrna",
    "slabika",
    "sladidlo",
    "slanina",
    "slast",
    "slavnost",
    "sledovat",
    "slepec",
    "sleva",
    "slezina",
    "slib",
    "slina",
    "sliznice",
    "slon",
    "sloupek",
    "slovo",
    "sluch",
    "sluha",
    "slunce",
    "slupka",
    "slza",
    "smaragd",
    "smetana",
    "smilstvo",
    "smlouva",
    "smog",
    "smrad",
    "smrk",
    "smrtka",
    "smutek",
    "smysl",
    "snad",
    "snaha",
    "snob",
    "sobota",
    "socha",
    "sodovka",
    "sokol",
    "sopka",
    "sotva",
    "souboj",
    "soucit",
    "soudce",
    "souhlas",
    "soulad",
    "soumrak",
    "souprava",
    "soused",
    "soutok",
    "souviset",
    "spalovna",
    "spasitel",
    "spis",
    "splav",
    "spodek",
    "spojenec",
    "spolu",
    "sponzor",
    "spornost",
    "spousta",
    "sprcha",
    "spustit",
    "sranda",
    "sraz",
    "srdce",
    "srna",
    "srnec",
    "srovnat",
    "srpen",
    "srst",
    "srub",
    "stanice",
    "starosta",
    "statika",
    "stavba",
    "stehno",
    "stezka",
    "stodola",
    "stolek",
    "stopa",
    "storno",
    "stoupat",
    "strach",
    "stres",
    "strhnout",
    "strom",
    "struna",
    "studna",
    "stupnice",
    "stvol",
    "styk",
    "subjekt",
    "subtropy",
    "suchar",
    "sudost",
    "sukno",
    "sundat",
    "sunout",
    "surikata",
    "surovina",
    "svah",
    "svalstvo",
    "svetr",
    "svatba",
    "svazek",
    "svisle",
    "svitek",
    "svoboda",
    "svodidlo",
    "svorka",
    "svrab",
    "sykavka",
    "sykot",
    "synek",
    "synovec",
    "sypat",
    "sypkost",
    "syrovost",
    "sysel",
    "sytost",
    "tabletka",
    "tabule",
    "tahoun",
    "tajemno",
    "tajfun",
    "tajga",
    "tajit",
    "tajnost",
    "taktika",
    "tamhle",
    "tampon",
    "tancovat",
    "tanec",
    "tanker",
    "tapeta",
    "tavenina",
    "tazatel",
    "technika",
    "tehdy",
    "tekutina",
    "telefon",
    "temnota",
    "tendence",
    "tenista",
    "tenor",
    "teplota",
    "tepna",
    "teprve",
    "terapie",
    "termoska",
    "textil",
    "ticho",
    "tiskopis",
    "titulek",
    "tkadlec",
    "tkanina",
    "tlapka",
    "tleskat",
    "tlukot",
    "tlupa",
    "tmel",
    "toaleta",
    "topinka",
    "topol",
    "torzo",
    "touha",
    "toulec",
    "tradice",
    "traktor",
    "tramp",
    "trasa",
    "traverza",
    "trefit",
    "trest",
    "trezor",
    "trhavina",
    "trhlina",
    "trochu",
    "trojice",
    "troska",
    "trouba",
    "trpce",
    "trpitel",
    "trpkost",
    "trubec",
    "truchlit",
    "truhlice",
    "trus",
    "trvat",
    "tudy",
    "tuhnout",
    "tuhost",
    "tundra",
    "turista",
    "turnaj",
    "tuzemsko",
    "tvaroh",
    "tvorba",
    "tvrdost",
    "tvrz",
    "tygr",
    "tykev",
    "ubohost",
    "uboze",
    "ubrat",
    "ubrousek",
    "ubrus",
    "ubytovna",
    "ucho",
    "uctivost",
    "udivit",
    "uhradit",
    "ujednat",
    "ujistit",
    "ujmout",
    "ukazatel",
    "uklidnit",
    "uklonit",
    "ukotvit",
    "ukrojit",
    "ulice",
    "ulita",
    "ulovit",
    "umyvadlo",
    "unavit",
    "uniforma",
    "uniknout",
    "upadnout",
    "uplatnit",
    "uplynout",
    "upoutat",
    "upravit",
    "uran",
    "urazit",
    "usednout",
    "usilovat",
    "usmrtit",
    "usnadnit",
    "usnout",
    "usoudit",
    "ustlat",
    "ustrnout",
    "utahovat",
    "utkat",
    "utlumit",
    "utonout",
    "utopenec",
    "utrousit",
    "uvalit",
    "uvolnit",
    "uvozovka",
    "uzdravit",
    "uzel",
    "uzenina",
    "uzlina",
    "uznat",
    "vagon",
    "valcha",
    "valoun",
    "vana",
    "vandal",
    "vanilka",
    "varan",
    "varhany",
    "varovat",
    "vcelku",
    "vchod",
    "vdova",
    "vedro",
    "vegetace",
    "vejce",
    "velbloud",
    "veletrh",
    "velitel",
    "velmoc",
    "velryba",
    "venkov",
    "veranda",
    "verze",
    "veselka",
    "veskrze",
    "vesnice",
    "vespodu",
    "vesta",
    "veterina",
    "veverka",
    "vibrace",
    "vichr",
    "videohra",
    "vidina",
    "vidle",
    "vila",
    "vinice",
    "viset",
    "vitalita",
    "vize",
    "vizitka",
    "vjezd",
    "vklad",
    "vkus",
    "vlajka",
    "vlak",
    "vlasec",
    "vlevo",
    "vlhkost",
    "vliv",
    "vlnovka",
    "vloupat",
    "vnucovat",
    "vnuk",
    "voda",
    "vodivost",
    "vodoznak",
    "vodstvo",
    "vojensky",
    "vojna",
    "vojsko",
    "volant",
    "volba",
    "volit",
    "volno",
    "voskovka",
    "vozidlo",
    "vozovna",
    "vpravo",
    "vrabec",
    "vracet",
    "vrah",
    "vrata",
    "vrba",
    "vrcholek",
    "vrhat",
    "vrstva",
    "vrtule",
    "vsadit",
    "vstoupit",
    "vstup",
    "vtip",
    "vybavit",
    "vybrat",
    "vychovat",
    "vydat",
    "vydra",
    "vyfotit",
    "vyhledat",
    "vyhnout",
    "vyhodit",
    "vyhradit",
    "vyhubit",
    "vyjasnit",
    "vyjet",
    "vyjmout",
    "vyklopit",
    "vykonat",
    "vylekat",
    "vymazat",
    "vymezit",
    "vymizet",
    "vymyslet",
    "vynechat",
    "vynikat",
    "vynutit",
    "vypadat",
    "vyplatit",
    "vypravit",
    "vypustit",
    "vyrazit",
    "vyrovnat",
    "vyrvat",
    "vyslovit",
    "vysoko",
    "vystavit",
    "vysunout",
    "vysypat",
    "vytasit",
    "vytesat",
    "vytratit",
    "vyvinout",
    "vyvolat",
    "vyvrhel",
    "vyzdobit",
    "vyznat",
    "vzadu",
    "vzbudit",
    "vzchopit",
    "vzdor",
    "vzduch",
    "vzdychat",
    "vzestup",
    "vzhledem",
    "vzkaz",
    "vzlykat",
    "vznik",
    "vzorek",
    "vzpoura",
    "vztah",
    "vztek",
    "xylofon",
    "zabrat",
    "zabydlet",
    "zachovat",
    "zadarmo",
    "zadusit",
    "zafoukat",
    "zahltit",
    "zahodit",
    "zahrada",
    "zahynout",
    "zajatec",
    "zajet",
    "zajistit",
    "zaklepat",
    "zakoupit",
    "zalepit",
    "zamezit",
    "zamotat",
    "zamyslet",
    "zanechat",
    "zanikat",
    "zaplatit",
    "zapojit",
    "zapsat",
    "zarazit",
    "zastavit",
    "zasunout",
    "zatajit",
    "zatemnit",
    "zatknout",
    "zaujmout",
    "zavalit",
    "zavelet",
    "zavinit",
    "zavolat",
    "zavrtat",
    "zazvonit",
    "zbavit",
    "zbrusu",
    "zbudovat",
    "zbytek",
    "zdaleka",
    "zdarma",
    "zdatnost",
    "zdivo",
    "zdobit",
    "zdroj",
    "zdvih",
    "zdymadlo",
    "zelenina",
    "zeman",
    "zemina",
    "zeptat",
    "zezadu",
    "zezdola",
    "zhatit",
    "zhltnout",
    "zhluboka",
    "zhotovit",
    "zhruba",
    "zima",
    "zimnice",
    "zjemnit",
    "zklamat",
    "zkoumat",
    "zkratka",
    "zkumavka",
    "zlato",
    "zlehka",
    "zloba",
    "zlom",
    "zlost",
    "zlozvyk",
    "zmapovat",
    "zmar",
    "zmatek",
    "zmije",
    "zmizet",
    "zmocnit",
    "zmodrat",
    "zmrzlina",
    "zmutovat",
    "znak",
    "znalost",
    "znamenat",
    "znovu",
    "zobrazit",
    "zotavit",
    "zoubek",
    "zoufale",
    "zplodit",
    "zpomalit",
    "zprava",
    "zprostit",
    "zprudka",
    "zprvu",
    "zrada",
    "zranit",
    "zrcadlo",
    "zrnitost",
    "zrno",
    "zrovna",
    "zrychlit",
    "zrzavost",
    "zticha",
    "ztratit",
    "zubovina",
    "zubr",
    "zvednout",
    "zvenku",
    "zvesela",
    "zvon",
    "zvrat",
    "zvukovod",
    "zvyk"
]

},
"HT/pJIWUIo+8yEwhsq6Do+C/gZeI0Vm0ZxOw/ruRWzY=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const blobIdToUrl = require('ssb-serve-blobs/id-to-url');
function augmentPeerWithExtras(kv, connDB, aboutSelf) {
    const [addr, peer] = kv;
    if (!peer.key)
        return kv;
    const output = aboutSelf.getProfile(peer.key);
    if (!output)
        return kv;
    const name = output.name;
    const imageUrl = output.image ? blobIdToUrl(output.image) : void 0;
    const isInDB = connDB.has(addr);
    return [addr, Object.assign({ name, imageUrl, isInDB }, peer)];
}
function augmentPeersWithExtras(ssb) {
    return (kvs, cb) => {
        let done = false;
        ssb.db.onDrain('aboutSelf', () => {
            if (!done) {
                done = true;
                const aboutSelf = ssb.db.getIndex('aboutSelf');
                const connDB = ssb.conn.db();
                const newKVs = kvs.map(kv => augmentPeerWithExtras(kv, connDB, aboutSelf));
                cb(null, newKVs);
            }
        });
    };
}
function removeOlderDuplicates(kvs) {
    // Only allow those that don't have a newer duplicate
    return kvs.filter(([_addr1, peer1]) => {
        const newerDuplicate = kvs.find(([_addr2, peer2]) => {
            if (!peer2.key)
                return false;
            if (peer2.key !== peer1.key)
                return false;
            if (peer1.hubUpdated && peer2.hubUpdated) {
                return peer2.hubUpdated > peer1.hubUpdated;
            }
            if (peer1.stagingUpdated && peer2.stagingUpdated) {
                return peer2.stagingUpdated > peer1.stagingUpdated;
            }
            return false;
        });
        return !newerDuplicate;
    });
}
module.exports = {
    name: 'connUtils',
    version: '1.0.0',
    manifest: {
        persistentConnect: 'async',
        persistentDisconnect: 'async',
        peers: 'source',
        stagedPeers: 'source',
    },
    permissions: {
        master: {
            allow: [
                'persistentConnect',
                'persistentDisconnect',
                'peers',
                'stagedPeers',
            ],
        },
    },
    init: function init(ssb) {
        return {
            persistentConnect(address, data, cb) {
                // if we had 'autoconnect=false', then make it true
                ssb.conn.db().update(address, (prev) => {
                    if (!prev.autoconnect)
                        return { autoconnect: true };
                    else
                        return {};
                });
                ssb.conn.connect(address, data, cb);
            },
            persistentDisconnect(address, cb) {
                // if we had 'autoconnect=true', then make it false
                ssb.conn.db().update(address, (prev) => {
                    if (prev.autoconnect)
                        return { autoconnect: false };
                    else
                        return {};
                });
                // disconnect
                ssb.conn.disconnect(address, cb);
            },
            peers() {
                return pull(ssb.conn.peers(), pull.map(removeOlderDuplicates), pull.asyncMap(augmentPeersWithExtras(ssb)));
            },
            stagedPeers() {
                return pull(ssb.conn.stagedPeers(), pull.map(removeOlderDuplicates), pull.asyncMap(augmentPeersWithExtras(ssb)));
            },
        };
    },
};
//# sourceMappingURL=connUtils.js.map
},
"HTzTRZJMVe7DbKvuxjjJBmn+0XN45NxOWQjzBG/8kwQ=":
function (require, module, exports, __dirname, __filename) {
var File = require('./file')
var Blocks = require('./blocks')

module.exports = function (file, block_size, flags, cache) {
  return Blocks(File(file, block_size, flags), block_size, cache)
}

},
"HVnKb+KWE30tj/D3xqwlFsBi5qsM5FfmM7BPj3BBBYI=":
function (require, module, exports, __dirname, __filename) {
/*! ReadWriteLock - v5.0.0 - 2015-01-16
 * Author: Alberto La Rocca <a71104@gmail.com> (https://github.com/71104)
 * Released under the MIT license
 * Copyright (c) 2015 Alberto La Rocca */
module.exports=function(){"use strict";function a(){this.readers=0,this.queue=[]}function b(b,c,f){var g;"function"!=typeof b?(e.hasOwnProperty(b)||(e[b]=new a),g=e[b]):(f=c,c=b,g=d),f||(f={});var h=null;f.hasOwnProperty("scope")&&(h=f.scope);var i=function(){var a=!1;return function(){a||(a=!0,g.readers--,g.queue.length&&g.queue[0]())}}();if(g.readers<0||g.queue.length){var j=!1;if(g.queue.push(function(){!j&&g.readers>=0&&(j=!0,g.queue.shift(),g.readers++,c.call(h,i),g.queue.length&&g.queue[0]())}),f.hasOwnProperty("timeout")){var k=null;f.hasOwnProperty("timeoutCallback")&&(k=f.timeoutCallback),setTimeout(function(){j||(j=!0,g.queue.shift(),k&&k.call(f.scope))},f.timeout)}}else g.readers++,c.call(f.scope,i)}function c(b,c,f){var g;"function"!=typeof b?(e.hasOwnProperty(b)||(e[b]=new a),g=e[b]):(f=c,c=b,g=d),f||(f={});var h=null;f.hasOwnProperty("scope")&&(h=f.scope);var i=function(){var a=!1;return function(){a||(a=!0,g.readers=0,g.queue.length&&g.queue[0]())}}();if(g.readers||g.queue.length){var j=!1;if(g.queue.push(function(){j||g.readers||(j=!0,g.queue.shift(),g.readers=-1,c.call(f.scope,i))}),f.hasOwnProperty("timeout")){var k=null;f.hasOwnProperty("timeoutCallback")&&(k=f.timeoutCallback),setTimeout(function(){j||(j=!0,g.queue.shift(),k&&k.call(h))},f.timeout)}}else g.readers=-1,c.call(f.scope,i)}var d=new a,e={};this.readLock=b,this.writeLock=c,this.async={readLock:function(a,c,d){"function"!=typeof a?b(a,function(a){c.call(this,null,a)},d):(c=a,d=c,b(function(a){c.call(this,null,a)},d))},writeLock:function(a,b,d){"function"!=typeof a?c(a,function(a){b.call(this,null,a)},d):(b=a,d=b,c(function(a){b.call(this,null,a)},d))}}};
},
"Hd42sxnEpaud2aKp5Kueybje9K86nee9rdK2HHTmBxE=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var sodium = require('chloride')
var Reader = require('pull-reader')
var increment = require('increment-buffer')
var through = require('pull-through')
var split = require('split-buffer')

var isBuffer = Buffer.isBuffer
var concat = Buffer.concat

var box = sodium.crypto_secretbox_easy
var unbox = sodium.crypto_secretbox_open_easy  

function unbox_detached (mac, boxed, nonce, key) {
  return sodium.crypto_secretbox_open_easy(concat([mac, boxed]), nonce, key)
}

var max = 1024*4

var NONCE_LEN = 24
var HEADER_LEN = 2+16+16

function isZeros(b) {
  for(var i = 0; i < b.length; i++)
    if(b[i] !== 0) return false
  return true
}

function randomSecret(n) {
  var rand = new Buffer(n)
  sodium.randombytes(rand)
  return rand
}

function copy (a) {
  var b = new Buffer(a.length)
  a.copy(b, 0, 0, a.length)
  return b
}

exports.createBoxStream =
exports.createEncryptStream = function (key, init_nonce) {

  if(key.length === 56) {
    init_nonce = key.slice(32, 56)
    key = key.slice(0, 32)
  }
  else if(!(key.length === 32 && init_nonce.length === 24))
    throw new Error('nonce must be 24 bytes')

  // we need two nonces because increment mutates,
  // and we need the next for the header,
  // and the next next nonce for the packet
  var nonce1 = copy(init_nonce), nonce2 = copy(init_nonce)
  var head = new Buffer(18)

  return through(function (data) {

    if('string' === typeof data)
      data = new Buffer(data, 'utf8')
    else if(!isBuffer(data))
      return this.emit('error', new Error('must be buffer'))

    if(data.length === 0) return

    var input = split(data, max)

    for(var i = 0; i < input.length; i++) {
      head.writeUInt16BE(input[i].length, 0)
      var boxed = box(input[i], increment(nonce2), key)
      //write the mac into the header.
      boxed.copy(head, 2, 0, 16)

      this.queue(box(head, nonce1, key))
      this.queue(boxed.slice(16, 16 + input[i].length))

      increment(increment(nonce1)); increment(nonce2)
    }
  }, function (err) {
    if(err) return this.queue(null)

    //handle special-case of empty session
    //final header is same length as header except all zeros (inside box)
    var final = new Buffer(2+16); final.fill(0)
    this.queue(box(final, nonce1, key))
    this.queue(null)
  })

}
exports.createUnboxStream =
exports.createDecryptStream = function (key, nonce) {


  if(key.length == 56) {
    nonce = key.slice(32, 56)
    key = key.slice(0, 32)
  }
  else if(!(key.length === 32 && nonce.length === 24))
    throw new Error('nonce must be 24 bytes')
  nonce = copy(nonce)

  var reader = Reader(), first = true,  ended
  var first = true

  return function (read) {
    reader(read)
    return function (end, cb) {
      if(end) return reader.abort(end, cb)
      //use abort when the input was invalid,
      //but the source hasn't actually ended yet.
      function abort(err) {
        reader.abort(ended = err || true, cb)
      }

      if(ended) return cb(ended)
      reader.read(HEADER_LEN, function (err, cipherheader) {
        if(err === true) return cb(ended = new Error('unexpected hangup'))
        if(err) return cb(ended = err)

        var header = unbox(cipherheader, nonce, key)

        if(!header)
          return abort(new Error('invalid header'))

        //valid end of stream
        if(isZeros(header))
          return cb(ended = true)

        var length = header.readUInt16BE(0)
        var mac = header.slice(2, 34)

        reader.read(length, function (err, cipherpacket) {
          if(err) return cb(ended = err)
          //recreate a valid packet
          //TODO: PR to sodium bindings for detached box/open
          var plainpacket = unbox_detached(mac, cipherpacket, increment(nonce), key)
          if(!plainpacket)
            return abort(new Error('invalid packet'))

          increment(nonce)
          cb(null, plainpacket)
        })
      })
    }
  }
}

},
"Hi1NqZ474PNLZlkr7jSNN+wTYA4W9nMY+B6BcVDdhaM=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Ref = require('ssb-ref');
const debug = require('debug')('ssb:http-auth:client');
const constants_1 = require("./constants");
const solution_1 = require("./solution");
function hasConnInstalled(ssb) {
    var _a;
    return !!((_a = ssb.conn) === null || _a === void 0 ? void 0 : _a.connect);
}
module.exports = {
    name: 'httpAuthClient',
    version: '1.0.0',
    manifest: {
        produceSignInWebUrl: 'async',
        consumeSignInSsbUri: 'async',
        invalidateAllSessions: 'async',
    },
    permissions: {
        anonymous: {},
    },
    init(ssb, config) {
        if (!hasConnInstalled(ssb)) {
            throw new Error('ssb-http-auth-client requires the ssb-conn plugin');
        }
        return {
            produceSignInWebUrl(sid, cb) {
                if (!Ref.isFeed(sid)) {
                    cb(new Error('Invalid SSB ID ' + sid));
                    return;
                }
                const peer = ssb.conn
                    .query()
                    .peersConnected()
                    .find(([, data]) => data.key === sid);
                if (!peer) {
                    cb(new Error('Cannot sign-in to disconnected server ' + sid));
                    return;
                }
                const [addr] = peer;
                const parsed = Ref.toAddress(addr);
                if (!parsed) {
                    cb(new Error(`Cannot sign-in to server with bad address ${addr}`));
                    return;
                }
                const { host } = parsed;
                const cid = ssb.id;
                const cc = ssb.httpAuthClientTokens.create();
                const _cid = encodeURIComponent(cid);
                const _cc = encodeURIComponent(cc);
                const url = `https://${host}/login?ssb-http-auth=1&cid=${_cid}&cc=${_cc}`;
                cb(null, url);
            },
            consumeSignInSsbUri(uri, cb) {
                let u;
                try {
                    u = new URL(uri);
                }
                catch (err) {
                    cb(new Error('Invalid SSB URI provided: ' + uri));
                    return;
                }
                if (u.protocol !== 'ssb:') {
                    cb(new Error('Invalid SSB URI provided: ' + uri));
                    return;
                }
                if (u.pathname !== 'experimental' && u.host !== 'experimental') {
                    cb(new Error('Invalid experimental SSB URI provided: ' + uri));
                    return;
                }
                if (u.searchParams.get('action') !== 'start-http-auth') {
                    cb(new Error('SSB URI is unrelated to httpAuth: ' + uri));
                    return;
                }
                const sid = u.searchParams.get('sid');
                if (!Ref.isFeed(sid)) {
                    cb(new Error('Invalid "sid" query in SSB URI: ' + uri));
                    return;
                }
                const sc = u.searchParams.get('sc');
                if (!sc) {
                    cb(new Error('Invalid "sc" query in SSB URI: ' + uri));
                    return;
                }
                if (sc.length < constants_1.NONCE_LENGTH_BASE64) {
                    cb(new Error('Server nonce "sc" is less than 256 bits: ' + sc));
                    return;
                }
                let serverMSAddr = u.searchParams.get('multiserverAddress');
                if (!serverMSAddr || !Ref.toAddress(serverMSAddr)) {
                    const peer = ssb.conn
                        .query()
                        .peersAll()
                        .find(([, data]) => data.key === sid);
                    if (!peer) {
                        cb(new Error('Cannot sign-in to unknown server ' + sid));
                        return;
                    }
                    [serverMSAddr] = peer;
                }
                const cc = ssb.httpAuthClientTokens.create();
                const cid = ssb.id;
                const sol = solution_1.solve(config.keys, sid, cid, sc, cc);
                debug(`sendSolution where sid=${sid}, cid=${cid}, sc=${sc}, cc=${cc}`);
                ssb.conn.connect(serverMSAddr, (err, rpc) => {
                    if (err) {
                        cb(new Error(`Cannot sign-in to server ${sid} because: ${err}`));
                        return;
                    }
                    if (!rpc) {
                        cb(new Error(`Cannot sign-in to server ${sid}, it seems offline`));
                        return;
                    }
                    rpc.httpAuth.sendSolution(sc, cc, sol, (err2, answer) => {
                        if (err2) {
                            cb(new Error(`httpAuth.sendSolution at ${sid} failed: ${err2}`));
                            return;
                        }
                        debug(`Server ${sid} answered our httpAuth.sendSolution with ${answer}`);
                        cb(null, answer);
                    });
                });
            },
            invalidateAllSessions(sid, cb) {
                if (!Ref.isFeed(sid)) {
                    cb(new Error('Invalid SSB ID ' + sid));
                    return;
                }
                const peer = ssb.conn
                    .query()
                    .peersConnected()
                    .find(([, data]) => data.key === sid);
                if (!peer) {
                    cb(new Error('Cannot sign-out from disconnected server ' + sid));
                    return;
                }
                const [addr] = peer;
                ssb.conn.connect(addr, (err, rpc) => {
                    if (err) {
                        cb(new Error(`Cannot sign-out from server ${sid} because: ${err}`));
                        return;
                    }
                    if (!rpc) {
                        cb(new Error(`Cannot sign-out from ${sid}, it seems offline`));
                        return;
                    }
                    rpc.httpAuth.invalidateAllSolutions((err2, answer) => {
                        if (err2) {
                            cb(new Error(`sign-out at ${sid} failed: ${err2}`));
                            return;
                        }
                        debug(`Server ${sid} answered our ` +
                            `httpAuth.invalidateAllSolutions with ${answer}`);
                        cb(null, answer);
                    });
                });
            },
        };
    },
};

},
"Hk6T3FVpUObSr+tQzzuU3LOQ2HC4cqsuS+qI19rk5aI=":
function (require, module, exports, __dirname, __filename) {
var all = module.exports.all = [
  {
    errno: -2,
    code: 'ENOENT',
    description: 'no such file or directory'
  },
  {
    errno: -1,
    code: 'UNKNOWN',
    description: 'unknown error'
  },
  {
    errno: 0,
    code: 'OK',
    description: 'success'
  },
  {
    errno: 1,
    code: 'EOF',
    description: 'end of file'
  },
  {
    errno: 2,
    code: 'EADDRINFO',
    description: 'getaddrinfo error'
  },
  {
    errno: 3,
    code: 'EACCES',
    description: 'permission denied'
  },
  {
    errno: 4,
    code: 'EAGAIN',
    description: 'resource temporarily unavailable'
  },
  {
    errno: 5,
    code: 'EADDRINUSE',
    description: 'address already in use'
  },
  {
    errno: 6,
    code: 'EADDRNOTAVAIL',
    description: 'address not available'
  },
  {
    errno: 7,
    code: 'EAFNOSUPPORT',
    description: 'address family not supported'
  },
  {
    errno: 8,
    code: 'EALREADY',
    description: 'connection already in progress'
  },
  {
    errno: 9,
    code: 'EBADF',
    description: 'bad file descriptor'
  },
  {
    errno: 10,
    code: 'EBUSY',
    description: 'resource busy or locked'
  },
  {
    errno: 11,
    code: 'ECONNABORTED',
    description: 'software caused connection abort'
  },
  {
    errno: 12,
    code: 'ECONNREFUSED',
    description: 'connection refused'
  },
  {
    errno: 13,
    code: 'ECONNRESET',
    description: 'connection reset by peer'
  },
  {
    errno: 14,
    code: 'EDESTADDRREQ',
    description: 'destination address required'
  },
  {
    errno: 15,
    code: 'EFAULT',
    description: 'bad address in system call argument'
  },
  {
    errno: 16,
    code: 'EHOSTUNREACH',
    description: 'host is unreachable'
  },
  {
    errno: 17,
    code: 'EINTR',
    description: 'interrupted system call'
  },
  {
    errno: 18,
    code: 'EINVAL',
    description: 'invalid argument'
  },
  {
    errno: 19,
    code: 'EISCONN',
    description: 'socket is already connected'
  },
  {
    errno: 20,
    code: 'EMFILE',
    description: 'too many open files'
  },
  {
    errno: 21,
    code: 'EMSGSIZE',
    description: 'message too long'
  },
  {
    errno: 22,
    code: 'ENETDOWN',
    description: 'network is down'
  },
  {
    errno: 23,
    code: 'ENETUNREACH',
    description: 'network is unreachable'
  },
  {
    errno: 24,
    code: 'ENFILE',
    description: 'file table overflow'
  },
  {
    errno: 25,
    code: 'ENOBUFS',
    description: 'no buffer space available'
  },
  {
    errno: 26,
    code: 'ENOMEM',
    description: 'not enough memory'
  },
  {
    errno: 27,
    code: 'ENOTDIR',
    description: 'not a directory'
  },
  {
    errno: 28,
    code: 'EISDIR',
    description: 'illegal operation on a directory'
  },
  {
    errno: 29,
    code: 'ENONET',
    description: 'machine is not on the network'
  },
  {
    errno: 31,
    code: 'ENOTCONN',
    description: 'socket is not connected'
  },
  {
    errno: 32,
    code: 'ENOTSOCK',
    description: 'socket operation on non-socket'
  },
  {
    errno: 33,
    code: 'ENOTSUP',
    description: 'operation not supported on socket'
  },
  {
    errno: 34,
    code: 'ENOENT',
    description: 'no such file or directory'
  },
  {
    errno: 35,
    code: 'ENOSYS',
    description: 'function not implemented'
  },
  {
    errno: 36,
    code: 'EPIPE',
    description: 'broken pipe'
  },
  {
    errno: 37,
    code: 'EPROTO',
    description: 'protocol error'
  },
  {
    errno: 38,
    code: 'EPROTONOSUPPORT',
    description: 'protocol not supported'
  },
  {
    errno: 39,
    code: 'EPROTOTYPE',
    description: 'protocol wrong type for socket'
  },
  {
    errno: 40,
    code: 'ETIMEDOUT',
    description: 'connection timed out'
  },
  {
    errno: 41,
    code: 'ECHARSET',
    description: 'invalid Unicode character'
  },
  {
    errno: 42,
    code: 'EAIFAMNOSUPPORT',
    description: 'address family for hostname not supported'
  },
  {
    errno: 44,
    code: 'EAISERVICE',
    description: 'servname not supported for ai_socktype'
  },
  {
    errno: 45,
    code: 'EAISOCKTYPE',
    description: 'ai_socktype not supported'
  },
  {
    errno: 46,
    code: 'ESHUTDOWN',
    description: 'cannot send after transport endpoint shutdown'
  },
  {
    errno: 47,
    code: 'EEXIST',
    description: 'file already exists'
  },
  {
    errno: 48,
    code: 'ESRCH',
    description: 'no such process'
  },
  {
    errno: 49,
    code: 'ENAMETOOLONG',
    description: 'name too long'
  },
  {
    errno: 50,
    code: 'EPERM',
    description: 'operation not permitted'
  },
  {
    errno: 51,
    code: 'ELOOP',
    description: 'too many symbolic links encountered'
  },
  {
    errno: 52,
    code: 'EXDEV',
    description: 'cross-device link not permitted'
  },
  {
    errno: 53,
    code: 'ENOTEMPTY',
    description: 'directory not empty'
  },
  {
    errno: 54,
    code: 'ENOSPC',
    description: 'no space left on device'
  },
  {
    errno: 55,
    code: 'EIO',
    description: 'i/o error'
  },
  {
    errno: 56,
    code: 'EROFS',
    description: 'read-only file system'
  },
  {
    errno: 57,
    code: 'ENODEV',
    description: 'no such device'
  },
  {
    errno: 58,
    code: 'ESPIPE',
    description: 'invalid seek'
  },
  {
    errno: 59,
    code: 'ECANCELED',
    description: 'operation canceled'
  }
]

module.exports.errno = {}
module.exports.code = {}

all.forEach(function (error) {
  module.exports.errno[error.errno] = error
  module.exports.code[error.code] = error
})

module.exports.custom = require('./custom')(module.exports)
module.exports.create = module.exports.custom.createError

},
"HlRhYmikJ/Hw88F2T7kYdCAM6NW+vFJDcRQf/jkGOXY=":
function (require, module, exports, __dirname, __filename) {
const BENIGN_STREAM_END = {
  // stream closed okay, ssb-js variant
  'unexpected end of parent stream': true,

  // stream closed okay, go-ssb variant
  'muxrpc: session terminated': true,
};

const STREAM_ERRORS = {
  ...BENIGN_STREAM_END,
  'unexpected hangup': true, // stream closed probably okay
  'read EHOSTUNREACH': true,
  'read ECONNRESET': true,
  'read ENETDOWN': true,
  'read ETIMEDOUT': true,
  'write ECONNRESET': true,
  'write EPIPE': true,
  'stream is closed': true, // rpc method called after stream ended
  'parent stream is closing': true,
};

function detectSsbNetworkErrorSeverity(err) {
  if (!err) return null;
  if (err === true) return null;
  const msg = err.message;
  if (msg in STREAM_ERRORS) {
    if (msg in BENIGN_STREAM_END) {
      if (err instanceof Error) {
        return 0;
      } else {
        return 1;
      }
    } else {
      return 2;
    }
  } else {
    return 3;
  }
}

module.exports = detectSsbNetworkErrorSeverity;

},
"HmhoBUNx528KX6oeQOYdonZP2HwDl8zLntuBhy/Jl9M=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var sodium = require("chloride");
var pb = require("private-box");
var u = require("./util");
var isBuffer = Buffer.isBuffer;

//UTILS

function clone(obj) {
  var _obj = {};
  for (var k in obj) {
    if (Object.hasOwnProperty.call(obj, k)) _obj[k] = obj[k];
  }
  return _obj;
}

var hmac = sodium.crypto_auth;

exports.hash = u.hash;

exports.getTag = u.getTag;

function isObject(o) {
  return "object" === typeof o;
}

function isString(s) {
  return "string" === typeof s;
}

var curves = {};
curves.ed25519 = require("./sodium");

function getCurve(keys) {
  var curve = keys.curve;

  if (!keys.curve && isString(keys.public)) keys = keys.public;

  if (!curve && isString(keys)) curve = u.getTag(keys);

  if (!curves[curve]) {
    throw new Error(
      "unkown curve:" + curve + " expected: " + Object.keys(curves)
    );
  }

  return curve;
}

//this should return a key pair:
// {curve: curve, public: Buffer, private: Buffer}

exports.generate = function (curve, seed) {
  curve = curve || "ed25519";

  if (!curves[curve]) throw new Error("unknown curve:" + curve);

  return u.keysToJSON(curves[curve].generate(seed), curve);
};

//import functions for loading/saving keys from storage
var storage = require("./storage")(exports.generate);
for (var key in storage) exports[key] = storage[key];

exports.loadOrCreate = function (filename, cb) {
  exports.load(filename, function (err, keys) {
    if (!err) return cb(null, keys);
    exports.create(filename, cb);
  });
};

exports.loadOrCreateSync = function (filename) {
  try {
    return exports.loadSync(filename);
  } catch (err) {
    return exports.createSync(filename);
  }
};

//takes a public key and a hash and returns a signature.
//(a signature must be a node buffer)

function sign(keys, hmac_key, msg) {
  if (!msg) {
    msg = hmac_key;
    hmac_key = null;
  }

  if (isString(msg)) msg = Buffer.from(msg);
  if (!isBuffer(msg)) throw new Error("msg should be buffer");
  if (hmac_key) msg = hmac(msg, u.toBuffer(hmac_key));
  var curve = getCurve(keys);

  return (
    curves[curve]
      .sign(u.toBuffer(keys.private || keys), msg)
      .toString("base64") +
    ".sig." +
    curve
  );
}
exports.sign = sign;

//takes a public key, signature, optional hmac_key and a hash
//and returns true if the signature was valid.
function verify(keys, sig, hmac_key, msg) {
  if (isObject(sig))
    throw new Error(
      "signature should be base64 string, did you mean verifyObj(public, signed_obj)"
    );
  if (!msg) {
    msg = hmac_key;
    hmac_key = null;
  }

  let bufferMsg = isBuffer(msg) ? msg : Buffer.from(msg);
  if (hmac_key) bufferMsg = hmac(bufferMsg, u.toBuffer(hmac_key));
  return curves[getCurve(keys)].verify(
    u.toBuffer(keys.public || keys),
    u.toBuffer(sig),
    bufferMsg
  );
}
exports.verify = verify;

// OTHER CRYTPO FUNCTIONS

exports.signObj = function (keys, hmac_key, obj) {
  if (!obj) (obj = hmac_key), (hmac_key = null);
  var _obj = clone(obj);
  var b = Buffer.from(JSON.stringify(_obj, null, 2));
  if (hmac_key) b = hmac(b, u.toBuffer(hmac_key));
  _obj.signature = sign(keys, b);
  return _obj;
};

exports.verifyObj = function (keys, hmac_key, obj) {
  if (!obj) (obj = hmac_key), (hmac_key = null);
  obj = clone(obj);
  var sig = obj.signature;
  delete obj.signature;
  var b = Buffer.from(JSON.stringify(obj, null, 2));
  if (hmac_key) b = hmac(b, u.toBuffer(hmac_key));
  return verify(keys, sig, b);
};

exports.box = function (msg, recipients) {
  msg = Buffer.from(JSON.stringify(msg));

  recipients = recipients.map(function (keys) {
    return sodium.crypto_sign_ed25519_pk_to_curve25519(
      u.toBuffer(keys.public || keys)
    );
  });

  return pb.multibox(msg, recipients).toString("base64") + ".box";
};

function ssbSecretKeyToPrivateBoxSecret(keys) {
  return sodium.crypto_sign_ed25519_sk_to_curve25519(
    u.toBuffer(keys.private || keys)
  );
}

exports.ssbSecretKeyToPrivateBoxSecret = ssbSecretKeyToPrivateBoxSecret;

exports.unboxKey = function (boxed, keys) {
  boxed = u.toBuffer(boxed);
  var sk = ssbSecretKeyToPrivateBoxSecret(keys);
  return pb.multibox_open_key(boxed, sk);
};

exports.unboxBody = function (boxed, key) {
  if (!key) return null;
  boxed = u.toBuffer(boxed);
  key = u.toBuffer(key);
  var msg = pb.multibox_open_body(boxed, key);
  try {
    return JSON.parse("" + msg);
  } catch (_) {
    return;
  }
};

exports.unbox = function (boxed, keys) {
  boxed = u.toBuffer(boxed);

  var sk =
    keys._exchangeKey ||
    sodium.crypto_sign_ed25519_sk_to_curve25519(
      u.toBuffer(keys.private || keys)
    );
  if (keys.private) keys._exchangeKey = sk; //if keys is an object, cache the curve key.
  try {
    var msg = pb.multibox_open(boxed, sk);
    return JSON.parse("" + msg);
  } catch (_) {
    return;
  }
};

exports.secretBox = function secretBox(data, key) {
  if (!data) return;
  var ptxt = Buffer.from(JSON.stringify(data));
  return sodium.crypto_secretbox_easy(ptxt, key.slice(0, 24), key);
};

exports.secretUnbox = function secretUnbox(ctxt, key) {
  var ptxt = sodium.crypto_secretbox_open_easy(ctxt, key.slice(0, 24), key);
  if (!ptxt) return;
  return JSON.parse(ptxt.toString());
};

},
"HnkDkn3zOq2zZZ7M5VJmychR2mXObItyOmCjBcHFQiw=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('stream');

},
"Hxyl99f9NK77cObdWj3oIbcx3nPOPiXE1FO+lkvBkfg=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2020-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const fs = require("fs");
const path = require("path");
const mkdirp = require('mkdirp');
const rimraf = require('rimraf');
const pull = require('pull-stream');
const pullAsync = require('pull-async');
const cat = require('pull-cat');
const THUMBS_UP_UNICODE = '\ud83d\udc4d';
const DIG_UNICODE = '\u270c\ufe0f';
const HEART_UNICODE = '\u2764\ufe0f';
function voteExpressionToReaction(expression) {
    const lowCase = expression.toLowerCase();
    if (lowCase === 'like')
        return THUMBS_UP_UNICODE;
    if (lowCase === 'yup')
        return THUMBS_UP_UNICODE;
    if (lowCase === 'heart')
        return HEART_UNICODE;
    if (lowCase === 'dig')
        return DIG_UNICODE;
    if (expression.codePointAt(0) === 0x270c)
        return DIG_UNICODE;
    if (expression)
        return expression;
    return THUMBS_UP_UNICODE;
}
module.exports = {
    name: 'dbUtils',
    version: '1.0.0',
    manifest: {
        rawLogReversed: 'source',
        mentionsMe: 'source',
        postsCount: 'async',
        preferredReactions: 'source',
        selfPublicRoots: 'source',
        selfPublicReplies: 'source',
        selfPrivateRootIdsLive: 'source',
        exitReadOnlyMode: 'async',
    },
    permissions: {
        master: {
            allow: [
                'rawLogReversed',
                'mentionsMe',
                'postsCount',
                'preferredReactions',
                'selfPublicRoots',
                'selfPublicReplies',
                'selfPrivateRootIdsLive',
                'exitReadOnlyMode',
            ],
        },
    },
    init: function init(ssb) {
        const { where, or, and, not, type, live: liveOperator, author, contact, votesFor, fullMentions: mentions, isRoot, isPublic, isPrivate, descending, batch, count, toPullStream, toCallback, } = ssb.db.operators;
        const BATCH_SIZE = 75;
        const reactionsCount = {
            _map: new Map(),
            update(msg) {
                var _a;
                const { expression, value } = msg.value.content.vote;
                if (value <= 0 || !expression)
                    return;
                const reaction = voteExpressionToReaction(expression);
                const previous = (_a = this._map.get(reaction)) !== null && _a !== void 0 ? _a : 0;
                this._map.set(reaction, previous + 1);
            },
            toArray() {
                return [...this._map.entries()]
                    .sort((a, b) => b[1] - a[1]) // sort by descending count
                    .map((x) => x[0]); // pick the emoji string
            },
        };
        // Wait until migration progress is somewhere in the middle
        pull(ssb.syncing.migrating(), pull.filter((x) => x > 0.4 && x < 1), pull.take(1), pull.drain(() => {
            // Query some indexes to eagerly build them during migration
            // (1) non-dedicated author index needed for all profile screens
            pull(ssb.db.query(where(author(ssb.id, { dedicated: false })), toPullStream()), pull.take(1), pull.drain());
            // (2) votes prefix index needed as soon as threads load
            pull(ssb.db.query(where(votesFor('whatever')), toPullStream()), pull.take(1), pull.drain());
        }));
        return {
            rawLogReversed() {
                return ssb.db.query(descending(), batch(BATCH_SIZE), toPullStream());
            },
            mentionsMe(opts) {
                return pull(ssb.db.query(where(and(isPublic(), or(and(type('post'), mentions(ssb.id)), contact(ssb.id)))), descending(), opts.live ? liveOperator({ old: opts.old }) : null, batch(BATCH_SIZE), toPullStream()), pull.filter((msg) => {
                    // Allow all posts
                    if (msg.value.content.type === 'post') {
                        return true;
                    }
                    // Only allow "followed" msgs
                    if (msg.value.content.type === 'contact') {
                        const content = msg.value.content;
                        const blocking = content.flagged || content.blocking;
                        const following = content.following;
                        return blocking === undefined && following === true;
                    }
                    // Disallow unexpected cases
                    return false;
                }), pull.map((msg) => (opts.live ? msg.key : msg)));
            },
            postsCount(cb) {
                ssb.db.query(where(and(isPublic(), type('post'))), count(), toCallback(cb));
            },
            preferredReactions() {
                return cat([
                    // First deliver latest preferred reactions
                    pullAsync((cb) => {
                        ssb.db.query(where(and(type('vote'), author(ssb.id, { dedicated: true }))), toCallback((err, msgs) => {
                            if (err)
                                return cb(err);
                            for (const msg of msgs)
                                reactionsCount.update(msg);
                            cb(null, reactionsCount.toArray());
                        }));
                    }),
                    // Then update preferred reactions when the user creates a vote
                    pull(ssb.db.query(where(and(type('vote'), author(ssb.id, { dedicated: true }))), liveOperator({ old: false }), toPullStream()), pull.map((msg) => {
                        reactionsCount.update(msg);
                        return reactionsCount.toArray();
                    })),
                ]);
            },
            selfPublicRoots(opts) {
                return ssb.db.query(where(and(author(ssb.id, { dedicated: true }), type('post'), isPublic(), isRoot())), opts.live ? liveOperator({ old: opts.old }) : null, toPullStream());
            },
            selfPublicReplies(opts) {
                return ssb.db.query(where(and(author(ssb.id, { dedicated: true }), type('post'), isPublic(), not(isRoot()))), opts.live ? liveOperator({ old: opts.old }) : null, toPullStream());
            },
            selfPrivateRootIdsLive() {
                return pull(ssb.db.query(where(and(author(ssb.id, { dedicated: true }), type('post'), isPrivate(), isRoot())), liveOperator({ old: false }), toPullStream()), pull.map((msg) => msg.key));
            },
            exitReadOnlyMode(cb) {
                if (process.env.MANYVERSE_PLATFORM !== 'desktop') {
                    return cb(new Error('Cannot run exitReadOnlyMode unless we are on desktop.'));
                }
                const SHARED_SSB_DIR = process.env.SHARED_SSB_DIR;
                const MANYVERSE_SSB_DIR = process.env.MANYVERSE_SSB_DIR;
                mkdirp.sync(MANYVERSE_SSB_DIR);
                // Move blobs folder from ~/.ssb to manyverse folder
                fs.rename(path.join(SHARED_SSB_DIR, 'blobs'), path.join(MANYVERSE_SSB_DIR, 'blobs'), (err) => {
                    if (err)
                        return cb(err);
                    // Move ssb-db2 folder from ~/.ssb to manyverse folder
                    fs.rename(path.join(SHARED_SSB_DIR, 'db2'), path.join(MANYVERSE_SSB_DIR, 'db2'), (err) => {
                        if (err)
                            return cb(err);
                        // Close sbot
                        ssb.close(true, () => {
                            // Move all other files
                            const files = [
                                'blobs_push',
                                'conn.json',
                                'conn-attempts.json',
                                'manyverse-settings.json',
                                'issue1223',
                                'issue1328',
                                'issue1486',
                                'issue1628',
                                'secret',
                            ];
                            for (const file of files) {
                                try {
                                    fs.renameSync(path.join(SHARED_SSB_DIR, file), path.join(MANYVERSE_SSB_DIR, file));
                                }
                                catch (err) {
                                    if (err.code !== 'ENOENT')
                                        return cb(err);
                                }
                            }
                            // Delete old shared folder
                            rimraf.sync(SHARED_SSB_DIR);
                            // Restart Electron app
                            delete process.env.SSB_DIR;
                            delete process.env.SSB_DB2_READ_ONLY;
                            const { app } = require('electron');
                            app.relaunch();
                            app.quit();
                            cb();
                        });
                    });
                });
            },
        };
    },
};
//# sourceMappingURL=dbUtils.js.map
},
"I6CkLO94rufcS9BY3wPo/nAqUrbH0vl6LBwlwkfuFAs=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const jsesc = require('jsesc')
const sanitize = require('sanitize-filename')
const TypedFastBitSet = require('typedfastbitset')
const { readFile, writeFile } = require('atomic-file-rw')
const toBuffer = require('typedarray-to-buffer')
const crcCalculate = require('crc/lib/crc32')

const FIELD_SIZE = 4 // bytes

/*
 * ## File format for tarr files
 *
 * Each header field is 4 bytes in size.
 *
 * | offset (bytes) | name    | type     |
 * | 0              | version | UInt32LE |
 * |----------------|---------|----------|
 * | 4              | offset  | UInt32LE |
 * | 8              | count   | UInt32LE |
 * | 12             | crc     | UInt32LE |
 * | 16             | body    | Buffer   |
 */

function calculateCRCAndWriteFile(buf, filename, cb) {
  const crc = crcCalculate(buf)
  buf.writeUInt32LE(crc, 3 * FIELD_SIZE)
  writeFile(filename, buf, cb)
}

function readFileAndCheckCRC(filename, cb) {
  readFile(filename, (err, buf) => {
    if (err) return cb(err)

    const crcFile = buf.readUInt32LE(3 * FIELD_SIZE)
    buf.writeUInt32LE(0, 3 * FIELD_SIZE)

    const crc = crcCalculate(buf)
    if (crcFile !== 0 && crc !== crcFile) return cb('crc check failed')
    cb(null, buf)
  })
}

function saveTypedArrayFile(filename, version, offset, count, tarr, cb) {
  if (!cb)
    cb = (err) => {
      if (err) console.error(err)
    }

  if (typeof version !== 'number') {
    return cb(new Error('cannot save file ' + filename + ' without version'))
  }

  const dataBuffer = toBuffer(tarr)
  // we try to save an extra 10% so we don't have to immediately grow
  // after loading and adding again
  const saveSize = Math.min(count * 1.1, tarr.length)
  const buf = Buffer.alloc(4 * FIELD_SIZE + saveSize * tarr.BYTES_PER_ELEMENT)
  buf.writeUInt32LE(version, 0)
  buf.writeUInt32LE(offset, FIELD_SIZE)
  buf.writeUInt32LE(count, 2 * FIELD_SIZE)
  dataBuffer.copy(buf, 4 * FIELD_SIZE)

  calculateCRCAndWriteFile(buf, filename, cb)
}

function loadTypedArrayFile(filename, Type, cb) {
  readFileAndCheckCRC(filename, (err, buf) => {
    if (err) return cb(err)

    const version = buf.readUInt32LE(0)
    const offset = buf.readUInt32LE(FIELD_SIZE)
    const count = buf.readUInt32LE(2 * FIELD_SIZE)
    const body = buf.slice(4 * FIELD_SIZE)

    cb(null, {
      version,
      offset,
      count,
      tarr: new Type(
        body.buffer,
        body.offset,
        body.byteLength / (Type === Float64Array ? 8 : 4)
      ),
    })
  })
}

function savePrefixMapFile(filename, version, offset, count, map, cb) {
  if (!cb)
    cb = (err) => {
      if (err) console.error(err)
    }

  if (typeof version !== 'number') {
    return cb(new Error('cannot save file ' + filename + ' without version'))
  }

  const jsonMap = JSON.stringify(map)
  const buf = Buffer.alloc(4 * FIELD_SIZE + jsonMap.length)
  buf.writeUInt32LE(version, 0)
  buf.writeUInt32LE(offset, FIELD_SIZE)
  buf.writeUInt32LE(count, 2 * FIELD_SIZE)
  Buffer.from(jsonMap).copy(buf, 4 * FIELD_SIZE)

  calculateCRCAndWriteFile(buf, filename, cb)
}

function loadPrefixMapFile(filename, cb) {
  readFileAndCheckCRC(filename, (err, buf) => {
    if (err) return cb(err)

    const version = buf.readUInt32LE(0)
    const offset = buf.readUInt32LE(FIELD_SIZE)
    const count = buf.readUInt32LE(2 * FIELD_SIZE)
    const body = buf.slice(4 * FIELD_SIZE)
    const map = JSON.parse(body)

    cb(null, {
      version,
      offset,
      count,
      map,
    })
  })
}

function saveBitsetFile(filename, version, offset, bitset, cb) {
  bitset.trim()
  const count = bitset.words.length
  saveTypedArrayFile(filename, version, offset, count, bitset.words, cb)
}

function loadBitsetFile(filename, cb) {
  loadTypedArrayFile(filename, Uint32Array, (err, data) => {
    if (err) return cb(err)

    const { version, offset, count, tarr } = data
    const bitset = new TypedFastBitSet()
    bitset.words = tarr
    cb(null, { version, offset, bitset })
  })
}

function listFilesIDB(dir, cb) {
  const IdbKvStore = require('idb-kv-store')
  const store = new IdbKvStore(dir, { disableBroadcast: true })
  store.keys(cb)
}

function listFilesFS(dir, cb) {
  const fs = require('fs')
  const mkdirp = require('mkdirp')
  mkdirp(dir).then(() => {
    fs.readdir(dir, cb)
  }, cb)
}

function safeFilename(filename) {
  // in general we want to escape wierd characters
  let result = jsesc(filename)
  // sanitize will remove special characters, which means that two
  // indexes might end up with the same name so lets replace those
  // with jsesc escapeEverything values
  result = result.replace(/\./g, 'x2E')
  result = result.replace(/\//g, 'x2F')
  result = result.replace(/\?/g, 'x3F')
  result = result.replace(/\</g, 'x3C')
  result = result.replace(/\>/g, 'x3E')
  result = result.replace(/\:/g, 'x3A')
  result = result.replace(/\*/g, 'x2A')
  result = result.replace(/\|/g, 'x7C')
  // finally sanitize
  return sanitize(result)
}

module.exports = {
  saveTypedArrayFile,
  loadTypedArrayFile,
  savePrefixMapFile,
  loadPrefixMapFile,
  saveBitsetFile,
  loadBitsetFile,
  listFilesIDB,
  listFilesFS,
  safeFilename,
}

},
"IE2TfAMT+iaqzlx89bUg2LLc/4d7G7cx4BjgL5dMB+A=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (opts) {
  return {
    name: 'noauth',
    create: function (_opts) {
      return function (stream, cb) {
        cb(null, {
          remote: opts.keys.publicKey,
          auth: { allow: null, deny: null },
          source: stream.source,
          sink: stream.sink,
          address: 'noauth:' + opts.keys.publicKey.toString('base64')
        })
      }
    },
    parse: function (str) {
      return {}
    },
    stringify: function () {
      return 'noauth'
    }
  }
}

},
"IH0m90wB0IOj5Amv6VG+cxD6xxtdt9sAbjB3YonTijY=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.writeIntBE = exports.readIntBE = exports.writeUIntBE = exports.readUIntBE = exports.writeIntLE = exports.AnsiStringType = exports.StringType = exports.BufferType = exports.IgnoreType = exports.Float80_LE = exports.Float80_BE = exports.Float64_LE = exports.Float64_BE = exports.Float32_LE = exports.Float32_BE = exports.Float16_LE = exports.Float16_BE = exports.INT64_BE = exports.UINT64_BE = exports.INT64_LE = exports.UINT64_LE = exports.INT32_LE = exports.INT32_BE = exports.INT24_BE = exports.INT24_LE = exports.INT16_LE = exports.INT16_BE = exports.INT8 = exports.UINT32_BE = exports.UINT32_LE = exports.UINT24_BE = exports.UINT24_LE = exports.UINT16_BE = exports.UINT16_LE = exports.UINT8 = void 0;
const ieee754 = require("ieee754");
// Primitive types
/**
 * 8-bit unsigned integer
 */
exports.UINT8 = {
    len: 1,
    get(buf, off) {
        return buf.readUInt8(off);
    },
    put(buf, off, v) {
        return buf.writeUInt8(v, off);
    }
};
/**
 * 16-bit unsigned integer, Little Endian byte order
 */
exports.UINT16_LE = {
    len: 2,
    get(buf, off) {
        return buf.readUInt16LE(off);
    },
    put(buf, off, v) {
        return buf.writeUInt16LE(v, off);
    }
};
/**
 * 16-bit unsigned integer, Big Endian byte order
 */
exports.UINT16_BE = {
    len: 2,
    get(buf, off) {
        return buf.readUInt16BE(off);
    },
    put(buf, off, v) {
        return buf.writeUInt16BE(v, off);
    }
};
/**
 * 24-bit unsigned integer, Little Endian byte order
 */
exports.UINT24_LE = {
    len: 3,
    get(buf, off) {
        return buf.readUIntLE(off, 3);
    },
    put(buf, off, v) {
        return buf.writeUIntLE(v, off, 3);
    }
};
/**
 * 24-bit unsigned integer, Big Endian byte order
 */
exports.UINT24_BE = {
    len: 3,
    get(buf, off) {
        return buf.readUIntBE(off, 3);
    },
    put(buf, off, v) {
        return buf.writeUIntBE(v, off, 3);
    }
};
/**
 * 32-bit unsigned integer, Little Endian byte order
 */
exports.UINT32_LE = {
    len: 4,
    get(buf, off) {
        return buf.readUInt32LE(off);
    },
    put(b, o, v) {
        return b.writeUInt32LE(v, o);
    }
};
/**
 * 32-bit unsigned integer, Big Endian byte order
 */
exports.UINT32_BE = {
    len: 4,
    get(buf, off) {
        return buf.readUInt32BE(off);
    },
    put(buf, off, v) {
        return buf.writeUInt32BE(v, off);
    }
};
/**
 * 8-bit signed integer
 */
exports.INT8 = {
    len: 1,
    get(buf, off) {
        return buf.readInt8(off);
    },
    put(buf, off, v) {
        return buf.writeInt8(v, off);
    }
};
/**
 * 16-bit signed integer, Big Endian byte order
 */
exports.INT16_BE = {
    len: 2,
    get(buf, off) {
        return buf.readInt16BE(off);
    },
    put(b, o, v) {
        return b.writeInt16BE(v, o);
    }
};
/**
 * 16-bit signed integer, Little Endian byte order
 */
exports.INT16_LE = {
    len: 2,
    get(buf, off) {
        return buf.readInt16LE(off);
    },
    put(b, o, v) {
        return b.writeInt16LE(v, o);
    }
};
/**
 * 24-bit signed integer, Little Endian byte order
 */
exports.INT24_LE = {
    len: 3,
    get(buf, off) {
        return buf.readIntLE(off, 3);
    },
    put(b, o, v) {
        return b.writeIntLE(v, o, 3);
    }
};
/**
 * 24-bit signed integer, Big Endian byte order
 */
exports.INT24_BE = {
    len: 3,
    get(buf, off) {
        return buf.readIntBE(off, 3);
    },
    put(b, o, v) {
        return b.writeIntBE(v, o, 3);
    }
};
/**
 * 32-bit signed integer, Big Endian byte order
 */
exports.INT32_BE = {
    len: 4,
    get(buf, off) {
        return buf.readInt32BE(off);
    },
    put(b, o, v) {
        return b.writeInt32BE(v, o);
    }
};
/**
 * 32-bit signed integer, Big Endian byte order
 */
exports.INT32_LE = {
    len: 4,
    get(buf, off) {
        return buf.readInt32LE(off);
    },
    put(b, o, v) {
        return b.writeInt32LE(v, o);
    }
};
/**
 * 64-bit unsigned integer, Little Endian byte order
 */
exports.UINT64_LE = {
    len: 8,
    get(buf, off) {
        return readUIntLE(buf, off, this.len);
    },
    put(b, o, v) {
        return writeUIntLE(b, v, o, this.len);
    }
};
/**
 * 64-bit signed integer, Little Endian byte order
 */
exports.INT64_LE = {
    len: 8,
    get(buf, off) {
        return readIntLE(buf, off, this.len);
    },
    put(b, off, v) {
        return writeIntLE(b, v, off, this.len);
    }
};
/**
 * 64-bit unsigned integer, Big Endian byte order
 */
exports.UINT64_BE = {
    len: 8,
    get(b, off) {
        return readUIntBE(b, off, this.len);
    },
    put(b, o, v) {
        return writeUIntBE(b, v, o, this.len);
    }
};
/**
 * 64-bit signed integer, Big Endian byte order
 */
exports.INT64_BE = {
    len: 8,
    get(b, off) {
        return readIntBE(b, off, this.len);
    },
    put(b, off, v) {
        return writeIntBE(b, v, off, this.len);
    }
};
/**
 * IEEE 754 16-bit (half precision) float, big endian
 */
exports.Float16_BE = {
    len: 2,
    get(b, off) {
        return ieee754.read(b, off, false, 10, this.len);
    },
    put(b, off, v) {
        ieee754.write(b, v, off, false, 10, this.len);
        return off + this.len;
    }
};
/**
 * IEEE 754 16-bit (half precision) float, little endian
 */
exports.Float16_LE = {
    len: 2,
    get(b, off) {
        return ieee754.read(b, off, true, 10, this.len);
    },
    put(b, off, v) {
        ieee754.write(b, v, off, true, 10, this.len);
        return off + this.len;
    }
};
/**
 * IEEE 754 32-bit (single precision) float, big endian
 */
exports.Float32_BE = {
    len: 4,
    get(b, off) {
        return b.readFloatBE(off);
    },
    put(b, off, v) {
        return b.writeFloatBE(v, off);
    }
};
/**
 * IEEE 754 32-bit (single precision) float, little endian
 */
exports.Float32_LE = {
    len: 4,
    get(b, off) {
        return b.readFloatLE(off);
    },
    put(b, off, v) {
        return b.writeFloatLE(v, off);
    }
};
/**
 * IEEE 754 64-bit (double precision) float, big endian
 */
exports.Float64_BE = {
    len: 8,
    get(b, off) {
        return b.readDoubleBE(off);
    },
    put(b, off, v) {
        return b.writeDoubleBE(v, off);
    }
};
/**
 * IEEE 754 64-bit (double precision) float, little endian
 */
exports.Float64_LE = {
    len: 8,
    get(b, off) {
        return b.readDoubleLE(off);
    },
    put(b, off, v) {
        return b.writeDoubleLE(v, off);
    }
};
/**
 * IEEE 754 80-bit (extended precision) float, big endian
 */
exports.Float80_BE = {
    len: 10,
    get(b, off) {
        return ieee754.read(b, off, false, 63, this.len);
    },
    put(b, off, v) {
        ieee754.write(b, v, off, false, 63, this.len);
        return off + this.len;
    }
};
/**
 * IEEE 754 80-bit (extended precision) float, little endian
 */
exports.Float80_LE = {
    len: 10,
    get(b, off) {
        return ieee754.read(b, off, true, 63, this.len);
    },
    put(b, off, v) {
        ieee754.write(b, v, off, true, 63, this.len);
        return off + this.len;
    }
};
/**
 * Ignore a given number of bytes
 */
class IgnoreType {
    /**
     * @param len number of bytes to ignore
     */
    constructor(len) {
        this.len = len;
    }
    // ToDo: don't read, but skip data
    get(buf, off) {
    }
}
exports.IgnoreType = IgnoreType;
class BufferType {
    constructor(len) {
        this.len = len;
    }
    get(buf, off) {
        return buf.slice(off, off + this.len);
    }
}
exports.BufferType = BufferType;
/**
 * Consume a fixed number of bytes from the stream and return a string with a specified encoding.
 */
class StringType {
    constructor(len, encoding) {
        this.len = len;
        this.encoding = encoding;
    }
    get(buf, off) {
        return buf.toString(this.encoding, off, off + this.len);
    }
}
exports.StringType = StringType;
/**
 * ANSI Latin 1 String
 * Using windows-1252 / ISO 8859-1 decoding
 */
class AnsiStringType {
    constructor(len) {
        this.len = len;
    }
    static decode(buffer, off, until) {
        let str = '';
        for (let i = off; i < until; ++i) {
            str += AnsiStringType.codePointToString(AnsiStringType.singleByteDecoder(buffer[i]));
        }
        return str;
    }
    static inRange(a, min, max) {
        return min <= a && a <= max;
    }
    static codePointToString(cp) {
        if (cp <= 0xFFFF) {
            return String.fromCharCode(cp);
        }
        else {
            cp -= 0x10000;
            return String.fromCharCode((cp >> 10) + 0xD800, (cp & 0x3FF) + 0xDC00);
        }
    }
    static singleByteDecoder(bite) {
        if (AnsiStringType.inRange(bite, 0x00, 0x7F)) {
            return bite;
        }
        const codePoint = AnsiStringType.windows1252[bite - 0x80];
        if (codePoint === null) {
            throw Error('invaliding encoding');
        }
        return codePoint;
    }
    get(buf, off = 0) {
        return AnsiStringType.decode(buf, off, off + this.len);
    }
}
exports.AnsiStringType = AnsiStringType;
AnsiStringType.windows1252 = [8364, 129, 8218, 402, 8222, 8230, 8224, 8225, 710, 8240, 352,
    8249, 338, 141, 381, 143, 144, 8216, 8217, 8220, 8221, 8226, 8211, 8212, 732,
    8482, 353, 8250, 339, 157, 382, 376, 160, 161, 162, 163, 164, 165, 166, 167, 168,
    169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,
    185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,
    201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,
    217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,
    233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,
    248, 249, 250, 251, 252, 253, 254, 255];
/**
 * Best effort approach to read up to 64 bit unsigned integer, little endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function readUIntLE(buf, offset, byteLength) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    let val = buf[offset];
    let mul = 1;
    let i = 0;
    while (++i < byteLength && (mul *= 0x100)) {
        val += buf[offset + i] * mul;
    }
    return val;
}
/**
 * Best effort approach to write up to 64 bit unsigned integer, little endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function writeUIntLE(buf, value, offset, byteLength) {
    value = +value;
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    let mul = 1;
    let i = 0;
    buf[offset] = value & 0xFF;
    while (++i < byteLength && (mul *= 0x100)) {
        buf[offset + i] = (value / mul) & 0xFF;
    }
    return offset + byteLength;
}
/**
 * Best effort approach to read 64 but signed integer, little endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function readIntLE(buf, offset, byteLength) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    let val = buf[offset];
    let mul = 1;
    let i = 0;
    while (++i < byteLength && (mul *= 0x100)) {
        val += buf[offset + i] * mul;
    }
    mul *= 0x80;
    if (val >= mul)
        val -= Math.pow(2, 8 * byteLength);
    return val;
}
/**
 * Best effort approach to write 64 but signed integer, little endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function writeIntLE(buf, value, offset, byteLength) {
    value = +value;
    offset = offset >>> 0;
    let i = 0;
    let mul = 1;
    let sub = 0;
    buf[offset] = value & 0xFF;
    while (++i < byteLength && (mul *= 0x100)) {
        if (value < 0 && sub === 0 && buf[offset + i - 1] !== 0) {
            sub = 1;
        }
        buf[offset + i] = ((value / mul) >> 0) - sub & 0xFF;
    }
    return offset + byteLength;
}
exports.writeIntLE = writeIntLE;
/**
 * Best effort approach to read up to 64 bit unsigned integer, big endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function readUIntBE(buf, offset, byteLength) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    let val = buf[offset + --byteLength];
    let mul = 1;
    while (byteLength > 0 && (mul *= 0x100)) {
        val += buf[offset + --byteLength] * mul;
    }
    return val;
}
exports.readUIntBE = readUIntBE;
/**
 * Best effort approach to write up to 64 bit unsigned integer, big endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function writeUIntBE(buf, value, offset, byteLength) {
    value = +value;
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    let i = byteLength - 1;
    let mul = 1;
    buf[offset + i] = value & 0xFF;
    while (--i >= 0 && (mul *= 0x100)) {
        buf[offset + i] = (value / mul) & 0xFF;
    }
    return offset + byteLength;
}
exports.writeUIntBE = writeUIntBE;
/**
 * Best effort approach to read 64 but signed integer, big endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function readIntBE(buf, offset, byteLength) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    let i = byteLength;
    let mul = 1;
    let val = buf[offset + --i];
    while (i > 0 && (mul *= 0x100)) {
        val += buf[offset + --i] * mul;
    }
    mul *= 0x80;
    if (val >= mul)
        val -= Math.pow(2, 8 * byteLength);
    return val;
}
exports.readIntBE = readIntBE;
/**
 * Best effort approach to write 64 but signed integer, big endian.
 * Note that JavasScript is limited to 2^53 - 1 bit.
 */
function writeIntBE(buf, value, offset, byteLength) {
    value = +value;
    offset = offset >>> 0;
    let i = byteLength - 1;
    let mul = 1;
    let sub = 0;
    buf[offset + i] = value & 0xFF;
    while (--i >= 0 && (mul *= 0x100)) {
        if (value < 0 && sub === 0 && buf[offset + i + 1] !== 0) {
            sub = 1;
        }
        buf[offset + i] = ((value / mul) >> 0) - sub & 0xFF;
    }
    return offset + byteLength;
}
exports.writeIntBE = writeIntBE;

},
"ITwob2+2DgxQU4os1EG+48uwEG3lL5vBuXCReCxT6ws=":
function (require, module, exports, __dirname, __filename) {
/**
 * FastIntegerCompression.js : a fast integer compression library in JavaScript.
 * (c) the authors
 * Licensed under the Apache License, Version 2.0.
 *
 *FastIntegerCompression
 * Simple usage :
 *  // var FastIntegerCompression = require("fastintcompression");// if you use node
 *  var array = [10,100000,65999,10,10,0,1,1,2000];
 *  var buf = FastIntegerCompression.compress(array);
 *  var back = FastIntegerCompression.uncompress(buf); // gets back [10,100000,65999,10,10,0,1,1,2000]
 *
 *
 * You can install the library under node with the command line
 *   npm install fastintcompression
 */
'use strict';


// you can provide an iterable
function FastIntegerCompression() {
}

// private function
function bytelog(val) {
  if (val < (1 << 7)) {
    return 1;
  } else if (val < (1 << 14)) {
    return 2;
  } else if (val < (1 << 21)) {
    return 3;
  } else if (val < (1 << 28)) {
    return 4;
  }
  return 5;
}

// private function
function zigzag_encode(val) {
  return (val + val) ^ (val >> 31);;
}

// private function
function zigzag_decode(val) {
  return  (val >> 1) ^ (- (val & 1));
}


// compute how many bytes an array of integers would use once compressed
// input is expected to be an array of non-negative integers
FastIntegerCompression.computeCompressedSizeInBytes = function(input) {
  var c = input.length;
  var answer = 0;
  for(var i = 0; i < c; i++) {
    answer += bytelog(input[i]);
  }
  return answer;
};


// compute how many bytes an array of integers would use once compressed
// input is expected to be an array of integers, some of them can be negative
FastIntegerCompression.computeCompressedSizeInBytesSigned = function(input) {
  var c = input.length;
  var answer = 0;
  for(var i = 0; i < c; i++) {
    answer += bytelog(zigzag_encode(input[i]));
  }
  return answer;
};

// Compress an array of integers, return a compressed buffer (as an ArrayBuffer).
// It is expected that the integers are non-negative: the caller is responsible
// for making this check. Floating-point numbers are not supported.
FastIntegerCompression.compress = function(input) {
  var c = input.length;
  var buf = new ArrayBuffer(FastIntegerCompression.computeCompressedSizeInBytes(input));
  var view   = new Int8Array(buf);
  var pos = 0;
  for(var i = 0; i < c; i++) {
    var val = input[i];
    if (val < (1 << 7)) {
      view[pos++] = val ;
    } else if (val < (1 << 14)) {
      view[pos++] = (val & 0x7F) | 0x80;
      view[pos++] = val >>> 7;
    } else if (val < (1 << 21)) {
      view[pos++] = (val & 0x7F) | 0x80;
      view[pos++] = ( (val >>> 7) & 0x7F ) | 0x80;
      view[pos++] = val >>> 14;
    } else if (val < (1 << 28)) {
      view[pos++] = (val & 0x7F ) | 0x80 ;
      view[pos++] = ( (val >>> 7) & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 14) & 0x7F ) | 0x80;
      view[pos++] = val >>> 21;
    } else {
      view[pos++] = ( val & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 7) & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 14) & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 21) & 0x7F ) | 0x80;
      view[pos++] = val >>> 28;
    }
  }
  return buf;
};

// from a compressed array of integers stored ArrayBuffer, compute the number of compressed integers by scanning the input
FastIntegerCompression.computeHowManyIntegers = function(input) {
  var view   = new Int8Array(input);
  var c = view.length;
  var count = 0;
  for(var i = 0; i < c; i++) {
    count += (input[i]>>>7);
  }
  return c - count;
}
// uncompress an array of integer from an ArrayBuffer, return the array
// it is assumed that they were compressed using the compress function, the caller
// is responsible for ensuring that it is the case.
FastIntegerCompression.uncompress = function(input) {
  var array = []
  var inbyte = new Int8Array(input);
  var end = inbyte.length;
  var pos = 0;
  while (end > pos) {
        var c = inbyte[pos++];
        var v = c & 0x7F;
        if (c >= 0) {
          array.push(v)
          continue;
        }
        c = inbyte[pos++];
        v |= (c & 0x7F) << 7;
        if (c >= 0) {
          array.push(v)
          continue;
        }
        c = inbyte[pos++];
        v |= (c & 0x7F) << 14;
        if (c >= 0) {
          array.push(v)
          continue;
        }
        c = inbyte[pos++];
        v |= (c & 0x7F) << 21;
        if (c >= 0) {
          array.push(v)
          continue;
        }
        c = inbyte[pos++];
        v |= c << 28;
        v >>>= 0; // make positive
        array.push(v)
  }
  return array;
};


// Compress an array of integers, return a compressed buffer (as an ArrayBuffer).
// The integers can be signed (negative), but floating-point values are not supported.
FastIntegerCompression.compressSigned = function(input) {
  var c = input.length;
  var buf = new ArrayBuffer(FastIntegerCompression.computeCompressedSizeInBytesSigned(input));
  var view   = new Int8Array(buf);
  var pos = 0;
  for(var i = 0; i < c; i++) {
    var val = zigzag_encode(input[i]);
    if (val < (1 << 7)) {
      view[pos++] = val ;
    } else if (val < (1 << 14)) {
      view[pos++] = (val & 0x7F) | 0x80;
      view[pos++] = val >>> 7;
    } else if (val < (1 << 21)) {
      view[pos++] = (val & 0x7F) | 0x80;
      view[pos++] = ( (val >>> 7) & 0x7F ) | 0x80;
      view[pos++] = val >>> 14;
    } else if (val < (1 << 28)) {
      view[pos++] = (val & 0x7F ) | 0x80 ;
      view[pos++] = ( (val >>> 7) & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 14) & 0x7F ) | 0x80;
      view[pos++] = val >>> 21;
    } else {
      view[pos++] = ( val & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 7) & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 14) & 0x7F ) | 0x80;
      view[pos++] = ( (val >>> 21) & 0x7F ) | 0x80;
      view[pos++] = val >>> 28;
    }
  }
  return buf;
};

// uncompress an array of integer from an ArrayBuffer, return the array
// it is assumed that they were compressed using the compressSigned function, the caller
// is responsible for ensuring that it is the case.
FastIntegerCompression.uncompressSigned = function(input) {
  var array = []
  var inbyte = new Int8Array(input);
  var end = inbyte.length;
  var pos = 0;
  while (end > pos) {
        var c = inbyte[pos++];
        var v = c & 0x7F;
        if (c >= 0) {
          array.push(zigzag_decode(v))
          continue;
        }
        c = inbyte[pos++];
        v |= (c & 0x7F) << 7;
        if (c >= 0) {
          array.push(zigzag_decode(v))
          continue;
        }
        c = inbyte[pos++];
        v |= (c & 0x7F) << 14;
        if (c >= 0) {
          array.push(zigzag_decode(v))
          continue;
        }
        c = inbyte[pos++];
        v |= (c & 0x7F) << 21;
        if (c >= 0) {
          array.push(zigzag_decode(v))
          continue;
        }
        c = inbyte[pos++];
        v |= c << 28;
        array.push(zigzag_decode(v))
  }
  return array;
};

///////////////

module.exports = FastIntegerCompression;

},
"IagCdeY6WtvLC5DWqerY/wKlWsDUE07fzN8+KNoMG2w=":
function (require, module, exports, __dirname, __filename) {
const fs = require('fs')
const path = require('path')
const mutexify = require('mutexify')

function getEncoding(opts) {
  return opts && opts.encoding ? opts.encoding : null
}

const locks = new Map()

module.exports = {
  readFile: function(filename, opts, cb) {
    if (!cb) cb = opts
    fs.readFile(filename, getEncoding(opts), cb)
  },
  writeFile: function(filename, value, opts, cb) {
    if (!cb) cb = opts

    if (!locks.has(filename))
      locks.set(filename, mutexify())

    const lock = locks.get(filename)

    lock((unlock) => {
      const tempFile = filename + '~'

      // make sure dir exists
      fs.mkdirSync(path.dirname(tempFile), { recursive: true })

      fs.open(tempFile, 'w', (err, fd) => {
        if (err) return unlock(cb, err)
        fs.writeFile(fd, value, getEncoding(opts), (err) => {
          if (err) return unlock(cb, err)
          fs.fsync(fd, (err) => {
            if (err) return unlock(cb, err)
            fs.close(fd, (err) => {
              if (err) return unlock(cb, err)
              fs.rename(tempFile, filename, (err) => {
                if (err) return unlock(cb, err)
                unlock(cb, null, value)
              })
            })
          })
        })
      })
    })
  }
}

},
"IcQfpQxyzQfjpUrE5UZsOmUXrjCPM4b2yiXwbu5wUOI=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = function pull (a) {
  var length = arguments.length
  if (typeof a === 'function' && a.length === 1) {
    var args = new Array(length)
    for(var i = 0; i < length; i++)
      args[i] = arguments[i]
    return function (read) {
      if (args == null) {
        throw new TypeError("partial sink should only be called once!")
      }

      // Grab the reference after the check, because it's always an array now
      // (engines like that kind of consistency).
      var ref = args
      args = null

      // Prioritize common case of small number of pulls.
      switch (length) {
      case 1: return pull(read, ref[0])
      case 2: return pull(read, ref[0], ref[1])
      case 3: return pull(read, ref[0], ref[1], ref[2])
      case 4: return pull(read, ref[0], ref[1], ref[2], ref[3])
      default:
        ref.unshift(read)
        return pull.apply(null, ref)
      }
    }
  }

  var read = a

  if (read && typeof read.source === 'function') {
    read = read.source
  }

  for (var i = 1; i < length; i++) {
    var s = arguments[i]
    if (typeof s === 'function') {
      read = s(read)
    } else if (s && typeof s === 'object') {
      s.sink(read)
      read = s.source
    }
  }

  return read
}

},
"IjMweMFBqwnpwblY1xD5UwkrhiTTc2HgwSlLDFiwG1o=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var u = require("./util");
var EventEmitter = require('events');
var Hookable = require('hoox');
var identity = function (x) { return x; };
function merge(a, b, mapper) {
    mapper = mapper !== null && mapper !== void 0 ? mapper : identity;
    for (var k in b) {
        if (b[k] &&
            typeof b[k] === 'object' &&
            !Buffer.isBuffer(b[k]) &&
            !Array.isArray(b[k])) {
            a[k] = {};
            merge(a[k], b[k], mapper);
        }
        else {
            a[k] = mapper(b[k], k);
        }
    }
    return a;
}
module.exports = function Api(plugins, defaultConfig) {
    function create(inputOpts) {
        var opts = merge(merge({}, defaultConfig), inputOpts);
        var api = new EventEmitter();
        create.plugins.forEach(function (plug) {
            var _api = plug.init.call({}, api, opts, create.permissions, create.manifest);
            if (plug.name) {
                var camelCaseName = u.toCamelCase(plug.name);
                var o = {};
                o[camelCaseName] = _api;
                _api = o;
            }
            api = merge(api, _api, function (val, key) {
                if (typeof val === 'function') {
                    val = Hookable(val);
                    if (plug.manifest && plug.manifest[key] === 'sync') {
                        u.hookOptionalCB(val);
                    }
                }
                return val;
            });
        });
        return api;
    }
    create.plugins = [];
    create.manifest = {};
    create.permissions = {};
    create.use = function (plug) {
        if (Array.isArray(plug)) {
            plug.forEach(create.use);
            return create;
        }
        if (!plug.init) {
            if (typeof plug === 'function') {
                create.plugins.push({ init: plug });
                return create;
            }
            else {
                throw new Error('plugins *must* have "init" method');
            }
        }
        if (plug.name && typeof plug.name === 'string') {
            var found = create.plugins.some(function (p) { return p.name === plug.name; });
            if (found) {
                console.error('plugin named:' + plug.name + ' is already loaded, skipping');
                return create;
            }
        }
        var name = plug.name;
        if (plug.manifest) {
            create.manifest = u.merge.manifest(create.manifest, plug.manifest, u.toCamelCase(name));
        }
        if (plug.permissions) {
            create.permissions = u.merge.permissions(create.permissions, plug.permissions, u.toCamelCase(name));
        }
        create.plugins.push(plug);
        return create;
    };
    [].concat(plugins).filter(Boolean).forEach(create.use);
    return create;
};

},
"Il16G9zxx06MfUmseVn0fq/M8pBXAjmNMQUNkSV9zrI=":
function (require, module, exports, __dirname, __filename) {
var pfs  = require('pull-fs')
var pull = require('pull-stream')
var path = require('path')

var glob = module.exports = function (x) {

  var rest = path.normalize(x).split(path.sep)
  var stream

  var pipe = []

  if(rest[0] == '...') {
    pipe.push(pfs.ancestors())
    rest.shift()
  } else if(rest[0] === '~' || rest[0] === '') {
    pipe.push(pull.values([rest.shift() ? process.env.HOME : '/']))
  } else {
    pipe.push(pull.values(['.']))
  }

  //this should be tidied up.
  //need a more betterer glob parser
  //that handles escapes...
  rest.forEach(function (e) {
    if('**' === e) {
      pipe.push(pfs.starStar())
    } else if(/[*?{}]/.test(e)) {
      //literal
      e = e
        .split('.').join('\\.')
        .split('?').join('.')
        .split(/({.*?})/).map(function (e, i) {
        if(i % 2)
          return e.replace('{', '(?:')
                  .replace('}', ')')
                  .split(',').join('|')
        return e
      }).join('')

      var x = new RegExp('^'+e.split('*').join('.*')+'$')
      pipe.push(pfs.star(x))
    } else if(e === '')
      //will only happen in the last position
      //if you do */
      pipe.push(pfs.isDirectory())
    else
      pipe.push(pull(pfs.resolve(e), pfs.exists()))
  })

  return pull.apply(null, pipe)
}


},
"ImbZbki9SHk612auyf0MzhjQ/wGqu0Q2IE83/XMkrWE=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const { deferred } = require('ssb-db2/operators');
const WordsIndex = require("./plugin");
module.exports = {
    name: 'search2',
    init(ssb, _config) {
        ssb.db.registerIndex(WordsIndex);
        return {
            operator(text) {
                return deferred((meta, cb, onAbort) => {
                    meta.db.onDrain('search2', () => {
                        const plugin = meta.db.getIndex('search2');
                        plugin.query(text, cb, onAbort);
                    });
                });
            },
        };
    },
};

},
"IxgLJt3/NF+dNRtoJCfb+Gqr8MYrbsMFV87Z356gB2w=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const pull = require('pull-stream')
const pullCont = require('pull-cont')
const ref = require('ssb-ref')
const Hookable = require('hoox')
const { author } = require('../operators')
const { reEncrypt } = require('../indexes/private')

// exports.name is blank to merge into global namespace

exports.manifest = {
  createHistoryStream: 'source',
}

exports.permissions = {
  anonymous: { allow: ['createHistoryStream'], deny: null },
}

exports.init = function (sbot, config) {
  sbot.createHistoryStream = Hookable(function createHistoryStream(opts) {
    // default values
    const sequence = opts.sequence || opts.seq || 0
    const limit = opts.limit
    const keys = opts.keys === false ? false : true
    const values = opts.values === false ? false : true

    let query = author(opts.id)

    if (sequence) {
      query = {
        type: 'AND',
        data: [
          query,
          {
            type: 'GTE',
            data: {
              indexName: 'sequence',
              value: sequence,
            },
          },
        ],
      }
    }

    function formatMsg(msg) {
      msg = reEncrypt(msg)

      if (!keys && values) return msg.value
      else if (keys && !values) return msg.key
      else return msg
    }

    return pull(
      pullCont(function (cb) {
        sbot.db.getLog().onDrain(() => {
          if (!ref.isFeed(opts.id)) return cb(opts.id + ' is not a feed')

          if (limit) {
            sbot.db
              .getJITDB()
              .paginate(query, 0, limit, false, false, (err, answer) => {
                cb(err, pull.values(answer.results.map(formatMsg)))
              })
          } else {
            sbot.db.getJITDB().all(query, 0, false, false, (err, results) => {
              cb(err, pull.values(results.map(formatMsg)))
            })
          }
        })
      })
    )
  })

  return {}
}

},
"J4rGzEdrgNsaSB4+u4V/fvZ0vLlKQ9mFheYKQFQ2XBA=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const AboutSelfIndex = require('./indexes/about-self')

exports.init = function (sbot, config) {
  sbot.db.registerIndex(AboutSelfIndex)
}

},
"JI5bMXQY9dKVqGD3OEE1aCjUp1viKEcQXFVJxofiPzE=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var tester = require('../util/tester')
var filter = require('./filter')

module.exports = function filterNot (test) {
  test = tester(test)
  return filter(function (data) { return !test(data) })
}

},
"JIegApdPUt0/wY9We7EikkVDnJlM/ZbTWj4HDvPpCPk=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const path = require('path')
const bipf = require('bipf')
const push = require('push-stream')
const pull = require('pull-stream')
const toPull = require('push-stream-to-pull-stream')
const pullAsync = require('pull-async')
const TypedFastBitSet = require('typedfastbitset')
const bsb = require('binary-search-bounds')
const multicb = require('multicb')
const FastPriorityQueue = require('fastpriorityqueue')
const debug = require('debug')('jitdb')
const debugQuery = debug.extend('query')
const Status = require('./status')
const {
  saveTypedArrayFile,
  loadTypedArrayFile,
  savePrefixMapFile,
  loadPrefixMapFile,
  saveBitsetFile,
  loadBitsetFile,
  safeFilename,
  listFilesIDB,
  listFilesFS,
} = require('./files')

module.exports = function (log, indexesPath) {
  debug('indexes path', indexesPath)

  let bitsetCache = new WeakMap()
  let sortedCache = { ascending: new WeakMap(), descending: new WeakMap() }
  let cacheOffset = -1

  const status = Status()

  const indexes = {}
  let isReady = false
  let waiting = []
  const coreIndexNames = ['seq', 'timestamp', 'sequence']

  loadIndexes(() => {
    debug('loaded indexes', Object.keys(indexes))

    if (!indexes['seq']) {
      indexes['seq'] = {
        offset: -1,
        count: 0,
        tarr: new Uint32Array(16 * 1000),
        version: 1,
      }
    }
    if (!indexes['timestamp']) {
      indexes['timestamp'] = {
        offset: -1,
        count: 0,
        tarr: new Float64Array(16 * 1000),
        version: 1,
      }
    }
    if (!indexes['sequence']) {
      indexes['sequence'] = {
        offset: -1,
        count: 0,
        tarr: new Uint32Array(16 * 1000),
        version: 1,
      }
    }

    status.batchUpdate(indexes, coreIndexNames)

    isReady = true
    for (let i = 0; i < waiting.length; ++i) waiting[i]()
    waiting = []
  })

  function onReady(cb) {
    if (isReady) cb()
    else waiting.push(cb)
  }

  const B_TIMESTAMP = Buffer.from('timestamp')
  const B_SEQUENCE = Buffer.from('sequence')
  const B_VALUE = Buffer.from('value')

  function loadIndexes(cb) {
    function parseIndexes(err, files) {
      push(
        push.values(files),
        push.asyncMap((file, cb) => {
          const indexName = path.parse(file).name
          if (file === 'seq.index') {
            loadTypedArrayFile(
              path.join(indexesPath, file),
              Uint32Array,
              (err, idx) => {
                if (!err) indexes[indexName] = idx
                cb()
              }
            )
          } else if (file === 'timestamp.index') {
            loadTypedArrayFile(
              path.join(indexesPath, file),
              Float64Array,
              (err, idx) => {
                if (!err) indexes[indexName] = idx
                cb()
              }
            )
          } else if (file === 'sequence.index') {
            loadTypedArrayFile(
              path.join(indexesPath, file),
              Uint32Array,
              (err, idx) => {
                if (!err) indexes[indexName] = idx
                cb()
              }
            )
          } else if (file.endsWith('.32prefix')) {
            // Don't load it yet, just tag it `lazy`
            indexes[indexName] = {
              offset: -1,
              count: 0,
              tarr: new Uint32Array(16 * 1000),
              lazy: true,
              prefix: 32,
              filepath: path.join(indexesPath, file),
            }
            cb()
          } else if (file.endsWith('.32prefixmap')) {
            // Don't load it yet, just tag it `lazy`
            indexes[indexName] = {
              offset: -1,
              count: 0,
              map: {},
              lazy: true,
              prefix: 32,
              filepath: path.join(indexesPath, file),
            }
            cb()
          } else if (file.endsWith('.index')) {
            // Don't load it yet, just tag it `lazy`
            indexes[indexName] = {
              offset: 0,
              bitset: new TypedFastBitSet(),
              lazy: true,
              filepath: path.join(indexesPath, file),
            }
            cb()
          } else cb()
        }),
        push.collect(cb)
      )
    }

    if (typeof window !== 'undefined') {
      // browser
      listFilesIDB(indexesPath, parseIndexes)
    } else {
      // node.js
      listFilesFS(indexesPath, parseIndexes)
    }
  }

  function updateCacheWithLog() {
    if (log.since.value > cacheOffset) {
      cacheOffset = log.since.value
      bitsetCache = new WeakMap()
      sortedCache.ascending = new WeakMap()
      sortedCache.descending = new WeakMap()
    }
  }

  function saveCoreIndex(name, coreIndex, count, cb) {
    if (coreIndex.offset < 0) return
    debug('saving core index: %s', name)
    const filename = path.join(indexesPath, name + '.index')
    saveTypedArrayFile(
      filename,
      coreIndex.version,
      coreIndex.offset,
      count,
      coreIndex.tarr,
      cb
    )
  }

  function saveIndex(name, index, count, cb) {
    if (index.prefix && index.map) savePrefixMapIndex(name, index, count, cb)
    else if (index.prefix) savePrefixIndex(name, index, count, cb)
    else saveBitsetIndex(name, index, cb)
  }

  function saveBitsetIndex(name, index, cb) {
    if (index.offset < 0 || index.bitset.size() === 0) return
    debug('saving index: %s', name)
    const filename = path.join(indexesPath, name + '.index')
    saveBitsetFile(filename, index.version, index.offset, index.bitset, cb)
  }

  function savePrefixIndex(name, prefixIndex, count, cb) {
    if (prefixIndex.offset < 0) return
    debug('saving prefix index: %s', name)
    const num = prefixIndex.prefix
    const filename = path.join(indexesPath, name + `.${num}prefix`)
    saveTypedArrayFile(
      filename,
      prefixIndex.version,
      prefixIndex.offset,
      count,
      prefixIndex.tarr,
      cb
    )
  }

  function savePrefixMapIndex(name, prefixIndex, count, cb) {
    if (prefixIndex.offset < 0) return
    debug('saving prefix map index: %s', name)
    const num = prefixIndex.prefix
    const filename = path.join(indexesPath, name + `.${num}prefixmap`)
    savePrefixMapFile(
      filename,
      prefixIndex.version,
      prefixIndex.offset,
      count,
      prefixIndex.map,
      cb
    )
  }

  function growTarrIndex(index, Type) {
    debug('growing index')
    const newArray = new Type(index.tarr.length * 2)
    newArray.set(index.tarr)
    index.tarr = newArray
  }

  function updateSeqIndex(seq, offset) {
    if (seq > indexes['seq'].count - 1) {
      if (seq > indexes['seq'].tarr.length - 1) {
        growTarrIndex(indexes['seq'], Uint32Array)
      }

      indexes['seq'].offset = offset
      indexes['seq'].tarr[seq] = offset
      indexes['seq'].count = seq + 1
      return true
    }
  }

  function seekMinTimestamp(buffer) {
    var p = 0 // note you pass in p!
    p = bipf.seekKey(buffer, p, B_TIMESTAMP)
    const arrivalTimestamp = bipf.decode(buffer, p)
    p = 0
    p = bipf.seekKey(buffer, p, B_VALUE)
    p = bipf.seekKey(buffer, p, B_TIMESTAMP)
    const declaredTimestamp = bipf.decode(buffer, p)
    return Math.min(arrivalTimestamp, declaredTimestamp)
  }

  function seekSequence(buffer) {
    var p = 0 // note you pass in p!
    p = bipf.seekKey(buffer, p, B_VALUE)
    p = bipf.seekKey(buffer, p, B_SEQUENCE)
    return bipf.decode(buffer, p)
  }

  function updateTimestampIndex(seq, offset, buffer) {
    if (seq > indexes['timestamp'].count - 1) {
      if (seq > indexes['timestamp'].tarr.length - 1)
        growTarrIndex(indexes['timestamp'], Float64Array)

      indexes['timestamp'].offset = offset

      const timestamp = seekMinTimestamp(buffer)

      indexes['timestamp'].tarr[seq] = timestamp
      indexes['timestamp'].count = seq + 1
      return true
    }
  }

  function updateSequenceIndex(seq, offset, buffer) {
    if (seq > indexes['sequence'].count - 1) {
      if (seq > indexes['sequence'].tarr.length - 1)
        growTarrIndex(indexes['sequence'], Uint32Array)

      indexes['sequence'].offset = offset

      const sequence = seekSequence(buffer)

      indexes['sequence'].tarr[seq] = sequence
      indexes['sequence'].count = seq + 1
      return true
    }
  }

  const undefinedBipf = bipf.allocAndEncode(undefined)

  function checkEqual(opData, buffer) {
    const fieldStart = opData.seek(buffer)

    if (fieldStart === -1 && opData.value.equals(undefinedBipf)) return true
    else return bipf.compare(buffer, fieldStart, opData.value, 0) === 0
  }

  function compareWithRangeOp(op, value) {
    if (op.type === 'GT') return value > op.data.value
    else if (op.type === 'GTE') return value >= op.data.value
    else if (op.type === 'LT') return value < op.data.value
    else if (op.type === 'LTE') return value <= op.data.value
    else {
      console.warn('Unknown op type: ' + op.type)
      return true
    }
  }

  function checkComparison(op, buffer) {
    if (op.data.indexName === 'timestamp') {
      const timestamp = seekMinTimestamp(buffer)
      return compareWithRangeOp(op, timestamp)
    } else if (op.data.indexName === 'sequence') {
      const sequence = seekSequence(buffer)
      return compareWithRangeOp(op, sequence)
    } else {
      console.warn(
        `Attempted to do a ${op.type} comparison on unsupported index ${op.data.indexName}`
      )
      return true
    }
  }

  function checkPredicate(opData, buffer) {
    const fieldStart = opData.seek(buffer)
    const predicateFn = opData.value
    if (fieldStart < 0) return false
    const fieldValue = bipf.decode(buffer, fieldStart)
    return predicateFn(fieldValue)
  }

  function checkAbsent(opData, buffer) {
    const fieldStart = opData.seek(buffer)
    return fieldStart < 0
  }

  function checkIncludes(opData, buffer) {
    const fieldStart = opData.seek(buffer)
    if (!~fieldStart) return false
    const type = bipf.getEncodedType(buffer, fieldStart)

    if (type === bipf.types.array) {
      let found = false
      bipf.iterate(buffer, fieldStart, (_, itemStart) => {
        const valueStart = opData.pluck
          ? opData.pluck(buffer, itemStart)
          : itemStart
        if (bipf.compare(buffer, valueStart, opData.value, 0) === 0) {
          found = true
          return true // abort the bipf.iterate
        }
      })
      return found
    } else return checkEqual(opData, buffer)
  }

  function safeReadUint32(buf, prefixOffset = 0) {
    if (buf.length < 4) {
      const bigger = Buffer.alloc(4)
      buf.copy(bigger)
      return bigger.readUInt32LE(0)
    } else if (buf.length === 4) {
      return buf.readUInt32LE(0)
    } else {
      return buf.readUInt32LE(prefixOffset)
    }
  }

  function addToPrefixMap(map, seq, prefix) {
    if (prefix === 0) return

    const arr = map[prefix] || (map[prefix] = [])
    arr.push(seq)
  }

  function updatePrefixMapIndex(opData, index, buffer, seq, offset) {
    if (seq > index.count - 1) {
      const fieldStart = opData.seek(buffer)
      if (~fieldStart) {
        const buf = bipf.slice(buffer, fieldStart)
        if (buf.length) {
          const prefix = safeReadUint32(buf, opData.prefixOffset)
          addToPrefixMap(index.map, seq, prefix)
        }
      }

      index.offset = offset
      index.count = seq + 1
    }
  }

  function updatePrefixIndex(opData, index, buffer, seq, offset) {
    if (seq > index.count - 1) {
      if (seq > index.tarr.length - 1) growTarrIndex(index, Uint32Array)

      const fieldStart = opData.seek(buffer)
      if (~fieldStart) {
        const buf = bipf.slice(buffer, fieldStart)
        index.tarr[seq] = buf.length
          ? safeReadUint32(buf, opData.prefixOffset)
          : 0
      } else {
        index.tarr[seq] = 0
      }
      index.offset = offset
      index.count = seq + 1
    }
  }

  function updateIndexValue(op, index, buffer, seq) {
    if (op.type === 'EQUAL' && checkEqual(op.data, buffer))
      index.bitset.add(seq)
    else if (op.type === 'PREDICATE' && checkPredicate(op.data, buffer))
      index.bitset.add(seq)
    else if (op.type === 'ABSENT' && checkAbsent(op.data, buffer))
      index.bitset.add(seq)
    else if (op.type === 'INCLUDES' && checkIncludes(op.data, buffer))
      index.bitset.add(seq)
  }

  function updateAllIndexValue(opData, newIndexes, buffer, seq) {
    const fieldStart = opData.seek(buffer)
    const value = bipf.decode(buffer, fieldStart)
    const indexName = safeFilename(opData.indexType + '_' + value)

    if (!newIndexes[indexName]) {
      newIndexes[indexName] = {
        offset: 0,
        bitset: new TypedFastBitSet(),
        version: opData.version || 1,
      }
    }

    newIndexes[indexName].bitset.add(seq)
  }

  // concurrent index helpers
  function onlyOneIndexAtATime(waitingMap, indexName, cb) {
    if (waitingMap.has(indexName)) {
      waitingMap.get(indexName).push(cb)
      return true // wait for other index update
    } else waitingMap.set(indexName, [])
  }

  function runWaitingIndexLoadCbs(waitingMap, indexName) {
    waitingMap.get(indexName).forEach((cb) => cb())
    waitingMap.delete(indexName)
  }

  // concurrent index update
  const waitingIndexUpdate = new Map()

  function updateIndex(op, cb) {
    const index = indexes[op.data.indexName]

    const indexNamesForStatus = [...coreIndexNames, op.data.indexName]

    const waitingKey = op.data.indexName
    if (onlyOneIndexAtATime(waitingIndexUpdate, waitingKey, cb)) return

    // Reset index if version was bumped
    if (op.data.version > index.version) {
      index.offset = -1
      index.count = 0
    }

    // find the next possible seq
    let seq = 0
    if (index.offset !== -1) {
      const { tarr } = indexes['seq']
      const indexOffset = index.offset
      for (const len = tarr.length; seq < len; ++seq)
        if (tarr[seq] === indexOffset) {
          seq++
          break
        }
    }

    let updatedSeqIndex = false
    let updatedTimestampIndex = false
    let updatedSequenceIndex = false
    const startSeq = seq
    const start = Date.now()
    let lastSaved = start

    const indexNeedsUpdate = !coreIndexNames.includes(op.data.indexName)

    function save(count, offset) {
      const done = multicb({ pluck: 1 })
      if (updatedSeqIndex) saveCoreIndex('seq', indexes['seq'], count, done())

      if (updatedTimestampIndex)
        saveCoreIndex('timestamp', indexes['timestamp'], count, done())

      if (updatedSequenceIndex)
        saveCoreIndex('sequence', indexes['sequence'], count, done())

      index.offset = offset
      if (op.data.version > index.version) index.version = op.data.version

      if (indexNeedsUpdate) {
        done(() => {
          saveIndex(op.data.indexName, index, count)
        })
      }
    }

    const logstreamId = Math.ceil(Math.random() * 1000)
    debug(`log.stream #${logstreamId} started, to update index ${waitingKey}`)

    log.stream({ gt: index.offset }).pipe({
      paused: false,
      write: function (record) {
        const offset = record.offset
        const buffer = record.value

        if (updateSeqIndex(seq, offset)) updatedSeqIndex = true

        if (!buffer) {
          // deleted
          seq++
          return
        }

        if (updateTimestampIndex(seq, offset, buffer))
          updatedTimestampIndex = true

        if (updateSequenceIndex(seq, offset, buffer))
          updatedSequenceIndex = true

        if (indexNeedsUpdate) {
          if (op.data.prefix && op.data.useMap)
            updatePrefixMapIndex(op.data, index, buffer, seq, offset)
          else if (op.data.prefix)
            updatePrefixIndex(op.data, index, buffer, seq, offset)
          else updateIndexValue(op, index, buffer, seq)
        }

        if (seq % 1000 === 0) {
          status.batchUpdate(indexes, indexNamesForStatus)
          const now = Date.now()
          if (now - lastSaved >= 60e3) {
            lastSaved = now
            save(seq, offset)
          }
        }

        seq++
      },
      end: () => {
        const count = seq // incremented at end
        debug(
          `log.stream #${logstreamId} done ${seq - startSeq} records in ${
            Date.now() - start
          }ms`
        )

        save(count, indexes['seq'].offset)

        status.batchUpdate(indexes, indexNamesForStatus)

        runWaitingIndexLoadCbs(waitingIndexUpdate, waitingKey)

        cb()
      },
    })
  }

  // concurrent index create
  const waitingIndexCreate = new Map()

  function createIndexes(opsMissingIdx, cb) {
    const newIndexes = {}

    const newIndexNames = opsMissingIdx.map((op) => op.data.indexName)

    const waitingKey = newIndexNames.join('|')
    if (onlyOneIndexAtATime(waitingIndexCreate, waitingKey, cb)) return

    opsMissingIdx.forEach((op) => {
      if (op.data.prefix && op.data.useMap) {
        newIndexes[op.data.indexName] = {
          offset: 0,
          count: 0,
          map: {},
          prefix: typeof op.data.prefix === 'number' ? op.data.prefix : 32,
          version: op.data.version || 1,
        }
      } else if (op.data.prefix)
        newIndexes[op.data.indexName] = {
          offset: 0,
          count: 0,
          tarr: new Uint32Array(16 * 1000),
          prefix: typeof op.data.prefix === 'number' ? op.data.prefix : 32,
          version: op.data.version || 1,
        }
      else
        newIndexes[op.data.indexName] = {
          offset: 0,
          bitset: new TypedFastBitSet(),
          version: op.data.version || 1,
        }
    })

    let seq = 0

    let updatedSeqIndex = false
    let updatedTimestampIndex = false
    let updatedSequenceIndex = false
    const start = Date.now()
    let lastSaved = start

    function save(count, offset, doneIndexing) {
      const done = multicb({ pluck: 1 })
      if (updatedSeqIndex) saveCoreIndex('seq', indexes['seq'], count, done())

      if (updatedTimestampIndex)
        saveCoreIndex('timestamp', indexes['timestamp'], count, done())

      if (updatedSequenceIndex)
        saveCoreIndex('sequence', indexes['sequence'], count, done())

      for (var indexName in newIndexes) {
        const index = newIndexes[indexName]
        if (doneIndexing) indexes[indexName] = index
        index.offset = offset
        done(() => {
          saveIndex(indexName, index, count)
        })
      }
    }

    const logstreamId = Math.ceil(Math.random() * 1000)
    debug(`log.stream #${logstreamId} started, to create indexes ${waitingKey}`)

    log.stream({}).pipe({
      paused: false,
      write: function (record) {
        const offset = record.offset
        const buffer = record.value

        if (updateSeqIndex(seq, offset)) updatedSeqIndex = true

        if (!buffer) {
          // deleted
          seq++
          return
        }

        if (updateTimestampIndex(seq, offset, buffer))
          updatedTimestampIndex = true

        if (updateSequenceIndex(seq, offset, buffer))
          updatedSequenceIndex = true

        opsMissingIdx.forEach((op) => {
          if (op.data.prefix && op.data.useMap)
            updatePrefixMapIndex(
              op.data,
              newIndexes[op.data.indexName],
              buffer,
              seq,
              offset
            )
          else if (op.data.prefix)
            updatePrefixIndex(
              op.data,
              newIndexes[op.data.indexName],
              buffer,
              seq,
              offset
            )
          else if (op.data.indexAll)
            updateAllIndexValue(op.data, newIndexes, buffer, seq)
          else updateIndexValue(op, newIndexes[op.data.indexName], buffer, seq)
        })

        if (seq % 1000 === 0) {
          status.batchUpdate(indexes, coreIndexNames)
          status.batchUpdate(newIndexes, newIndexNames)
          const now = Date.now()
          if (now - lastSaved >= 60e3) {
            lastSaved = now
            save(seq, offset, false)
          }
        }

        seq++
      },
      end: () => {
        const count = seq // incremented at end
        debug(
          `log.stream #${logstreamId} done ${count} records in ${
            Date.now() - start
          }ms`
        )

        save(count, indexes['seq'].offset, true)

        status.batchUpdate(indexes, coreIndexNames)
        status.batchUpdate(newIndexes, newIndexNames)

        runWaitingIndexLoadCbs(waitingIndexCreate, waitingKey)

        cb()
      },
    })
  }

  // concurrent index load
  const waitingIndexLoad = new Map()

  function loadLazyIndex(indexName, cb) {
    if (onlyOneIndexAtATime(waitingIndexLoad, indexName, cb)) return

    debug('lazy loading %s', indexName)
    let index = indexes[indexName]
    if (index.prefix && index.map) {
      loadPrefixMapFile(index.filepath, (err, data) => {
        if (err) {
          debug('index %s failed to load with %s', indexName, err)
          delete indexes[indexName]
          return cb() // don't return a error, index will be rebuild
        }

        const { version, offset, count, map } = data
        index.version = version
        index.offset = offset
        index.count = count
        index.map = map
        index.lazy = false

        runWaitingIndexLoadCbs(waitingIndexLoad, indexName)

        cb()
      })
    } else if (index.prefix) {
      loadTypedArrayFile(index.filepath, Uint32Array, (err, data) => {
        if (err) {
          debug('index %s failed to load with %s', indexName, err)
          delete indexes[indexName]
          return cb() // don't return a error, index will be rebuild
        }

        const { version, offset, count, tarr } = data
        index.version = version
        index.offset = offset
        index.count = count
        index.tarr = tarr
        index.lazy = false

        runWaitingIndexLoadCbs(waitingIndexLoad, indexName)

        cb()
      })
    } else {
      loadBitsetFile(index.filepath, (err, data) => {
        if (err) {
          debug('index %s failed to load with %s', indexName, err)
          delete indexes[indexName]
          return cb() // don't return a error, index will be rebuild
        }

        const { version, offset, bitset } = data
        index.version = version
        index.offset = offset
        index.bitset = bitset
        index.lazy = false

        runWaitingIndexLoadCbs(waitingIndexLoad, indexName)

        cb()
      })
    }
  }

  function ensureIndexSync(op, cb) {
    const index = indexes[op.data.indexName]
    if (log.since.value > index.offset || op.data.version > index.version) {
      updateIndex(op, cb)
    } else {
      debug('ensureIndexSync %s is already synced', op.data.indexName)
      cb()
    }
  }

  function ensureSeqIndexSync(cb) {
    ensureIndexSync({ data: { indexName: 'seq' } }, cb)
  }

  function filterIndex(op, filterCheck, cb) {
    ensureIndexSync(op, () => {
      if (op.data.indexName === 'sequence') {
        const bitset = new TypedFastBitSet()
        const { tarr, count } = indexes['sequence']
        for (let seq = 0; seq < count; ++seq) {
          if (filterCheck(tarr[seq], op)) bitset.add(seq)
        }
        cb(bitset)
      } else if (op.data.indexName === 'timestamp') {
        const bitset = new TypedFastBitSet()
        const { tarr, count } = indexes['timestamp']
        for (let seq = 0; seq < count; ++seq) {
          if (filterCheck(tarr[seq], op)) bitset.add(seq)
        }
        cb(bitset)
      } else {
        debug('filterIndex() is unsupported for %s', op.data.indexName)
      }
    })
  }

  function getFullBitset(cb) {
    ensureIndexSync({ data: { indexName: 'sequence' } }, () => {
      const bitset = new TypedFastBitSet()
      const { count } = indexes['sequence']
      bitset.addRange(0, count)
      cb(bitset)
    })
  }

  function getOffsetsBitset(opOffsets, cb) {
    const seqs = []
    opOffsets.sort((x, y) => x - y)
    const opOffsetsLen = opOffsets.length
    const { tarr } = indexes['seq']
    for (let seq = 0, len = tarr.length; seq < len; ++seq) {
      if (bsb.eq(opOffsets, tarr[seq]) !== -1) seqs.push(seq)
      if (seqs.length === opOffsetsLen) break
    }
    cb(new TypedFastBitSet(seqs))
  }

  function matchAgainstPrefix(op, prefixIndex, cb) {
    const target = op.data.value
    const targetPrefix = target
      ? safeReadUint32(bipf.slice(target, 0), op.data.prefixOffset)
      : 0
    const bitset = new TypedFastBitSet()
    const bitsetFilters = new Map()

    const seek = op.data.seek
    function checker(value) {
      if (!value) return false // deleted

      const fieldStart = seek(value)

      if (target) return bipf.compare(value, fieldStart, target, 0) === 0
      else if (~fieldStart) return false

      return true
    }

    if (prefixIndex.map) {
      if (prefixIndex.map[targetPrefix]) {
        prefixIndex.map[targetPrefix].forEach((seq) => {
          bitset.add(seq)
          bitsetFilters.set(seq, [checker])
        })
      }
    } else {
      const count = prefixIndex.count
      const tarr = prefixIndex.tarr
      for (let seq = 0; seq < count; ++seq) {
        if (tarr[seq] === targetPrefix) {
          bitset.add(seq)
          bitsetFilters.set(seq, [checker])
        }
      }
    }

    cb(bitset, bitsetFilters)
  }

  function nestLargeOpsArray(ops, type) {
    let op = ops[0]
    ops.slice(1).forEach((rest) => {
      op = {
        type,
        data: [op, rest],
      }
    })
    return op
  }

  function getNameFromOperation(op) {
    if (
      op.type === 'EQUAL' ||
      op.type === 'INCLUDES' ||
      op.type === 'PREDICATE'
    ) {
      const value = op.data.value
        ? op.data.value.toString().substring(0, 10)
        : ''
      return `${op.data.indexType}(${value})`
    } else if (op.type === 'ABSENT') {
      return `ABSENT(${op.data.indexType})`
    } else if (
      op.type === 'GT' ||
      op.type === 'GTE' ||
      op.type === 'LT' ||
      op.type === 'LTE'
    ) {
      const value = op.data.value
        ? op.data.value.toString().substring(0, 10)
        : ''
      return `${op.type}(${value})`
    } else if (op.type === 'SEQS') {
      return `SEQS(${op.seqs.toString().substring(0, 10)})`
    } else if (op.type === 'OFFSETS') {
      return `OFFSETS(${op.offsets.toString().substring(0, 10)})`
    } else if (op.type === 'LIVESEQS') {
      return `LIVESEQS()`
    } else if (op.type === 'AND') {
      if (op.data.length > 2) op = nestLargeOpsArray(op.data, 'AND')

      const op1name = getNameFromOperation(op.data[0])
      const op2name = getNameFromOperation(op.data[1])

      if (!op1name) return op2name
      if (!op2name) return op1name

      return `AND(${op1name},${op2name})`
    } else if (op.type === 'OR') {
      if (op.data.length > 2) op = nestLargeOpsArray(op.data, 'AND')

      const op1name = getNameFromOperation(op.data[0])
      const op2name = getNameFromOperation(op.data[1])

      if (!op1name) return op2name
      if (!op2name) return op1name

      return `OR(${op1name},${op2name})`
    } else if (op.type === 'NOT') {
      return `NOT(${getNameFromOperation(op.data[0])})`
    } else {
      return '*'
    }
  }

  function mergeFilters(filters1, filters2) {
    if (!filters1 && !filters2) return null
    else if (filters1 && !filters2) return filters1
    else if (!filters1 && filters2) return filters2
    else {
      const filters = new Map(filters1)
      for (let seq of filters2.keys()) {
        const f1 = filters1.get(seq) || []
        const f2 = filters2.get(seq)
        filters.set(seq, [...f1, ...f2])
      }
      return filters
    }
  }

  function getBitsetForOperation(op, cb) {
    if (
      op.type === 'EQUAL' ||
      op.type === 'INCLUDES' ||
      op.type === 'PREDICATE' ||
      op.type === 'ABSENT'
    ) {
      if (op.data.prefix) {
        ensureIndexSync(op, () => {
          matchAgainstPrefix(op, indexes[op.data.indexName], cb)
        })
      } else {
        ensureIndexSync(op, () => {
          cb(indexes[op.data.indexName].bitset)
        })
      }
    } else if (op.type === 'GT') {
      filterIndex(op, (num, op) => num > op.data.value, cb)
    } else if (op.type === 'GTE') {
      filterIndex(op, (num, op) => num >= op.data.value, cb)
    } else if (op.type === 'LT') {
      filterIndex(op, (num, op) => num < op.data.value, cb)
    } else if (op.type === 'LTE') {
      filterIndex(op, (num, op) => num <= op.data.value, cb)
    } else if (op.type === 'OFFSETS') {
      ensureSeqIndexSync(() => {
        getOffsetsBitset(op.offsets, cb)
      })
    } else if (op.type === 'SEQS') {
      ensureSeqIndexSync(() => {
        cb(new TypedFastBitSet(op.seqs))
      })
    } else if (op.type === 'LIVESEQS') {
      cb(new TypedFastBitSet())
    } else if (op.type === 'AND') {
      if (op.data.length > 2) op = nestLargeOpsArray(op.data, 'AND')

      getBitsetForOperation(op.data[0], (op1, filters1) => {
        getBitsetForOperation(op.data[1], (op2, filters2) => {
          cb(op1.new_intersection(op2), mergeFilters(filters1, filters2))
        })
      })
    } else if (op.type === 'OR') {
      if (op.data.length > 2) op = nestLargeOpsArray(op.data, 'OR')

      getBitsetForOperation(op.data[0], (op1, filters1) => {
        getBitsetForOperation(op.data[1], (op2, filters2) => {
          cb(op1.new_union(op2), mergeFilters(filters1, filters2))
        })
      })
    } else if (op.type === 'NOT') {
      getBitsetForOperation(op.data[0], (op1, filters) => {
        getFullBitset((fullBitset) => {
          cb(fullBitset.difference(op1), filters)
        })
      })
    } else if (!op.type) {
      // to support `query(fromDB(jitdb), toCallback(cb))`
      getFullBitset(cb)
    } else console.error('Unknown type', op)
  }

  function traverseEqualsAndIncludes(operation, fn) {
    function traverseMore(ops) {
      ops.forEach((op) => {
        if (
          op.type === 'EQUAL' ||
          op.type === 'INCLUDES' ||
          op.type === 'PREDICATE' ||
          op.type === 'ABSENT'
        ) {
          fn(op)
        } else if (op.type === 'AND' || op.type === 'OR' || op.type === 'NOT')
          traverseMore(op.data)
        else if (
          op.type === 'SEQS' ||
          op.type === 'LIVESEQS' ||
          op.type === 'OFFSETS' ||
          op.type === 'LT' ||
          op.type === 'LTE' ||
          op.type === 'GT' ||
          op.type === 'GTE' ||
          !op.type // e.g. query(fromDB, toCallback), or empty deferred()
        );
        else debug('Unknown operator type: ' + op.type)
      })
    }
    traverseMore([operation])
  }

  function detectLazyIndexesUsed(operation) {
    const results = []
    traverseEqualsAndIncludes(operation, (op) => {
      const name = op.data.indexName
      if (indexes[name] && indexes[name].lazy) results.push(name)
    })
    return results
  }

  function detectOpsMissingIndexes(operation) {
    const results = []
    traverseEqualsAndIncludes(operation, (op) => {
      if (!indexes[op.data.indexName]) results.push(op)
    })
    return results
  }

  function executeOperation(operation, cb) {
    updateCacheWithLog()
    if (bitsetCache.has(operation)) return cb(null, bitsetCache.get(operation))

    push(
      // kick-start this chain with a dummy null value
      push.values([null]),

      // ensure that the seq->offset index is synchronized with the log
      push.asyncMap((_, next) => ensureSeqIndexSync(next)),

      // load lazy indexes, if any
      push.asyncMap((_, next) => {
        const lazyIdxNames = detectLazyIndexesUsed(operation)
        if (lazyIdxNames.length === 0) return next()
        push(
          push.values(lazyIdxNames),
          push.asyncMap(loadLazyIndex),
          push.collect(next)
        )
      }),

      // create missing indexes, if any
      //
      // this needs to happen after loading lazy indexes because some
      // lazy indexes may have failed to load, and are now considered missing
      push.asyncMap((_, next) => {
        const opsMissingIdx = detectOpsMissingIndexes(operation)
        if (opsMissingIdx.length === 0) return next()
        debug('missing indexes: %o', opsMissingIdx)
        createIndexes(opsMissingIdx, next)
      }),

      // get bitset for the input operation, and cache it
      push.asyncMap((_, next) => {
        getBitsetForOperation(operation, (bitset, filters) => {
          bitsetCache.set(operation, [bitset, filters])
          next(null, [bitset, filters])
        })
      }),

      // return bitset and filter functions
      push.collect((err, results) => {
        if (err) cb(err)
        else cb(null, results[0])
      })
    )
  }

  function isValueOk(ops, value, isOr) {
    for (let i = 0; i < ops.length; ++i) {
      const op = ops[i]
      let ok = false
      if (op.type === 'EQUAL') ok = checkEqual(op.data, value)
      else if (op.type === 'PREDICATE') ok = checkPredicate(op.data, value)
      else if (op.type === 'ABSENT') ok = checkAbsent(op.data, value)
      else if (op.type === 'INCLUDES') ok = checkIncludes(op.data, value)
      else if (op.type === 'NOT') ok = !isValueOk(op.data, value, false)
      else if (op.type === 'AND') ok = isValueOk(op.data, value, false)
      else if (op.type === 'OR') ok = isValueOk(op.data, value, true)
      else if (
        op.type === 'GT' ||
        op.type === 'GTE' ||
        op.type === 'LT' ||
        op.type === 'LTE'
      )
        ok = checkComparison(op, value)
      else if (op.type === 'LIVESEQS') ok = true
      else if (!op.type) ok = true

      if (ok && isOr) return true
      else if (!ok && !isOr) return false
    }

    if (isOr) return false
    else return true
  }

  function getMessage(seq, recBufferCache, cb) {
    if (recBufferCache[seq]) {
      const recBuffer = recBufferCache[seq]
      const message = bipf.decode(recBuffer, 0)
      cb(null, message)
      return
    }
    const offset = indexes['seq'].tarr[seq]
    log.get(offset, (err, recBuffer) => {
      if (err && err.code === 'flumelog:deleted') cb()
      else if (err) cb(err)
      else cb(null, bipf.decode(recBuffer, 0))
    })
  }

  function getRecord(seq, cb) {
    const offset = indexes['seq'].tarr[seq]
    log.get(offset, (err, value) => {
      if (err && err.code === 'flumelog:deleted') cb(null, { seq, offset })
      else if (err) cb(err)
      else cb(null, { offset, value, seq })
    })
  }

  function compareAscending(a, b) {
    return b.timestamp > a.timestamp
  }

  function compareDescending(a, b) {
    return a.timestamp > b.timestamp
  }

  function sortedByTimestamp(bitset, descending) {
    updateCacheWithLog()
    const order = descending ? 'descending' : 'ascending'
    if (sortedCache[order].has(bitset)) return sortedCache[order].get(bitset)
    const fpq = new FastPriorityQueue(
      descending ? compareDescending : compareAscending
    )
    bitset.forEach((seq) => {
      fpq.add({
        seq,
        timestamp: indexes['timestamp'].tarr[seq],
      })
    })
    fpq.trim()
    sortedCache[order].set(bitset, fpq)
    return fpq
  }

  function filterRecord(seq, filters, recBufferCache, cb) {
    const seqFilters = filters.get(seq)
    if (!seqFilters) return cb(null, seq)

    getRecord(seq, (err, record) => {
      if (err) return cb(err)

      const recBuffer = record.value
      let ok = true
      if (seqFilters) ok = seqFilters.every((filter) => filter(recBuffer))

      if (ok) {
        recBufferCache[seq] = recBuffer
        cb(null, seq)
      } else cb()
    })
  }

  function sliceResults(sorted, seq, limit) {
    if (sorted.size === 0 || limit <= 0) {
      return []
    } else if (seq === 0 && limit === 1) {
      return [sorted.peek()]
    } else {
      if (seq > 0) {
        sorted = sorted.clone()
        for (let j = 0; j < seq && !sorted.isEmpty(); j++) {
          sorted.poll()
        }
      }
      return sorted.kSmallest(limit || Infinity)
    }
  }

  function getMessagesFromBitsetSlice(
    bitset,
    filters,
    seq,
    limit,
    descending,
    onlyOffset,
    cb
  ) {
    seq = seq || 0

    const sorted = sortedByTimestamp(bitset, descending)
    const resultSize = sorted.size

    // seq -> record buffer
    const recBufferCache = {}

    function processResults(seqs, resultSize) {
      push(
        push.values(seqs),
        push.asyncMap((seq, continueCB) => {
          if (onlyOffset) continueCB(null, indexes['seq'].tarr[seq])
          else getMessage(seq, recBufferCache, continueCB)
        }),
        push.filter((x) => (onlyOffset ? true : x)), // removes deleted messages
        push.collect((err, results) => {
          cb(err, {
            results: results,
            total: resultSize,
          })
        })
      )
    }

    if (filters) {
      function ensureEnoughResults(err, startSeq, seqs) {
        if (err) return cb(err)
        const rawLength = seqs.length
        seqs = seqs.filter((x) => x !== undefined)
        const moreResults = startSeq + seqs.length < sorted.size

        if (seqs.length < limit && moreResults)
          // results were filtered or deleted
          getMoreResults(
            startSeq + rawLength,
            limit - seqs.length,
            seqs,
            (e, seqs) => ensureEnoughResults(e, startSeq + rawLength, seqs)
          )
        else processResults(seqs, resultSize)
      }

      function getMoreResults(startSeq, remaining, seqs, continueCB) {
        const done = multicb({ pluck: 1 })

        // existing results
        for (let i = 0; i < seqs.length; ++i) done()(null, seqs[i])

        const sliced = sliceResults(sorted, startSeq, remaining)
        for (let i = 0; i < sliced.length; ++i)
          filterRecord(sliced[i].seq, filters, recBufferCache, done())

        done(continueCB)
      }

      getMoreResults(seq, limit, [], (err, seqs) =>
        ensureEnoughResults(err, seq, seqs)
      )
    } else {
      const slicedSeqs = sliceResults(sorted, seq, limit).map((s) => s.seq)
      processResults(slicedSeqs, resultSize)
    }
  }

  function countBitsetSlice(bitset, seq, descending) {
    if (!seq) return bitset.size()
    else return bitset.size() - seq
  }

  function paginate(operation, seq, limit, descending, onlyOffset, cb) {
    onReady(() => {
      const start = Date.now()
      executeOperation(operation, (err0, result) => {
        if (err0) return cb(err0)
        const [bitset, filters] = result
        getMessagesFromBitsetSlice(
          bitset,
          filters,
          seq,
          limit,
          descending,
          onlyOffset,
          (err1, answer) => {
            if (err1) cb(err1)
            else {
              answer.duration = Date.now() - start
              if (debugQuery.enabled)
                debugQuery(
                  `paginate(${getNameFromOperation(
                    operation
                  )}), seq: ${seq}, limit: ${limit}: ${
                    answer.duration
                  }ms, total messages: ${answer.total}`.replace(/%/g, '%% ')
                )
              cb(null, answer)
            }
          }
        )
      })
    })
  }

  function all(operation, seq, descending, onlyOffset, cb) {
    onReady(() => {
      const start = Date.now()
      executeOperation(operation, (err0, result) => {
        if (err0) return cb(err0)
        const [bitset, filters] = result
        getMessagesFromBitsetSlice(
          bitset,
          filters,
          seq,
          Infinity,
          descending,
          onlyOffset,
          (err1, answer) => {
            if (err1) cb(err1)
            else {
              answer.duration = Date.now() - start
              if (debugQuery.enabled)
                debugQuery(
                  `all(${getNameFromOperation(operation)}): ${
                    answer.duration
                  }ms, total messages: ${answer.total}`.replace(/%/g, '%% ')
                )
              cb(null, answer.results)
            }
          }
        )
      })
    })
  }

  function count(operation, seq, descending, cb) {
    onReady(() => {
      const start = Date.now()
      executeOperation(operation, (err0, result) => {
        if (err0) return cb(err0)
        const [bitset] = result
        const total = countBitsetSlice(bitset, seq, descending)
        const duration = Date.now() - start
        if (debugQuery.enabled)
          debugQuery(
            `count(${getNameFromOperation(
              operation
            )}): ${duration}ms, total messages: ${total}`.replace(/%/g, '%% ')
          )
        cb(null, total)
      })
    })
  }

  // live will return new messages as they enter the log
  // can be combined with a normal all or paginate first
  function live(op) {
    return pull(
      pullAsync((cb) =>
        onReady(() => {
          executeOperation(op, (err) => cb(err))
        })
      ),
      pull.map(() => {
        let offset = -1
        let seqStream

        function detectOffsetAndSeqStream(ops) {
          ops.forEach((op) => {
            if (
              op.type === 'EQUAL' ||
              op.type === 'INCLUDES' ||
              op.type === 'PREDICATE' ||
              op.type === 'ABSENT'
            ) {
              if (!indexes[op.data.indexName]) offset = -1
              else offset = indexes[op.data.indexName].offset
            } else if (
              op.type === 'AND' ||
              op.type === 'OR' ||
              op.type === 'NOT'
            ) {
              detectOffsetAndSeqStream(op.data)
            } else if (op.type === 'LIVESEQS') {
              if (seqStream)
                throw new Error('Only one seq stream in live supported')
              seqStream = op.stream
            }
          })
        }

        detectOffsetAndSeqStream([op])

        // There are two cases here:
        // - op contains a live seq stream, in which case we let the
        //   seq stream drive new values
        // - op doesn't, in which we let the log stream drive new values

        let recordStream
        if (seqStream) {
          recordStream = pull(
            seqStream,
            pull.asyncMap((seq, cb) => {
              ensureSeqIndexSync(() => {
                getRecord(seq, cb)
              })
            })
          )
        } else {
          const opts =
            offset === -1
              ? { live: true, gt: indexes['seq'].offset }
              : { live: true, gt: offset }
          const logstreamId = Math.ceil(Math.random() * 1000)
          debug(`log.stream #${logstreamId} started, for a live query`)
          recordStream = toPull(log.stream(opts))
        }

        return recordStream
      }),
      pull.flatten(),
      pull.filter((record) => isValueOk([op], record.value)),
      pull.through(() => {
        if (debugQuery.enabled)
          debugQuery(
            `live(${getNameFromOperation(op)}): 1 new msg`.replace(/%/g, '%% ')
          )
      }),
      pull.map((record) => bipf.decode(record.value, 0))
    )
  }

  function reindex(offset, cb) {
    // Find the previous offset and corresponding seq.
    // We need previous because log.stream() is always gt
    let seq = 0
    let prevOffset = 0
    if (offset === 0 || offset === -1) {
      prevOffset = -1
    } else {
      const { tarr } = indexes['seq']
      for (const len = tarr.length; seq < len; ++seq) {
        if (tarr[seq] === offset) break
        else prevOffset = tarr[seq]
      }
    }

    if (prevOffset === 0 && seq === indexes['seq'].tarr.length) {
      // not found
      seq = 1
    }

    function resetIndex(index) {
      if (index.offset >= prevOffset) {
        if (index.count) index.count = seq

        if (index.map) {
          // prefix map pushes to arrays, so we need to clean up
          for (let [prefix, arr] of Object.entries(index.map)) {
            index.map[prefix] = arr.filter((x) => x < seq)
          }
        }

        index.offset = prevOffset
      }
    }

    push(
      push.values(Object.entries(indexes)),
      push.asyncMap(([indexName, index], cb) => {
        if (coreIndexNames.includes(indexName)) return cb()

        if (index.lazy) {
          loadLazyIndex(indexName, (err) => {
            if (err) return cb(err)

            resetIndex(index)
            saveIndex(indexName, index, seq)
            cb()
          })
        } else {
          resetIndex(index)
          saveIndex(indexName, index, seq)
          cb()
        }
      }),
      push.collect((err) => {
        if (err) return cb(err)

        bitsetCache = new WeakMap()
        sortedCache.ascending = new WeakMap()
        sortedCache.descending = new WeakMap()
        cb()
      })
    )
  }

  return {
    onReady,
    paginate,
    all,
    count,
    live,
    status: status.obv,
    reindex,

    // testing
    indexes,
  }
}

},
"JIiAvBspwjfdfeQG9aYaxD+5xVceD3JArLLS2pqM0I8=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.AbstractTokenizer = void 0;
const peek_readable_1 = require("peek-readable");
/**
 * Core tokenizer
 */
class AbstractTokenizer {
    constructor(fileInfo) {
        /**
         * Tokenizer-stream position
         */
        this.position = 0;
        this.numBuffer = new Uint8Array(8);
        this.fileInfo = fileInfo ? fileInfo : {};
    }
    /**
     * Read a token from the tokenizer-stream
     * @param token - The token to read
     * @param position - If provided, the desired position in the tokenizer-stream
     * @returns Promise with token data
     */
    async readToken(token, position = this.position) {
        const uint8Array = Buffer.alloc(token.len);
        const len = await this.readBuffer(uint8Array, { position });
        if (len < token.len)
            throw new peek_readable_1.EndOfStreamError();
        return token.get(uint8Array, 0);
    }
    /**
     * Peek a token from the tokenizer-stream.
     * @param token - Token to peek from the tokenizer-stream.
     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.
     * @returns Promise with token data
     */
    async peekToken(token, position = this.position) {
        const uint8Array = Buffer.alloc(token.len);
        const len = await this.peekBuffer(uint8Array, { position });
        if (len < token.len)
            throw new peek_readable_1.EndOfStreamError();
        return token.get(uint8Array, 0);
    }
    /**
     * Read a numeric token from the stream
     * @param token - Numeric token
     * @returns Promise with number
     */
    async readNumber(token) {
        const len = await this.readBuffer(this.numBuffer, { length: token.len });
        if (len < token.len)
            throw new peek_readable_1.EndOfStreamError();
        return token.get(this.numBuffer, 0);
    }
    /**
     * Read a numeric token from the stream
     * @param token - Numeric token
     * @returns Promise with number
     */
    async peekNumber(token) {
        const len = await this.peekBuffer(this.numBuffer, { length: token.len });
        if (len < token.len)
            throw new peek_readable_1.EndOfStreamError();
        return token.get(this.numBuffer, 0);
    }
    /**
     *  Ignore number of bytes, advances the pointer in under tokenizer-stream.
     * @param length - Number of bytes to ignore
     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available
     */
    async ignore(length) {
        if (this.fileInfo.size !== undefined) {
            const bytesLeft = this.fileInfo.size - this.position;
            if (length > bytesLeft) {
                this.position += bytesLeft;
                return bytesLeft;
            }
        }
        this.position += length;
        return length;
    }
    async close() {
        // empty
    }
    normalizeOptions(uint8Array, options) {
        if (options && options.position !== undefined && options.position < this.position) {
            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');
        }
        if (options) {
            return {
                mayBeLess: options.mayBeLess === true,
                offset: options.offset ? options.offset : 0,
                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),
                position: options.position ? options.position : this.position
            };
        }
        return {
            mayBeLess: false,
            offset: 0,
            length: uint8Array.length,
            position: this.position
        };
    }
}
exports.AbstractTokenizer = AbstractTokenizer;

},
"JNpFV7Uxb5ZrEIrciRhj53M0aQzxKco8nXrzYkR8zhE=":
function (require, module, exports, __dirname, __filename) {
var fs = require('fs')
var uint48be = require('uint48be')
var int53 = require('int53')

/*
  Represent a file, as a table of buffers.
  copy from a range in the file into a buffer
  (may cross buffer boundries)

  Also, write into the file at any point.
  always update the cached buffer after the write.
  (always read a buffer before write, except for appending a new buffer)
*/

function assertInteger (a) {
  if(!Number.isInteger(a))
    throw new Error('expected positive integer, was:'+JSON.stringify(a))
}

var Cache = require('hashlru')

module.exports = function (file, block_size, cache) {
  var cbs = [], br, writing = 0
  cache = cache || Cache(1000)

  function get(i, cb) {
    var c = cache.get(i)
    if(Buffer.isBuffer(c))
      cb(null, c, block_size)
    else if(Array.isArray(cbs[i]))
      cbs[i].push(cb)
    else {
      cbs[i] = [cb]
      file.get(i, function (err, buf, bytes_read) {
        var cb = cbs[i]
        cbs[i] = null
        if(!err) cache.set(i, buf)
        for (var j = 0; j < cb.length; ++j)
          cb[j](err, buf, bytes_read)
      })
    }
  }

  function read(start, end, cb) {
    assertInteger(start);assertInteger(end)
    //check if start & end are part of the same buffer
    var i = Math.floor(start/block_size)
    if(file && end > file.offset.value)
      return cb(new Error('past end:'+start+'-'+end+' < '+file.offset.value), null, 0)
    var bufs = []
    ;(function next (i) {
      var block_start = i*block_size
      get(i, function (err, block, bytes_read) {
        if(err) return cb(err)
        //this is not right.
        if(bytes_read === 0) return cb(new Error('past end'), null, bytes_read)

        var read_start = start - block_start
        var read_end = Math.min(end - block_start, block_size)
        bufs.push(block.slice(read_start, read_end))
        start += (read_end - read_start)

        if (start < end) {
          next(i+1)
        } else {
          var buffer = bufs.length == 1 ? bufs[0] : Buffer.concat(bufs)
          if (!buffer.length)
            return cb(new Error('read an empty buffer at:'+start + ' to ' + end + '\n'+
              JSON.stringify({
                start: start, end: end, i:i,
                bytes_read: bytes_read,
                bufs: bufs
              }))
            )
          cb(null, buffer, bytes_read)
        }
      })
    })(i)

  }

  //start by reading the end of the last block.
  //this must always be kept in memory.

  function readInteger(width, reader) {
    return function (start, cb) {
      var i = Math.floor(start/block_size)
      var _i = start%block_size

      //if the UInt32BE aligns with in a block
      //read directly and it's 3x faster.
      if(_i < block_size - width)
        get(i, function (err, block) {
          if(err) return cb(err)
          var value = reader(block, start%block_size)
          cb(null, value)
        })
      //but handle overlapping reads this easier way
      //instead of messing around with bitwise ops
      else
        read(start, start+width, function (err, buf, bytes_read) {
          if(err) return cb(err)
          var value = reader(buf, 0);
          cb(isNaN(value) ? new Error('Number is too large') : null, value)
        })
    }
  }

  return br = {
    read: read,
    readUInt32BE: readInteger(4, function(b, offset) {
      return b.readUInt32BE(offset)
    }),
    readUInt48BE: readInteger(6, function(b, offset) {
      return uint48be.decode(b, offset)
    }),
    readUInt64BE: readInteger(8, function(b, offset) {
      // int53.readUInt64BE will throw if number is too large
      try {
        return int53.readUInt64BE(b, offset)
      } catch(err) {
        return NaN;
      }
    }),
    size: file && file.size,
    offset: file && file.offset,
    //starting to realize: what I really need is just a lib for
    //relative copies between two arrays of buffers, with a given offset.
    append: function (buf, cb) {
      //write to the end of the file.
      //if successful, copy into cache.
      if(writing++) throw new Error('already appending to this file')
      file.offset.once(function (_offset) {

        var start = _offset
        var b_start = 0
        var i = Math.floor(start/block_size)
        if(i*block_size < _offset) //usually true, unless file length is multiple of block_size
          get(i, function (err) { //this will add the last block to the cache.
            if(err) cb(explain(err, 'precache before append failed'))
            else next()
          })
        else next()

        function next () {
          while(b_start < buf.length) { //start < _offset+buf.length) {
            var block_start = i*block_size
            var b = cache.get(i)
            if(null == b) {
              b = Buffer.alloc(block_size)
              cache.set(i, b)
            }
            //including if set in above if...
            if(Buffer.isBuffer(b)) {
                var len = Math.min(block_size - (start - block_start), block_size)
                buf.copy(b, start - block_start, b_start, b_start + len)
                start += len
                b_start += len
            }
            else if(Array.isArray(cbs[i]))
              throw new Error('should never happen: new block should be initialized, before a read ever happens')
            else {
              start += block_size
            }

            i++
          }

          file.append(buf, function (err, offset) {
            if(err) return cb(err)
            writing = 0
            cb(null, offset)
          })
        }
      })
    },
    /**
     * Writes a buffer directly to a position in the file.
     * This wraps `file.write()` and removes the block cache after the file
     * write finishes to avoid having the item re-cached during the write.
     *
     * @param {buffer} buf - the data to write to the file
     * @param {number} pos - position in the file to write the buffer
     * @param {function} cb - callback that returns any error as an argument
     */
    write: (buf, pos, cb) => {
      const i = Math.floor(pos/block_size)
      file.write(buf, pos, (err) => {
        cache.remove(i)
        cb(err)
      })
    },
    //we arn't specifically clearing the buffers,
    //but they should get updated anyway.
    truncate: file ? file.truncate : function (len, cb) {
      cb()
    }
  }
}


},
"JTC/Fj0gcy4Hk7lDAtqjl5ZMxM7/P87Ec2+rcXG5sOM=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.EndOfStreamError = exports.defaultMessages = void 0;
exports.defaultMessages = 'End-Of-Stream';
/**
 * Thrown on read operation of the end of file or stream has been reached
 */
class EndOfStreamError extends Error {
    constructor() {
        super(exports.defaultMessages);
    }
}
exports.EndOfStreamError = EndOfStreamError;

},
"JZKVVZFwolTe6of+EmBC7QR4zbX38nI6VWeZwpZxj3U=":
function (require, module, exports, __dirname, __filename) {
var pull = require('pull-stream/pull')
var Cat = require('pull-cat')
var Once = require('pull-stream/sources/once')

module.exports = function (createSource, createLive) {

  return function (opts) {
      opts = opts || {}
      var isOld = opts.old !== false
      var isLive = opts.live === true || opts.old === false

      if(!isLive && !isOld)
        throw new Error('ls with neither old or new is empty')

      if(isLive && isOld)
        return Cat([
          createSource(opts),
          opts.sync === false ? null : Once({sync: true}),
          createLive(opts)
        ])
      else if(!isLive)
        return createSource(opts)
      else
        return createLive(opts)
  }
}







},
"JZPGDHJrp9d7qlcUmyXIpEwjjmizZCwL61YgfUu6FEo=":
function (require, module, exports, __dirname, __filename) {
'use strict';

function isHighSurrogate(codePoint) {
  return codePoint >= 0xd800 && codePoint <= 0xdbff;
}

function isLowSurrogate(codePoint) {
  return codePoint >= 0xdc00 && codePoint <= 0xdfff;
}

// Truncate string by size in bytes
module.exports = function truncate(getLength, string, byteLength) {
  if (typeof string !== "string") {
    throw new Error("Input must be string");
  }

  var charLength = string.length;
  var curByteLength = 0;
  var codePoint;
  var segment;

  for (var i = 0; i < charLength; i += 1) {
    codePoint = string.charCodeAt(i);
    segment = string[i];

    if (isHighSurrogate(codePoint) && isLowSurrogate(string.charCodeAt(i + 1))) {
      i += 1;
      segment += string[i];
    }

    curByteLength += getLength(segment);

    if (curByteLength === byteLength) {
      return string.slice(0, i + 1);
    }
    else if (curByteLength > byteLength) {
      return string.slice(0, i - segment.length + 1);
    }
  }

  return string;
};


},
"JczFU1xaSOlfDIj/bfki3cAkCh3PBIunWfLagGh0jBk=":
function (require, module, exports, __dirname, __filename) {
module.exports = process.nextTick

},
"JdmrN6fAzt50f1H7c9iV5a4yNrlFGCj2h+jn6RgK9aw=":
function (require, module, exports, __dirname, __filename) {


module.exports = function (onPause) {

  var wait, read, paused

  function reader (_read) {
    read = _read
    return function (abort, cb) {
      if(!paused) read(abort, cb)
      else        wait = [abort, cb]
    }
  }

  reader.pause = function () {
    if(paused) return
    paused = true
    onPause && onPause(paused)
  }

  reader.resume = function () {
    if(!paused) return
    paused = false
    onPause && onPause(paused)
    if(wait) {
      var _wait = wait
      wait = null
      read(_wait[0], _wait[1])
    }
  }

  return reader

}



},
"Jipyk9wcme+vGp+ggtaUWfkrlQCNoaN9cZ0KQwDd/wQ=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
const secret_stack_decorators_1 = require("secret-stack-decorators");
const broadcast = require('broadcast-stream');
const Ref = require('ssb-ref');
const Keys = require('ssb-keys');
const Notify = require('pull-notify');
const debug = require('debug')('ssb:lan');
const NORMAL_PORT = require('../port');
const LEGACY_PORT = 8008;
let LAN = class LAN {
    constructor(ssb, config) {
        var _a;
        this.readLegacy = (buf) => {
            if (buf.loopback)
                return;
            const address = buf.toString();
            const peerKey = Ref.getKeyFromAddress(address);
            if (peerKey && peerKey !== this.ssb.id) {
                this.notifyDiscovery({ address, verified: false });
            }
        };
        this.readNormal = (buf) => {
            const ciphertext = buf.slice(0, buf.length - 64);
            const sig = buf.slice(buf.length - 64, buf.length);
            let address;
            try {
                const obj = Keys.secretUnbox(ciphertext, this.caps);
                address = obj.address;
            }
            catch (err) {
                debug('failed to interpret broadcasted message: %s', buf.toString('hex'));
                return;
            }
            const peerKey = Ref.getKeyFromAddress(address);
            if (!peerKey) {
                debug('failed to parse address from broadcasted message: %s', buf.toString('hex'));
                return;
            }
            if (peerKey === this.ssb.id) {
                return;
            }
            const b64sig = sig.toString('base64') + '.sig.ed25519';
            const obj = { address, signature: b64sig };
            const verified = Keys.verifyObj({ public: peerKey }, obj);
            this.notifyDiscovery({ address, verified });
        };
        this.writeBoth = () => {
            this.writeLegacy();
            this.writeNormal();
        };
        this.start = () => {
            var _a, _b;
            try {
                this.normalBroadcast = broadcast(NORMAL_PORT);
            }
            catch (err) {
                debug('LAN broadcast turned off because: %s', err);
                this.normalBroadcast = void 0;
            }
            try {
                this.legacyBroadcast = this.legacyEnabled
                    ? broadcast(LEGACY_PORT)
                    : void 0;
            }
            catch (err) {
                debug('legacy broadcast turned off because: %s', err);
                this.legacyBroadcast = void 0;
            }
            if (this.normalBroadcast)
                this.normalBroadcast.on('data', this.readNormal);
            if (this.legacyBroadcast)
                this.legacyBroadcast.on('data', this.readLegacy);
            this.writeBoth();
            this.int = setInterval(this.writeBoth, 2e3);
            (_b = (_a = this.int) === null || _a === void 0 ? void 0 : _a.unref) === null || _b === void 0 ? void 0 : _b.call(_a);
            const that = this;
            this.ssb.close.hook(function (fn, args) {
                that.stop();
                fn.apply(this, args);
            });
        };
        this.stop = () => {
            var _a, _b;
            clearInterval(this.int);
            (_a = this.normalBroadcast) === null || _a === void 0 ? void 0 : _a.close();
            this.normalBroadcast = void 0;
            (_b = this.legacyBroadcast) === null || _b === void 0 ? void 0 : _b.close();
            this.legacyBroadcast = void 0;
        };
        this.discoveredPeers = () => {
            return this.notifyDiscovery.listen();
        };
        this.ssb = ssb;
        this.notifyDiscovery = Notify();
        this.caps = Buffer.from(config.caps.shs, 'base64');
        this.legacyEnabled = ((_a = config.lan) === null || _a === void 0 ? void 0 : _a.legacy) !== false;
    }
    writeLegacy() {
        var _a;
        if (!this.legacyBroadcast)
            return;
        const address = (_a = this.ssb.getAddress('private')) !== null && _a !== void 0 ? _a : this.ssb.getAddress('local');
        if (address)
            this.legacyBroadcast.write(address);
    }
    writeNormal() {
        var _a;
        if (!this.normalBroadcast)
            return;
        const address = (_a = this.ssb.getAddress('private')) !== null && _a !== void 0 ? _a : this.ssb.getAddress('local');
        if (address) {
            const ciphertext = Keys.secretBox({ address }, this.caps);
            const b64sig = Keys.signObj(this.ssb.keys, { address }).signature;
            const sig = Buffer.from(b64sig.replace(/\.sig\.ed25519$/, ''), 'base64');
            const payload = Buffer.concat([ciphertext, sig]);
            this.normalBroadcast.write(payload);
        }
    }
};
__decorate([
    (0, secret_stack_decorators_1.muxrpc)('sync')
], LAN.prototype, "start", void 0);
__decorate([
    (0, secret_stack_decorators_1.muxrpc)('sync')
], LAN.prototype, "stop", void 0);
__decorate([
    (0, secret_stack_decorators_1.muxrpc)('source')
], LAN.prototype, "discoveredPeers", void 0);
LAN = __decorate([
    (0, secret_stack_decorators_1.plugin)('1.1.0')
], LAN);
module.exports = LAN;

},
"Jwj2rCfgJw0NHt3AvO4xbjvr7f5LsUZc5tTrf2iQ3Vo=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const pull = require('pull-stream')
// wrap pull streams around packet-stream's weird streams.

function once (fn) {
  let done = false
  return (err, val) => {
    if (done) return
    done = true
    fn(err, val)
  }
}

function duplex (weird, _done) {
  const buffer = []
  let ended = false
  let waiting
  let abort

  const done = once((err, v) => {
    if (_done) _done(err, v)
    // deallocate
    weird = null
    _done = null
    waiting = null
    if (abort) abort(err || true, () => {})
  })

  weird.read = function (data, end) {
    ended = ended || end

    if (waiting) {
      const cb = waiting
      waiting = null
      cb(ended, data)
    } else if (!ended) {
      buffer.push(data)
    }

    if (ended) {
      done(ended !== true ? ended : null)
    }
  }

  return {
    source (abort, cb) {
      if (abort) {
        if (weird) weird.write(null, abort)
        cb(abort)
        done(abort !== true ? abort : null)
      } else if (buffer.length) {
        cb(null, buffer.shift())
      } else if (ended) {
        cb(ended)
      } else {
        waiting = cb
      }
    },
    sink (read) {
      if (ended) {
        abort = null
        return read(ended, () => {})
      }
      abort = read
      pull.drain((data) => {
        // TODO: make this should only happen on a UNIPLEX stream.
        if (ended) return false
        weird.write(data)
      }, (err) => {
        if (weird && !weird.writeEnd) {
          weird.write(null, err || true)
        }
        if (done) done(err)
      })(read)
    }
  }
}

function uniplex (s, done) {
  return duplex(s, (err) => {
    if (!s.writeEnd) s.write(null, err || true)
    if (done) done(err)
  })
}

function source (s) {
  return uniplex(s).source
}

function sink (s, done) {
  return uniplex(s, done).sink
}

module.exports = duplex
module.exports.source = source
module.exports.sink = sink
module.exports.duplex = duplex

},
"Jz6VhAuWsvtxE+LasoUSSdn52Ibbx7Z0NYFJtuHv76g=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.wordsToKeys = exports.keysToWords = void 0;
var bip39 = require("bip39");
var chloride = require('chloride');
function keysToWords(keys) {
    if (keys.curve !== 'ed25519')
        throw new Error('only ed25519 is supported');
    if (!keys.public)
        throw new Error('keys object is missing .public field');
    if (!keys.private)
        throw new Error('keys object is missing .private field');
    var pub = Buffer.from(keys.public.replace(/\.ed25519$/, ''), 'base64');
    var priv = Buffer.from(keys.private.replace(/\.ed25519$/, ''), 'base64');
    if (pub.length !== 32)
        throw new Error('public should be exactly 32 bytes');
    if (priv.length !== 64)
        throw new Error('private should be exactly 64 bytes');
    if (pub.compare(priv, 32, 64, 0, 32) !== 0) {
        throw new Error('public ed2519 key must be embedded within private key');
    }
    var seed = priv.slice(0, 32);
    var words = bip39.entropyToMnemonic(seed);
    return words;
}
exports.keysToWords = keysToWords;
function wordsToKeys(words) {
    var wordArr = words.trim().split(/\s+/g);
    var amount = wordArr.length;
    if (amount < 24 || amount > 48)
        throw new Error('there should be 24 words');
    var fixedWords = wordArr.slice(0, 24).join(' ');
    if (!bip39.validateMnemonic(fixedWords))
        throw new Error('invalid words');
    var seed = Buffer.from(bip39.mnemonicToEntropy(fixedWords), 'hex');
    var _a = chloride.crypto_sign_seed_keypair(seed), publicKey = _a.publicKey, secretKey = _a.secretKey;
    var _public = publicKey.toString('base64') + '.ed25519';
    var _private = secretKey.toString('base64') + '.ed25519';
    var keys = {
        curve: 'ed25519',
        public: _public,
        private: _private,
        id: '@' + _public,
    };
    return keys;
}
exports.wordsToKeys = wordsToKeys;

},
"K1cNFqtlGOBiwNIxcnqMaT1oKNvJUTxlHDxw61tnn6I=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN
var AbstractChainedBatch = require('abstract-leveldown').AbstractChainedBatch
var AbstractIterator = require('abstract-leveldown').AbstractIterator
var inherits = require('inherits')
var Codec = require('level-codec')
var EncodingError = require('level-errors').EncodingError
var rangeMethods = ['approximateSize', 'compactRange']

module.exports = DB.default = DB

function DB (db, opts) {
  if (!(this instanceof DB)) return new DB(db, opts)

  var manifest = db.supports || {}
  var additionalMethods = manifest.additionalMethods || {}

  AbstractLevelDOWN.call(this, manifest)

  this.supports.encodings = true
  this.supports.additionalMethods = {}

  rangeMethods.forEach(function (m) {
    // TODO (future major): remove this fallback
    var fallback = typeof db[m] === 'function'

    if (additionalMethods[m] || fallback) {
      this.supports.additionalMethods[m] = true

      this[m] = function (start, end, opts, cb) {
        start = this.codec.encodeKey(start, opts)
        end = this.codec.encodeKey(end, opts)
        return this.db[m](start, end, opts, cb)
      }
    }
  }, this)

  opts = opts || {}
  if (typeof opts.keyEncoding === 'undefined') opts.keyEncoding = 'utf8'
  if (typeof opts.valueEncoding === 'undefined') opts.valueEncoding = 'utf8'

  this.db = db
  this.codec = new Codec(opts)
}

inherits(DB, AbstractLevelDOWN)

DB.prototype.type = 'encoding-down'

DB.prototype._serializeKey =
DB.prototype._serializeValue = function (datum) {
  return datum
}

DB.prototype._open = function (opts, cb) {
  this.db.open(opts, cb)
}

DB.prototype._close = function (cb) {
  this.db.close(cb)
}

DB.prototype._put = function (key, value, opts, cb) {
  key = this.codec.encodeKey(key, opts)
  value = this.codec.encodeValue(value, opts)
  this.db.put(key, value, opts, cb)
}

DB.prototype._get = function (key, opts, cb) {
  var self = this
  key = this.codec.encodeKey(key, opts)
  opts.asBuffer = this.codec.valueAsBuffer(opts)
  this.db.get(key, opts, function (err, value) {
    if (err) return cb(err)
    try {
      value = self.codec.decodeValue(value, opts)
    } catch (err) {
      return cb(new EncodingError(err))
    }
    cb(null, value)
  })
}

DB.prototype._del = function (key, opts, cb) {
  key = this.codec.encodeKey(key, opts)
  this.db.del(key, opts, cb)
}

DB.prototype._chainedBatch = function () {
  return new Batch(this)
}

DB.prototype._batch = function (ops, opts, cb) {
  ops = this.codec.encodeBatch(ops, opts)
  this.db.batch(ops, opts, cb)
}

DB.prototype._iterator = function (opts) {
  opts.keyAsBuffer = this.codec.keyAsBuffer(opts)
  opts.valueAsBuffer = this.codec.valueAsBuffer(opts)
  return new Iterator(this, opts)
}

DB.prototype._clear = function (opts, callback) {
  opts = this.codec.encodeLtgt(opts)
  this.db.clear(opts, callback)
}

function Iterator (db, opts) {
  AbstractIterator.call(this, db)
  this.codec = db.codec
  this.keys = opts.keys
  this.values = opts.values
  this.opts = this.codec.encodeLtgt(opts)
  this.it = db.db.iterator(this.opts)
}

inherits(Iterator, AbstractIterator)

Iterator.prototype._next = function (cb) {
  var self = this
  this.it.next(function (err, key, value) {
    if (err) return cb(err)
    try {
      if (self.keys && typeof key !== 'undefined') {
        key = self.codec.decodeKey(key, self.opts)
      } else {
        key = undefined
      }

      if (self.values && typeof value !== 'undefined') {
        value = self.codec.decodeValue(value, self.opts)
      } else {
        value = undefined
      }
    } catch (err) {
      return cb(new EncodingError(err))
    }
    cb(null, key, value)
  })
}

Iterator.prototype._seek = function (key) {
  key = this.codec.encodeKey(key, this.opts)
  this.it.seek(key)
}

Iterator.prototype._end = function (cb) {
  this.it.end(cb)
}

function Batch (db, codec) {
  AbstractChainedBatch.call(this, db)
  this.codec = db.codec
  this.batch = db.db.batch()
}

inherits(Batch, AbstractChainedBatch)

Batch.prototype._put = function (key, value) {
  key = this.codec.encodeKey(key)
  value = this.codec.encodeValue(value)
  this.batch.put(key, value)
}

Batch.prototype._del = function (key) {
  key = this.codec.encodeKey(key)
  this.batch.del(key)
}

Batch.prototype._clear = function () {
  this.batch.clear()
}

Batch.prototype._write = function (opts, cb) {
  this.batch.write(opts, cb)
}

},
"K3OiX0hdGM37TALUd22PFuE3iR3ful7ryRkaTyMDD/c=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var truncate = require("./lib/truncate");
var getLength = Buffer.byteLength.bind(Buffer);
module.exports = truncate.bind(null, getLength);

},
"K4U/gwpEILfX6/S+ODXPSq1xnOum4jqZ3Tzyy6eJoeE=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const Obv = require('obz')

module.exports = function Status() {
  const indexesStatus = {}
  const indexesLastTime = {}
  const obv = Obv()
  obv.set(indexesStatus)
  const EMIT_INTERVAL = 1000 // ms
  const PRUNE_INTERVAL = 2000 // ms
  let i = 0
  let iTimer = 0
  let timer = null

  function pruneStatus() {
    const now = Date.now()
    for (const indexName in indexesStatus) {
      if (indexesLastTime[indexName] + PRUNE_INTERVAL < now) {
        delete indexesStatus[indexName]
      }
    }
  }

  function setTimer() {
    // Turn on
    timer = setInterval(() => {
      if (i === iTimer) {
        // Turn off because nothing has been updated recently
        clearInterval(timer)
        timer = null
        i = iTimer = 0
      } else {
        iTimer = i
        pruneStatus()
        obv.set(indexesStatus)
      }
    }, EMIT_INTERVAL)
    if (timer.unref) timer.unref()
  }

  function batchUpdate(indexes, names) {
    const now = Date.now()
    for (const indexName of names) {
      indexesStatus[indexName] = indexes[indexName].offset
      indexesLastTime[indexName] = now
    }

    ++i
    if (!timer) {
      iTimer = i
      pruneStatus()
      obv.set(indexesStatus)
      setTimer()
    }
  }

  return {
    obv,
    batchUpdate,
  }
}

},
"KHT2zwAwGOe0diYUS598siZKhRnHGqq4hWKBWyQW09I=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var origSymbol = typeof Symbol !== 'undefined' && Symbol;
var hasSymbolSham = require('./shams');

module.exports = function hasNativeSymbols() {
	if (typeof origSymbol !== 'function') { return false; }
	if (typeof Symbol !== 'function') { return false; }
	if (typeof origSymbol('foo') !== 'symbol') { return false; }
	if (typeof Symbol('bar') !== 'symbol') { return false; }

	return hasSymbolSham();
};

},
"KID55Erb5JNu50aaP7V7PIxQcAyvG1EUFfmvEmafO6g=":
function (require, module, exports, __dirname, __filename) {
'use strict'
/**
  ### `source(socket)`

  Create a pull-stream `Source` that will read data from the `socket`.

  <<< examples/read.js

**/
var Buffer = require('safe-buffer').Buffer;

// copied from github.com/feross/buffer
// Some ArrayBuffers are not passing the instanceof check, so we need to do a bit more work :(
function isArrayBuffer (obj) {
  return obj instanceof ArrayBuffer ||
    (obj != null && obj.constructor != null && obj.constructor.name === 'ArrayBuffer' &&
      typeof obj.byteLength === 'number')
}

module.exports = function(socket, cb) {
  var buffer = [];
  var receiver;
  var ended;
  var started = false;
  socket.addEventListener('message', function(evt) {
    var data = evt.data;
    if (isArrayBuffer(data)) {
      data = Buffer.from(data);
    }

    if (receiver) {
      return receiver(null, data);
    }

    buffer.push(data);
  });

  socket.addEventListener('close', function(evt) {
    if (ended) return
    if (receiver) {
      receiver(ended = true)
    }
  });

  socket.addEventListener('error', function (evt) {
    if (ended) return;
    ended = evt;
    if(!started) {
      started = true
      cb && cb(evt.error)
    }
    if (receiver) {
      receiver(ended.error)
    }
  });

  socket.addEventListener('open', function (evt) {
    if(started || ended) return
    started = true
  })

  function read(abort, cb) {
    receiver = null;

    //if stream has already ended.
    if (ended)
      return cb(ended);

    // if ended, abort
    else if (abort) {
      //this will callback when socket closes
      receiver = cb
      socket.close()
    }

    // return data, if any
    else if(buffer.length > 0)
      cb(null, buffer.shift());

    // wait for more data (or end)
    else
      receiver = cb;

  };

  return read;
};

},
"KPtuL0Xd6xLgTpL0WOseyTJ5g3IUh8NC7yadL+Apq2Y=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fromStream = exports.fromBuffer = exports.EndOfStreamError = exports.fromFile = void 0;
const fs = require("./FsPromise");
const core = require("./core");
var FileTokenizer_1 = require("./FileTokenizer");
Object.defineProperty(exports, "fromFile", { enumerable: true, get: function () { return FileTokenizer_1.fromFile; } });
var core_1 = require("./core");
Object.defineProperty(exports, "EndOfStreamError", { enumerable: true, get: function () { return core_1.EndOfStreamError; } });
Object.defineProperty(exports, "fromBuffer", { enumerable: true, get: function () { return core_1.fromBuffer; } });
/**
 * Construct ReadStreamTokenizer from given Stream.
 * Will set fileSize, if provided given Stream has set the .path property.
 * @param stream - Node.js Stream.Readable
 * @param fileInfo - Pass additional file information to the tokenizer
 * @returns Tokenizer
 */
async function fromStream(stream, fileInfo) {
    fileInfo = fileInfo ? fileInfo : {};
    if (stream.path) {
        const stat = await fs.stat(stream.path);
        fileInfo.path = stream.path;
        fileInfo.size = stat.size;
    }
    return core.fromStream(stream, fileInfo);
}
exports.fromStream = fromStream;

},
"KTFBBqPJiD+ipt+uIZq+21hHyhbKzxOGf7LKfekqoMo=":
function (require, module, exports, __dirname, __filename) {
const IdbKvStore = require('idb-kv-store')

function getStoreAndKey(filename) {
  const parts = filename.split('/')
  const key = parts.pop()
  const storename = parts.join('/')
  const store = new IdbKvStore(storename, { disableBroadcast: true })
  return { store, key }
}

function isUint8Array(value) {
  return toString.call(value).indexOf('Uint8Array') !== -1
}

module.exports = {
  readFile: function(filename, opts, cb) {
    if (!cb) cb = opts
    const { store, key } = getStoreAndKey(filename)
    const storeGet = store.get.bind(store)
    storeGet(key, (err, value) => {
      if (err) return cb(err)
      else cb(null, isUint8Array(value) ? Buffer.from(value) : value)
    })
  },
  writeFile: function(filename, value, opts, cb) {
    if (!cb) cb = opts

    const { store, key } = getStoreAndKey(filename)
    return store.set.bind(store)(key, value, cb)
  }
}

},
"KTuLg9BprAdeeu1VSnlH1oabcpcDJWgLTe3Zc/+2Mlc=":
function (require, module, exports, __dirname, __filename) {
var looper = require('looper')
module.exports = function (map, width, inOrder) {
  inOrder = inOrder === undefined ? true : inOrder
  var reading = false, abort
  return function (read) {
    var i = 0, j = 0, last = 0
    var seen = [], started = false, ended = false, _cb, error

    function drain () {
      if(_cb) {
        var cb = _cb
        if(error) {
          _cb = null
          return cb(error)
        }
        if(Object.hasOwnProperty.call(seen, j)) {
          _cb = null
          var data = seen[j]; delete seen[j]; j++
          cb(null, data)
          if(width) start()
        } else if(j >= last && ended) {
          _cb = null
          cb(ended)
        }
      }
    }

    var start = looper(function () {
      started = true
      if(ended) return drain()
      if(reading || width && (i - width >= j)) return
      reading = true
      read(abort, function (end, data) {
        reading = false
        if(end) {
          last = i; ended = end
          drain()
        } else {
          var k = i++

          map(data, function (err, data) {
            if (inOrder) seen[k] = data
            else seen.push(data)
            if(err) error = err
            drain()
          })

          if(!ended)
            start()

        }
      })
    })

    return function (_abort, cb) {
      if(_abort)
        read(ended = abort = _abort, function (err) {
          if(cb) return cb(err)
        })
      else {
        _cb = cb
        if(!started) start()
        drain()
      }
    }
  }
}


},
"KUTx08jF1cXgfnww1svvX8N0QLfHPeR66zf6hCTwS/E=":
function (require, module, exports, __dirname, __filename) {
var Stream = require('stream');
if (process.env.READABLE_STREAM === 'disable' && Stream) {
  module.exports = Stream.Readable;
  Object.assign(module.exports, Stream);
  module.exports.Stream = Stream;
} else {
  exports = module.exports = require('./lib/_stream_readable.js');
  exports.Stream = Stream || exports;
  exports.Readable = exports;
  exports.Writable = require('./lib/_stream_writable.js');
  exports.Duplex = require('./lib/_stream_duplex.js');
  exports.Transform = require('./lib/_stream_transform.js');
  exports.PassThrough = require('./lib/_stream_passthrough.js');
  exports.finished = require('./lib/internal/streams/end-of-stream.js');
  exports.pipeline = require('./lib/internal/streams/pipeline.js');
}

},
"KcAdw1Y02Jmq/A95ch7hazXdngoAqwNcmjwsovDiIwY=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const fs = require('fs')
const pull = require('pull-stream')
const drainGently = require('pull-drain-gently')
const FlumeLog = require('flumelog-offset')
const AsyncLog = require('async-append-only-log')
const bipf = require('bipf')
const Obv = require('obz')
const rimraf = require('rimraf')
const jsonCodec = require('flumecodec/json')
const debug = require('debug')('ssb:db2:migrate')
const {
  BLOCK_SIZE,
  flumePath,
  oldLogPath,
  newLogPath,
  tooHotOpts,
} = require('./defaults')
const seekers = require('./seekers')

function fileExists(filename) {
  return fs.existsSync(filename) && fs.statSync(filename).size > 0
}

function makeFileExistsObv(filename) {
  const obv = Obv()
  obv.set(fileExists(filename))
  return obv
}

// Forked from flumecodec because we have to support
// bendy butt messages which may contain Buffers
const jsonCodecForSSBFixtures = {
  encode: JSON.stringify,
  decode(str) {
    const parsed = JSON.parse(str)
    const content = parsed.value.content
    if (content.type === 'metafeed/add/derived') {
      for (const key of Object.keys(content)) {
        const field = content[key]
        if (field.type === 'Buffer' && Array.isArray(field.data)) {
          content[key] = Buffer.from(field.data)
        }
      }
    }
    return parsed
  },
  buffer: false,
  type: 'json',
}

function getOldLog(sbot, config) {
  const oldLog = FlumeLog(oldLogPath(config.path), {
    blockSize: BLOCK_SIZE,
    codec: config.db2._ssbFixtures ? jsonCodecForSSBFixtures : jsonCodec,
  })
  const opts = {
    keys: true,
    seqs: true,
    value: true,
    sync: false,
    reverse: false,
    codec: config.db2._ssbFixtures ? jsonCodecForSSBFixtures : jsonCodec,
  }
  const getStream = (moreOpts) =>
    oldLog.stream({ old: true, live: false, ...opts, ...moreOpts })
  const getLiveStream = () => oldLog.stream({ old: false, live: true, ...opts })
  const getSize = () => oldLog.since.value
  // FIXME: when we do #129, should replace Obv() with something from db.js
  const newMsgObv = sbot.post ? sbot.post : Obv()
  return { getStream, getLiveStream, getSize, newMsgObv }
}

function toBIPF(msg) {
  const len = bipf.encodingLength(msg)
  const buf = Buffer.alloc(len)
  bipf.encode(msg, buf, 0)
  return buf
}

function scanAndCount(pushstream, cb) {
  let count = 0
  pushstream.pipe({
    paused: false,
    write: () => {
      count += 1
    },
    end: function (err) {
      cb(null, count)
    },
  })
}

function guardAgainstDecryptedMsg(msg) {
  if (
    (msg && msg.meta && msg.meta.private) ||
    (msg && msg.value && msg.value.meta && msg.value.meta.private)
  ) {
    return new Error(
      'ssb:db2:migrate was about to write ' +
        'private message *decrypted* to disk'
    )
  }
}

/**
 * Fallback algorithm that does the same as findMigratedOffset, but is slow
 * because it does a scan of BOTH new log and old log. First, it scans the new
 * log to count how many msgs there exists, then it scans the old log to match
 * that count.
 */
function inefficientFindMigratedOffset(newLog, oldLog, cb) {
  scanAndCount(newLog.stream({ gte: 0, decrypt: false }), (err, msgCount) => {
    if (err) return cb(err) // TODO: might need an explain() here
    if (!msgCount) return cb(null, -1)

    let result = -1
    pull(
      oldLog.getStream({ gte: 0 }),
      pull.take(msgCount),
      pull.drain(
        (x) => {
          result = x.seq
        },
        (err) => {
          if (err) return cb(err) // TODO: might need an explain() here
          cb(null, result)
        }
      )
    )
  })
}

function findMigratedOffset(sbot, oldLog, newLog, cb) {
  if (!sbot.get) {
    debug('running in inefficient mode because no ssb-db is installed')
    inefficientFindMigratedOffset(newLog, oldLog, cb)
    return
  }

  newLog.onDrain(() => {
    if (typeof newLog.since.value !== 'number' || newLog.since.value < 0) {
      cb(null, -1)
      return
    }

    const offsetInNewLog = newLog.since.value
    newLog.get(offsetInNewLog, (err, buf) => {
      if (err) return cb(err) // TODO: might need an explain() here

      const msgKey = bipf.decode(buf, seekers.seekKey(buf))
      sbot.get(msgKey, (err2, msg, offsetInOldLog) => {
        if (err2) return cb(err2) // TODO: might need an explain() here

        if (typeof offsetInOldLog === 'number') {
          cb(null, offsetInOldLog)
        } else {
          // NOTE! Currently all versions of ssb-db do not support returning
          // byte offset, so this case will trigger always! The only way to
          // make ssb-db support it is to hack it with patch-package. This is
          // fine temporarily because the only change is faster performance.
          debug(
            'running in inefficient mode because your ssb-db ' +
              'does not support returning byte offset from ssb.get()'
          )
          inefficientFindMigratedOffset(newLog, oldLog, cb)
        }
      })
    })
  })
}

exports.name = 'db2migrate'

exports.version = '1.9.1'

exports.manifest = {
  start: 'sync',
  doesOldLogExist: 'sync',
  synchronized: 'async',
}

exports.init = function init(sbot, config) {
  config = config || {}
  config.db2 = config.db2 || {}
  const oldLogExists = makeFileExistsObv(oldLogPath(config.path))

  /**
   * Boolean obv that indicates whether the new log is synced with the old log.
   */
  const synchronized = Obv()
  synchronized.set(true) // assume true until we `start()`

  let started = false
  let hasCloseHook = false
  let retryPeriod = 250
  let drainAborter = null
  let liveProgressInterval = null

  function oldLogMissingThenRetry(retryFn) {
    if (!hasCloseHook) {
      sbot.close.hook(function (fn, args) {
        stop()
        fn.apply(this, args)
      })
      hasCloseHook = true
    }
    oldLogExists.set(fileExists(oldLogPath(config.path)))
    if (oldLogExists.value === false) {
      retryPeriod = Math.min(retryPeriod * 2, 8000)
      setTimeout(retryFn, retryPeriod).unref()
      return true
    } else {
      return false
    }
  }

  function guardAgainstMigrationDangers() {
    if (sbot.messagesByType && config.db2.dangerouslyKillFlumeWhenMigrated) {
      return new Error(
        'we cannot have ssb-db installed simultaneously with ' +
          'config.db2.dangerouslyKillFlumeWhenMigrated enabled'
      )
    }
  }

  if (config.db2 && config.db2.automigrate) {
    start()
  }

  function stop() {
    started = false
    if (drainAborter) {
      drainAborter.abort()
      drainAborter = null
    }
    if (liveProgressInterval) {
      clearInterval(liveProgressInterval)
      liveProgressInterval = null
    }
  }

  function start() {
    if (started) return
    const guard = guardAgainstMigrationDangers()
    if (guard) throw guard
    if (oldLogMissingThenRetry(start)) return
    started = true
    debug('started')

    if (sbot.db) sbot.db.setStateFeedsReady('migrating')
    synchronized.set(false)

    const oldLog = getOldLog(sbot, config)
    const newLog =
      sbot.db && sbot.db.getLog() && sbot.db.getLog().stream
        ? sbot.db.getLog()
        : AsyncLog(newLogPath(config.path), { blockSize: BLOCK_SIZE })

    let migratedSize = 0

    function updateMigratedSizeAndPluck(obj) {
      // "seq" in flumedb is an abstract num, here it actually means "offset"
      migratedSize = obj.seq
      return obj.value
    }

    let previousProgress = -1
    function emitProgressEvent() {
      const oldSize = oldLog.getSize()
      if (migratedSize === 0 && oldSize === 0) {
        sbot.emit('ssb:db2:migrate:progress', 1)
        return
      }
      if (!oldSize) return // avoid division by zero
      const progress = Math.min(migratedSize / oldSize, 1)
      if (progress === 1 || progress !== previousProgress) {
        sbot.emit('ssb:db2:migrate:progress', progress)
        previousProgress = progress
      }
    }

    let dataTransferred = 0 // FIXME: does this only work if the new log is empty?
    function writeToNewLog(data, cb) {
      dataTransferred += data.length
      // FIXME: could we use log.add since it already converts to BIPF?
      // FIXME: see also issue #16
      newLog.append(data, () => {})
      if (dataTransferred % BLOCK_SIZE === 0) newLog.onDrain(cb)
      else cb()
    }

    function migrateLive() {
      let liveMsgCount = 0
      // Setup periodic progress event and `debug` reporter of live migrate
      liveProgressInterval = setInterval(() => {
        emitProgressEvent()
        if (liveMsgCount > 0) {
          debug('%d msgs synced from old log to new log', liveMsgCount)
          liveMsgCount = 0
        }
      }, 3000).unref()

      // Setup migration of live new msgs identified on the old log
      oldLog.newMsgObv((msg) => {
        const guard = guardAgainstDecryptedMsg(msg)
        if (guard) throw guard

        writeToNewLog(toBIPF(msg), () => {
          liveMsgCount++
        })
      })
    }

    findMigratedOffset(sbot, oldLog, newLog, (err, migratedOffset) => {
      if (err) return console.error(err)

      if (migratedOffset >= 0) {
        debug('continue migrating from previous offset %s', migratedOffset)
        migratedSize = migratedOffset
      }
      emitProgressEvent()

      let msgCountOldLog = 0
      function op() {
        msgCountOldLog++
      }

      const progressInterval = setInterval(emitProgressEvent, 3000)
      function opDone(err) {
        if (err) return console.error(err)

        // Inform the other parts of ssb-db2 that migration is done
        function doneMigrating() {
          clearInterval(progressInterval)
          emitProgressEvent()
          synchronized.set(true)
          debug('done migrating %s msgs from old log', msgCountOldLog)
          drainAborter = null
        }

        if (config.db2.dangerouslyKillFlumeWhenMigrated) {
          rimraf(flumePath(config.path), (err) => {
            if (err) return console.error(err)
            if (sbot.db) {
              sbot.db.loadStateFeeds(() => {
                sbot.db.setStateFeedsReady(true)
                oldLogExists.set(false)
                doneMigrating()
              })
            } else {
              oldLogExists.set(false)
              doneMigrating()
            }
          })
        } else {
          if (sbot.db) {
            sbot.db.loadStateFeeds(() => {
              sbot.db.setStateFeedsReady(true)
            })
          }
          doneMigrating()
          migrateLive()
        }
      }

      pull(
        oldLog.getStream({ gt: migratedOffset }),
        pull.map(updateMigratedSizeAndPluck),
        pull.map(toBIPF),
        pull.asyncMap(writeToNewLog),
        (drainAborter = config.db2.maxCpu
          ? drainGently(tooHotOpts(config), op, opDone)
          : pull.drain(op, opDone))
      )
    })
  }

  return {
    start,
    stop,
    doesOldLogExist: () => oldLogExists.value,
    synchronized,
  }
}

},
"KeOe/kUQLqH0ZVsn667GMT/xNkS+X3KXhqwXVeL+564=":
function (require, module, exports, __dirname, __filename) {
var encodings = require('./lib/encodings')

module.exports = Codec

function Codec (opts) {
  if (!(this instanceof Codec)) {
    return new Codec(opts)
  }
  this.opts = opts || {}
  this.encodings = encodings
}

Codec.prototype._encoding = function (encoding) {
  if (typeof encoding === 'string') encoding = encodings[encoding]
  if (!encoding) encoding = encodings.id
  return encoding
}

Codec.prototype._keyEncoding = function (opts, batchOpts) {
  return this._encoding((batchOpts && batchOpts.keyEncoding) ||
                        (opts && opts.keyEncoding) ||
                        this.opts.keyEncoding)
}

Codec.prototype._valueEncoding = function (opts, batchOpts) {
  return this._encoding((batchOpts && (batchOpts.valueEncoding || batchOpts.encoding)) ||
                        (opts && (opts.valueEncoding || opts.encoding)) ||
                        (this.opts.valueEncoding || this.opts.encoding))
}

Codec.prototype.encodeKey = function (key, opts, batchOpts) {
  return this._keyEncoding(opts, batchOpts).encode(key)
}

Codec.prototype.encodeValue = function (value, opts, batchOpts) {
  return this._valueEncoding(opts, batchOpts).encode(value)
}

Codec.prototype.decodeKey = function (key, opts) {
  return this._keyEncoding(opts).decode(key)
}

Codec.prototype.decodeValue = function (value, opts) {
  return this._valueEncoding(opts).decode(value)
}

Codec.prototype.encodeBatch = function (ops, opts) {
  var self = this

  return ops.map(function (_op) {
    var op = {
      type: _op.type,
      key: self.encodeKey(_op.key, opts, _op)
    }
    if (self.keyAsBuffer(opts, _op)) op.keyEncoding = 'binary'
    if (_op.prefix) op.prefix = _op.prefix
    if ('value' in _op) {
      op.value = self.encodeValue(_op.value, opts, _op)
      if (self.valueAsBuffer(opts, _op)) op.valueEncoding = 'binary'
    }
    return op
  })
}

var ltgtKeys = ['lt', 'gt', 'lte', 'gte', 'start', 'end']

Codec.prototype.encodeLtgt = function (ltgt) {
  var self = this
  var ret = {}
  Object.keys(ltgt).forEach(function (key) {
    ret[key] = ltgtKeys.indexOf(key) > -1
      ? self.encodeKey(ltgt[key], ltgt)
      : ltgt[key]
  })
  return ret
}

Codec.prototype.createStreamDecoder = function (opts) {
  var self = this

  if (opts.keys && opts.values) {
    return function (key, value) {
      return {
        key: self.decodeKey(key, opts),
        value: self.decodeValue(value, opts)
      }
    }
  } else if (opts.keys) {
    return function (key) {
      return self.decodeKey(key, opts)
    }
  } else if (opts.values) {
    return function (_, value) {
      return self.decodeValue(value, opts)
    }
  } else {
    return function () {}
  }
}

Codec.prototype.keyAsBuffer = function (opts) {
  return this._keyEncoding(opts).buffer
}

Codec.prototype.valueAsBuffer = function (opts) {
  return this._valueEncoding(opts).buffer
}

},
"KlqkCRk/B0PV38it7aKYg0A8huEk9IuWX7SBHN50lNQ=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const FullMentionsIndex = require('./indexes/full-mentions')
const fullMentions = require('./operators/full-mentions')

exports.init = function (sbot, config) {
  sbot.db.registerIndex(FullMentionsIndex)
  sbot.db.operators.fullMentions = fullMentions
}

},
"KricQafdcfK9V/7mcHaPDtDxPjqNg+ipAtIcKJI7Du4=":
function (require, module, exports, __dirname, __filename) {


module.exports = function (fn) {
  var active = false, called = 0
  return function () {
    called = true
    if(!active) {
      active = true
      while(called) {
        called = false
        fn()
      }
      active = false
    }
  }
}









},
"Ky/OdiL91oAlbSi81ZwwkTVGqCW/addU0hodIczCkow=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var GetIntrinsic = require('get-intrinsic');

var callBind = require('./');

var $indexOf = callBind(GetIntrinsic('String.prototype.indexOf'));

module.exports = function callBoundIntrinsic(name, allowMissing) {
	var intrinsic = GetIntrinsic(name, !!allowMissing);
	if (typeof intrinsic === 'function' && $indexOf(name, '.prototype.') > -1) {
		return callBind(intrinsic);
	}
	return intrinsic;
};

},
"L8Nn1TL1ypFEFXQDGSFGtOMVJgFtYUb4UaEFgq+4qpY=":
function (require, module, exports, __dirname, __filename) {
var MAX_ALLOC = Math.pow(2, 30) - 1 // default in iojs

module.exports = function (iterations, keylen) {
  if (typeof iterations !== 'number') {
    throw new TypeError('Iterations not a number')
  }

  if (iterations < 0) {
    throw new TypeError('Bad iterations')
  }

  if (typeof keylen !== 'number') {
    throw new TypeError('Key length not a number')
  }

  if (keylen < 0 || keylen > MAX_ALLOC || keylen !== keylen) { /* eslint no-self-compare: 0 */
    throw new TypeError('Bad key length')
  }
}

},
"LC6Paru3wjFNVzbvCo0R8E3cPPT68ccQ3111xBcOk34=":
function (require, module, exports, __dirname, __filename) {
'use strict';

module.exports = {
  BINARY_TYPES: ['nodebuffer', 'arraybuffer', 'fragments'],
  GUID: '258EAFA5-E914-47DA-95CA-C5AB0DC85B11',
  kStatusCode: Symbol('status-code'),
  kWebSocket: Symbol('websocket'),
  EMPTY_BUFFER: Buffer.alloc(0),
  NOOP: () => {}
};

},
"LHlpxkX13FKDHbe7FdwU8SvWnU61CEaZbSiRKwgyNFA=":
function (require, module, exports, __dirname, __filename) {
const INTEGER_START = 0x69 // 'i'
const STRING_DELIM = 0x3A // ':'
const DICTIONARY_START = 0x64 // 'd'
const LIST_START = 0x6C // 'l'
const END_OF_TYPE = 0x65 // 'e'

/**
 * replaces parseInt(buffer.toString('ascii', start, end)).
 * For strings with less then ~30 charachters, this is actually a lot faster.
 *
 * @param {Buffer} data
 * @param {Number} start
 * @param {Number} end
 * @return {Number} calculated number
 */
function getIntFromBuffer (buffer, start, end) {
  let sum = 0
  let sign = 1

  for (let i = start; i < end; i++) {
    const num = buffer[i]

    if (num < 58 && num >= 48) {
      sum = sum * 10 + (num - 48)
      continue
    }

    if (i === start && num === 43) { // +
      continue
    }

    if (i === start && num === 45) { // -
      sign = -1
      continue
    }

    if (num === 46) { // .
      // its a float. break here.
      break
    }

    throw new Error('not a number: buffer[' + i + '] = ' + num)
  }

  return sum * sign
}

/**
 * Decodes bencoded data.
 *
 * @param  {Buffer} data
 * @param  {Number} start (optional)
 * @param  {Number} end (optional)
 * @param  {String} encoding (optional)
 * @return {Object|Array|Buffer|String|Number}
 */
function decode (data, start, end, encoding) {
  if (data == null || data.length === 0) {
    return null
  }

  if (typeof start !== 'number' && encoding == null) {
    encoding = start
    start = undefined
  }

  if (typeof end !== 'number' && encoding == null) {
    encoding = end
    end = undefined
  }

  decode.position = 0
  decode.encoding = encoding || null

  decode.data = !(Buffer.isBuffer(data))
    ? Buffer.from(data)
    : data.slice(start, end)

  decode.bytes = decode.data.length

  return decode.next()
}

decode.bytes = 0
decode.position = 0
decode.data = null
decode.encoding = null

decode.next = function () {
  switch (decode.data[decode.position]) {
    case DICTIONARY_START:
      return decode.dictionary()
    case LIST_START:
      return decode.list()
    case INTEGER_START:
      return decode.integer()
    default:
      return decode.buffer()
  }
}

decode.find = function (chr) {
  let i = decode.position
  const c = decode.data.length
  const d = decode.data

  while (i < c) {
    if (d[i] === chr) return i
    i++
  }

  throw new Error(
    'Invalid data: Missing delimiter "' +
    String.fromCharCode(chr) + '" [0x' +
    chr.toString(16) + ']'
  )
}

decode.dictionary = function () {
  decode.position++

  const dict = {}

  while (decode.data[decode.position] !== END_OF_TYPE) {
    dict[decode.buffer()] = decode.next()
  }

  decode.position++

  return dict
}

decode.list = function () {
  decode.position++

  const lst = []

  while (decode.data[decode.position] !== END_OF_TYPE) {
    lst.push(decode.next())
  }

  decode.position++

  return lst
}

decode.integer = function () {
  const end = decode.find(END_OF_TYPE)
  const number = getIntFromBuffer(decode.data, decode.position + 1, end)

  decode.position += end + 1 - decode.position

  return number
}

decode.buffer = function () {
  let sep = decode.find(STRING_DELIM)
  const length = getIntFromBuffer(decode.data, decode.position, sep)
  const end = ++sep + length

  decode.position = end

  return decode.encoding
    ? decode.data.toString(decode.encoding, sep, end)
    : decode.data.slice(sep, end)
}

module.exports = decode

},
"LNMmQ887D8pIaPCl9mWvS7Lwx2T3qk+TcUnyxU0yfQY=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var through = require('pull-through')

module.exports = function split (matcher, mapper, reverse, last) {
  var soFar = ''
  if('function' === typeof matcher)
    mapper = matcher, matcher = null
  if (!matcher)
    matcher = '\n'

  function map(stream, piece) {
    if(mapper) {
      piece = mapper(piece)
      if('undefined' !== typeof piece)
        stream.queue(piece)
    }
    else
      stream.queue(piece)
  }

  return through(function (buffer) {
    var stream = this
      , pieces = ( reverse
        ? buffer + soFar
        : soFar + buffer
      ).split(matcher)

    soFar = reverse ? pieces.shift() : pieces.pop()
    var l = pieces.length
    for (var i = 0; i < l; i++) {
      map(stream, pieces[reverse ? l - 1 - i : i ])
    }
  },
  function () {
    if(last && soFar == '')
      return this.queue(null)

    map(this, soFar)
    this.queue(null)
  })
}

},
"LOgJFiE4jDSnvlkw/xVoJGC16bPVePyumo/9xppTGXA=":
function (require, module, exports, __dirname, __filename) {
exports.getCallback = function (options, callback) {
  return typeof options === 'function' ? options : callback
}

exports.getOptions = function (options) {
  return typeof options === 'object' && options !== null ? options : {}
}

},
"LQ3/9ZCyjrFzcGWZYv38oAimQKrnHM/xg9ytYOazV5I=":
function (require, module, exports, __dirname, __filename) {
const get = require('lodash.get')
const os = require('os')
const defaultPorts = require('../default-ports')
const ip = require('ip')

// generates all possible incoming connection settings that you could bind to
module.exports = function (config) {
  var incoming

  // We have to deal with some legacy behavior where:
  //
  // - net port is defined by `config.port`
  // - ws port is defined by `config.ws.port`
  // - other services have no canonical port config location (TODO?)
  const getPort = (service) => {
    const defaultPort = defaultPorts[service]

    if (service === 'net') {
      return get(config, 'port', defaultPort)
    }
    if (service === 'ws') {
      return get(config, 'ws.port', defaultPort)
    }

    return defaultPort
  }


  //legacy configuration didn't have a scopes concept,
  //so interpret that as every scope at once.
  //I think there is probably a better way to do this,
  //but am fairly sure this will probably work.
  const allScopes = ['device', 'local', 'public']

  // If `config.host` is defined then we don't need to enumerate interfaces.
  if (config.host) {
    incoming = {
      net: [{
        host: config.host,
        port: getPort('net'),
        scope: allScopes,
        transform: 'shs'
      }],
      ws: [{
        host: config.host,
        port: getPort('ws'),
        scope: allScopes,
        transform: 'shs'
      }]
    }
  } else {
    // Trying to hardcode reasonable defaults here doesn't seem possible.
    //
    // Instead, the below code enumerates all network interfaces and adds them
    // to `config.connections.incoming` for each service in `defaultPorts`.

    // If you aren't familiar, you should at least skim these docs:
    // https://nodejs.org/api/os.html#os_os_networkinterfaces
    const interfaces = os.networkInterfaces()

    // Game plan: we're going to enumerate the services (e.g. net and ws) and
    // return an object that looks like this:
    //
    // {
    //   net: [ interface, interface, ... ]
    //   ws: [ interface, interface, ... ]
    // }
    incoming = Object.keys(defaultPorts).map((service) => {
      return {
        service,
        interfaces: Object.values(interfaces).reduce((acc, val) => {
          // Future TODO: replace with shiny new `Array.prototype.flat()`.
          return acc.concat(val)
        }, []).filter(item => {
          // We want to avoid scoped IPv6 addresses since they don't seem to
          // play nicely with the Node.js networking stack. These addresses
          // often start with `fe80` and throw EINVAL when we try to bind to
          // them.
          return item.scopeid == null || item.scopeid === 0
        }).map(item => {
          // This bit is simple because the ssb-config options for `incoming`
          // can either be hardcoded or directly inferred from `interfaces`.

          //if an interface is internal, it can only be accessed from the device.
          //if it's got a private ip address it can only be accessed from some network.
          //otherwise, it's presumably a publically accessable address.
          var scope = (
            item.internal ? 'device'
            : ip.isPrivate(item.address) ? 'local'
            : 'public'
          )

          return {
            host: item.address,
            port: getPort(service),
            scope: [scope],
            transform: 'shs'
          }
        })
      }
    }).reduce((result, obj) => {
      // This `reduce()` step is necessary because we need to return an object
      // rather than an array. There may be a simpler way to do this.
      result[obj.service] = obj.interfaces
      return result
    }, {})
  }

  incoming.unix = [{ "scope":"device", "transform":"noauth" }]

  return incoming
}

},
"LQrn+beMz9sSTqtT7mL/SXunAGHjhGQnZY0eip5XI+o=":
function (require, module, exports, __dirname, __filename) {
var prr = require('prr')

function init (type, message, cause) {
  if (!!message && typeof message != 'string') {
    message = message.message || message.name
  }
  prr(this, {
      type    : type
    , name    : type
      // can be passed just a 'cause'
    , cause   : typeof message != 'string' ? message : cause
    , message : message
  }, 'ewr')
}

// generic prototype, not intended to be actually used - helpful for `instanceof`
function CustomError (message, cause) {
  Error.call(this)
  if (Error.captureStackTrace)
    Error.captureStackTrace(this, this.constructor)
  init.call(this, 'CustomError', message, cause)
}

CustomError.prototype = new Error()

function createError (errno, type, proto) {
  var err = function (message, cause) {
    init.call(this, type, message, cause)
    //TODO: the specificity here is stupid, errno should be available everywhere
    if (type == 'FilesystemError') {
      this.code    = this.cause.code
      this.path    = this.cause.path
      this.errno   = this.cause.errno
      this.message =
        (errno.errno[this.cause.errno]
          ? errno.errno[this.cause.errno].description
          : this.cause.message)
        + (this.cause.path ? ' [' + this.cause.path + ']' : '')
    }
    Error.call(this)
    if (Error.captureStackTrace)
      Error.captureStackTrace(this, err)
  }
  err.prototype = !!proto ? new proto() : new CustomError()
  return err
}

module.exports = function (errno) {
  var ce = function (type, proto) {
    return createError(errno, type, proto)
  }
  return {
      CustomError     : CustomError
    , FilesystemError : ce('FilesystemError')
    , createError     : ce
  }
}

},
"Lf3FXjpfE9rGl2M4iHXcaMHf6OFB1AM88FgQ3CkKRyM=":
function (require, module, exports, __dirname, __filename) {
var pull = require('pull-stream')
var pl = require('pull-level')

module.exports = function (db) {
  var set = {}

  pull(
    pl.read(db, {live: true}),
    pull.drain(function (e) {
      if(!e.sync)
      if(e.type === 'del')
        delete set[e.key]
      else set[e.key] = e.value
    })
  )

  return {
    set: set,
    add: function (key, cb) {
      db.put(key, -1, cb)
    },
    remove: function (key, cb) {
      db.del(key, cb)
    }
  }
}



},
"Lg2mVZsGiq5Wiye6kgSPZsLMHEXpvpP7b5teWzEUECQ=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const Obv = require('obz')
const bipf = require('bipf')
const fic = require('fastintcompression')
const bsb = require('binary-search-bounds')
const { readFile, writeFile } = require('atomic-file-rw')
const toBuffer = require('typedarray-to-buffer')
const ssbKeys = require('ssb-keys')
const DeferredPromise = require('p-defer')
const path = require('path')
const Debug = require('debug')
const SSBURI = require('ssb-uri2')

const { indexesPath } = require('../defaults')

module.exports = function (dir, sbot, config) {
  const latestOffset = Obv()
  const stateLoaded = DeferredPromise()
  let encrypted = []
  let canDecrypt = []

  const debug = Debug('ssb:db2:private')

  const encryptedFile = path.join(indexesPath(dir), 'encrypted.index')
  // an option is to cache the read keys instead of only where the
  // messages are, this has an overhead around storage.  The
  // performance of that is a decrease in unbox time to 50% of
  // original for box1 and around 75% box2
  const canDecryptFile = path.join(indexesPath(dir), 'canDecrypt.index')

  function save(filename, arr) {
    const buf = toBuffer(fic.compress(arr))
    const b = Buffer.alloc(4 + buf.length)
    b.writeInt32LE(latestOffset.value, 0)
    buf.copy(b, 4)

    writeFile(filename, b, (err) => {
      if (err) debug('failed to save file %o, got error %o', filename, err)
    })
  }

  function load(filename, cb) {
    readFile(filename, (err, buf) => {
      if (err) return cb(err)
      else if (!buf) return cb(new Error('empty file'))

      const offset = buf.readInt32LE(0)
      const body = buf.slice(4)

      cb(null, { offset, arr: fic.uncompress(body) })
    })
  }

  function loadIndexes(cb) {
    load(encryptedFile, (err, data) => {
      if (err) {
        debug('failed to load encrypted')
        latestOffset.set(-1)
        if (sbot.box2)
          sbot.box2.isReady(stateLoaded.resolve)
        else
          stateLoaded.resolve()
        if (err.code === 'ENOENT') cb()
        else if (err.message === 'empty file') cb()
        else cb(err)
        return
      }

      const { offset, arr } = data
      encrypted = arr

      debug('encrypted loaded', encrypted.length)

      load(canDecryptFile, (err, data) => {
        let canDecryptOffset = -1
        if (!err) {
          canDecrypt = data.arr
          canDecryptOffset = data.offset
          debug('canDecrypt loaded', canDecrypt.length)
        }

        latestOffset.set(Math.min(offset, canDecryptOffset))
        if (sbot.box2)
          sbot.box2.isReady(stateLoaded.resolve)
        else
          stateLoaded.resolve()
        debug('loaded offset', latestOffset.value)

        cb()
      })
    })
  }

  loadIndexes((err) => {
    if (err) throw err
  })

  let savedTimer
  function saveIndexes(cb) {
    if (!savedTimer) {
      savedTimer = setTimeout(() => {
        savedTimer = null
        save(encryptedFile, encrypted)
        save(canDecryptFile, canDecrypt)
      }, 1000)
    }
    cb()
  }

  function reconstructMessage(record, unboxedContent) {
    const msg = bipf.decode(record.value, 0)
    const originalContent = msg.value.content
    if (SSBURI.isBendyButtV1FeedSSBURI(msg.value.author) && Array.isArray(unboxedContent)) {
      msg.value.content = unboxedContent[0]
      msg.value.contentSignature = unboxedContent[1]
    } else
      msg.value.content = unboxedContent

    msg.meta = {
      private: true,
      originalContent,
    }

    const len = bipf.encodingLength(msg)
    const buf = Buffer.alloc(len)
    bipf.encode(msg, buf, 0)

    return { offset: record.offset, value: buf }
  }

  const B_VALUE = Buffer.from('value')
  const B_CONTENT = Buffer.from('content')
  const B_AUTHOR = Buffer.from('author')
  const B_PREVIOUS = Buffer.from('previous')

  function decryptBox1(ciphertext, keys) {
    return ssbKeys.unbox(ciphertext, keys)
  }

  function tryDecryptContent(ciphertext, recBuffer, pValue) {
    let content = ''
    if (ciphertext.endsWith('.box')) content = decryptBox1(ciphertext, config.keys)
    else if (sbot.box2 && ciphertext.endsWith('.box2')) {
      const pAuthor = bipf.seekKey(recBuffer, pValue, B_AUTHOR)
      if (pAuthor >= 0) {
        const author = bipf.decode(recBuffer, pAuthor)
        const pPrevious = bipf.seekKey(recBuffer, pValue, B_PREVIOUS)
        if (pPrevious >= 0) {
          const previousMsg = bipf.decode(recBuffer, pPrevious)
          content = sbot.box2.decryptBox2(ciphertext, author, previousMsg)
        }
      }
    }
    return content
  }

  function decrypt(record, streaming) {
    const recOffset = record.offset
    const recBuffer = record.value
    if (!recBuffer) return record
    let p = 0 // note you pass in p!
    if (bsb.eq(canDecrypt, recOffset) !== -1) {
      const pValue = bipf.seekKey(recBuffer, p, B_VALUE)
      if (pValue < 0) return record
      const pContent = bipf.seekKey(recBuffer, pValue, B_CONTENT)
      if (pContent < 0) return record

      const ciphertext = bipf.decode(recBuffer, pContent)
      const content = tryDecryptContent(ciphertext, recBuffer, pValue)
      if (!content) return record

      const originalMsg = reconstructMessage(record, content)
      return originalMsg
    } else if (recOffset > latestOffset.value || !streaming) {
      if (streaming) latestOffset.set(recOffset)

      const pValue = bipf.seekKey(recBuffer, p, B_VALUE)
      if (pValue < 0) return record
      const pContent = bipf.seekKey(recBuffer, pValue, B_CONTENT)
      if (pContent < 0) return record

      const type = bipf.getEncodedType(recBuffer, pContent)
      if (type !== bipf.types.string) return record

      const ciphertext = bipf.decode(recBuffer, pContent)

      if (streaming && ciphertext.endsWith('.box2'))
        encrypted.push(recOffset)

      const content = tryDecryptContent(ciphertext, recBuffer, pValue)
      if (!content) return record

      if (!streaming) {
        // since we use bsb for canDecrypt we need to ensure recOffset
        // is inserted at the correct place when reindexing
        const insertLocation = bsb.gt(canDecrypt, recOffset)
        canDecrypt.splice(insertLocation, 0, recOffset)
      } else
        canDecrypt.push(recOffset)

      if (!streaming) saveIndexes(() => {})
      return reconstructMessage(record, content)
    } else {
      return record
    }
  }

  function missingDecrypt() {
    let canDecryptSet = new Set(canDecrypt)

    return encrypted.filter(x => !canDecryptSet.has(x))
  }

  return {
    latestOffset,
    decrypt,
    missingDecrypt,
    saveIndexes,
    stateLoaded: stateLoaded.promise,
  }
}

module.exports.reEncrypt = function (msg) {
  if (msg.meta && msg.meta.private) {
    msg.value.content = msg.meta.originalContent
    delete msg.meta
  }
  return msg
}

},
"LjNLpDzUhS96PtaBWQKRZ8Bdf6avU25u8XfrhozNG7g=":
function (require, module, exports, __dirname, __filename) {
module.exports = realpath
realpath.realpath = realpath
realpath.sync = realpathSync
realpath.realpathSync = realpathSync
realpath.monkeypatch = monkeypatch
realpath.unmonkeypatch = unmonkeypatch

var fs = require('fs')
var origRealpath = fs.realpath
var origRealpathSync = fs.realpathSync

var version = process.version
var ok = /^v[0-5]\./.test(version)
var old = require('./old.js')

function newError (er) {
  return er && er.syscall === 'realpath' && (
    er.code === 'ELOOP' ||
    er.code === 'ENOMEM' ||
    er.code === 'ENAMETOOLONG'
  )
}

function realpath (p, cache, cb) {
  if (ok) {
    return origRealpath(p, cache, cb)
  }

  if (typeof cache === 'function') {
    cb = cache
    cache = null
  }
  origRealpath(p, cache, function (er, result) {
    if (newError(er)) {
      old.realpath(p, cache, cb)
    } else {
      cb(er, result)
    }
  })
}

function realpathSync (p, cache) {
  if (ok) {
    return origRealpathSync(p, cache)
  }

  try {
    return origRealpathSync(p, cache)
  } catch (er) {
    if (newError(er)) {
      return old.realpathSync(p, cache)
    } else {
      throw er
    }
  }
}

function monkeypatch () {
  fs.realpath = realpath
  fs.realpathSync = realpathSync
}

function unmonkeypatch () {
  fs.realpath = origRealpath
  fs.realpathSync = origRealpathSync
}

},
"Lta3am9ceHN18sGtRfYsVM7JX7PYRPD85r4mnC6A61U=":
function (require, module, exports, __dirname, __filename) {

/* jshint node: true */
'use strict';

var fs = require('fs');
var Decoder = require('pull-utf8-decoder')
/**
  # pull-file

  This is a simple module which uses raw file reading methods available in
  the node `fs` module to read files on-demand.  It's a work in progress
  and feedback is welcome :)

  ## Example Usage

  <<< examples/ipsum-chunks.js

**/
module.exports = function(filename, opts) {
  var mode = opts && opts.mode || 0x1B6; // 0666
  var bufferSize = opts && opts.bufferSize || 1024*64;
  var start = opts && opts.start || 0
  var end = opts && opts.end || Number.MAX_SAFE_INTEGER
  var fd = opts && opts.fd
  var ended, closeNext, busy, _cb;
  var _buffer = new Buffer(bufferSize)

  var flags = opts && opts.flags || 'r'

  function readNext(cb) {
    if(closeNext) return close(cb)
    var toRead = Math.min(end - start, bufferSize);
    busy = true

    fs.read(
      fd,
      _buffer,
      0,
      toRead,
      start,
      function(err, count, buffer) {
        busy = false
        start += count;
        // if we have received an end noticiation, just discard this data
        if(closeNext) {
          close(_cb)
          return cb(closeNext)
        }

        if (ended) {
          return cb(err || ended);
        }

        // if we encountered a read error pass it on
        if (err) {
          return cb(err);
        }

        if(count === buffer.length) {
          cb(null, buffer);
        } else {
          closeNext = true;
          cb(null, buffer.slice(0, count));
        }
      }
    );
    _buffer = new Buffer(Math.min(end - start, bufferSize))
  }

  function open(cb) {
    busy = true
    fs.open(filename, flags, mode, function(err, descriptor) {
      // save the file descriptor
      fd = descriptor;

      busy = false
      if(closeNext) {
        close(_cb)
        return cb(closeNext)
      }

      if (err) {
        return cb(err);
      }

      // read the next bytes
      return readNext(cb);
    });
  }

  function close (cb) {
    //if auto close is disabled, then user manages fd.
    if(opts && opts.autoClose === false) return cb(true)

    //wait until we have got out of bed, then go back to bed.
    //or if we are reading, wait till we read, then go back to bed.
    else if(busy) {
      _cb = cb
      return closeNext = true
    }

    //first read was close, don't even get out of bed.
    else if(!fd) {
      return cb(true)
    }

    //go back to bed
    else {
      fs.close(fd, function(err) {
        fd = null;
        cb(err || true);
      });
    }
  }

  function source (end, cb) {
    if (end) {
      ended = end;
      close(cb);
    }
    // if we have already received the end notification, abort further
    else if (ended) {
      cb(ended)
    }

    else if (! fd) {
      open(cb);
    }

    else
      readNext(cb);
  };

  //read directly to text
  if(opts && opts.encoding)
    return Decoder(opts.encoding)(source)

  return source

};











},
"M2s7N+UQG1+EifxUtcNvRoOZabc7NGGGELYEZsq+F+k=":
function (require, module, exports, __dirname, __filename) {
const path = require('path')
const pull = require('pull-stream')
const toPull = require('push-stream-to-pull-stream')
const EBT = require('epidemic-broadcast-trees')
const Store = require('key-value-file-store')
const toUrlFriendly = require('base64-url').escape
const getSeverity = require('ssb-network-errors')
const pullDefer = require('pull-defer')
const classicMethods = require('./formats/classic')

function hook(hookable, fn) {
  if (typeof hookable === 'function' && hookable.hook) {
    hookable.hook(fn)
  }
}

exports.name = 'ebt'

exports.version = '1.0.0'

exports.manifest = {
  replicate: 'duplex',
  replicateFormat: 'duplex',
  request: 'sync',
  block: 'sync',
  peerStatus: 'sync',
  clock: 'async',
}

exports.permissions = {
  anonymous: {
    allow: ['replicate', 'replicateFormat', 'clock'],
  },
}

// there was a bug that caused some peers
// to request things that weren't feeds.
// this is fixed, so just ignore anything that isn't a feed.
function cleanClock(clock, isFeed) {
  for (const k in clock) {
    if (!isFeed(k)) {
      delete clock[k]
    }
  }
}

function isMuxrpcMissing(err, methodName) {
  const jsErrorMessage =
    'method:ebt,' + methodName + ' is not in list of allowed methods'
  const goErrorMessage = 'muxrpc: no such command: ebt.' + methodName
  return err.message === jsErrorMessage || err.message === goErrorMessage
}

exports.init = function (sbot, config) {
  const ebts = []
  registerFormat(classicMethods)

  function registerFormat(format) {
    if (!format.name) throw new Error('format must have a name')

    const dirName = 'ebt' + (format.name === 'classic' ? '' : format.name)
    const dir = config.path ? path.join(config.path, dirName) : null
    const store = Store(dir, null, toUrlFriendly)

    // EBT expects a function of only feedId so we bind sbot here
    const isFeed = format.isFeed.bind(format, sbot)
    const { isMsg, getMsgAuthor, getMsgSequence } = format

    const ebt = EBT({
      logging: config.ebt && config.ebt.logging,
      id: sbot.id,
      getClock(id, cb) {
        store.ensure(id, function () {
          const clock = store.get(id) || {}
          cleanClock(clock, isFeed)
          cb(null, clock)
        })
      },
      setClock(id, clock) {
        cleanClock(clock, isFeed)
        store.set(id, clock)
      },
      getAt(pair, cb) {
        format.getAtSequence(sbot, pair, cb)
      },
      append(msgVal, cb) {
        format.appendMsg(sbot, msgVal, cb)
      },

      isFeed,
      isMsg,
      getMsgAuthor,
      getMsgSequence,
    })

    // attach a few methods we need in this module
    ebt.convertMsg = format.convertMsg.bind(format, sbot)
    ebt.isReady = format.isReady.bind(format, sbot)
    ebt.isFeed = isFeed
    ebt.name = format.name
    ebt.prepareForIsFeed = format.prepareForIsFeed.bind(format, sbot)

    const existingId = ebts.findIndex((e) => e.name === format.name)
    if (existingId !== -1) ebts[existingId] = ebt
    else ebts.push(ebt)
  }

  function getEBT(formatName) {
    const ebt = ebts.find((ebt) => ebt.name === formatName)
    if (!ebt) throw new Error('Unknown format: ' + formatName)

    return ebt
  }

  let isReady = false
  let waiting = []
  function onReady(fn) {
    if (isReady) fn()
    else waiting.push(fn)
  }

  sbot.getVectorClock((err, clock) => {
    if (err) console.warn('Failed to getVectorClock in ssb-ebt because:', err)

    const readies = ebts.map((ebt) => ebt.isReady())
    Promise.all(readies).then(() => {
      ebts.forEach((ebt) => {
        const validClock = {}
        for (const k in clock) {
          if (ebt.isFeed(k)) {
            validClock[k] = clock[k]
          }
        }

        ebt.state.clock = validClock
        ebt.update()
      })

      isReady = true
      for (let i = 0; i < waiting.length; ++i) waiting[i]()
      waiting = []
    })
  })

  sbot.post((msg) => {
    onReady(() => {
      ebts.forEach((ebt) => {
        if (ebt.isFeed(msg.value.author)) {
          ebt.convertMsg(msg.value, (err, converted) => {
            if (err)
              console.warn('Failed to convert msg in ssb-ebt because:', err)
            else ebt.onAppend(converted)
          })
        }
      })
    })
  })

  // TODO: remove this when no one uses ssb-db anymore, because
  // sbot.progress is defined in ssb-db but not in ssb-db2
  if (sbot.progress) {
    hook(sbot.progress, function (fn) {
      const _progress = fn()
      const ebt = ebts.find((ebt) => ebt.name === 'classic')
      const ebtProg = ebt.progress()
      if (ebtProg.target) _progress.ebt = ebtProg
      return _progress
    })
  }

  sbot.on('rpc:connect', function (rpc, isClient) {
    if (rpc.id === sbot.id) return // ssb-client connecting to ssb-server
    if (isClient) {
      onReady(() => {
        ebts.forEach((ebt) => {
          const format = ebt.name
          const opts = { version: 3, format }
          const local = toPull.duplex(
            ebt.createStream(rpc.id, opts.version, true)
          )

          // for backwards compatibility we always replicate classic
          // feeds using existing replicate RPC
          const methodName =
            format === 'classic' ? 'replicate' : 'replicateFormat'

          const remote = rpc.ebt[methodName](opts, (networkError) => {
            if (networkError && getSeverity(networkError) >= 3) {
              if (isMuxrpcMissing(networkError, methodName)) {
                console.warn(
                  'peer ' + rpc.id + ' does not support RPC ebt.' + methodName
                )
              } else {
                console.error('rpc.ebt.replicate exception:', networkError)
              }
            }
          })
          pull(local, remote, local)
        })
      })
    }
  })

  function findEBTForFeed(feedId, formatName) {
    let ebt
    if (formatName) {
      ebt = ebts.find((ebt) => ebt.name === formatName)
    } else {
      ebt = ebts.find((ebt) => ebt.isFeed(feedId))
    }

    if (!ebt) {
      ebt = ebts.find((ebt) => ebt.name === 'classic')
    }

    return ebt
  }

  function request(destFeedId, requesting, formatName) {
    onReady(() => {
      if (requesting) {
        const ebt = findEBTForFeed(destFeedId, formatName)
        ebt.prepareForIsFeed(destFeedId, () => {
          if (!ebt.isFeed(destFeedId)) return
          ebt.request(destFeedId, true)
        })
      } else {
        // If we don't want a destFeedId, make sure it's not registered anywhere
        ebts.forEach((ebt) => {
          ebt.request(destFeedId, false)
        })
      }
    })
  }

  function block(origFeedId, destFeedId, blocking, formatName) {
    onReady(() => {
      const ebt = findEBTForFeed(origFeedId, formatName)
      ebt.prepareForIsFeed(destFeedId, () => {
        if (!ebt.isFeed(origFeedId)) return
        if (!ebt.isFeed(destFeedId)) return

        if (blocking) {
          ebt.block(origFeedId, destFeedId, true)
        } else if (
          ebt.state.blocks[origFeedId] &&
          ebt.state.blocks[origFeedId][destFeedId]
        ) {
          // only update unblock if they were already blocked
          ebt.block(origFeedId, destFeedId, false)
        }
      })
    })
  }

  function replicateFormat(opts) {
    if (opts.version !== 3) {
      throw new Error('expected ebt.replicate({version: 3})')
    }

    const formatName = opts.format || 'classic'
    const ebt = getEBT(formatName)

    const deferred = pullDefer.duplex()
    onReady(() => {
      // `this` refers to the remote peer who called this muxrpc API
      deferred.resolve(
        toPull.duplex(ebt.createStream(this.id, opts.version, false))
      )
    })
    return deferred
  }

  // get replication status for feeds for this id
  function peerStatus(id) {
    id = id || sbot.id

    const ebt = findEBTForFeed(id)

    const data = {
      id: id,
      seq: ebt.state.clock[id],
      peers: {},
    }

    for (const k in ebt.state.peers) {
      const peer = ebt.state.peers[k]
      if (
        peer.clock[id] != null ||
        (peer.replicating && peer.replicating[id] != null)
      ) {
        const rep = peer.replicating && peer.replicating[id]
        data.peers[k] = {
          seq: peer.clock[id],
          replicating: rep,
        }
      }
    }

    return data
  }

  function clock(opts, cb) {
    if (!cb) {
      cb = opts
      opts = { format: 'classic' }
    }

    onReady(() => {
      const ebt = getEBT(opts.format)
      cb(null, ebt.state.clock)
    })
  }

  function setClockForSlicedReplication(feedId, sequence, formatName) {
    onReady(() => {
      const ebt = findEBTForFeed(feedId, formatName)

      ebt.state.clock[feedId] = sequence
    })
  }

  return {
    request,
    block,
    replicate: replicateFormat,
    replicateFormat,
    peerStatus,
    clock,
    setClockForSlicedReplication,
    registerFormat,
  }
}

},
"M2waEw6vcov0DK2BRKoWlCliMH8ZJJjGMyHW/1nZqqw=":
function (require, module, exports, __dirname, __filename) {
/*!
  * prr
  * (c) 2013 Rod Vagg <rod@vagg.org>
  * https://github.com/rvagg/prr
  * License: MIT
  */

(function (name, context, definition) {
  if (typeof module != 'undefined' && module.exports)
    module.exports = definition()
  else
    context[name] = definition()
})('prr', this, function() {

  var setProperty = typeof Object.defineProperty == 'function'
      ? function (obj, key, options) {
          Object.defineProperty(obj, key, options)
          return obj
        }
      : function (obj, key, options) { // < es5
          obj[key] = options.value
          return obj
        }

    , makeOptions = function (value, options) {
        var oo = typeof options == 'object'
          , os = !oo && typeof options == 'string'
          , op = function (p) {
              return oo
                ? !!options[p]
                : os
                  ? options.indexOf(p[0]) > -1
                  : false
            }

        return {
            enumerable   : op('enumerable')
          , configurable : op('configurable')
          , writable     : op('writable')
          , value        : value
        }
      }

    , prr = function (obj, key, value, options) {
        var k

        options = makeOptions(value, options)

        if (typeof key == 'object') {
          for (k in key) {
            if (Object.hasOwnProperty.call(key, k)) {
              options.value = key[k]
              setProperty(obj, k, options)
            }
          }
          return obj
        }

        return setProperty(obj, key, options)
      }

  return prr
})
},
"MFvgRymxsxnD2IUCoCxMftlhI2mmRvOjePIYa43LPIc=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = function drain (op, done) {
  var read, abort

  function sink (_read) {
    read = _read
    if(abort) return sink.abort()
    //this function is much simpler to write if you
    //just use recursion, but by using a while loop
    //we do not blow the stack if the stream happens to be sync.
    ;(function next() {
        var loop = true, cbed = false
        while(loop) {
          cbed = false
          read(null, function (end, data) {
            cbed = true
            if(end = end || abort) {
              loop = false
              if(done) done(end === true ? null : end)
              else if(end && end !== true)
                throw end
            }
            else if(op && false === op(data) || abort) {
              loop = false
              read(abort || true, done || function () {})
            }
            else if(!loop){
              next()
            }
          })
          if(!cbed) {
            loop = false
            return
          }
        }
      })()
  }

  sink.abort = function (err, cb) {
    if('function' == typeof err)
      cb = err, err = true
    abort = err || true
    if(read) return read(abort, cb || function () {})
  }

  return sink
}

},
"MLOcvdJDegn+WNAXrQHN4ksrhEr+RDmG6uEDAckfU/k=":
function (require, module, exports, __dirname, __filename) {
var pull   = require('pull-stream')
var toPull = require('stream-to-pull-stream')
var many = require('pull-many')
var urlParse = require('url-parse')
var parseRange = require('range-parser')

var YEAR = 60*60*24*365

function headers(res, hash) {
  //don't set cache control because (i think) that tells
  //the browser to not keep the cache
  res.setHeader('cache-control', 'maxage='+YEAR)
  //expires makes the brower not even revalidate.
  res.setHeader('expires', new Date(Date.now()+YEAR*1000).toISOString())
  res.setHeader('expiry', new Date(Date.now()+YEAR*1000).toISOString())
  res.setHeader('etag', hash)
  // support range requests
  res.setHeader('accept-ranges', 'bytes')
}

//host blobs
module.exports = function (blobs, url, opts) {
  opts = opts || {}
  return function (req, res, next) {

    next = next || function (err) {
      res.writeHead(404, {'Content-Type': 'application/json'})
      res.end(JSON.stringify({error: true, status: 404}))
    }

    if(req.method === 'POST' && req.url === url+'/add' && opts.readonly !== true)
      pull(
        toPull(req),
        blobs.add(function (err, hash) {
          res.end(hash)
        })
      )
    else if(req.url.indexOf(url+'/get/') === 0) {
      if(!(req.method === "GET" || req.method === 'HEAD')) return next()

      var u = urlParse('http://makeurlparseright.com'+req.url, true)
      var hash = decodeURIComponent(u.pathname.substring((url+'/get/').length))
      var q = u.query

      //if a browser revalidates, just tell them it hasn't changed, the hash has not changed.
      if(req.headers['if-none-match'] === hash) {
        headers(res, hash)
        return res.writeHead(304), res.end()
      }

      if (opts.csp) {
        res.setHeader('Content-Security-Policy', opts.csp)
      }

      //enable cors by default
      if(opts.cors !== false) {
        res.setHeader('Access-Control-Allow-Origin', '*')
      }

      // prevent timeout while waiting for blob
      res.setTimeout(0)

      blobs.size(hash, function (err, size) {
        if(err) return next(err)
        if(!size) return next(new Error('no blob:'+hash))

        headers(res, hash)

        var boundary
        var ranges = req.headers.range && parseRange(size, req.headers.range)
        if (ranges === -2) {
          // bad request
          return res.writeHead(400), res.end()
        } else if (ranges === -1) {
          // Unsadisfiable range
          res.setHeader('content-range', 'bytes */' + size)
          return res.writeHead(416), res.end()
        }
        if (!ranges || !ranges.length) ranges = null

        if (ranges) {
          if (ranges.length>1) {
            boundary = hash.slice(0, 20)
          } else {
            //request for single range
            res.setHeader(
              'content-range',
              ranges.type + ' ' + ranges[0].start + '-' + ranges[0].end + '/' + size
            )
            res.setHeader('content-length', ranges[0].end - ranges[0].start + 1)
          }
        } else if(opts.size !== false || q.size) {
          res.setHeader('content-length', size)
        }

        if(q.filename)
          res.setHeader('Content-Disposition', 'inline; filename='+q.filename)

        if(q.gzip)
          res.setHeader('Content-Encoding', 'gzip')

        if (!ranges || ranges.length < 2) {
          if(q.contentType) {
            res.setHeader('Content-Type', q.contentType)
          }
        } else {
          res.setHeader('Content-Type', 'multipart/byteranges; boundary=' + boundary)
        }

        if(req.method === 'HEAD') {
          res.writeHead(200)
          return res.end()
        }

        if (!ranges) {
          res.writeHead(200)
          pull(
            blobs.get(hash),
            //since this is an http stream, handle error the http way.
            //there is nothing we can do about an error now, since
            //we already wrote the headers. but since we included content-length
            //the client will know it went wrong.
            opts.transform ? opts.transform (q) : pull.through(),
            toPull(res)
          )
        } else if (ranges.length === 1) {
          res.writeHead(206)
          pull(
            blobs.getSlice({hash, start: ranges[0].start, end: ranges[0].end + 1}),
            opts.transform ? opts.transform (q) : pull.through(),
            toPull(res)
          )
        } else {
          var multipart_headers = ranges.map(function(range, i) {
            return (i ? '\r\n' : '') + '--' + boundary + '\r\n' +
                   (q.contentType ? 'Content-Type: ' + q.contentType + '\r\n' : '') +
                   'Content-Range: ' +
                      ranges.type + ' ' + range.start + '-' + range.end + '/' + size + '\r\n' +
                    '\r\n'
          })
          multipart_headers.push(
            '\r\n--' + boundary + '--'
          )
          let contentLength = ranges.reduce( (a, r)=> a + r.end - r.start + 1, 0)
          contentLength += multipart_headers.reduce( (a, h) => a + h.length, 0)
          res.setHeader('Content-Length', contentLength)
          res.writeHead(206)
          pull(
            many([
              pull.values(multipart_headers.map(s => pull.once(s))),
              pull.values(ranges.map(range => pull(
                blobs.getSlice({hash, start: range.start, end: range.end + 1}),
                opts.transform ? opts.transform (q) : pull.through()
              )))
            ]),
            pull.flatten(),
            toPull(res)
          )
        }
      })
    }
    else next()
  }
}

},
"MOaFSzZeJ/pFf1bOYLzmtaAS2kSjjg2M11K5mzCm/hc=":
function (require, module, exports, __dirname, __filename) {
module.exports = encode

var MSB = 0x80
  , REST = 0x7F
  , MSBALL = ~REST
  , INT = Math.pow(2, 31)

function encode(num, out, offset) {
  out = out || []
  offset = offset || 0
  var oldOffset = offset

  while(num >= INT) {
    out[offset++] = (num & 0xFF) | MSB
    num /= 128
  }
  while(num & MSBALL) {
    out[offset++] = (num & 0xFF) | MSB
    num >>>= 7
  }
  out[offset] = num | 0
  
  encode.bytes = offset - oldOffset + 1
  
  return out
}

},
"MPt8C16/vEjBz4HvZWE4nL0TRrByiC2xv/wtHIxN044=":
function (require, module, exports, __dirname, __filename) {

module.exports = function endable (goodbye) {
  var ended, waiting, sentEnd
  function h (read) {
    return function (abort, cb) {
      read(abort, function (end, data) {
        if(end && !sentEnd) {
          sentEnd = true
          return cb(null, goodbye)
        }
        //send end message...

        if(end && ended) cb(end)
        else if(end)     waiting = cb
        else             cb(null, data)
      })
    }
  }
  h.end = function () {
    ended = true
    if(waiting) waiting(ended)
    return h
  }
  return h
}


},
"MZNAuf/Vk6btL7qAEyf1tKcUS0ojiXtWJ1bT9eyhPic=":
function (require, module, exports, __dirname, __filename) {
var maybeCallback = require("continuable/maybe-callback")

module.exports = maybeCallback(list)

//  list := (tasks:Array<Continuable<T>>)
//      => Continuable<Array<T>>
function list(tasks) {
    return function continuable(callback) {
        var result = []
        var count = 0

        if (tasks.length === 0) {
            return callback(null, result)
        }

        tasks.forEach(function invokeSource(source, index) {
            source(function continuation(err, value) {
                if (err && result) {
                    result = null
                    callback(err)
                } else if (!err && result) {
                    result[index] = value
                    if (++count === tasks.length) {
                        callback(null, result)
                    }
                }
            })
        })
    }
}

},
"MfNt7SeEFQt0gPVspC5/2m4RnUNF1YhKTV9V4T/mrDA=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var toStr = Object.prototype.toString;

module.exports = function isArguments(value) {
	var str = toStr.call(value);
	var isArgs = str === '[object Arguments]';
	if (!isArgs) {
		isArgs = str !== '[object Array]' &&
			value !== null &&
			typeof value === 'object' &&
			typeof value.length === 'number' &&
			value.length >= 0 &&
			toStr.call(value.callee) === '[object Function]';
	}
	return isArgs;
};

},
"MjvLr/xOseyqvTTmpIHI8bgRJsCpKTL5QuFJFStCwCs=":
function (require, module, exports, __dirname, __filename) {
// both := (Continuable) => Continuable<[Error, Any]>
module.exports = both

function both(source) {
    return function continuable(callback) {
        source(function (err, value) {
            callback(null, [err || null, value])
        })
    }
}

},
"N4AuyayS6B7XIgVGR+Mj/YZ/o0Y4aBgIy4yJRVAEFMw=":
function (require, module, exports, __dirname, __filename) {
'use strict'
module.exports = {
  keys: require('./keys'),
  once: require('./once'),
  values: require('./values'),
  count: require('./count'),
  infinite: require('./infinite'),
  empty: require('./empty'),
  error: require('./error')
}

},
"N6CE39E4absFwePI6bRfr43tXN4FV3L3mxO/OdUpmEg=":
function (require, module, exports, __dirname, __filename) {
var prop = require('./prop')

function id (e) { return e }

module.exports = function tester (test) {
  return (
    'object' === typeof test && 'function' === typeof test.test //regexp
    ? function (data) { return test.test(data) }
    : prop (test) || id
  )
}

},
"NBNR/F8atKw3gYuYtJtZKLDqCBTAhVt3SAJbeaVYNF8=":
function (require, module, exports, __dirname, __filename) {
var nearley = require('nearley')
var grammar = nearley.Grammar.fromCompiled(require('./multiserver'))

function parse (string) {
  var parser = new nearley.Parser(grammar)
  parser.feed(string)
  var a = parser.results
  if(a.length  === 0) throw new Error('unexpected end')
  return a[0]
}

exports.decode = function (address) {
  return parse(address)
}

exports.encode = function (data) {
  return data.map(function (e) {
    return e.map(function (e) {
      return e.name + (e.data.length ? ':'+e.data.join(':') : '')
    }).join('~')
  }).join(';')
}

function repeat (head, separator, tail) {
  if(!tail) tail = head
  return head + '(?:'+ separator + tail + ')*'
}

var name = '[a-z][a-z\-0-9]+'
var data = '(?:["-9]|[<-}]|![!~:;])*'
var protocol = repeat(name, ':', data)
var address = repeat(protocol, '~')
var multi = repeat(address, ';')

var multi_rx = new RegExp('^'+multi+'$')

exports.check = function (data) {
  return !!multi_rx.exec(data)
}

exports.type = 'multiaddress'

exports.buffer = false


},
"NPTQaqC0L+LL08vg469X8W8PG9i/6dnupB6Z8HZ13w4=":
function (require, module, exports, __dirname, __filename) {
var path = require('path')
var pull = require('pull-stream')
var core  = require('./core')
var fs    = require('fs')
var DepthFirst = require('pull-traverse').depthFirst

var ancestors = exports.ancestors = function (dir) {
  dir = dir || process.cwd()
  var paths = []

  while(dir) {
    paths.push(dir)
    dir = path.dirname(dir)
    if(dir === '/') {
      paths.push(dir) 
      break
    }
  }

  return pull.values(paths)
}

var star = exports.star = function (match) {
  return pull(
    pull.map(function (dir) {
      return core.readdir(dir, match)
    }),
    pull.flatten(),
    pull.filter()
  )
}

var starStar =
exports.starStar =
function (match) {
  var seen = {}
  return pull(
    pull.map(function (dir) {
      var first = true
      return DepthFirst(path.resolve(dir), function (_dir) {
        return pull(
          core.readdir(_dir, match, true),
          pull.filter(function (e) {
            if(seen[e]) return false
            return seen[e] = true
          })
        )
      })
    }),
    pull.flatten(),
    pull.filter()
  )
}

var resolve = exports.resolve = function (rel) {
 return pull.map(function (dir) { //map to $dir/node_modules
    if(rel)
      return path.resolve(dir, rel)
    return path.resolve(dir)
  })
}

var relative = exports.relative = function (rel) {
  rel = rel || process.cwd()
  return pull.map(function (file) {
    return path.relative(rel, file)
  })
}

var absolute = exports.absolute =
function () {
  return resolve()
}

var readFile =
exports.readFile = function (parse) {
  return pull.asyncMap(function (file, cb) {
    fs.readFile(file, 'utf-8', function (err, data) {
      if(err) return cb(err) 
      try {
         data = parse ? parse(data) : data
      } catch (err) {
        return cb(err)
      }
      return cb(null, data)
    })
  })
}

if(!module.parent) {
  pull(
    pull.values(['.']),
    starStar(),
    pull.drain(console.log)
  )
}



},
"NRHFeNHC/84D/xoLT79B8HK/a17eF0B1K2LDGKUogok=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var numberIsNaN = function (value) {
	return value !== value;
};

module.exports = function is(a, b) {
	if (a === 0 && b === 0) {
		return 1 / a === 1 / b;
	}
	if (a === b) {
		return true;
	}
	if (numberIsNaN(a) && numberIsNaN(b)) {
		return true;
	}
	return false;
};


},
"NbCMBVfsi0jux2Xra6nge5X8Tj+gPSMhmiwmxC/Yli8=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const f = (fn) => [
    /*eslint no-unused-vars: 0*/
    function (a) {return fn(...arguments);},
    function (a, b) {return fn(...arguments);},
    function (a, b, c) {return fn(...arguments);},
    function (a, b, c, d) {return fn(...arguments);},
    function (a, b, c, d, e) {return fn(...arguments);},
];

const currify = (fn, ...args) => {
    check(fn);
    
    if (args.length >= fn.length)
        return fn(...args);
    
    const again = (...args2) => {
        return currify(fn, ...[...args, ...args2]);
    };
    
    const count = fn.length - args.length - 1;
    const func = f(again)[count];
    
    return func || again;
};

module.exports = currify;

function check(fn) {
    if (typeof fn !== 'function')
        throw Error('fn should be function!');
}


},
"Nj3ROjAbFi1qrgkmx5q/WWdY3lLCpXfDCBVJKuvY9sc=":
function (require, module, exports, __dirname, __filename) {
'use strict';

module.exports = require('./es6/crc32').default;

},
"Nxlk1SJ4gkCoR/Qq7WpBa1bj4fd6NwzTYJsWfveiWfs=":
function (require, module, exports, __dirname, __filename) {

//if(false && !process.env.FV_REDUCE_LS)
//  module.exports = require('./local-storage')
//else
  module.exports = require('./fs')


},
"O77Ee49dvz+Zr5xnNk3T8kIxIBbIbMX3dTMVDQBXvoU=":
function (require, module, exports, __dirname, __filename) {
var toPull   = require('stream-to-pull-stream')

module.exports = function read(db, opts) {
  return toPull.read1(db.createReadStream(opts))
}


},
"OF65+WylOvlXjk1yJq4Rbgn2F/8X5KQBXU2B7MOMzlE=":
function (require, module, exports, __dirname, __filename) {

var char = '[a-zA-Z0-9\/\+]'
var trail2 = '[AQgw]=='
var trail4 = '[AEIMQUYcgkosw048]='
var rx = '(?:' +char+ '{4})*(?:' +char+ '(?:(?:' +trail2 + ')|(?:' +char+trail4+ ')))?'
module.exports = function (prefix,suffix, length) {
  if(!Number.isInteger(length)) return new RegExp('^'+(prefix||'')+rx+(suffix||'')+'$')

  var mod = length % 3

  return new RegExp('^'+(prefix||'')+(
      char +'{'+~~((length*8)/6)+'}' + (
        mod === 0 ? ''
      : mod === 1 ? trail2
      :             trail4
      )
  )+(suffix||'')+'$')
}
















},
"OHhlJtAAR1MAco2wdFWqIdHjew8k5I+8TLMBNq4wsHs=":
function (require, module, exports, __dirname, __filename) {
/*!
 * range-parser
 * Copyright(c) 2012-2014 TJ Holowaychuk
 * Copyright(c) 2015-2016 Douglas Christopher Wilson
 * MIT Licensed
 */

'use strict'

/**
 * Module exports.
 * @public
 */

module.exports = rangeParser

/**
 * Parse "Range" header `str` relative to the given file `size`.
 *
 * @param {Number} size
 * @param {String} str
 * @param {Object} [options]
 * @return {Array}
 * @public
 */

function rangeParser (size, str, options) {
  if (typeof str !== 'string') {
    throw new TypeError('argument str must be a string')
  }

  var index = str.indexOf('=')

  if (index === -1) {
    return -2
  }

  // split the range string
  var arr = str.slice(index + 1).split(',')
  var ranges = []

  // add ranges type
  ranges.type = str.slice(0, index)

  // parse all ranges
  for (var i = 0; i < arr.length; i++) {
    var range = arr[i].split('-')
    var start = parseInt(range[0], 10)
    var end = parseInt(range[1], 10)

    // -nnn
    if (isNaN(start)) {
      start = size - end
      end = size - 1
    // nnn-
    } else if (isNaN(end)) {
      end = size - 1
    }

    // limit last-byte-pos to current length
    if (end > size - 1) {
      end = size - 1
    }

    // invalid or unsatisifiable
    if (isNaN(start) || isNaN(end) || start > end || start < 0) {
      continue
    }

    // add range
    ranges.push({
      start: start,
      end: end
    })
  }

  if (ranges.length < 1) {
    // unsatisifiable
    return -1
  }

  return options && options.combine
    ? combineRanges(ranges)
    : ranges
}

/**
 * Combine overlapping & adjacent ranges.
 * @private
 */

function combineRanges (ranges) {
  var ordered = ranges.map(mapWithIndex).sort(sortByRangeStart)

  for (var j = 0, i = 1; i < ordered.length; i++) {
    var range = ordered[i]
    var current = ordered[j]

    if (range.start > current.end + 1) {
      // next range
      ordered[++j] = range
    } else if (range.end > current.end) {
      // extend range
      current.end = range.end
      current.index = Math.min(current.index, range.index)
    }
  }

  // trim ordered array
  ordered.length = j + 1

  // generate combined range
  var combined = ordered.sort(sortByRangeIndex).map(mapWithoutIndex)

  // copy ranges type
  combined.type = ranges.type

  return combined
}

/**
 * Map function to add index value to ranges.
 * @private
 */

function mapWithIndex (range, index) {
  return {
    start: range.start,
    end: range.end,
    index: index
  }
}

/**
 * Map function to remove index value from ranges.
 * @private
 */

function mapWithoutIndex (range) {
  return {
    start: range.start,
    end: range.end
  }
}

/**
 * Sort function to sort ranges by index.
 * @private
 */

function sortByRangeIndex (a, b) {
  return a.index - b.index
}

/**
 * Sort function to sort ranges by start position.
 * @private
 */

function sortByRangeStart (a, b) {
  return a.start - b.start
}

},
"OUSl51p34cFBP3IsJL6CccLd2j6LVCv9wboKpFQUmwA=":
function (require, module, exports, __dirname, __filename) {

module.exports = Single

function Single (async, opts) {
  if(!(this instanceof Single)) return new Single(async, opts)
  this.writing = false
  this.value = null
  this.onDrain = null
  this._async = async
  this._options = opts || {}
  this._setTimeout = opts && opts.setTimeout || function (fn, delay) { return setTimeout(fn, delay) }
}

Single.prototype.write = function (value) {
  this.value = value
  if(!this.writing)
    this._timeout()
}

Single.prototype._write = function () {
  this.writing = true
  var value = this.value
  this.value = null
  this._async(value, this._written.bind(this))
}

Single.prototype._timeout = function (delay) {
  clearTimeout(this._timer)
  this._timer = this._setTimeout(
    this._write.bind(this),
    delay == null ? Math.max(
      this._options.min,
      this._options.max - (Date.now() - this._ts)
    ) : delay
  )
}

Single.prototype._written = function () {
  this._ts = Date.now()
  this.writing = false
  if(this.value) this.write(this.value)
  else {
    if(this.onDrain) this.onDrain()
    var cb = this._cb
    this._cb = null
    if(cb) cb()
  }
}

Single.prototype.close = function (cb) {
  if(this.writing) this._cb = cb
  else if(this.value) {
    this._cb = cb
    this._timeout(0)
  }
  else cb()
}

/*
this style was the easiest to write, but I implemented
this third, so I understood the problem fairly well by now.

This still has loose disipline about events and states.
_* functions _could_ represent events, if all state updates
was moved to normal functions. that would take a few extra lines
and duplicate some code though.

and it's a different distinction from private/public.
_cb is an update.
*/





},
"ObijCKnT/swbgPsChLHJV0zC2amgKxjwlh4yPR1ctyw=":
function (require, module, exports, __dirname, __filename) {
module.exports = rimraf
rimraf.sync = rimrafSync

var assert = require("assert")
var path = require("path")
var fs = require("fs")
var glob = undefined
try {
  glob = require("glob")
} catch (_err) {
  // treat glob as optional.
}
var _0666 = parseInt('666', 8)

var defaultGlobOpts = {
  nosort: true,
  silent: true
}

// for EMFILE handling
var timeout = 0

var isWindows = (process.platform === "win32")

function defaults (options) {
  var methods = [
    'unlink',
    'chmod',
    'stat',
    'lstat',
    'rmdir',
    'readdir'
  ]
  methods.forEach(function(m) {
    options[m] = options[m] || fs[m]
    m = m + 'Sync'
    options[m] = options[m] || fs[m]
  })

  options.maxBusyTries = options.maxBusyTries || 3
  options.emfileWait = options.emfileWait || 1000
  if (options.glob === false) {
    options.disableGlob = true
  }
  if (options.disableGlob !== true && glob === undefined) {
    throw Error('glob dependency not found, set `options.disableGlob = true` if intentional')
  }
  options.disableGlob = options.disableGlob || false
  options.glob = options.glob || defaultGlobOpts
}

function rimraf (p, options, cb) {
  if (typeof options === 'function') {
    cb = options
    options = {}
  }

  assert(p, 'rimraf: missing path')
  assert.equal(typeof p, 'string', 'rimraf: path should be a string')
  assert.equal(typeof cb, 'function', 'rimraf: callback function required')
  assert(options, 'rimraf: invalid options argument provided')
  assert.equal(typeof options, 'object', 'rimraf: options should be object')

  defaults(options)

  var busyTries = 0
  var errState = null
  var n = 0

  if (options.disableGlob || !glob.hasMagic(p))
    return afterGlob(null, [p])

  options.lstat(p, function (er, stat) {
    if (!er)
      return afterGlob(null, [p])

    glob(p, options.glob, afterGlob)
  })

  function next (er) {
    errState = errState || er
    if (--n === 0)
      cb(errState)
  }

  function afterGlob (er, results) {
    if (er)
      return cb(er)

    n = results.length
    if (n === 0)
      return cb()

    results.forEach(function (p) {
      rimraf_(p, options, function CB (er) {
        if (er) {
          if ((er.code === "EBUSY" || er.code === "ENOTEMPTY" || er.code === "EPERM") &&
              busyTries < options.maxBusyTries) {
            busyTries ++
            var time = busyTries * 100
            // try again, with the same exact callback as this one.
            return setTimeout(function () {
              rimraf_(p, options, CB)
            }, time)
          }

          // this one won't happen if graceful-fs is used.
          if (er.code === "EMFILE" && timeout < options.emfileWait) {
            return setTimeout(function () {
              rimraf_(p, options, CB)
            }, timeout ++)
          }

          // already gone
          if (er.code === "ENOENT") er = null
        }

        timeout = 0
        next(er)
      })
    })
  }
}

// Two possible strategies.
// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR
// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR
//
// Both result in an extra syscall when you guess wrong.  However, there
// are likely far more normal files in the world than directories.  This
// is based on the assumption that a the average number of files per
// directory is >= 1.
//
// If anyone ever complains about this, then I guess the strategy could
// be made configurable somehow.  But until then, YAGNI.
function rimraf_ (p, options, cb) {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')

  // sunos lets the root user unlink directories, which is... weird.
  // so we have to lstat here and make sure it's not a dir.
  options.lstat(p, function (er, st) {
    if (er && er.code === "ENOENT")
      return cb(null)

    // Windows can EPERM on stat.  Life is suffering.
    if (er && er.code === "EPERM" && isWindows)
      fixWinEPERM(p, options, er, cb)

    if (st && st.isDirectory())
      return rmdir(p, options, er, cb)

    options.unlink(p, function (er) {
      if (er) {
        if (er.code === "ENOENT")
          return cb(null)
        if (er.code === "EPERM")
          return (isWindows)
            ? fixWinEPERM(p, options, er, cb)
            : rmdir(p, options, er, cb)
        if (er.code === "EISDIR")
          return rmdir(p, options, er, cb)
      }
      return cb(er)
    })
  })
}

function fixWinEPERM (p, options, er, cb) {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')
  if (er)
    assert(er instanceof Error)

  options.chmod(p, _0666, function (er2) {
    if (er2)
      cb(er2.code === "ENOENT" ? null : er)
    else
      options.stat(p, function(er3, stats) {
        if (er3)
          cb(er3.code === "ENOENT" ? null : er)
        else if (stats.isDirectory())
          rmdir(p, options, er, cb)
        else
          options.unlink(p, cb)
      })
  })
}

function fixWinEPERMSync (p, options, er) {
  assert(p)
  assert(options)
  if (er)
    assert(er instanceof Error)

  try {
    options.chmodSync(p, _0666)
  } catch (er2) {
    if (er2.code === "ENOENT")
      return
    else
      throw er
  }

  try {
    var stats = options.statSync(p)
  } catch (er3) {
    if (er3.code === "ENOENT")
      return
    else
      throw er
  }

  if (stats.isDirectory())
    rmdirSync(p, options, er)
  else
    options.unlinkSync(p)
}

function rmdir (p, options, originalEr, cb) {
  assert(p)
  assert(options)
  if (originalEr)
    assert(originalEr instanceof Error)
  assert(typeof cb === 'function')

  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)
  // if we guessed wrong, and it's not a directory, then
  // raise the original error.
  options.rmdir(p, function (er) {
    if (er && (er.code === "ENOTEMPTY" || er.code === "EEXIST" || er.code === "EPERM"))
      rmkids(p, options, cb)
    else if (er && er.code === "ENOTDIR")
      cb(originalEr)
    else
      cb(er)
  })
}

function rmkids(p, options, cb) {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')

  options.readdir(p, function (er, files) {
    if (er)
      return cb(er)
    var n = files.length
    if (n === 0)
      return options.rmdir(p, cb)
    var errState
    files.forEach(function (f) {
      rimraf(path.join(p, f), options, function (er) {
        if (errState)
          return
        if (er)
          return cb(errState = er)
        if (--n === 0)
          options.rmdir(p, cb)
      })
    })
  })
}

// this looks simpler, and is strictly *faster*, but will
// tie up the JavaScript thread and fail on excessively
// deep directory trees.
function rimrafSync (p, options) {
  options = options || {}
  defaults(options)

  assert(p, 'rimraf: missing path')
  assert.equal(typeof p, 'string', 'rimraf: path should be a string')
  assert(options, 'rimraf: missing options')
  assert.equal(typeof options, 'object', 'rimraf: options should be object')

  var results

  if (options.disableGlob || !glob.hasMagic(p)) {
    results = [p]
  } else {
    try {
      options.lstatSync(p)
      results = [p]
    } catch (er) {
      results = glob.sync(p, options.glob)
    }
  }

  if (!results.length)
    return

  for (var i = 0; i < results.length; i++) {
    var p = results[i]

    try {
      var st = options.lstatSync(p)
    } catch (er) {
      if (er.code === "ENOENT")
        return

      // Windows can EPERM on stat.  Life is suffering.
      if (er.code === "EPERM" && isWindows)
        fixWinEPERMSync(p, options, er)
    }

    try {
      // sunos lets the root user unlink directories, which is... weird.
      if (st && st.isDirectory())
        rmdirSync(p, options, null)
      else
        options.unlinkSync(p)
    } catch (er) {
      if (er.code === "ENOENT")
        return
      if (er.code === "EPERM")
        return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)
      if (er.code !== "EISDIR")
        throw er

      rmdirSync(p, options, er)
    }
  }
}

function rmdirSync (p, options, originalEr) {
  assert(p)
  assert(options)
  if (originalEr)
    assert(originalEr instanceof Error)

  try {
    options.rmdirSync(p)
  } catch (er) {
    if (er.code === "ENOENT")
      return
    if (er.code === "ENOTDIR")
      throw originalEr
    if (er.code === "ENOTEMPTY" || er.code === "EEXIST" || er.code === "EPERM")
      rmkidsSync(p, options)
  }
}

function rmkidsSync (p, options) {
  assert(p)
  assert(options)
  options.readdirSync(p).forEach(function (f) {
    rimrafSync(path.join(p, f), options)
  })

  // We only end up here once we got ENOTEMPTY at least once, and
  // at this point, we are guaranteed to have removed all the kids.
  // So, we know that it won't be ENOENT or ENOTDIR or anything else.
  // try really hard to delete stuff on windows, because it has a
  // PROFOUNDLY annoying habit of not closing handles promptly when
  // files are deleted, resulting in spurious ENOTEMPTY errors.
  var retries = isWindows ? 100 : 1
  var i = 0
  do {
    var threw = true
    try {
      var ret = options.rmdirSync(p, options)
      threw = false
      return ret
    } finally {
      if (++i < retries && threw)
        continue
    }
  } while (true)
}

},
"Oc5R85kAunEsl9tmxVP0hyHzugCqnT53PX/JhoVOXXE=":
function (require, module, exports, __dirname, __filename) {
module.exports = promisize

function promisize (cb) {
  var promise
  var res
  var rej

  if (cb != null && typeof cb !== 'function') throw new Error('cb must be a function')

  if (cb == null && typeof Promise !== 'undefined') {
    promise = new Promise(function (resolve, reject) {
      res = resolve
      rej = reject
    })
  }

  function intercept (err, result) {
    if (promise) {
      if (err) rej(err)
      else res(result)
    } else {
      if (cb) cb(err, result)
      else if (err) throw err
    }
  }

  intercept.promise = promise

  return intercept
}

},
"Ofp/3pHGnR/xhrB0q5TIvQrTtz5GW+A+PkWMdavBy0o=":
function (require, module, exports, __dirname, __filename) {
var maybeCallback = require("continuable/maybe-callback")

module.exports = maybeCallback(hash)

//  hash := (tasks:Object<String, Continuable<T>>)
//      => Continuable<Object<String, T>>
function hash(tasks) {
    return function continuable(callback) {
        var keys = Object.keys(tasks)
        var count = 0
        var result = {}

        if (keys.length === 0) {
            return callback(null, result)
        }

        keys.forEach(function (key) {
            tasks[key](function (err, value) {
                if (err && result) {
                    result = null
                    callback(err)
                } else if (!err && result) {
                    result[key] = value
                    if (++count === keys.length) {
                        callback(null, result)
                    }
                }
            })
        })
    }
}

},
"OnUvL8sN41MmXy1JKBJhg7WgjZyetqpPq3SAgobmmEQ=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var _Object$setPrototypeO;

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

var finished = require('./end-of-stream');

var kLastResolve = Symbol('lastResolve');
var kLastReject = Symbol('lastReject');
var kError = Symbol('error');
var kEnded = Symbol('ended');
var kLastPromise = Symbol('lastPromise');
var kHandlePromise = Symbol('handlePromise');
var kStream = Symbol('stream');

function createIterResult(value, done) {
  return {
    value: value,
    done: done
  };
}

function readAndResolve(iter) {
  var resolve = iter[kLastResolve];

  if (resolve !== null) {
    var data = iter[kStream].read(); // we defer if data is null
    // we can be expecting either 'end' or
    // 'error'

    if (data !== null) {
      iter[kLastPromise] = null;
      iter[kLastResolve] = null;
      iter[kLastReject] = null;
      resolve(createIterResult(data, false));
    }
  }
}

function onReadable(iter) {
  // we wait for the next tick, because it might
  // emit an error with process.nextTick
  process.nextTick(readAndResolve, iter);
}

function wrapForNext(lastPromise, iter) {
  return function (resolve, reject) {
    lastPromise.then(function () {
      if (iter[kEnded]) {
        resolve(createIterResult(undefined, true));
        return;
      }

      iter[kHandlePromise](resolve, reject);
    }, reject);
  };
}

var AsyncIteratorPrototype = Object.getPrototypeOf(function () {});
var ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {
  get stream() {
    return this[kStream];
  },

  next: function next() {
    var _this = this;

    // if we have detected an error in the meanwhile
    // reject straight away
    var error = this[kError];

    if (error !== null) {
      return Promise.reject(error);
    }

    if (this[kEnded]) {
      return Promise.resolve(createIterResult(undefined, true));
    }

    if (this[kStream].destroyed) {
      // We need to defer via nextTick because if .destroy(err) is
      // called, the error will be emitted via nextTick, and
      // we cannot guarantee that there is no error lingering around
      // waiting to be emitted.
      return new Promise(function (resolve, reject) {
        process.nextTick(function () {
          if (_this[kError]) {
            reject(_this[kError]);
          } else {
            resolve(createIterResult(undefined, true));
          }
        });
      });
    } // if we have multiple next() calls
    // we will wait for the previous Promise to finish
    // this logic is optimized to support for await loops,
    // where next() is only called once at a time


    var lastPromise = this[kLastPromise];
    var promise;

    if (lastPromise) {
      promise = new Promise(wrapForNext(lastPromise, this));
    } else {
      // fast path needed to support multiple this.push()
      // without triggering the next() queue
      var data = this[kStream].read();

      if (data !== null) {
        return Promise.resolve(createIterResult(data, false));
      }

      promise = new Promise(this[kHandlePromise]);
    }

    this[kLastPromise] = promise;
    return promise;
  }
}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {
  return this;
}), _defineProperty(_Object$setPrototypeO, "return", function _return() {
  var _this2 = this;

  // destroy(err, cb) is a private API
  // we can guarantee we have that here, because we control the
  // Readable class this is attached to
  return new Promise(function (resolve, reject) {
    _this2[kStream].destroy(null, function (err) {
      if (err) {
        reject(err);
        return;
      }

      resolve(createIterResult(undefined, true));
    });
  });
}), _Object$setPrototypeO), AsyncIteratorPrototype);

var createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {
  var _Object$create;

  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {
    value: stream,
    writable: true
  }), _defineProperty(_Object$create, kLastResolve, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kLastReject, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kError, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kEnded, {
    value: stream._readableState.endEmitted,
    writable: true
  }), _defineProperty(_Object$create, kHandlePromise, {
    value: function value(resolve, reject) {
      var data = iterator[kStream].read();

      if (data) {
        iterator[kLastPromise] = null;
        iterator[kLastResolve] = null;
        iterator[kLastReject] = null;
        resolve(createIterResult(data, false));
      } else {
        iterator[kLastResolve] = resolve;
        iterator[kLastReject] = reject;
      }
    },
    writable: true
  }), _Object$create));
  iterator[kLastPromise] = null;
  finished(stream, function (err) {
    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise
      // returned by next() and store the error

      if (reject !== null) {
        iterator[kLastPromise] = null;
        iterator[kLastResolve] = null;
        iterator[kLastReject] = null;
        reject(err);
      }

      iterator[kError] = err;
      return;
    }

    var resolve = iterator[kLastResolve];

    if (resolve !== null) {
      iterator[kLastPromise] = null;
      iterator[kLastResolve] = null;
      iterator[kLastReject] = null;
      resolve(createIterResult(undefined, true));
    }

    iterator[kEnded] = true;
  });
  stream.on('readable', onReadable.bind(null, iterator));
  return iterator;
};

module.exports = createReadableStreamAsyncIterator;
},
"P+jANL/GScjoBFL0xwUhU6SciaV58/h6Tfavi6tc4rk=":
function (require, module, exports, __dirname, __filename) {
'use strict';
var singleComment = 1;
var multiComment = 2;

function stripWithoutWhitespace() {
	return '';
}

function stripWithWhitespace(str, start, end) {
	return str.slice(start, end).replace(/\S/g, ' ');
}

module.exports = function (str, opts) {
	opts = opts || {};

	var currentChar;
	var nextChar;
	var insideString = false;
	var insideComment = false;
	var offset = 0;
	var ret = '';
	var strip = opts.whitespace === false ? stripWithoutWhitespace : stripWithWhitespace;

	for (var i = 0; i < str.length; i++) {
		currentChar = str[i];
		nextChar = str[i + 1];

		if (!insideComment && currentChar === '"') {
			var escaped = str[i - 1] === '\\' && str[i - 2] !== '\\';
			if (!escaped) {
				insideString = !insideString;
			}
		}

		if (insideString) {
			continue;
		}

		if (!insideComment && currentChar + nextChar === '//') {
			ret += str.slice(offset, i);
			offset = i;
			insideComment = singleComment;
			i++;
		} else if (insideComment === singleComment && currentChar + nextChar === '\r\n') {
			i++;
			insideComment = false;
			ret += strip(str, offset, i);
			offset = i;
			continue;
		} else if (insideComment === singleComment && currentChar === '\n') {
			insideComment = false;
			ret += strip(str, offset, i);
			offset = i;
		} else if (!insideComment && currentChar + nextChar === '/*') {
			ret += str.slice(offset, i);
			offset = i;
			insideComment = multiComment;
			i++;
			continue;
		} else if (insideComment === multiComment && currentChar + nextChar === '*/') {
			i++;
			insideComment = false;
			ret += strip(str, offset, i + 1);
			offset = i + 1;
			continue;
		}
	}

	return ret + (insideComment ? strip(str.substr(offset)) : str.substr(offset));
};

},
"P3Um8oE0K7rBaONmz4AY7ZGfkojbO1Lzb2nWN/IL1pE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const { randomFillSync } = require('crypto');

const PerMessageDeflate = require('./permessage-deflate');
const { EMPTY_BUFFER } = require('./constants');
const { isValidStatusCode } = require('./validation');
const { mask: applyMask, toBuffer } = require('./buffer-util');

const mask = Buffer.alloc(4);

/**
 * HyBi Sender implementation.
 */
class Sender {
  /**
   * Creates a Sender instance.
   *
   * @param {net.Socket} socket The connection socket
   * @param {Object} [extensions] An object containing the negotiated extensions
   */
  constructor(socket, extensions) {
    this._extensions = extensions || {};
    this._socket = socket;

    this._firstFragment = true;
    this._compress = false;

    this._bufferedBytes = 0;
    this._deflating = false;
    this._queue = [];
  }

  /**
   * Frames a piece of data according to the HyBi WebSocket protocol.
   *
   * @param {Buffer} data The data to frame
   * @param {Object} options Options object
   * @param {Number} options.opcode The opcode
   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be
   *     modified
   * @param {Boolean} [options.fin=false] Specifies whether or not to set the
   *     FIN bit
   * @param {Boolean} [options.mask=false] Specifies whether or not to mask
   *     `data`
   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the
   *     RSV1 bit
   * @return {Buffer[]} The framed data as a list of `Buffer` instances
   * @public
   */
  static frame(data, options) {
    const merge = options.mask && options.readOnly;
    let offset = options.mask ? 6 : 2;
    let payloadLength = data.length;

    if (data.length >= 65536) {
      offset += 8;
      payloadLength = 127;
    } else if (data.length > 125) {
      offset += 2;
      payloadLength = 126;
    }

    const target = Buffer.allocUnsafe(merge ? data.length + offset : offset);

    target[0] = options.fin ? options.opcode | 0x80 : options.opcode;
    if (options.rsv1) target[0] |= 0x40;

    target[1] = payloadLength;

    if (payloadLength === 126) {
      target.writeUInt16BE(data.length, 2);
    } else if (payloadLength === 127) {
      target.writeUInt32BE(0, 2);
      target.writeUInt32BE(data.length, 6);
    }

    if (!options.mask) return [target, data];

    randomFillSync(mask, 0, 4);

    target[1] |= 0x80;
    target[offset - 4] = mask[0];
    target[offset - 3] = mask[1];
    target[offset - 2] = mask[2];
    target[offset - 1] = mask[3];

    if (merge) {
      applyMask(data, mask, target, offset, data.length);
      return [target];
    }

    applyMask(data, mask, data, 0, data.length);
    return [target, data];
  }

  /**
   * Sends a close message to the other peer.
   *
   * @param {Number} [code] The status code component of the body
   * @param {String} [data] The message component of the body
   * @param {Boolean} [mask=false] Specifies whether or not to mask the message
   * @param {Function} [cb] Callback
   * @public
   */
  close(code, data, mask, cb) {
    let buf;

    if (code === undefined) {
      buf = EMPTY_BUFFER;
    } else if (typeof code !== 'number' || !isValidStatusCode(code)) {
      throw new TypeError('First argument must be a valid error code number');
    } else if (data === undefined || data === '') {
      buf = Buffer.allocUnsafe(2);
      buf.writeUInt16BE(code, 0);
    } else {
      const length = Buffer.byteLength(data);

      if (length > 123) {
        throw new RangeError('The message must not be greater than 123 bytes');
      }

      buf = Buffer.allocUnsafe(2 + length);
      buf.writeUInt16BE(code, 0);
      buf.write(data, 2);
    }

    if (this._deflating) {
      this.enqueue([this.doClose, buf, mask, cb]);
    } else {
      this.doClose(buf, mask, cb);
    }
  }

  /**
   * Frames and sends a close message.
   *
   * @param {Buffer} data The message to send
   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`
   * @param {Function} [cb] Callback
   * @private
   */
  doClose(data, mask, cb) {
    this.sendFrame(
      Sender.frame(data, {
        fin: true,
        rsv1: false,
        opcode: 0x08,
        mask,
        readOnly: false
      }),
      cb
    );
  }

  /**
   * Sends a ping message to the other peer.
   *
   * @param {*} data The message to send
   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`
   * @param {Function} [cb] Callback
   * @public
   */
  ping(data, mask, cb) {
    const buf = toBuffer(data);

    if (buf.length > 125) {
      throw new RangeError('The data size must not be greater than 125 bytes');
    }

    if (this._deflating) {
      this.enqueue([this.doPing, buf, mask, toBuffer.readOnly, cb]);
    } else {
      this.doPing(buf, mask, toBuffer.readOnly, cb);
    }
  }

  /**
   * Frames and sends a ping message.
   *
   * @param {Buffer} data The message to send
   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`
   * @param {Boolean} [readOnly=false] Specifies whether `data` can be modified
   * @param {Function} [cb] Callback
   * @private
   */
  doPing(data, mask, readOnly, cb) {
    this.sendFrame(
      Sender.frame(data, {
        fin: true,
        rsv1: false,
        opcode: 0x09,
        mask,
        readOnly
      }),
      cb
    );
  }

  /**
   * Sends a pong message to the other peer.
   *
   * @param {*} data The message to send
   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`
   * @param {Function} [cb] Callback
   * @public
   */
  pong(data, mask, cb) {
    const buf = toBuffer(data);

    if (buf.length > 125) {
      throw new RangeError('The data size must not be greater than 125 bytes');
    }

    if (this._deflating) {
      this.enqueue([this.doPong, buf, mask, toBuffer.readOnly, cb]);
    } else {
      this.doPong(buf, mask, toBuffer.readOnly, cb);
    }
  }

  /**
   * Frames and sends a pong message.
   *
   * @param {Buffer} data The message to send
   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`
   * @param {Boolean} [readOnly=false] Specifies whether `data` can be modified
   * @param {Function} [cb] Callback
   * @private
   */
  doPong(data, mask, readOnly, cb) {
    this.sendFrame(
      Sender.frame(data, {
        fin: true,
        rsv1: false,
        opcode: 0x0a,
        mask,
        readOnly
      }),
      cb
    );
  }

  /**
   * Sends a data message to the other peer.
   *
   * @param {*} data The message to send
   * @param {Object} options Options object
   * @param {Boolean} [options.compress=false] Specifies whether or not to
   *     compress `data`
   * @param {Boolean} [options.binary=false] Specifies whether `data` is binary
   *     or text
   * @param {Boolean} [options.fin=false] Specifies whether the fragment is the
   *     last one
   * @param {Boolean} [options.mask=false] Specifies whether or not to mask
   *     `data`
   * @param {Function} [cb] Callback
   * @public
   */
  send(data, options, cb) {
    const buf = toBuffer(data);
    const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];
    let opcode = options.binary ? 2 : 1;
    let rsv1 = options.compress;

    if (this._firstFragment) {
      this._firstFragment = false;
      if (rsv1 && perMessageDeflate) {
        rsv1 = buf.length >= perMessageDeflate._threshold;
      }
      this._compress = rsv1;
    } else {
      rsv1 = false;
      opcode = 0;
    }

    if (options.fin) this._firstFragment = true;

    if (perMessageDeflate) {
      const opts = {
        fin: options.fin,
        rsv1,
        opcode,
        mask: options.mask,
        readOnly: toBuffer.readOnly
      };

      if (this._deflating) {
        this.enqueue([this.dispatch, buf, this._compress, opts, cb]);
      } else {
        this.dispatch(buf, this._compress, opts, cb);
      }
    } else {
      this.sendFrame(
        Sender.frame(buf, {
          fin: options.fin,
          rsv1: false,
          opcode,
          mask: options.mask,
          readOnly: toBuffer.readOnly
        }),
        cb
      );
    }
  }

  /**
   * Dispatches a data message.
   *
   * @param {Buffer} data The message to send
   * @param {Boolean} [compress=false] Specifies whether or not to compress
   *     `data`
   * @param {Object} options Options object
   * @param {Number} options.opcode The opcode
   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be
   *     modified
   * @param {Boolean} [options.fin=false] Specifies whether or not to set the
   *     FIN bit
   * @param {Boolean} [options.mask=false] Specifies whether or not to mask
   *     `data`
   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the
   *     RSV1 bit
   * @param {Function} [cb] Callback
   * @private
   */
  dispatch(data, compress, options, cb) {
    if (!compress) {
      this.sendFrame(Sender.frame(data, options), cb);
      return;
    }

    const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];

    this._bufferedBytes += data.length;
    this._deflating = true;
    perMessageDeflate.compress(data, options.fin, (_, buf) => {
      if (this._socket.destroyed) {
        const err = new Error(
          'The socket was closed while data was being compressed'
        );

        if (typeof cb === 'function') cb(err);

        for (let i = 0; i < this._queue.length; i++) {
          const callback = this._queue[i][4];

          if (typeof callback === 'function') callback(err);
        }

        return;
      }

      this._bufferedBytes -= data.length;
      this._deflating = false;
      options.readOnly = false;
      this.sendFrame(Sender.frame(buf, options), cb);
      this.dequeue();
    });
  }

  /**
   * Executes queued send operations.
   *
   * @private
   */
  dequeue() {
    while (!this._deflating && this._queue.length) {
      const params = this._queue.shift();

      this._bufferedBytes -= params[1].length;
      Reflect.apply(params[0], this, params.slice(1));
    }
  }

  /**
   * Enqueues a send operation.
   *
   * @param {Array} params Send operation parameters.
   * @private
   */
  enqueue(params) {
    this._bufferedBytes += params[1].length;
    this._queue.push(params);
  }

  /**
   * Sends a frame.
   *
   * @param {Buffer[]} list The frame to send
   * @param {Function} [cb] Callback
   * @private
   */
  sendFrame(list, cb) {
    if (list.length === 2) {
      this._socket.cork();
      this._socket.write(list[0]);
      this._socket.write(list[1], cb);
      this._socket.uncork();
    } else {
      this._socket.write(list[0], cb);
    }
  }
}

module.exports = Sender;

},
"P4SmaY4k9IerC2UPiYhuHbO5MvGb9gN+MjKTVCtIdH4=":
function (require, module, exports, __dirname, __filename) {
function promisify () {
  var callback
  var promise = new Promise(function (resolve, reject) {
    callback = function callback (err, value) {
      if (err) reject(err)
      else resolve(value)
    }
  })
  callback.promise = promise
  return callback
}

module.exports = promisify

},
"PA0rKtb47h3RL+1b/tkpJ1aYrM4wxnYp6aM84nJojzA=":
function (require, module, exports, __dirname, __filename) {
var objectKeys = require('object-keys');
var isArguments = require('is-arguments');
var is = require('object-is');
var isRegex = require('is-regex');
var flags = require('regexp.prototype.flags');
var isDate = require('is-date-object');

var getTime = Date.prototype.getTime;

function deepEqual(actual, expected, options) {
  var opts = options || {};

  // 7.1. All identical values are equivalent, as determined by ===.
  if (opts.strict ? is(actual, expected) : actual === expected) {
    return true;
  }

  // 7.3. Other pairs that do not both pass typeof value == 'object', equivalence is determined by ==.
  if (!actual || !expected || (typeof actual !== 'object' && typeof expected !== 'object')) {
    return opts.strict ? is(actual, expected) : actual == expected;
  }

  /*
   * 7.4. For all other Object pairs, including Array objects, equivalence is
   * determined by having the same number of owned properties (as verified
   * with Object.prototype.hasOwnProperty.call), the same set of keys
   * (although not necessarily the same order), equivalent values for every
   * corresponding key, and an identical 'prototype' property. Note: this
   * accounts for both named and indexed properties on Arrays.
   */
  // eslint-disable-next-line no-use-before-define
  return objEquiv(actual, expected, opts);
}

function isUndefinedOrNull(value) {
  return value === null || value === undefined;
}

function isBuffer(x) {
  if (!x || typeof x !== 'object' || typeof x.length !== 'number') {
    return false;
  }
  if (typeof x.copy !== 'function' || typeof x.slice !== 'function') {
    return false;
  }
  if (x.length > 0 && typeof x[0] !== 'number') {
    return false;
  }
  return true;
}

function objEquiv(a, b, opts) {
  /* eslint max-statements: [2, 50] */
  var i, key;
  if (typeof a !== typeof b) { return false; }
  if (isUndefinedOrNull(a) || isUndefinedOrNull(b)) { return false; }

  // an identical 'prototype' property.
  if (a.prototype !== b.prototype) { return false; }

  if (isArguments(a) !== isArguments(b)) { return false; }

  var aIsRegex = isRegex(a);
  var bIsRegex = isRegex(b);
  if (aIsRegex !== bIsRegex) { return false; }
  if (aIsRegex || bIsRegex) {
    return a.source === b.source && flags(a) === flags(b);
  }

  if (isDate(a) && isDate(b)) {
    return getTime.call(a) === getTime.call(b);
  }

  var aIsBuffer = isBuffer(a);
  var bIsBuffer = isBuffer(b);
  if (aIsBuffer !== bIsBuffer) { return false; }
  if (aIsBuffer || bIsBuffer) { // && would work too, because both are true or both false here
    if (a.length !== b.length) { return false; }
    for (i = 0; i < a.length; i++) {
      if (a[i] !== b[i]) { return false; }
    }
    return true;
  }

  if (typeof a !== typeof b) { return false; }

  try {
    var ka = objectKeys(a);
    var kb = objectKeys(b);
  } catch (e) { // happens when one is a string literal and the other isn't
    return false;
  }
  // having the same number of owned properties (keys incorporates hasOwnProperty)
  if (ka.length !== kb.length) { return false; }

  // the same set of keys (although not necessarily the same order),
  ka.sort();
  kb.sort();
  // ~~~cheap key test
  for (i = ka.length - 1; i >= 0; i--) {
    if (ka[i] != kb[i]) { return false; }
  }
  // equivalent values for every corresponding key, and ~~~possibly expensive deep test
  for (i = ka.length - 1; i >= 0; i--) {
    key = ka[i];
    if (!deepEqual(a[key], b[key], opts)) { return false; }
  }

  return true;
}

module.exports = deepEqual;

},
"PGOrAEx6yT+O2u4PPKx2aE/za+5eJjh/yw1SCj5dM5k=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

module.exports = [require('./db'), require('./migrate')]

},
"PGWYEYmYIgPUf88EuAnryg5Ac4vxRG7uvYuILVqpgGw=":
function (require, module, exports, __dirname, __filename) {
var defaultEncoding
/* istanbul ignore next */
if (global.process && global.process.browser) {
  defaultEncoding = 'utf-8'
} else if (global.process && global.process.version) {
  var pVersionMajor = parseInt(process.version.split('.')[0].slice(1), 10)

  defaultEncoding = pVersionMajor >= 6 ? 'utf-8' : 'binary'
} else {
  defaultEncoding = 'utf-8'
}
module.exports = defaultEncoding

},
"PLjBxlVJaOPqbLzJb1o7ySXTwuRANZRpg2f4OXSYyU0=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const Obv = require('obz')

module.exports = function Status(log, jitdb) {
  const statsObj = {
    log: log.since.value || 0,
    jit: {},
    indexes: {},
  }
  const obv = Obv()
  obv.set(statsObj)
  const EMIT_INTERVAL = 1000
  const PRUNE_INTERVAL = 2000
  let jitdbLastTime = Date.now()
  let i = 0
  let iTimer = 0
  let timer = null

  jitdb.status((jitStats) => {
    updateLog()
    statsObj.jit = jitStats
    jitdbLastTime = Date.now()
    obv.set(statsObj)
  })

  function setTimer() {
    // Turn on
    timer = setInterval(() => {
      if (i === iTimer) {
        // Turn off because nothing has been updated recently
        clearInterval(timer)
        timer = null
        i = iTimer = 0
      } else {
        iTimer = i
        if (jitdbLastTime + PRUNE_INTERVAL < Date.now()) {
          statsObj.jit = {}
        }
        obv.set(statsObj)
      }
    }, EMIT_INTERVAL)
    if (timer.unref) timer.unref()
  }

  function updateLog() {
    statsObj.log = log.since.value
  }

  function updateIndex(name, offset) {
    updateLog()
    statsObj.indexes[name] = offset
    ++i
    if (!timer) {
      iTimer = i
      if (jitdbLastTime + PRUNE_INTERVAL < Date.now()) {
        statsObj.jit = {}
      }
      obv.set(statsObj)
      setTimer()
    }
  }

  return {
    obv,
    updateLog,
    updateIndex,
  }
}

},
"Pbc+NH7L26/fjQ24UUXId+Ez9TcudnNg75DAn3CsUQM=":
function (require, module, exports, __dirname, __filename) {
var wrappy = require('wrappy')
module.exports = wrappy(once)
module.exports.strict = wrappy(onceStrict)

once.proto = once(function () {
  Object.defineProperty(Function.prototype, 'once', {
    value: function () {
      return once(this)
    },
    configurable: true
  })

  Object.defineProperty(Function.prototype, 'onceStrict', {
    value: function () {
      return onceStrict(this)
    },
    configurable: true
  })
})

function once (fn) {
  var f = function () {
    if (f.called) return f.value
    f.called = true
    return f.value = fn.apply(this, arguments)
  }
  f.called = false
  return f
}

function onceStrict (fn) {
  var f = function () {
    if (f.called)
      throw new Error(f.onceError)
    f.called = true
    return f.value = fn.apply(this, arguments)
  }
  var name = fn.name || 'Function wrapped with `once`'
  f.onceError = name + " shouldn't be called more than once"
  f.called = false
  return f
}

},
"Pi7pp3AAuDKQ0CIj2zahLYspEqHEZEYrlGKbRKrMLIE=":
function (require, module, exports, __dirname, __filename) {
var sldMap= require('./domains/sld')

module.exports = function isValidDomain(v, opts) {
  if (typeof v !== 'string') return false
  if (!(opts instanceof Object)) opts = {}
  v = v.toLowerCase()

  var validChars = /^([a-z0-9-.*]+)$/g
  if (!validChars.test(v)) {
    return false
  }

  var sldRegex = /(.*)\.(([a-z0-9]+)(\.[a-z0-9]+))/
  var matches = v.match(sldRegex)
  var tld = null
  var parts = null
  if (matches && matches.length > 2) {
    if (sldMap[matches[2]]) {
      tld = matches[2]
      parts = matches[1].split('.')
    }
  }

  if (!parts) {
    parts = v.split('.')
    if (parts.length <= 1) return false

    tld = parts.pop()
    var tldRegex = /^(?:xn--)?(?!^\d+$)[a-z0-9]+$/gi

    if (!tldRegex.test(tld)) return false
  }

  if (opts.subdomain == false && parts.length > 1) return false

  var isValid = parts.every(function(host, index) {
    if (opts.wildcard && index === 0 && host === '*' && parts.length > 1) return true

    var hostRegex = /^(?!:\/\/)([a-z0-9]+|[a-z0-9][a-z0-9-]*[a-z0-9])$/gi;

    return hostRegex.test(host)
  })

  return isValid
}
},
"Pro16v0HiixIQ6EQAMBkQ7XYsv6jtoKq4g2u6lvmbNI=":
function (require, module, exports, __dirname, __filename) {
'use strict';
var fs   = require('fs')
var ini  = require('ini')
var path = require('path')
var stripJsonComments = require('strip-json-comments')

var parse = exports.parse = function (content) {

  //if it ends in .json or starts with { then it must be json.
  //must be done this way, because ini accepts everything.
  //can't just try and parse it and let it throw if it's not ini.
  //everything is ini. even json with a syntax error.

  if(/^\s*{/.test(content))
    return JSON.parse(stripJsonComments(content))
  return ini.parse(content)

}

var file = exports.file = function () {
  var args = [].slice.call(arguments).filter(function (arg) { return arg != null })

  //path.join breaks if it's a not a string, so just skip this.
  for(var i in args)
    if('string' !== typeof args[i])
      return

  var file = path.join.apply(null, args)
  var content
  try {
    return fs.readFileSync(file,'utf-8')
  } catch (err) {
    return
  }
}

var json = exports.json = function () {
  var content = file.apply(null, arguments)
  return content ? parse(content) : null
}

var env = exports.env = function (prefix, env) {
  env = env || process.env
  var obj = {}
  var l = prefix.length
  for(var k in env) {
    if(k.toLowerCase().indexOf(prefix.toLowerCase()) === 0) {

      var keypath = k.substring(l).split('__')

      // Trim empty strings from keypath array
      var _emptyStringIndex
      while ((_emptyStringIndex=keypath.indexOf('')) > -1) {
        keypath.splice(_emptyStringIndex, 1)
      }

      var cursor = obj
      keypath.forEach(function _buildSubObj(_subkey,i){

        // (check for _subkey first so we ignore empty strings)
        // (check for cursor to avoid assignment to primitive objects)
        if (!_subkey || typeof cursor !== 'object')
          return

        // If this is the last key, just stuff the value in there
        // Assigns actual value from env variable to final key
        // (unless it's just an empty string- in that case use the last valid key)
        if (i === keypath.length-1)
          cursor[_subkey] = env[k]


        // Build sub-object if nothing already exists at the keypath
        if (cursor[_subkey] === undefined)
          cursor[_subkey] = {}

        // Increment cursor used to track the object at the current depth
        cursor = cursor[_subkey]

      })

    }

  }

  return obj
}

var find = exports.find = function () {
  var rel = path.join.apply(null, [].slice.call(arguments))

  function find(start, rel) {
    var file = path.join(start, rel)
    try {
      fs.statSync(file)
      return file
    } catch (err) {
      if(path.dirname(start) !== start) // root
        return find(path.dirname(start), rel)
    }
  }
  return find(process.cwd(), rel)
}



},
"PvSh3VWqh6+Ionq3pEqT4x/SnbFEdKKj1+KEj1K7hfY=":
function (require, module, exports, __dirname, __filename) {
'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

const defaultSerializers = {
    'application/json': { parse: JSON.parse, convert: JSON.stringify },
};
const defaults = {
    contentType: 'application/json',
    responseType: 'parsed',
    accept: '*/*',
};
function makeQueryString(query) {
    if (!query) {
        return '';
    }
    if (typeof query === 'string') {
        if (query.charAt(0) === '?') {
            return query;
        }
        else {
            return '?' + query;
        }
    }
    let str = '?';
    for (const key of Object.keys(query)) {
        str +=
            encodeURIComponent(key) +
                '=' +
                encodeURIComponent(query[key]) +
                '&';
    }
    if (str === '?') {
        throw new Error('An empty object is not valid as query parameter');
    }
    return str;
}

exports.defaultSerializers = defaultSerializers;
exports.defaults = defaults;
exports.makeQueryString = makeQueryString;

},
"PzOz7rfDJGtBCy6Ul16dAVoxSjTPHYn2SJum6kU2C+8=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var supportsDescriptors = require('define-properties').supportsDescriptors;
var getPolyfill = require('./polyfill');
var gOPD = Object.getOwnPropertyDescriptor;
var defineProperty = Object.defineProperty;
var TypeErr = TypeError;
var getProto = Object.getPrototypeOf;
var regex = /a/;

module.exports = function shimFlags() {
	if (!supportsDescriptors || !getProto) {
		throw new TypeErr('RegExp.prototype.flags requires a true ES5 environment that supports property descriptors');
	}
	var polyfill = getPolyfill();
	var proto = getProto(regex);
	var descriptor = gOPD(proto, 'flags');
	if (!descriptor || descriptor.get !== polyfill) {
		defineProperty(proto, 'flags', {
			configurable: true,
			enumerable: false,
			get: polyfill
		});
	}
	return polyfill;
};

},
"PzqmH036YAvn8s/HIs/BtoJzKFyXkFW/tpzfv/YOWWI=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (filter) {
  var value = null, listeners = [], oncers = []

  function trigger (_value) {
    value = _value
    var length = listeners.length
    for (var i = 0; i < length && value === _value; i++) {
      const listener = listeners[i]
      listener(value)
      if (listeners.length !== length) { // remove
        length = listeners.length
        if (listener !== listeners[i]) {
          // we removed an earlier listener, must decrement i also
          i -= 1
        }
      }
    }
    // decrement from length, incase a !immediately
    // listener is added during a trigger
    var l = oncers.length
    var _oncers = oncers
    oncers = []
    while (l-- && _value === value) {
      _oncers.shift()(value)
    }
  }

  function many (ready, immediately) {
    var i = listeners.push(ready) - 1
    if (value !== null && immediately !== false) ready(value)
    return function () { //manually remove...
      //fast path, will happen if an earlier listener has not been removed.
      if (listeners[i] !== ready)
        i = listeners.indexOf(ready)
      listeners.splice(i, 1)
    }
  }

  many.set = function (_value) {
    if (filter ? filter(value, _value) : true) trigger(many.value = _value)
    return many
  }

  many.once = function (once, immediately) {
    if(value !== null && immediately !== false) {
      once(value)
      return function () {}
    }
    else {
      var i = oncers.push(once) - 1
      return function () {
        if(oncers[i] !== once)
          i = oncers.indexOf(once)
      }
    }
  }

  return many
}

},
"Q4bxXCqL1Ab2Xb/fdXqD8A0XLVWcCYDImaKNU7YGEMQ=":
function (require, module, exports, __dirname, __filename) {
const {flat, closedread} = require('./utils')

function PacketStreamSubstream (id, ps, remove) {
  this.id       = id
  this.read     = null   // must release, may capture `this`
  this.writeEnd = null
  this.readEnd  = null

  this._ps      = ps     // must release, may capture `this`
  this._remove  = remove // must release, may capture `this`
}

PacketStreamSubstream.prototype.write = function (data, err) {
  const ps = this._ps
  if (err) {
    this.writeEnd = err
    if (ps) {
      ps.read({ req: this.id, stream: true, end: true, value: flat(err) })
      if (this.readEnd)
        this.destroy(err)
      ps._maybedone(err)
    }
  }
  else {
    if (ps) ps.read({ req: this.id, stream: true, end: false, value: data })
  }
}

// Send the `end` message for the substream
PacketStreamSubstream.prototype.end = function (err) {
  this.write(null, flat(err || true))
}

PacketStreamSubstream.prototype.destroy = function (err) {
  if (!this.writeEnd) {
    this.writeEnd = true
    if (!this.readEnd) {
      this.readEnd = true
      try {
        // catch errors to ensure cleanup
        this.read(null, err)
      } catch (e) {
        console.error('Exception thrown by PacketStream substream end handler', e)
        console.error(e.stack)
      }
    }
    this.write(null, err)
  }
  else if (!this.readEnd) {
    this.readEnd = true
    try {
      // catch errors to ensure cleanup
      // don't assume that a stream has been piped anywhere.
      if(this.read) this.read(null, err)
    } catch (e) {
      console.error('Exception thrown by PacketStream substream end handler', e)
      console.error(e.stack)
    }
  }

  // deallocate
  if (this._ps) {
    this._remove()
    this._remove = null
    this.read = closedread
    this._ps = null
  }
}

module.exports = PacketStreamSubstream
},
"QARYiqejdp2MNO+ag34WMiN0h+U+1XyuxRv8xmaPLCk=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var slice = Array.prototype.slice;
var isArgs = require('./isArguments');

var origKeys = Object.keys;
var keysShim = origKeys ? function keys(o) { return origKeys(o); } : require('./implementation');

var originalKeys = Object.keys;

keysShim.shim = function shimObjectKeys() {
	if (Object.keys) {
		var keysWorksWithArguments = (function () {
			// Safari 5.0 bug
			var args = Object.keys(arguments);
			return args && args.length === arguments.length;
		}(1, 2));
		if (!keysWorksWithArguments) {
			Object.keys = function keys(object) { // eslint-disable-line func-name-matching
				if (isArgs(object)) {
					return originalKeys(slice.call(object));
				}
				return originalKeys(object);
			};
		}
	} else {
		Object.keys = keysShim;
	}
	return Object.keys || keysShim;
};

module.exports = keysShim;

},
"QC13FnlczWnvX4IxreFGpKJod3GHol2Nh0MeFAx7rdg=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = {
  map: require('./map'),
  asyncMap: require('./async-map'),
  filter: require('./filter'),
  filterNot: require('./filter-not'),
  through: require('./through'),
  take: require('./take'),
  unique: require('./unique'),
  nonUnique: require('./non-unique'),
  flatten: require('./flatten')
}




},
"QQQAILjqxIlVNE7ftJTfhXmUZcvNV/Z14NAv7EgrKxw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ReadStreamTokenizer = void 0;
const AbstractTokenizer_1 = require("./AbstractTokenizer");
const peek_readable_1 = require("peek-readable");
const maxBufferSize = 256000;
class ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {
    constructor(stream, fileInfo) {
        super(fileInfo);
        this.streamReader = new peek_readable_1.StreamReader(stream);
    }
    /**
     * Get file information, an HTTP-client may implement this doing a HEAD request
     * @return Promise with file information
     */
    async getFileInfo() {
        return this.fileInfo;
    }
    /**
     * Read buffer from tokenizer
     * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream
     * @param options - Read behaviour options
     * @returns Promise with number of bytes read
     */
    async readBuffer(uint8Array, options) {
        const normOptions = this.normalizeOptions(uint8Array, options);
        const skipBytes = normOptions.position - this.position;
        if (skipBytes > 0) {
            await this.ignore(skipBytes);
            return this.readBuffer(uint8Array, options);
        }
        else if (skipBytes < 0) {
            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');
        }
        if (normOptions.length === 0) {
            return 0;
        }
        const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);
        this.position += bytesRead;
        if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {
            throw new peek_readable_1.EndOfStreamError();
        }
        return bytesRead;
    }
    /**
     * Peek (read ahead) buffer from tokenizer
     * @param uint8Array - Uint8Array (or Buffer) to write data to
     * @param options - Read behaviour options
     * @returns Promise with number of bytes peeked
     */
    async peekBuffer(uint8Array, options) {
        const normOptions = this.normalizeOptions(uint8Array, options);
        let bytesRead = 0;
        if (normOptions.position) {
            const skipBytes = normOptions.position - this.position;
            if (skipBytes > 0) {
                const skipBuffer = new Uint8Array(normOptions.length + skipBytes);
                bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: normOptions.mayBeLess });
                uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);
                return bytesRead - skipBytes;
            }
            else if (skipBytes < 0) {
                throw new Error('Cannot peek from a negative offset in a stream');
            }
        }
        if (normOptions.length > 0) {
            try {
                bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);
            }
            catch (err) {
                if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {
                    return 0;
                }
                throw err;
            }
            if ((!normOptions.mayBeLess) && bytesRead < normOptions.length) {
                throw new peek_readable_1.EndOfStreamError();
            }
        }
        return bytesRead;
    }
    async ignore(length) {
        // debug(`ignore ${this.position}...${this.position + length - 1}`);
        const bufSize = Math.min(maxBufferSize, length);
        const buf = new Uint8Array(bufSize);
        let totBytesRead = 0;
        while (totBytesRead < length) {
            const remaining = length - totBytesRead;
            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });
            if (bytesRead < 0) {
                return bytesRead;
            }
            totBytesRead += bytesRead;
        }
        return totBytesRead;
    }
}
exports.ReadStreamTokenizer = ReadStreamTokenizer;

},
"Qg1CsWWNepr40cYFYD6RaalQweqmyGedX0o07WLYU5w=":
function (require, module, exports, __dirname, __filename) {
var get = require('lodash.get')

module.exports = function getNet (config) {
  const conns = get(config, 'connections.incoming.net', [])

  return (
    conns.find(isPublic) ||
    conns.find(isLocal) ||
    conns.find(isDevice)
  )
}

function isPublic (transport) {
  const scope = 'public' // internet

  return (
    transport.scope === scope ||
    transport.scope.includes(scope)
  )
}

function isLocal (transport) {
  const scopes = [
    'local', // local wifi
    'private' // (alias of local)
  ]

  return scopes.some(s => {
    return transport.scope === s || transport.scope.includes(s)
  })
}

function isDevice (transport) {
  const scope = 'device' // local device only

  return (
    transport.scope === scope ||
    transport.scope.includes(scope)
  )
}

},
"QrRfUuyA/i3GFdhBNRafl+L/COPbuRemdgn5J6I2vsU=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bipf = require('bipf')
const pl = require('pull-level')
const pull = require('pull-stream')
const Plugin = require('./plugin')
const { or, seqs, liveSeqs } = require('../operators')

const B_KEY = Buffer.from('key')
const B_VALUE = Buffer.from('value')
const B_CONTENT = Buffer.from('content')
const B_MENTIONS = Buffer.from('mentions')

function parseInt10(x) {
  return parseInt(x, 10)
}

// [destMsgId, origShortMsgId] => seq
module.exports = class FullMentions extends Plugin {
  constructor(log, dir) {
    super(log, dir, 'fullMentions', 1, 'json')
  }

  processRecord(record, seq) {
    const buf = record.value
    const pKey = bipf.seekKey(buf, 0, B_KEY)
    let p = 0 // note you pass in p!
    p = bipf.seekKey(buf, p, B_VALUE)
    if (p < 0) return
    p = bipf.seekKey(buf, p, B_CONTENT)
    if (p < 0) return
    p = bipf.seekKey(buf, p, B_MENTIONS)
    if (p < 0) return
    const mentionsData = bipf.decode(buf, p)
    if (!Array.isArray(mentionsData)) return
    const shortKey = bipf.decode(buf, pKey).slice(1, 10)
    mentionsData.forEach((mention) => {
      if (
        mention.link &&
        typeof mention.link === 'string' &&
        (mention.link[0] === '@' || mention.link[0] === '%')
      ) {
        this.batch.push({
          type: 'put',
          key: [mention.link, shortKey],
          value: seq,
        })
      }
    })
  }

  indexesContent() {
    return true
  }

  getMessagesByMention(key, live, cb) {
    const opts = {
      gte: [key, ''],
      lte: [key, undefined],
      keyEncoding: this.keyEncoding,
      keys: false,
    }

    pull(
      pl.read(this.level, opts),
      pull.collect((err, seqArr) => {
        if (err) return cb(err)
        if (live) {
          const ps = pull(
            pl.read(this.level, Object.assign({}, opts, { live, old: false })),
            pull.map(parseInt10)
          )
          cb(null, or(seqs(seqArr.map(parseInt10)), liveSeqs(ps)))
        } else cb(null, seqs(seqArr.map(parseInt10)))
      })
    )
  }
}

},
"Qtq0Zi1h5w+31kHBhWxZ18CIVEQ1XWTjrqNLMRMfh3Y=":
function (require, module, exports, __dirname, __filename) {
var net
try {
  net = require('net')
} catch (_) {
  // This only throws in browsers because they don't have access to the Node
  // net library, which is safe to ignore because they shouldn't be running
  // any methods that require the net library. Maybe we should be setting a
  // flag somewhere rather than checking whether `net == null`?
}

var toPull = require('stream-to-pull-stream')
var scopes = require('multiserver-scopes')
var debug = require('debug')('multiserver:net')

const isString = (s) => 'string' == typeof s
const toAddress = (host, port) => ['net', host, port ].join(':')

function toDuplex (str) {
  var stream = toPull.duplex(str)
  stream.address = toAddress(str.remoteAddress, str.remotePort)
  return stream
}

// Choose a dynamic port between 49152 and 65535
// https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers#Dynamic,_private_or_ephemeral_ports
const getRandomPort = () =>
  Math.floor(49152 + (65535 - 49152 + 1) * Math.random())

module.exports = ({ scope = 'device', host, port, external, allowHalfOpen, pauseOnConnect }) => {
  // Arguments are `scope` and `external` plus selected options for
  // `net.createServer()` and `server.listen()`.
  host = host || (isString(scope) && scopes.host(scope))
  port = port || getRandomPort()

  function isAllowedScope (s) {
    return s === scope || Array.isArray(scope) && scope.includes(s)
  }

  return {
    name: 'net',
    scope: () => scope,
    server: function (onConnection, startedCb) {
      debug('Listening on %s:%d', host, port)

      // TODO: We convert `allowHalfOpen` to boolean for legacy reasons, this
      // might not be getting used anywhere but I'm too scared to change it.
      // This should probably be removed when we do a major version bump.
      const serverOpts = {
        allowHalfOpen: Boolean(allowHalfOpen),
        pauseOnConnect
      }

      var server = net.createServer(serverOpts, function (stream) {
        onConnection(toDuplex(stream))
      })

      server.on('error', function (err) {
        if (startedCb) startedCb(err)
      })

      server.listen(port, host, startedCb)
      return function (cb) {
        debug('Closing server on %s:%d', host, port)
        server.close(function(err) {
          if (err) console.error(err)
          else debug('No longer listening on %s:%d', host, port)
          if (cb) cb(err)
        })
      }
    },
    client: function (opts, cb) {
      var started = false
      var stream = net.connect(opts)
        .on('connect', function () {
          if(started) return
          started = true

          cb(null, toDuplex(stream))
        })
        .on('error', function (err) {
          if(started) return
          started = true
          cb(err)
        })

      return function () {
        started = true
        stream.destroy()
        cb(new Error('multiserver.net: aborted'))
      }
    },
    //MUST be net:<host>:<port>
    parse: function (s) {
      if (net == null) return null
      var ary = s.split(':')
      if(ary.length < 3) return null
      if('net' !== ary.shift()) return null
      var port = Number(ary.pop())
      if(isNaN(port)) return null
      return {
        name: 'net',
        host: ary.join(':') || 'localhost',
        port: port
      }
    },
    stringify: function (targetScope = 'device') {
      if (isAllowedScope(targetScope) === false) {
        return null
      }

      // We want to avoid using `host` if the target scope is public and some
      // external host (like example.com) is defined.
      const externalHost = targetScope === 'public' && external
      let resultHost = externalHost || host || scopes.host(targetScope)

      if (resultHost == null) {
        // The device has no network interface for a given `targetScope`.
        return null
      }

      // Remove IPv6 scopeid suffix, if any, e.g. `%wlan0`
      resultHost = resultHost.replace(/(\%\w+)$/, '')

      return toAddress(resultHost, port)
    }
  }
}


},
"QzzVVDyj80I8Dq8ntLH+CSESdr8WCQqDnXP1/oCXJ7o=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const zlib = require('zlib');

const bufferUtil = require('./buffer-util');
const Limiter = require('./limiter');
const { kStatusCode, NOOP } = require('./constants');

const TRAILER = Buffer.from([0x00, 0x00, 0xff, 0xff]);
const kPerMessageDeflate = Symbol('permessage-deflate');
const kTotalLength = Symbol('total-length');
const kCallback = Symbol('callback');
const kBuffers = Symbol('buffers');
const kError = Symbol('error');

//
// We limit zlib concurrency, which prevents severe memory fragmentation
// as documented in https://github.com/nodejs/node/issues/8871#issuecomment-250915913
// and https://github.com/websockets/ws/issues/1202
//
// Intentionally global; it's the global thread pool that's an issue.
//
let zlibLimiter;

/**
 * permessage-deflate implementation.
 */
class PerMessageDeflate {
  /**
   * Creates a PerMessageDeflate instance.
   *
   * @param {Object} [options] Configuration options
   * @param {Boolean} [options.serverNoContextTakeover=false] Request/accept
   *     disabling of server context takeover
   * @param {Boolean} [options.clientNoContextTakeover=false] Advertise/
   *     acknowledge disabling of client context takeover
   * @param {(Boolean|Number)} [options.serverMaxWindowBits] Request/confirm the
   *     use of a custom server window size
   * @param {(Boolean|Number)} [options.clientMaxWindowBits] Advertise support
   *     for, or request, a custom client window size
   * @param {Object} [options.zlibDeflateOptions] Options to pass to zlib on
   *     deflate
   * @param {Object} [options.zlibInflateOptions] Options to pass to zlib on
   *     inflate
   * @param {Number} [options.threshold=1024] Size (in bytes) below which
   *     messages should not be compressed
   * @param {Number} [options.concurrencyLimit=10] The number of concurrent
   *     calls to zlib
   * @param {Boolean} [isServer=false] Create the instance in either server or
   *     client mode
   * @param {Number} [maxPayload=0] The maximum allowed message length
   */
  constructor(options, isServer, maxPayload) {
    this._maxPayload = maxPayload | 0;
    this._options = options || {};
    this._threshold =
      this._options.threshold !== undefined ? this._options.threshold : 1024;
    this._isServer = !!isServer;
    this._deflate = null;
    this._inflate = null;

    this.params = null;

    if (!zlibLimiter) {
      const concurrency =
        this._options.concurrencyLimit !== undefined
          ? this._options.concurrencyLimit
          : 10;
      zlibLimiter = new Limiter(concurrency);
    }
  }

  /**
   * @type {String}
   */
  static get extensionName() {
    return 'permessage-deflate';
  }

  /**
   * Create an extension negotiation offer.
   *
   * @return {Object} Extension parameters
   * @public
   */
  offer() {
    const params = {};

    if (this._options.serverNoContextTakeover) {
      params.server_no_context_takeover = true;
    }
    if (this._options.clientNoContextTakeover) {
      params.client_no_context_takeover = true;
    }
    if (this._options.serverMaxWindowBits) {
      params.server_max_window_bits = this._options.serverMaxWindowBits;
    }
    if (this._options.clientMaxWindowBits) {
      params.client_max_window_bits = this._options.clientMaxWindowBits;
    } else if (this._options.clientMaxWindowBits == null) {
      params.client_max_window_bits = true;
    }

    return params;
  }

  /**
   * Accept an extension negotiation offer/response.
   *
   * @param {Array} configurations The extension negotiation offers/reponse
   * @return {Object} Accepted configuration
   * @public
   */
  accept(configurations) {
    configurations = this.normalizeParams(configurations);

    this.params = this._isServer
      ? this.acceptAsServer(configurations)
      : this.acceptAsClient(configurations);

    return this.params;
  }

  /**
   * Releases all resources used by the extension.
   *
   * @public
   */
  cleanup() {
    if (this._inflate) {
      this._inflate.close();
      this._inflate = null;
    }

    if (this._deflate) {
      const callback = this._deflate[kCallback];

      this._deflate.close();
      this._deflate = null;

      if (callback) {
        callback(
          new Error(
            'The deflate stream was closed while data was being processed'
          )
        );
      }
    }
  }

  /**
   *  Accept an extension negotiation offer.
   *
   * @param {Array} offers The extension negotiation offers
   * @return {Object} Accepted configuration
   * @private
   */
  acceptAsServer(offers) {
    const opts = this._options;
    const accepted = offers.find((params) => {
      if (
        (opts.serverNoContextTakeover === false &&
          params.server_no_context_takeover) ||
        (params.server_max_window_bits &&
          (opts.serverMaxWindowBits === false ||
            (typeof opts.serverMaxWindowBits === 'number' &&
              opts.serverMaxWindowBits > params.server_max_window_bits))) ||
        (typeof opts.clientMaxWindowBits === 'number' &&
          !params.client_max_window_bits)
      ) {
        return false;
      }

      return true;
    });

    if (!accepted) {
      throw new Error('None of the extension offers can be accepted');
    }

    if (opts.serverNoContextTakeover) {
      accepted.server_no_context_takeover = true;
    }
    if (opts.clientNoContextTakeover) {
      accepted.client_no_context_takeover = true;
    }
    if (typeof opts.serverMaxWindowBits === 'number') {
      accepted.server_max_window_bits = opts.serverMaxWindowBits;
    }
    if (typeof opts.clientMaxWindowBits === 'number') {
      accepted.client_max_window_bits = opts.clientMaxWindowBits;
    } else if (
      accepted.client_max_window_bits === true ||
      opts.clientMaxWindowBits === false
    ) {
      delete accepted.client_max_window_bits;
    }

    return accepted;
  }

  /**
   * Accept the extension negotiation response.
   *
   * @param {Array} response The extension negotiation response
   * @return {Object} Accepted configuration
   * @private
   */
  acceptAsClient(response) {
    const params = response[0];

    if (
      this._options.clientNoContextTakeover === false &&
      params.client_no_context_takeover
    ) {
      throw new Error('Unexpected parameter "client_no_context_takeover"');
    }

    if (!params.client_max_window_bits) {
      if (typeof this._options.clientMaxWindowBits === 'number') {
        params.client_max_window_bits = this._options.clientMaxWindowBits;
      }
    } else if (
      this._options.clientMaxWindowBits === false ||
      (typeof this._options.clientMaxWindowBits === 'number' &&
        params.client_max_window_bits > this._options.clientMaxWindowBits)
    ) {
      throw new Error(
        'Unexpected or invalid parameter "client_max_window_bits"'
      );
    }

    return params;
  }

  /**
   * Normalize parameters.
   *
   * @param {Array} configurations The extension negotiation offers/reponse
   * @return {Array} The offers/response with normalized parameters
   * @private
   */
  normalizeParams(configurations) {
    configurations.forEach((params) => {
      Object.keys(params).forEach((key) => {
        let value = params[key];

        if (value.length > 1) {
          throw new Error(`Parameter "${key}" must have only a single value`);
        }

        value = value[0];

        if (key === 'client_max_window_bits') {
          if (value !== true) {
            const num = +value;
            if (!Number.isInteger(num) || num < 8 || num > 15) {
              throw new TypeError(
                `Invalid value for parameter "${key}": ${value}`
              );
            }
            value = num;
          } else if (!this._isServer) {
            throw new TypeError(
              `Invalid value for parameter "${key}": ${value}`
            );
          }
        } else if (key === 'server_max_window_bits') {
          const num = +value;
          if (!Number.isInteger(num) || num < 8 || num > 15) {
            throw new TypeError(
              `Invalid value for parameter "${key}": ${value}`
            );
          }
          value = num;
        } else if (
          key === 'client_no_context_takeover' ||
          key === 'server_no_context_takeover'
        ) {
          if (value !== true) {
            throw new TypeError(
              `Invalid value for parameter "${key}": ${value}`
            );
          }
        } else {
          throw new Error(`Unknown parameter "${key}"`);
        }

        params[key] = value;
      });
    });

    return configurations;
  }

  /**
   * Decompress data. Concurrency limited.
   *
   * @param {Buffer} data Compressed data
   * @param {Boolean} fin Specifies whether or not this is the last fragment
   * @param {Function} callback Callback
   * @public
   */
  decompress(data, fin, callback) {
    zlibLimiter.add((done) => {
      this._decompress(data, fin, (err, result) => {
        done();
        callback(err, result);
      });
    });
  }

  /**
   * Compress data. Concurrency limited.
   *
   * @param {Buffer} data Data to compress
   * @param {Boolean} fin Specifies whether or not this is the last fragment
   * @param {Function} callback Callback
   * @public
   */
  compress(data, fin, callback) {
    zlibLimiter.add((done) => {
      this._compress(data, fin, (err, result) => {
        done();
        callback(err, result);
      });
    });
  }

  /**
   * Decompress data.
   *
   * @param {Buffer} data Compressed data
   * @param {Boolean} fin Specifies whether or not this is the last fragment
   * @param {Function} callback Callback
   * @private
   */
  _decompress(data, fin, callback) {
    const endpoint = this._isServer ? 'client' : 'server';

    if (!this._inflate) {
      const key = `${endpoint}_max_window_bits`;
      const windowBits =
        typeof this.params[key] !== 'number'
          ? zlib.Z_DEFAULT_WINDOWBITS
          : this.params[key];

      this._inflate = zlib.createInflateRaw({
        ...this._options.zlibInflateOptions,
        windowBits
      });
      this._inflate[kPerMessageDeflate] = this;
      this._inflate[kTotalLength] = 0;
      this._inflate[kBuffers] = [];
      this._inflate.on('error', inflateOnError);
      this._inflate.on('data', inflateOnData);
    }

    this._inflate[kCallback] = callback;

    this._inflate.write(data);
    if (fin) this._inflate.write(TRAILER);

    this._inflate.flush(() => {
      const err = this._inflate[kError];

      if (err) {
        this._inflate.close();
        this._inflate = null;
        callback(err);
        return;
      }

      const data = bufferUtil.concat(
        this._inflate[kBuffers],
        this._inflate[kTotalLength]
      );

      if (this._inflate._readableState.endEmitted) {
        this._inflate.close();
        this._inflate = null;
      } else {
        this._inflate[kTotalLength] = 0;
        this._inflate[kBuffers] = [];

        if (fin && this.params[`${endpoint}_no_context_takeover`]) {
          this._inflate.reset();
        }
      }

      callback(null, data);
    });
  }

  /**
   * Compress data.
   *
   * @param {Buffer} data Data to compress
   * @param {Boolean} fin Specifies whether or not this is the last fragment
   * @param {Function} callback Callback
   * @private
   */
  _compress(data, fin, callback) {
    const endpoint = this._isServer ? 'server' : 'client';

    if (!this._deflate) {
      const key = `${endpoint}_max_window_bits`;
      const windowBits =
        typeof this.params[key] !== 'number'
          ? zlib.Z_DEFAULT_WINDOWBITS
          : this.params[key];

      this._deflate = zlib.createDeflateRaw({
        ...this._options.zlibDeflateOptions,
        windowBits
      });

      this._deflate[kTotalLength] = 0;
      this._deflate[kBuffers] = [];

      //
      // An `'error'` event is emitted, only on Node.js < 10.0.0, if the
      // `zlib.DeflateRaw` instance is closed while data is being processed.
      // This can happen if `PerMessageDeflate#cleanup()` is called at the wrong
      // time due to an abnormal WebSocket closure.
      //
      this._deflate.on('error', NOOP);
      this._deflate.on('data', deflateOnData);
    }

    this._deflate[kCallback] = callback;

    this._deflate.write(data);
    this._deflate.flush(zlib.Z_SYNC_FLUSH, () => {
      if (!this._deflate) {
        //
        // The deflate stream was closed while data was being processed.
        //
        return;
      }

      let data = bufferUtil.concat(
        this._deflate[kBuffers],
        this._deflate[kTotalLength]
      );

      if (fin) data = data.slice(0, data.length - 4);

      //
      // Ensure that the callback will not be called again in
      // `PerMessageDeflate#cleanup()`.
      //
      this._deflate[kCallback] = null;

      this._deflate[kTotalLength] = 0;
      this._deflate[kBuffers] = [];

      if (fin && this.params[`${endpoint}_no_context_takeover`]) {
        this._deflate.reset();
      }

      callback(null, data);
    });
  }
}

module.exports = PerMessageDeflate;

/**
 * The listener of the `zlib.DeflateRaw` stream `'data'` event.
 *
 * @param {Buffer} chunk A chunk of data
 * @private
 */
function deflateOnData(chunk) {
  this[kBuffers].push(chunk);
  this[kTotalLength] += chunk.length;
}

/**
 * The listener of the `zlib.InflateRaw` stream `'data'` event.
 *
 * @param {Buffer} chunk A chunk of data
 * @private
 */
function inflateOnData(chunk) {
  this[kTotalLength] += chunk.length;

  if (
    this[kPerMessageDeflate]._maxPayload < 1 ||
    this[kTotalLength] <= this[kPerMessageDeflate]._maxPayload
  ) {
    this[kBuffers].push(chunk);
    return;
  }

  this[kError] = new RangeError('Max payload size exceeded');
  this[kError][kStatusCode] = 1009;
  this.removeListener('data', inflateOnData);
  this.reset();
}

/**
 * The listener of the `zlib.InflateRaw` stream `'error'` event.
 *
 * @param {Error} err The emitted error
 * @private
 */
function inflateOnError(err) {
  //
  // There is no need to call `Zlib#close()` as the handle is automatically
  // closed when an error is emitted.
  //
  this[kPerMessageDeflate]._inflate = null;
  err[kStatusCode] = 1007;
  this[kCallback](err);
}

},
"R2J3cRqemhtoXodLUPWZ3x6GpeIWFb5CYpk7ZO7AgjY=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var looper = require('pull-looper')
module.exports = function (push, length, done) {
  var abort_cb, ended, buffer = [], _cb
  length = length || 0

  var adapter = {
    paused: false,
    write: function (data) {
      if(_cb) {
        var cb = _cb; _cb = null; cb(null, data)
      }
      else {
        buffer.push(data)
        if(buffer.length > length) {
          adapter.paused = true
        }
      }
    },
    end: function (err) {
      ended = err || true
      if(_cb && (err || !buffer.length)) {
        var cb = _cb; _cb = null; cb(ended)
        if(done) {
          var _done = done; done = null; _done(err)
        }
      }
    },
    source: null
  }

  push.pipe(adapter)

  return looper(function (abort, cb) {
    if(_cb && !abort) {
      throw new Error('source:read twice')
    }

    if(abort) {
      push.abort(abort)
//      abort_cb = cb
      cb(abort)
    }
    // if it ended with an error, cb immedately, dropping the buffer
    else if(ended && ended !== true) {
      cb(ended)
      if(done) {
        var _done = done; done = null; _done(ended)
      }
    }
    // else read the buffer
    else if(buffer.length) {
      var data = buffer.shift()
      cb(null, data)
      if(buffer.length <= length/2 && adapter.paused) {
        adapter.paused = false
        push.resume()
      }
    }
    else if(ended === true) {
      cb(true)
      if(done) {
        var _done = done; done = null; _done()
      }
    }
    else _cb = cb
  })
}


},
"RC0G4pXmjf4c8/Lyl7lseK6vKwAETWfBC2RSfyB7mR0=":
function (require, module, exports, __dirname, __filename) {

exports.compare = function (a, b) {

  if(Buffer.isBuffer(a)) {
    var l = Math.min(a.length, b.length)
    for(var i = 0; i < l; i++) {
      var cmp = a[i] - b[i]
      if(cmp) return cmp
    }
    return a.length - b.length
  }

  return a < b ? -1 : a > b ? 1 : 0
}

// to be compatible with the current abstract-leveldown tests
// nullish or empty strings.
// I could use !!val but I want to permit numbers and booleans,
// if possible.

function isDef (val) {
  return val !== undefined && val !== ''
}

function has (range, name) {
  return Object.hasOwnProperty.call(range, name)
}

function hasKey(range, name) {
  return Object.hasOwnProperty.call(range, name) && name
}

var lowerBoundKey = exports.lowerBoundKey = function (range) {
    return (
       hasKey(range, 'gt')
    || hasKey(range, 'gte')
    || hasKey(range, 'min')
    || (range.reverse ? hasKey(range, 'end') : hasKey(range, 'start'))
    || undefined
    )
}

var lowerBound = exports.lowerBound = function (range, def) {
  var k = lowerBoundKey(range)
  return k ? range[k] : def
}

var lowerBoundInclusive = exports.lowerBoundInclusive = function (range) {
  return has(range, 'gt') ? false : true
}

var upperBoundInclusive = exports.upperBoundInclusive =
  function (range) {
    return (has(range, 'lt') /*&& !range.maxEx*/) ? false : true
  }

var lowerBoundExclusive = exports.lowerBoundExclusive =
  function (range) {
    return !lowerBoundInclusive(range)
  }

var upperBoundExclusive = exports.upperBoundExclusive =
  function (range) {
    return !upperBoundInclusive(range)
  }

var upperBoundKey = exports.upperBoundKey = function (range) {
    return (
       hasKey(range, 'lt')
    || hasKey(range, 'lte')
    || hasKey(range, 'max')
    || (range.reverse ? hasKey(range, 'start') : hasKey(range, 'end'))
    || undefined
    )
}

var upperBound = exports.upperBound = function (range, def) {
  var k = upperBoundKey(range)
  return k ? range[k] : def
}

exports.start = function (range, def) {
  return range.reverse ? upperBound(range, def) : lowerBound(range, def)
}
exports.end = function (range, def) {
  return range.reverse ? lowerBound(range, def) : upperBound(range, def)
}
exports.startInclusive = function (range) {
  return (
    range.reverse
  ? upperBoundInclusive(range)
  : lowerBoundInclusive(range)
  )
}
exports.endInclusive = function (range) {
  return (
    range.reverse
  ? lowerBoundInclusive(range)
  : upperBoundInclusive(range)
  )
}

function id (e) { return e }

exports.toLtgt = function (range, _range, map, lower, upper) {
  _range = _range || {}
  map = map || id
  var defaults = arguments.length > 3
  var lb = exports.lowerBoundKey(range)
  var ub = exports.upperBoundKey(range)
  if(lb) {
    if(lb === 'gt') _range.gt = map(range.gt, false)
    else            _range.gte = map(range[lb], false)
  }
  else if(defaults)
    _range.gte = map(lower, false)

  if(ub) {
    if(ub === 'lt') _range.lt = map(range.lt, true)
    else            _range.lte = map(range[ub], true)
  }
  else if(defaults)
    _range.lte = map(upper, true)

  if(range.reverse != null)
    _range.reverse = !!range.reverse

  //if range was used mutably
  //(in level-sublevel it's part of an options object
  //that has more properties on it.)
  if(has(_range, 'max'))   delete _range.max
  if(has(_range, 'min'))   delete _range.min
  if(has(_range, 'start')) delete _range.start
  if(has(_range, 'end'))   delete _range.end

  return _range
}

exports.contains = function (range, key, compare) {
  compare = compare || exports.compare

  var lb = lowerBound(range)
  if(isDef(lb)) {
    var cmp = compare(key, lb)
    if(cmp < 0 || (cmp === 0 && lowerBoundExclusive(range)))
      return false
  }

  var ub = upperBound(range)
  if(isDef(ub)) {
    var cmp = compare(key, ub)
    if(cmp > 0 || (cmp === 0) && upperBoundExclusive(range))
      return false
  }

  return true
}

exports.filter = function (range, compare) {
  return function (key) {
    return exports.contains(range, key, compare)
  }
}



},
"RD33PvzBdB9vjmR0whP8kFyH+s8oYunkaCAcv75Hhf0=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var looper = require('pull-looper')

module.exports = function (push, cb) {
  var reading = false, ended, read
  while(push.source) push = push.source

  var adapter = push.source = {
    resume: more,
    paused: false,
    abort: function (err) {
      ended = err || true
      if(read)
        read(ended, function (err) {
          if(!push.ended) push.end(err)
        })
    }
  }

  function more () {
    if(reading) return
    if(!(adapter.paused = push.paused)) {
      reading = true
      read(null, function next (err, data) {
        reading = false
        if(err && err !== true) {
          if(!push.ended)
            push.end(ended = err)
        } else {
          //if the push-stream has already ended, abort the source.
          if(push.ended) {
            if(!err) read(push.ended, function () {})
            return
          }
          if(err) push.end(err)
          else push.write(data)
          if(push.ended && !err) return read(push.ended, cb || function () {})
          if(!push.paused && !err && !reading) more()
        }
      })
    }
  }

  return function (_read) {
    read = looper(_read)
    if(!push.paused && !ended) more()
  }
}



},
"Rms3M4gDfsKdRDioD3XNrGHVcubF/mm51QWSAvpRRT4=":
function (require, module, exports, __dirname, __filename) {
const pull = require('pull-stream')
const Pushable = require('pull-pushable')
const pCont = require('pull-cont')
const LayeredGraph = require('layered-graph')
const isFeed = require('ssb-ref').isFeed
const contacts = require('./contacts')
const db2Contacts = require('./db2-contacts')
const help = require('./help')
const authGlue = require('./auth-glue')

exports.name = 'friends'
exports.version = '1.0.0'
exports.manifest = {
  follow: 'async',
  isFollowing: 'async',
  block: 'async',
  isBlocking: 'async',
  hops: 'async',
  hopStream: 'source',
  graph: 'async',
  graphStream: 'source',
  help: 'sync'
}

exports.init = function (sbot, config) {
  if (!config.friends) config.friends = {}
  const max = config.friends.hops || 3
  const layered = LayeredGraph({ max, start: sbot.id })

  if (sbot.db) {
    sbot.db.registerIndex(db2Contacts(layered.createLayer))
  } else {
    contacts(sbot, layered.createLayer)
  }

  function onReady (cb) {
    layered.onReady(() => {
      if (sbot.db) {
        sbot.db.onDrain('contacts', cb)
      } else {
        cb()
      }
    })
  }

  function isFollowing (opts, cb) {
    const { source, dest, details } = opts
    onReady(() => {
      const g = layered.getGraph()
      const response = g[source] ? g[source][dest] >= 0 : false
      if (details) {
        const g2 = layered.getGraph('contactsPrivate')
        const privately = g2[source] ? g2[source][dest] >= 0 : false
        cb(null, { response, private: privately })
      } else {
        cb(null, response)
      }
    })
  }

  function isBlocking (opts, cb) {
    const { source, dest, details } = opts
    onReady(() => {
      const g = layered.getGraph()
      const response = Math.round(g[source] && g[source][dest]) === -1
      if (details) {
        const g2 = layered.getGraph('contactsPrivate')
        const privately = Math.round(g2[source] && g2[source][dest]) === -1
        cb(null, { response, private: privately })
      } else {
        cb(null, response)
      }
    })
  }

  function follow (feedId, opts, cb) {
    if (!isFeed(feedId)) {
      return cb(new Error(`follow() requires a feedId, got ${feedId}`))
    }
    opts = opts || {}

    const content = {
      type: 'contact',
      contact: feedId,
      following: 'state' in opts ? opts.state : true,
      recps: opts.recps
    }
    sbot.publish(content, cb)
  }

  function block (feedId, opts, cb) {
    if (!isFeed(feedId)) {
      return cb(new Error(`block() requires a feedId, got ${feedId}`))
    }
    opts = opts || {}

    const content = {
      type: 'contact',
      contact: feedId,
      blocking: 'state' in opts ? opts.state : true,
      reason: typeof opts.reason === 'string' ? opts.reason : undefined,
      recps: opts.recps
    }
    sbot.publish(content, cb)
  }

  function graph (cb) {
    onReady(() => {
      cb(null, layered.getGraph())
    })
  }

  function graphStream (opts) {
    const {
      live = true,
      old = false
    } = opts || {}
    if (live) {
      return pCont((cb) => {
        onReady(() => {
          const unsubscribe = layered.onEdge((source, dest, value) => {
            p.push({ [source]: { [dest]: value } })
          })
          const p = Pushable(unsubscribe)
          if (old) {
            p.push(layered.getGraph())
          }
          cb(null, p)
        })
      })
    } else {
      return pCont((cb) => {
        onReady(() => {
          cb(null, pull.once(layered.getGraph()))
        })
      })
    }
  }

  function hops (opts, cb) {
    if (typeof opts === 'function') {
      cb = opts
      opts = {}
    }

    onReady(() => {
      cb(null, layered.getHops(opts))
    })
  }

  function hopStream (opts) {
    const {
      live = true,
      old = false
    } = opts || {}
    return layered.hopStream({ live, old, ...opts })
  }

  // Make sure blocked peers cannot connect, default is true
  if (config.friends.hookAuth !== false) {
    authGlue(sbot, layered, isBlocking)
  }

  return {
    follow,
    block,
    isFollowing,
    isBlocking,
    hops,
    hopStream,
    graph,
    graphStream,
    help: () => help
  }
}

},
"RtJfR0T1FNWmtbehnPBLchbGZ16wg/GW6tq6tYHH2Xk=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var State = require('./state')

function isInteger (i) {
  return Number.isFinite(i)
}

function isFunction (f) {
  return 'function' === typeof f
}

function maxDelay(fn, delay) {
  if(!delay) return fn
  return function (a, cb) {
    var timer = setTimeout(function () {
      fn(new Error('pull-reader: read exceeded timeout'), cb)
    }, delay)
    fn(a, function (err, value) {
      clearTimeout(timer)
      cb(err, value)
    })

  }

}

module.exports = function (timeout) {

  var queue = [], read, readTimed, reading = false
  var state = State(), ended, streaming, abort

  function drain () {
    while (queue.length) {
      if(null == queue[0].length && state.has(1)) {
        queue.shift().cb(null, state.get())
      }
      else if(state.has(queue[0].length)) {
        var next = queue.shift()
        next.cb(null, state.get(next.length))
      }
      else if(ended == true && queue[0].length && state.length < queue[0].length) {
        var msg = 'stream ended with:'+state.length+' but wanted:'+queue[0].length
        queue.shift().cb(new Error(msg))
      }
      else if(ended)
        queue.shift().cb(ended)
      else
        return !!queue.length
    }
    //always read a little data
    return queue.length || !state.has(1) || abort
  }

  function more () {
    var d = drain()
    if(d && !reading)
    if(read && !reading && !streaming) {
      reading = true
      readTimed (null, function (err, data) {
        reading = false
        if(err) {
          ended = err
          return drain()
        }
        state.add(data)
        more()
      })
    }
  }

  function reader (_read) {
    if(abort) {
      while(queue.length) queue.shift().cb(abort)
      return cb && cb(abort)
    }
    readTimed = maxDelay(_read, timeout)
    read = _read
    more()
  }

  reader.abort = function (err, cb) {
    abort = err || true
    if(read) {
      reading = true
      read(abort, function () {
        while(queue.length) queue.shift().cb(abort)
        cb && cb(abort)
      })
    }
    else
      cb()
  }

  reader.read = function (len, _timeout, cb) {
    if(isFunction(_timeout))
      cb = _timeout, _timeout = timeout
    if(isFunction(cb)) {
      queue.push({length: isInteger(len) ? len : null, cb: cb})
      more()
    }
    else {
      //switch into streaming mode for the rest of the stream.
      streaming = true
      //wait for the current read to complete
      return function (abort, cb) {
        //if there is anything still in the queue,
        if(reading || state.has(1)) {
          if(abort) return read(abort, cb)
          queue.push({length: null, cb: cb})
          more()
        }
        else
          maxDelay(read, _timeout)(abort, function (err, data) {
            cb(err, data)
          })
      }
    }
  }

  return reader
}







},
"S+3liXlUHl7GifvxI0J9bDoAPmlOkR0CpQbNmeW3Vfg=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
  {
    "code": 0,
    "type": "feed",
    "formats": [
      { "code": 0, "format": "classic",      "data_length": 32, "sigil": "@", "suffix": ".ed25519" },
      { "code": 1, "format": "gabbygrove-v1",  "data_length": 32 },
      { "code": 2, "format": "bamboo",       "data_length": 32 },
      { "code": 3, "format": "bendybutt-v1", "data_length": 32 }
    ]
  },
  {
    "code": 1,
    "type": "message",
    "formats": [
      { "code": 0, "format": "classic",      "data_length": 32, "sigil": "%", "suffix": ".sha256" },
      { "code": 1, "format": "gabbygrove-v1",  "data_length": 32 },
      { "code": 2, "format": "cloaked",      "data_length": 32, "sigil": "%", "suffix": ".cloaked" },
      { "code": 3, "format": "bamboo",       "data_length": 64 },
      { "code": 4, "format": "bendybutt-v1", "data_length": 32 }
    ]
  },
  {
    "code": 2,
    "type": "blob",
    "formats": [
      { "code": 0, "format": "classic", "data_length": 32, "sigil": "&", "suffix": ".sha256" }
    ]
  },
  {
    "code": 3,
    "type": "encryption-key",
    "formats": [
      { "code": 0, "format": "box2-dm-dh", "data_length": 32, "key_length": 32 },
      { "code": 1, "format": "box2-pobox-dh", "data_length": 32, "key_length": 32 }
    ]
  },
  {
    "code": 4,
    "type": "signature",
    "formats": [
      { "code": 0, "format": "msg-ed25519", "data_length": 64, "signature_length": 64, "suffix": ".sig.ed25519" }
    ]
  },
  {
    "code": 5,
    "type": "encrypted",
    "formats": [
      { "code": 0, "format": "box1", "suffix": ".box" },
      { "code": 1, "format": "box2", "suffix": ".box2" }
    ]
  },
  {
    "code": 6,
    "type": "generic",
    "formats": [
      { "code": 0, "format": "string-UTF8" },
      { "code": 1, "format": "boolean" },
      { "code": 2, "format": "nil" },
      { "code": 3, "format": "any-bytes" }
    ]
  },
  {
    "code": 7,
    "type": "identity",
    "formats": [
      { "code": 0, "format": "po-box" , "data_length": 32 }
    ]
  }
]

},
"S1YIYzrBJPak7W+hfc3pGalXWJaV8W25l4eY9v2Pcew=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('crypto').createHash

},
"S2rBVEZMo4/ty/rY/enQ5WJaFapBlW5050ajj0i1i4s=":
function (require, module, exports, __dirname, __filename) {

var Pair = require('./')
module.exports = function () {
  var a = Pair(), b = Pair()
  return [
    {
      source: a.source,
      sink: b.sink
    },
    {
      source: b.source,
      sink: a.sink
    }
  ]
}

},
"SKDUqBxHSbRcpgTkh/aWxV6pcWp6Gx8e19/kk8OjzBU=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "abandon",
    "ability",
    "able",
    "about",
    "above",
    "absent",
    "absorb",
    "abstract",
    "absurd",
    "abuse",
    "access",
    "accident",
    "account",
    "accuse",
    "achieve",
    "acid",
    "acoustic",
    "acquire",
    "across",
    "act",
    "action",
    "actor",
    "actress",
    "actual",
    "adapt",
    "add",
    "addict",
    "address",
    "adjust",
    "admit",
    "adult",
    "advance",
    "advice",
    "aerobic",
    "affair",
    "afford",
    "afraid",
    "again",
    "age",
    "agent",
    "agree",
    "ahead",
    "aim",
    "air",
    "airport",
    "aisle",
    "alarm",
    "album",
    "alcohol",
    "alert",
    "alien",
    "all",
    "alley",
    "allow",
    "almost",
    "alone",
    "alpha",
    "already",
    "also",
    "alter",
    "always",
    "amateur",
    "amazing",
    "among",
    "amount",
    "amused",
    "analyst",
    "anchor",
    "ancient",
    "anger",
    "angle",
    "angry",
    "animal",
    "ankle",
    "announce",
    "annual",
    "another",
    "answer",
    "antenna",
    "antique",
    "anxiety",
    "any",
    "apart",
    "apology",
    "appear",
    "apple",
    "approve",
    "april",
    "arch",
    "arctic",
    "area",
    "arena",
    "argue",
    "arm",
    "armed",
    "armor",
    "army",
    "around",
    "arrange",
    "arrest",
    "arrive",
    "arrow",
    "art",
    "artefact",
    "artist",
    "artwork",
    "ask",
    "aspect",
    "assault",
    "asset",
    "assist",
    "assume",
    "asthma",
    "athlete",
    "atom",
    "attack",
    "attend",
    "attitude",
    "attract",
    "auction",
    "audit",
    "august",
    "aunt",
    "author",
    "auto",
    "autumn",
    "average",
    "avocado",
    "avoid",
    "awake",
    "aware",
    "away",
    "awesome",
    "awful",
    "awkward",
    "axis",
    "baby",
    "bachelor",
    "bacon",
    "badge",
    "bag",
    "balance",
    "balcony",
    "ball",
    "bamboo",
    "banana",
    "banner",
    "bar",
    "barely",
    "bargain",
    "barrel",
    "base",
    "basic",
    "basket",
    "battle",
    "beach",
    "bean",
    "beauty",
    "because",
    "become",
    "beef",
    "before",
    "begin",
    "behave",
    "behind",
    "believe",
    "below",
    "belt",
    "bench",
    "benefit",
    "best",
    "betray",
    "better",
    "between",
    "beyond",
    "bicycle",
    "bid",
    "bike",
    "bind",
    "biology",
    "bird",
    "birth",
    "bitter",
    "black",
    "blade",
    "blame",
    "blanket",
    "blast",
    "bleak",
    "bless",
    "blind",
    "blood",
    "blossom",
    "blouse",
    "blue",
    "blur",
    "blush",
    "board",
    "boat",
    "body",
    "boil",
    "bomb",
    "bone",
    "bonus",
    "book",
    "boost",
    "border",
    "boring",
    "borrow",
    "boss",
    "bottom",
    "bounce",
    "box",
    "boy",
    "bracket",
    "brain",
    "brand",
    "brass",
    "brave",
    "bread",
    "breeze",
    "brick",
    "bridge",
    "brief",
    "bright",
    "bring",
    "brisk",
    "broccoli",
    "broken",
    "bronze",
    "broom",
    "brother",
    "brown",
    "brush",
    "bubble",
    "buddy",
    "budget",
    "buffalo",
    "build",
    "bulb",
    "bulk",
    "bullet",
    "bundle",
    "bunker",
    "burden",
    "burger",
    "burst",
    "bus",
    "business",
    "busy",
    "butter",
    "buyer",
    "buzz",
    "cabbage",
    "cabin",
    "cable",
    "cactus",
    "cage",
    "cake",
    "call",
    "calm",
    "camera",
    "camp",
    "can",
    "canal",
    "cancel",
    "candy",
    "cannon",
    "canoe",
    "canvas",
    "canyon",
    "capable",
    "capital",
    "captain",
    "car",
    "carbon",
    "card",
    "cargo",
    "carpet",
    "carry",
    "cart",
    "case",
    "cash",
    "casino",
    "castle",
    "casual",
    "cat",
    "catalog",
    "catch",
    "category",
    "cattle",
    "caught",
    "cause",
    "caution",
    "cave",
    "ceiling",
    "celery",
    "cement",
    "census",
    "century",
    "cereal",
    "certain",
    "chair",
    "chalk",
    "champion",
    "change",
    "chaos",
    "chapter",
    "charge",
    "chase",
    "chat",
    "cheap",
    "check",
    "cheese",
    "chef",
    "cherry",
    "chest",
    "chicken",
    "chief",
    "child",
    "chimney",
    "choice",
    "choose",
    "chronic",
    "chuckle",
    "chunk",
    "churn",
    "cigar",
    "cinnamon",
    "circle",
    "citizen",
    "city",
    "civil",
    "claim",
    "clap",
    "clarify",
    "claw",
    "clay",
    "clean",
    "clerk",
    "clever",
    "click",
    "client",
    "cliff",
    "climb",
    "clinic",
    "clip",
    "clock",
    "clog",
    "close",
    "cloth",
    "cloud",
    "clown",
    "club",
    "clump",
    "cluster",
    "clutch",
    "coach",
    "coast",
    "coconut",
    "code",
    "coffee",
    "coil",
    "coin",
    "collect",
    "color",
    "column",
    "combine",
    "come",
    "comfort",
    "comic",
    "common",
    "company",
    "concert",
    "conduct",
    "confirm",
    "congress",
    "connect",
    "consider",
    "control",
    "convince",
    "cook",
    "cool",
    "copper",
    "copy",
    "coral",
    "core",
    "corn",
    "correct",
    "cost",
    "cotton",
    "couch",
    "country",
    "couple",
    "course",
    "cousin",
    "cover",
    "coyote",
    "crack",
    "cradle",
    "craft",
    "cram",
    "crane",
    "crash",
    "crater",
    "crawl",
    "crazy",
    "cream",
    "credit",
    "creek",
    "crew",
    "cricket",
    "crime",
    "crisp",
    "critic",
    "crop",
    "cross",
    "crouch",
    "crowd",
    "crucial",
    "cruel",
    "cruise",
    "crumble",
    "crunch",
    "crush",
    "cry",
    "crystal",
    "cube",
    "culture",
    "cup",
    "cupboard",
    "curious",
    "current",
    "curtain",
    "curve",
    "cushion",
    "custom",
    "cute",
    "cycle",
    "dad",
    "damage",
    "damp",
    "dance",
    "danger",
    "daring",
    "dash",
    "daughter",
    "dawn",
    "day",
    "deal",
    "debate",
    "debris",
    "decade",
    "december",
    "decide",
    "decline",
    "decorate",
    "decrease",
    "deer",
    "defense",
    "define",
    "defy",
    "degree",
    "delay",
    "deliver",
    "demand",
    "demise",
    "denial",
    "dentist",
    "deny",
    "depart",
    "depend",
    "deposit",
    "depth",
    "deputy",
    "derive",
    "describe",
    "desert",
    "design",
    "desk",
    "despair",
    "destroy",
    "detail",
    "detect",
    "develop",
    "device",
    "devote",
    "diagram",
    "dial",
    "diamond",
    "diary",
    "dice",
    "diesel",
    "diet",
    "differ",
    "digital",
    "dignity",
    "dilemma",
    "dinner",
    "dinosaur",
    "direct",
    "dirt",
    "disagree",
    "discover",
    "disease",
    "dish",
    "dismiss",
    "disorder",
    "display",
    "distance",
    "divert",
    "divide",
    "divorce",
    "dizzy",
    "doctor",
    "document",
    "dog",
    "doll",
    "dolphin",
    "domain",
    "donate",
    "donkey",
    "donor",
    "door",
    "dose",
    "double",
    "dove",
    "draft",
    "dragon",
    "drama",
    "drastic",
    "draw",
    "dream",
    "dress",
    "drift",
    "drill",
    "drink",
    "drip",
    "drive",
    "drop",
    "drum",
    "dry",
    "duck",
    "dumb",
    "dune",
    "during",
    "dust",
    "dutch",
    "duty",
    "dwarf",
    "dynamic",
    "eager",
    "eagle",
    "early",
    "earn",
    "earth",
    "easily",
    "east",
    "easy",
    "echo",
    "ecology",
    "economy",
    "edge",
    "edit",
    "educate",
    "effort",
    "egg",
    "eight",
    "either",
    "elbow",
    "elder",
    "electric",
    "elegant",
    "element",
    "elephant",
    "elevator",
    "elite",
    "else",
    "embark",
    "embody",
    "embrace",
    "emerge",
    "emotion",
    "employ",
    "empower",
    "empty",
    "enable",
    "enact",
    "end",
    "endless",
    "endorse",
    "enemy",
    "energy",
    "enforce",
    "engage",
    "engine",
    "enhance",
    "enjoy",
    "enlist",
    "enough",
    "enrich",
    "enroll",
    "ensure",
    "enter",
    "entire",
    "entry",
    "envelope",
    "episode",
    "equal",
    "equip",
    "era",
    "erase",
    "erode",
    "erosion",
    "error",
    "erupt",
    "escape",
    "essay",
    "essence",
    "estate",
    "eternal",
    "ethics",
    "evidence",
    "evil",
    "evoke",
    "evolve",
    "exact",
    "example",
    "excess",
    "exchange",
    "excite",
    "exclude",
    "excuse",
    "execute",
    "exercise",
    "exhaust",
    "exhibit",
    "exile",
    "exist",
    "exit",
    "exotic",
    "expand",
    "expect",
    "expire",
    "explain",
    "expose",
    "express",
    "extend",
    "extra",
    "eye",
    "eyebrow",
    "fabric",
    "face",
    "faculty",
    "fade",
    "faint",
    "faith",
    "fall",
    "false",
    "fame",
    "family",
    "famous",
    "fan",
    "fancy",
    "fantasy",
    "farm",
    "fashion",
    "fat",
    "fatal",
    "father",
    "fatigue",
    "fault",
    "favorite",
    "feature",
    "february",
    "federal",
    "fee",
    "feed",
    "feel",
    "female",
    "fence",
    "festival",
    "fetch",
    "fever",
    "few",
    "fiber",
    "fiction",
    "field",
    "figure",
    "file",
    "film",
    "filter",
    "final",
    "find",
    "fine",
    "finger",
    "finish",
    "fire",
    "firm",
    "first",
    "fiscal",
    "fish",
    "fit",
    "fitness",
    "fix",
    "flag",
    "flame",
    "flash",
    "flat",
    "flavor",
    "flee",
    "flight",
    "flip",
    "float",
    "flock",
    "floor",
    "flower",
    "fluid",
    "flush",
    "fly",
    "foam",
    "focus",
    "fog",
    "foil",
    "fold",
    "follow",
    "food",
    "foot",
    "force",
    "forest",
    "forget",
    "fork",
    "fortune",
    "forum",
    "forward",
    "fossil",
    "foster",
    "found",
    "fox",
    "fragile",
    "frame",
    "frequent",
    "fresh",
    "friend",
    "fringe",
    "frog",
    "front",
    "frost",
    "frown",
    "frozen",
    "fruit",
    "fuel",
    "fun",
    "funny",
    "furnace",
    "fury",
    "future",
    "gadget",
    "gain",
    "galaxy",
    "gallery",
    "game",
    "gap",
    "garage",
    "garbage",
    "garden",
    "garlic",
    "garment",
    "gas",
    "gasp",
    "gate",
    "gather",
    "gauge",
    "gaze",
    "general",
    "genius",
    "genre",
    "gentle",
    "genuine",
    "gesture",
    "ghost",
    "giant",
    "gift",
    "giggle",
    "ginger",
    "giraffe",
    "girl",
    "give",
    "glad",
    "glance",
    "glare",
    "glass",
    "glide",
    "glimpse",
    "globe",
    "gloom",
    "glory",
    "glove",
    "glow",
    "glue",
    "goat",
    "goddess",
    "gold",
    "good",
    "goose",
    "gorilla",
    "gospel",
    "gossip",
    "govern",
    "gown",
    "grab",
    "grace",
    "grain",
    "grant",
    "grape",
    "grass",
    "gravity",
    "great",
    "green",
    "grid",
    "grief",
    "grit",
    "grocery",
    "group",
    "grow",
    "grunt",
    "guard",
    "guess",
    "guide",
    "guilt",
    "guitar",
    "gun",
    "gym",
    "habit",
    "hair",
    "half",
    "hammer",
    "hamster",
    "hand",
    "happy",
    "harbor",
    "hard",
    "harsh",
    "harvest",
    "hat",
    "have",
    "hawk",
    "hazard",
    "head",
    "health",
    "heart",
    "heavy",
    "hedgehog",
    "height",
    "hello",
    "helmet",
    "help",
    "hen",
    "hero",
    "hidden",
    "high",
    "hill",
    "hint",
    "hip",
    "hire",
    "history",
    "hobby",
    "hockey",
    "hold",
    "hole",
    "holiday",
    "hollow",
    "home",
    "honey",
    "hood",
    "hope",
    "horn",
    "horror",
    "horse",
    "hospital",
    "host",
    "hotel",
    "hour",
    "hover",
    "hub",
    "huge",
    "human",
    "humble",
    "humor",
    "hundred",
    "hungry",
    "hunt",
    "hurdle",
    "hurry",
    "hurt",
    "husband",
    "hybrid",
    "ice",
    "icon",
    "idea",
    "identify",
    "idle",
    "ignore",
    "ill",
    "illegal",
    "illness",
    "image",
    "imitate",
    "immense",
    "immune",
    "impact",
    "impose",
    "improve",
    "impulse",
    "inch",
    "include",
    "income",
    "increase",
    "index",
    "indicate",
    "indoor",
    "industry",
    "infant",
    "inflict",
    "inform",
    "inhale",
    "inherit",
    "initial",
    "inject",
    "injury",
    "inmate",
    "inner",
    "innocent",
    "input",
    "inquiry",
    "insane",
    "insect",
    "inside",
    "inspire",
    "install",
    "intact",
    "interest",
    "into",
    "invest",
    "invite",
    "involve",
    "iron",
    "island",
    "isolate",
    "issue",
    "item",
    "ivory",
    "jacket",
    "jaguar",
    "jar",
    "jazz",
    "jealous",
    "jeans",
    "jelly",
    "jewel",
    "job",
    "join",
    "joke",
    "journey",
    "joy",
    "judge",
    "juice",
    "jump",
    "jungle",
    "junior",
    "junk",
    "just",
    "kangaroo",
    "keen",
    "keep",
    "ketchup",
    "key",
    "kick",
    "kid",
    "kidney",
    "kind",
    "kingdom",
    "kiss",
    "kit",
    "kitchen",
    "kite",
    "kitten",
    "kiwi",
    "knee",
    "knife",
    "knock",
    "know",
    "lab",
    "label",
    "labor",
    "ladder",
    "lady",
    "lake",
    "lamp",
    "language",
    "laptop",
    "large",
    "later",
    "latin",
    "laugh",
    "laundry",
    "lava",
    "law",
    "lawn",
    "lawsuit",
    "layer",
    "lazy",
    "leader",
    "leaf",
    "learn",
    "leave",
    "lecture",
    "left",
    "leg",
    "legal",
    "legend",
    "leisure",
    "lemon",
    "lend",
    "length",
    "lens",
    "leopard",
    "lesson",
    "letter",
    "level",
    "liar",
    "liberty",
    "library",
    "license",
    "life",
    "lift",
    "light",
    "like",
    "limb",
    "limit",
    "link",
    "lion",
    "liquid",
    "list",
    "little",
    "live",
    "lizard",
    "load",
    "loan",
    "lobster",
    "local",
    "lock",
    "logic",
    "lonely",
    "long",
    "loop",
    "lottery",
    "loud",
    "lounge",
    "love",
    "loyal",
    "lucky",
    "luggage",
    "lumber",
    "lunar",
    "lunch",
    "luxury",
    "lyrics",
    "machine",
    "mad",
    "magic",
    "magnet",
    "maid",
    "mail",
    "main",
    "major",
    "make",
    "mammal",
    "man",
    "manage",
    "mandate",
    "mango",
    "mansion",
    "manual",
    "maple",
    "marble",
    "march",
    "margin",
    "marine",
    "market",
    "marriage",
    "mask",
    "mass",
    "master",
    "match",
    "material",
    "math",
    "matrix",
    "matter",
    "maximum",
    "maze",
    "meadow",
    "mean",
    "measure",
    "meat",
    "mechanic",
    "medal",
    "media",
    "melody",
    "melt",
    "member",
    "memory",
    "mention",
    "menu",
    "mercy",
    "merge",
    "merit",
    "merry",
    "mesh",
    "message",
    "metal",
    "method",
    "middle",
    "midnight",
    "milk",
    "million",
    "mimic",
    "mind",
    "minimum",
    "minor",
    "minute",
    "miracle",
    "mirror",
    "misery",
    "miss",
    "mistake",
    "mix",
    "mixed",
    "mixture",
    "mobile",
    "model",
    "modify",
    "mom",
    "moment",
    "monitor",
    "monkey",
    "monster",
    "month",
    "moon",
    "moral",
    "more",
    "morning",
    "mosquito",
    "mother",
    "motion",
    "motor",
    "mountain",
    "mouse",
    "move",
    "movie",
    "much",
    "muffin",
    "mule",
    "multiply",
    "muscle",
    "museum",
    "mushroom",
    "music",
    "must",
    "mutual",
    "myself",
    "mystery",
    "myth",
    "naive",
    "name",
    "napkin",
    "narrow",
    "nasty",
    "nation",
    "nature",
    "near",
    "neck",
    "need",
    "negative",
    "neglect",
    "neither",
    "nephew",
    "nerve",
    "nest",
    "net",
    "network",
    "neutral",
    "never",
    "news",
    "next",
    "nice",
    "night",
    "noble",
    "noise",
    "nominee",
    "noodle",
    "normal",
    "north",
    "nose",
    "notable",
    "note",
    "nothing",
    "notice",
    "novel",
    "now",
    "nuclear",
    "number",
    "nurse",
    "nut",
    "oak",
    "obey",
    "object",
    "oblige",
    "obscure",
    "observe",
    "obtain",
    "obvious",
    "occur",
    "ocean",
    "october",
    "odor",
    "off",
    "offer",
    "office",
    "often",
    "oil",
    "okay",
    "old",
    "olive",
    "olympic",
    "omit",
    "once",
    "one",
    "onion",
    "online",
    "only",
    "open",
    "opera",
    "opinion",
    "oppose",
    "option",
    "orange",
    "orbit",
    "orchard",
    "order",
    "ordinary",
    "organ",
    "orient",
    "original",
    "orphan",
    "ostrich",
    "other",
    "outdoor",
    "outer",
    "output",
    "outside",
    "oval",
    "oven",
    "over",
    "own",
    "owner",
    "oxygen",
    "oyster",
    "ozone",
    "pact",
    "paddle",
    "page",
    "pair",
    "palace",
    "palm",
    "panda",
    "panel",
    "panic",
    "panther",
    "paper",
    "parade",
    "parent",
    "park",
    "parrot",
    "party",
    "pass",
    "patch",
    "path",
    "patient",
    "patrol",
    "pattern",
    "pause",
    "pave",
    "payment",
    "peace",
    "peanut",
    "pear",
    "peasant",
    "pelican",
    "pen",
    "penalty",
    "pencil",
    "people",
    "pepper",
    "perfect",
    "permit",
    "person",
    "pet",
    "phone",
    "photo",
    "phrase",
    "physical",
    "piano",
    "picnic",
    "picture",
    "piece",
    "pig",
    "pigeon",
    "pill",
    "pilot",
    "pink",
    "pioneer",
    "pipe",
    "pistol",
    "pitch",
    "pizza",
    "place",
    "planet",
    "plastic",
    "plate",
    "play",
    "please",
    "pledge",
    "pluck",
    "plug",
    "plunge",
    "poem",
    "poet",
    "point",
    "polar",
    "pole",
    "police",
    "pond",
    "pony",
    "pool",
    "popular",
    "portion",
    "position",
    "possible",
    "post",
    "potato",
    "pottery",
    "poverty",
    "powder",
    "power",
    "practice",
    "praise",
    "predict",
    "prefer",
    "prepare",
    "present",
    "pretty",
    "prevent",
    "price",
    "pride",
    "primary",
    "print",
    "priority",
    "prison",
    "private",
    "prize",
    "problem",
    "process",
    "produce",
    "profit",
    "program",
    "project",
    "promote",
    "proof",
    "property",
    "prosper",
    "protect",
    "proud",
    "provide",
    "public",
    "pudding",
    "pull",
    "pulp",
    "pulse",
    "pumpkin",
    "punch",
    "pupil",
    "puppy",
    "purchase",
    "purity",
    "purpose",
    "purse",
    "push",
    "put",
    "puzzle",
    "pyramid",
    "quality",
    "quantum",
    "quarter",
    "question",
    "quick",
    "quit",
    "quiz",
    "quote",
    "rabbit",
    "raccoon",
    "race",
    "rack",
    "radar",
    "radio",
    "rail",
    "rain",
    "raise",
    "rally",
    "ramp",
    "ranch",
    "random",
    "range",
    "rapid",
    "rare",
    "rate",
    "rather",
    "raven",
    "raw",
    "razor",
    "ready",
    "real",
    "reason",
    "rebel",
    "rebuild",
    "recall",
    "receive",
    "recipe",
    "record",
    "recycle",
    "reduce",
    "reflect",
    "reform",
    "refuse",
    "region",
    "regret",
    "regular",
    "reject",
    "relax",
    "release",
    "relief",
    "rely",
    "remain",
    "remember",
    "remind",
    "remove",
    "render",
    "renew",
    "rent",
    "reopen",
    "repair",
    "repeat",
    "replace",
    "report",
    "require",
    "rescue",
    "resemble",
    "resist",
    "resource",
    "response",
    "result",
    "retire",
    "retreat",
    "return",
    "reunion",
    "reveal",
    "review",
    "reward",
    "rhythm",
    "rib",
    "ribbon",
    "rice",
    "rich",
    "ride",
    "ridge",
    "rifle",
    "right",
    "rigid",
    "ring",
    "riot",
    "ripple",
    "risk",
    "ritual",
    "rival",
    "river",
    "road",
    "roast",
    "robot",
    "robust",
    "rocket",
    "romance",
    "roof",
    "rookie",
    "room",
    "rose",
    "rotate",
    "rough",
    "round",
    "route",
    "royal",
    "rubber",
    "rude",
    "rug",
    "rule",
    "run",
    "runway",
    "rural",
    "sad",
    "saddle",
    "sadness",
    "safe",
    "sail",
    "salad",
    "salmon",
    "salon",
    "salt",
    "salute",
    "same",
    "sample",
    "sand",
    "satisfy",
    "satoshi",
    "sauce",
    "sausage",
    "save",
    "say",
    "scale",
    "scan",
    "scare",
    "scatter",
    "scene",
    "scheme",
    "school",
    "science",
    "scissors",
    "scorpion",
    "scout",
    "scrap",
    "screen",
    "script",
    "scrub",
    "sea",
    "search",
    "season",
    "seat",
    "second",
    "secret",
    "section",
    "security",
    "seed",
    "seek",
    "segment",
    "select",
    "sell",
    "seminar",
    "senior",
    "sense",
    "sentence",
    "series",
    "service",
    "session",
    "settle",
    "setup",
    "seven",
    "shadow",
    "shaft",
    "shallow",
    "share",
    "shed",
    "shell",
    "sheriff",
    "shield",
    "shift",
    "shine",
    "ship",
    "shiver",
    "shock",
    "shoe",
    "shoot",
    "shop",
    "short",
    "shoulder",
    "shove",
    "shrimp",
    "shrug",
    "shuffle",
    "shy",
    "sibling",
    "sick",
    "side",
    "siege",
    "sight",
    "sign",
    "silent",
    "silk",
    "silly",
    "silver",
    "similar",
    "simple",
    "since",
    "sing",
    "siren",
    "sister",
    "situate",
    "six",
    "size",
    "skate",
    "sketch",
    "ski",
    "skill",
    "skin",
    "skirt",
    "skull",
    "slab",
    "slam",
    "sleep",
    "slender",
    "slice",
    "slide",
    "slight",
    "slim",
    "slogan",
    "slot",
    "slow",
    "slush",
    "small",
    "smart",
    "smile",
    "smoke",
    "smooth",
    "snack",
    "snake",
    "snap",
    "sniff",
    "snow",
    "soap",
    "soccer",
    "social",
    "sock",
    "soda",
    "soft",
    "solar",
    "soldier",
    "solid",
    "solution",
    "solve",
    "someone",
    "song",
    "soon",
    "sorry",
    "sort",
    "soul",
    "sound",
    "soup",
    "source",
    "south",
    "space",
    "spare",
    "spatial",
    "spawn",
    "speak",
    "special",
    "speed",
    "spell",
    "spend",
    "sphere",
    "spice",
    "spider",
    "spike",
    "spin",
    "spirit",
    "split",
    "spoil",
    "sponsor",
    "spoon",
    "sport",
    "spot",
    "spray",
    "spread",
    "spring",
    "spy",
    "square",
    "squeeze",
    "squirrel",
    "stable",
    "stadium",
    "staff",
    "stage",
    "stairs",
    "stamp",
    "stand",
    "start",
    "state",
    "stay",
    "steak",
    "steel",
    "stem",
    "step",
    "stereo",
    "stick",
    "still",
    "sting",
    "stock",
    "stomach",
    "stone",
    "stool",
    "story",
    "stove",
    "strategy",
    "street",
    "strike",
    "strong",
    "struggle",
    "student",
    "stuff",
    "stumble",
    "style",
    "subject",
    "submit",
    "subway",
    "success",
    "such",
    "sudden",
    "suffer",
    "sugar",
    "suggest",
    "suit",
    "summer",
    "sun",
    "sunny",
    "sunset",
    "super",
    "supply",
    "supreme",
    "sure",
    "surface",
    "surge",
    "surprise",
    "surround",
    "survey",
    "suspect",
    "sustain",
    "swallow",
    "swamp",
    "swap",
    "swarm",
    "swear",
    "sweet",
    "swift",
    "swim",
    "swing",
    "switch",
    "sword",
    "symbol",
    "symptom",
    "syrup",
    "system",
    "table",
    "tackle",
    "tag",
    "tail",
    "talent",
    "talk",
    "tank",
    "tape",
    "target",
    "task",
    "taste",
    "tattoo",
    "taxi",
    "teach",
    "team",
    "tell",
    "ten",
    "tenant",
    "tennis",
    "tent",
    "term",
    "test",
    "text",
    "thank",
    "that",
    "theme",
    "then",
    "theory",
    "there",
    "they",
    "thing",
    "this",
    "thought",
    "three",
    "thrive",
    "throw",
    "thumb",
    "thunder",
    "ticket",
    "tide",
    "tiger",
    "tilt",
    "timber",
    "time",
    "tiny",
    "tip",
    "tired",
    "tissue",
    "title",
    "toast",
    "tobacco",
    "today",
    "toddler",
    "toe",
    "together",
    "toilet",
    "token",
    "tomato",
    "tomorrow",
    "tone",
    "tongue",
    "tonight",
    "tool",
    "tooth",
    "top",
    "topic",
    "topple",
    "torch",
    "tornado",
    "tortoise",
    "toss",
    "total",
    "tourist",
    "toward",
    "tower",
    "town",
    "toy",
    "track",
    "trade",
    "traffic",
    "tragic",
    "train",
    "transfer",
    "trap",
    "trash",
    "travel",
    "tray",
    "treat",
    "tree",
    "trend",
    "trial",
    "tribe",
    "trick",
    "trigger",
    "trim",
    "trip",
    "trophy",
    "trouble",
    "truck",
    "true",
    "truly",
    "trumpet",
    "trust",
    "truth",
    "try",
    "tube",
    "tuition",
    "tumble",
    "tuna",
    "tunnel",
    "turkey",
    "turn",
    "turtle",
    "twelve",
    "twenty",
    "twice",
    "twin",
    "twist",
    "two",
    "type",
    "typical",
    "ugly",
    "umbrella",
    "unable",
    "unaware",
    "uncle",
    "uncover",
    "under",
    "undo",
    "unfair",
    "unfold",
    "unhappy",
    "uniform",
    "unique",
    "unit",
    "universe",
    "unknown",
    "unlock",
    "until",
    "unusual",
    "unveil",
    "update",
    "upgrade",
    "uphold",
    "upon",
    "upper",
    "upset",
    "urban",
    "urge",
    "usage",
    "use",
    "used",
    "useful",
    "useless",
    "usual",
    "utility",
    "vacant",
    "vacuum",
    "vague",
    "valid",
    "valley",
    "valve",
    "van",
    "vanish",
    "vapor",
    "various",
    "vast",
    "vault",
    "vehicle",
    "velvet",
    "vendor",
    "venture",
    "venue",
    "verb",
    "verify",
    "version",
    "very",
    "vessel",
    "veteran",
    "viable",
    "vibrant",
    "vicious",
    "victory",
    "video",
    "view",
    "village",
    "vintage",
    "violin",
    "virtual",
    "virus",
    "visa",
    "visit",
    "visual",
    "vital",
    "vivid",
    "vocal",
    "voice",
    "void",
    "volcano",
    "volume",
    "vote",
    "voyage",
    "wage",
    "wagon",
    "wait",
    "walk",
    "wall",
    "walnut",
    "want",
    "warfare",
    "warm",
    "warrior",
    "wash",
    "wasp",
    "waste",
    "water",
    "wave",
    "way",
    "wealth",
    "weapon",
    "wear",
    "weasel",
    "weather",
    "web",
    "wedding",
    "weekend",
    "weird",
    "welcome",
    "west",
    "wet",
    "whale",
    "what",
    "wheat",
    "wheel",
    "when",
    "where",
    "whip",
    "whisper",
    "wide",
    "width",
    "wife",
    "wild",
    "will",
    "win",
    "window",
    "wine",
    "wing",
    "wink",
    "winner",
    "winter",
    "wire",
    "wisdom",
    "wise",
    "wish",
    "witness",
    "wolf",
    "woman",
    "wonder",
    "wood",
    "wool",
    "word",
    "work",
    "world",
    "worry",
    "worth",
    "wrap",
    "wreck",
    "wrestle",
    "wrist",
    "write",
    "wrong",
    "yard",
    "year",
    "yellow",
    "you",
    "young",
    "youth",
    "zebra",
    "zero",
    "zone",
    "zoo"
]

},
"SMmQWmiQ5Q+ptcXBccp9IbX7AzbT063HbpFOXbNDIH4=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const pullAsync = require('pull-async');
const cat = require('pull-cat');
const Ref = require('ssb-ref');
const { where, and, author, type, live, toPullStream, } = require('ssb-db2/operators');
function makeID(room, alias) {
    return `${room}~${alias}`;
}
module.exports = {
    name: 'aliasUtils',
    version: '1.0.0',
    manifest: {
        get: 'async',
        stream: 'source',
    },
    permissions: {
        master: {
            allow: ['get', 'stream'],
        },
    },
    init: function init(ssb) {
        function getMap(feedId, cb) {
            return pull(ssb.db.query(where(and(author(feedId, { dedicated: feedId === ssb.id }), type('room/alias'))), toPullStream()), pull.collect((err, msgs) => {
                var _a, _b;
                if (err) {
                    cb(err);
                    return;
                }
                const map = new Map();
                for (const msg of msgs) {
                    if (!((_a = msg.value) === null || _a === void 0 ? void 0 : _a.content))
                        continue;
                    const { action, alias, aliasURL, room } = (_b = msg.value) === null || _b === void 0 ? void 0 : _b.content;
                    if (!room)
                        continue;
                    if (!Ref.isFeed(room))
                        continue;
                    if (!alias)
                        continue;
                    if (action !== 'registered' && action !== 'revoked')
                        continue;
                    if (action === 'registered') {
                        if (!aliasURL)
                            continue;
                        map.set(makeID(room, alias), { alias, aliasURL, room });
                    }
                    else {
                        map.delete(makeID(room, alias));
                    }
                }
                cb(null, map);
            }));
        }
        function get(feedId, cb) {
            getMap(feedId, (err, map) => {
                if (err)
                    cb(err);
                else
                    cb(null, [...map.values()]);
            });
        }
        function stream(feedId) {
            let map;
            return cat([
                // First deliver latest information on past alias msgs
                pullAsync((cb) => {
                    getMap(feedId, (err, m) => {
                        if (err)
                            cb(err);
                        else {
                            map = m;
                            cb(null, [...map.values()]);
                        }
                    });
                }),
                // Then update the array as live msgs appear
                pull(ssb.db.query(where(and(author(feedId, { dedicated: feedId === ssb.id }), type('room/alias'))), live({ old: false }), toPullStream()), pull.filter((msg) => {
                    var _a, _b;
                    if (!((_a = msg.value) === null || _a === void 0 ? void 0 : _a.content))
                        return false;
                    const { action, alias, aliasURL, room } = (_b = msg.value) === null || _b === void 0 ? void 0 : _b.content;
                    if (!room)
                        return false;
                    if (!Ref.isFeed(room))
                        return false;
                    if (!alias)
                        return false;
                    if (action !== 'registered' && action !== 'revoked')
                        return false;
                    if (action === 'registered' && !aliasURL)
                        return false;
                    return true;
                }), pull.map((msg) => {
                    var _a;
                    const { alias, aliasURL, room, action } = (_a = msg.value) === null || _a === void 0 ? void 0 : _a.content;
                    if (action === 'registered') {
                        map.set(makeID(room, alias), { alias, aliasURL, room });
                    }
                    else {
                        map.delete(makeID(room, alias));
                    }
                    return [...map.values()];
                })),
            ]);
        }
        return {
            get,
            stream,
        };
    },
};
//# sourceMappingURL=aliasUtils.js.map
},
"SPMiGnBLYmi33rld2nIMoA5gBeSZlQWJFsyFJOTNTuA=":
function (require, module, exports, __dirname, __filename) {
exports.asyncMap = require('./async-map')
exports.filter   = require('./filter')
exports.map      = require('./map')
exports.take     = require('./take')
exports.through  = require('./through')

},
"SRR26D+P2KAM1tEuK5udvEj+qVVrS36Kj9kuuE0Vug0=":
function (require, module, exports, __dirname, __filename) {
"use strict";
module.exports = [
    require('./plugin-http-auth-client-tokens'),
    require('./plugin-http-auth-client'),
    require('./plugin-http-auth'),
];

},
"SSvtzZkQFGlYA6N4j2xSDfnJtG/DFckjfev9txPXWq8=":
function (require, module, exports, __dirname, __filename) {
const {dirname} = require('path')

const mkdirpManual = (path, opts, made) => {
  opts.recursive = false
  const parent = dirname(path)
  if (parent === path) {
    return opts.mkdirAsync(path, opts).catch(er => {
      // swallowed by recursive implementation on posix systems
      // any other error is a failure
      if (er.code !== 'EISDIR')
        throw er
    })
  }

  return opts.mkdirAsync(path, opts).then(() => made || path, er => {
    if (er.code === 'ENOENT')
      return mkdirpManual(parent, opts)
        .then(made => mkdirpManual(path, opts, made))
    if (er.code !== 'EEXIST' && er.code !== 'EROFS')
      throw er
    return opts.statAsync(path).then(st => {
      if (st.isDirectory())
        return made
      else
        throw er
    }, () => { throw er })
  })
}

const mkdirpManualSync = (path, opts, made) => {
  const parent = dirname(path)
  opts.recursive = false

  if (parent === path) {
    try {
      return opts.mkdirSync(path, opts)
    } catch (er) {
      // swallowed by recursive implementation on posix systems
      // any other error is a failure
      if (er.code !== 'EISDIR')
        throw er
      else
        return
    }
  }

  try {
    opts.mkdirSync(path, opts)
    return made || path
  } catch (er) {
    if (er.code === 'ENOENT')
      return mkdirpManualSync(path, opts, mkdirpManualSync(parent, opts, made))
    if (er.code !== 'EEXIST' && er.code !== 'EROFS')
      throw er
    try {
      if (!opts.statSync(path).isDirectory())
        throw er
    } catch (_) {
      throw er
    }
  }
}

module.exports = {mkdirpManual, mkdirpManualSync}

},
"SX4Koa9IgsQ5iVOz8Wb+hmYGHG0EDhBnFus2kWOtzUQ=":
function (require, module, exports, __dirname, __filename) {
var cont     = require('cont')
var pull     = require('pull-stream')
var defer    = require('pull-defer')
var path     = require('path')
var explain  = require('explain-error')
var mkdirp   = require('mkdirp')
var rimraf   = require('rimraf')
var fs       = require('fs')
var glob     = require('pull-glob')
var paramap  = require('pull-paramap')
var Notify   = require('pull-notify')
var Live     = require('pull-live')
var Write    = require('pull-write-file')

var u = require('./util')
var createHash = u.createHash

module.exports = function Blobs (config) {
  if (!config) throw Error('multiblob expects config')

  var dir
  if('string' === typeof config)
    dir = config, config = {dir: dir}

  dir = config.dir
  var alg = config.hash = config.hash || config.alg || 'blake2s'
  var encode = config.encode || u.encode
  var decode = config.decode || u.decode
  var isHash = config.isHash || u.isHash

  function toPath (dir, string) {
    if(!string || !isHash(string)) return false
    var d = decode(string)
    var h = d.hash.toString('hex')
    return path.join(dir, d.alg, h.substring(0,2), h.substring(2))
  }

  function toHash(filename) {
    var parts = path.relative(dir, filename).split(path.sep)
    var alg = parts.shift()
    return encode(new Buffer(parts.join(''), 'hex'), alg)
  }

  var newBlob = Notify()

  var empty = u.encode(u.algs[alg]().digest(), alg)
  // MIX: I think this should be encode NOT u.encode ?!

  function isEmptyHash(hash) {
    return empty === hash
  }

  var n = 0
  var waiting = [], tmp = false

  function init (cb) {
    if(tmp) return cb()
    else waiting.push(cb)
  }

  var stat = u.single(fs.stat)

  var tmpdir = path.join(dir, 'tmp')

  rimraf(tmpdir, function () {
    mkdirp(tmpdir, function () {
      tmp = true; while(waiting.length) waiting.shift()()
    })
  })

  function toMeta(hash, stat) {
    if(!stat) return null
    return {id: hash, size: stat.size, ts: +stat.ctime}
  }

  function has (hash) {
    return function (cb) {
      if(isEmptyHash(hash)) return cb(null, true)
      var p = toPath(dir, hash)
      if(!p) return cb(new Error('not a valid blob hash:'+hash))
      stat(p, function (err, stat) {
        cb(null, !!stat)
      })
    }
  }

  function size (hash) {
    return function (cb) {
      if(isEmptyHash(hash)) return cb(null, 0)
      var p = toPath(dir, hash)
      if(!p) return cb(new Error('not a valid blob hash:'+hash))
      stat(p, function (err, stat) {
        cb(null, stat ? stat.size : null)
      })
    }
  }

  var meta = function (hash, cb) {
    if(isEmptyHash(hash)) return cb(null, {id: hash, size: 0, ts: 0})
    stat(toPath(dir, hash), function (err, stat) {
      cb(err, toMeta(hash, stat))
    })
  }

  function createTester (test) {
    return function (hashes, cb) {
      var n = !Array.isArray(hashes)
      //check if any hashes are invalid.
      var invalid
      if(n ? !isHash(hashes) : !hashes.every(function (h) {
        if(!isHash(h)) invalid = h
        else return true
      }))
        return cb(new Error('not a valid hash:'+invalid))
        
      cont.para(u.toArray(hashes).map(test)) (function (err, ary) {
        //will give an error if any hash was invalid.
        if(err) cb(err)
        // This will only error if the hash is not present,
        // so never callback an error.
        // PS. if you have a situation where you never error
        // add a comment like this one to explain why.
        else if(n) cb(null, ary[0])
        else       cb(null, ary)
      })
      return cb
    }
  }

  function getSlice(opts) {
    if(isEmptyHash(opts.hash)) return pull.empty()

    var stream = defer.source()
    stat(toPath(dir, opts.hash), function (err, stat) {
      if(err)
        stream.abort(explain(err, 'stat failed'))

      else if(opts.size != null && opts.size !== stat.size)
        stream.abort(new Error('incorrect file length,'
          + ' requested:' + opts.size + ' file was:' + stat.size
          + ' for file:' + opts.hash
        ))

      else if(opts.max != null && opts.max < stat.size)
        stream.abort(new Error('incorrect file length,'
          + ' requested:' + opts.size + ' file was:' + stat.size
          + ' for file:' + opts.hash
        ))

      else
        stream.resolve(u.readFile(toPath(dir, opts.hash), {
          start: opts.start,
          end: opts.end
        }))
    })

    return stream
  }


  return {
    get: function (opts) {
      if(isHash(opts)) {
        if(isEmptyHash(hash)) return pull.empty()
        return u.readFile(toPath(dir, opts))
      }
      var hash = opts.key || opts.hash
      if(!isHash(hash))
        return pull.error(new Error(
          'multiblob.get: {hash} is mandatory'
        ))

      return getSlice({hash: hash, size: opts.size, max: opts.max})
    },
    isEmptyHash: isEmptyHash,

    getSlice: function (opts) {
      if(!isHash(opts.hash))
        return pull.error(new Error(
          'multiblob.getSlice: {hash} is mandatory'
        ))

      if(isNaN(opts.start))
        return pull.error(new Error(
          'multiblob.getSlice: {start} must be a number'
        ))

      if(isNaN(opts.end))
        return pull.error(new Error(
          'multiblob.getSlice: {end} must be a number'
        ))

      return getSlice(opts)
    },

    size: createTester(size),

    has: createTester(has),
    meta: meta,

    add: function (hash, cb) {
      if('function' === typeof hash) cb = hash, hash = null

      if(!cb) cb = function (err) {
        if(err) throw explain(err, 'no callback provided')
      }

      if(hash && !isHash(hash)) {
        //abort input stream and callback once source is aborted.
        var err = new Error('not a valid hash:'+hash)
        return function (read) {
          read(err, cb)
        }
      }

      var deferred = defer.sink()
      init(function () {
        var tmpfile = path.join(dir, 'tmp', Date.now() + '-' + n++)
        var hasher = createHash(alg, true)
        var size = 0

        deferred.resolve(pull(
          hasher,
          pull.map(function (data) {
            if('string' === typeof data) data = new Buffer(data, 'utf8')
            size += data.length
            return data
          }),
          Write(tmpfile, function (err) {
            if(err) return cb(explain(err, 'could not write to tmpfile'))

            var _hash = encode(hasher.digest, alg)

            if(hash && hash !== _hash)
              return cb(new Error('actual hash:'+ _hash
                + ' did not match expected hash:'+hash), _hash)

            var p = toPath(dir, hash || _hash)

            mkdirp(path.dirname(p), function () {
              fs.rename(tmpfile, p, function (err) {
                if(err) cb(explain(err, 'could not move file'))
                else    newBlob({id:toHash(p), size: size, ts: Date.now()}), cb(null, _hash)
              })
            })
          })
        ))
      })

      return deferred
    },

    ls: Live(function old (opts) {
      var long = (opts.size || opts.long || opts.meta)
      return pull(
        glob(path.join(dir, '*', '*', '*')),
        long ? paramap(function (filename, cb) {
          stat(filename, function (err, stat) {
            cb(err, toMeta(toHash(filename), stat))
          })
        }, 32) : pull.map(toHash)
      )
    }, function live (opts) {
      var long = (opts.size || opts.long || opts.meta)
      return long
        ? newBlob.listen()
        : pull(newBlob.listen(), pull.map(function (e) { return e.id }))
    }),

    rm: function (hash, cb) {
      if(!isHash(hash)) cb(new Error('not valid hash:'+hash))
      else              fs.unlink(toPath(dir, hash), cb)
    },

    resolve: function (hash) {
      if(!isHash(hash)) throw new Error('not valid hash:'+hash)
      return toPath(dir, hash)
    }
  }
}




},
"SuH9xO3Rm8LEqlsnebPcb0XKI0O52FtK1EQ8Zea6z4I=":
function (require, module, exports, __dirname, __filename) {
"use strict";

function isFunction(f) {
  return "function" == typeof f;
}

module.exports = function (generate) {
  function create(filename, curve, legacy) {
    var keys = generate(curve, legacy);
    localStorage[filename] = JSON.stringify(keys);
    return keys;
  }

  function load(filename) {
    return JSON.parse(localStorage[filename]);
  }

  return {
    createSync: create,
    create: function (filename, curve, legacy, cb) {
      if (isFunction(legacy)) (cb = legacy), (legacy = null);
      if (isFunction(curve)) (cb = curve), (curve = null);
      cb(null, create(filename, curve, legacy));
    },
    loadSync: load,
    load: function (filename, cb) {
      cb(null, load(filename));
    },
  };
};

},
"SuebAfIKqQBB1uxEahV1WftDO2rU0Qt4teNgrjRwMeg=":
function (require, module, exports, __dirname, __filename) {
var Looper = require('looper')
module.exports = function (n) {
  if(!Number.isInteger(n))
    throw new Error('Skip:N must be number')

  return function (read) {
    return function (abort, cb) {
      if(n <= 0) return read(abort, cb)

      var next = Looper(function () {
        read(abort, function (end, data) {
          if(end) return cb(end)
          else if(n-->0) next()
          else cb(null, data)
        })
      })

      next()
    }
  }
}



},
"T3UqgRvH4bF+fXBGd8nMc1944LbajxvPEQKRdhx9vNs=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var sources  = require('./sources')
var sinks    = require('./sinks')
var throughs = require('./throughs')

exports = module.exports = require('./pull')

for(var k in sources)
  exports[k] = sources[k]

for(var k in throughs)
  exports[k] = throughs[k]

for(var k in sinks)
  exports[k] = sinks[k]


},
"T60KyaOFdTt6P3sFlqayBcT4CMcG5+lsJKiByZOZTgM=":
function (require, module, exports, __dirname, __filename) {

exports.collect = require('./collect')
exports.drain = require('./drain')
exports.reduce = require('./reduce')

},
"TOUXLCiaod6gCRkjK5KmIJP3+b1QDDs7BmP1pH5UhHc=":
function (require, module, exports, __dirname, __filename) {
var path = require('path')
var AtomicFile = require('atomic-file')
function id (e) { return e }

var none = {
  encode: id, decode: id
}

module.exports = function (dir, name, codec) {
  codec = codec || require('flumecodec/json')
  var af = AtomicFile(path.join(dir, name+'.json'), '~', none)
  var self
  return self = {
    size: null,
    get: function (cb) {
      af.get(function (err, value) {
        if(err) return cb(err)
        if(value == null) return cb()
        try {
          self.size = value.length
          value = codec.decode(value)
          value.size = self.size
        } catch(err) {
          return cb(err)
        }
        cb(null, value)
      })
    },
    set: function (value, cb) {
      value = codec.encode(value)
      self.size = value.length
      af.set(value, cb)
    },
    destroy: function (cb) {
      value = null
      self.size = 0
      af.destroy(cb)
    }
  }
}









},
"TQAUexAH54IG+4QLpJseo/IuVTYWBRpcD0xFGxX05rE=":
function (require, module, exports, __dirname, __filename) {
var sodium = require('chloride')
var scalarmult = sodium.crypto_scalarmult
var box  = sodium.crypto_box_easy
var secretbox = sodium.crypto_secretbox_easy
var secretbox_open = sodium.crypto_secretbox_open_easy
var keypair = sodium.crypto_box_keypair
var concat = Buffer.concat

function randombytes(n) {
  var b = new Buffer(n)
  sodium.randombytes(b)
  return b
}

function setMax (m) {
  m = m || DEFAULT_MAX
  if (m < 1 || m > 255)
    throw new Error('max recipients must be between 0 and 255.')
  return m
}


const DEFAULT_MAX = 7

exports.encrypt =
exports.multibox = function (msg, recipients, max) {

  max = setMax(max)

  if(recipients.length > max)
    throw new Error('max recipients is:'+max+' found:'+recipients.length)

  var nonce = randombytes(24)
  var key = randombytes(32)
  var onetime = keypair()

  var length_and_key = concat([new Buffer([recipients.length]), key])
  return concat([
    nonce,
    onetime.publicKey,
    concat(recipients.map(function (r_pk, i) {
      return secretbox(length_and_key, nonce, scalarmult(onetime.secretKey, r_pk))
    })),
    secretbox(msg, nonce, key)
  ])
}

exports.multibox_open_key = function (ctxt, sk, max) { //, groups...

  max = setMax(max)

  var nonce = ctxt.slice(0, 24)
  var onetime_pk = ctxt.slice(24, 24+32)
  var my_key = scalarmult(sk, onetime_pk)
  var length_and_key, key, length, start = 24+32, size = 32+1+16
  for(var i = 0; i <= max; i++) {
    var s = start+size*i
    if(s + size > (ctxt.length - 16)) return null
    length_and_key = secretbox_open(ctxt.slice(s, s + size), nonce, my_key)
    if(length_and_key) return length_and_key
  }
}

exports.multibox_open_body = function (ctxt, length_and_key) { //, groups...
  if(!length_and_key) return
  var key = length_and_key.slice(1)
  var length = length_and_key[0]
  var start = 24+32, size = 32+1+16
  var nonce = ctxt.slice(0, 24)
  return secretbox_open(ctxt.slice(start+length*size), nonce, key)
}

exports.decrypt =
exports.multibox_open = function (ctxt, sk, max) { //, groups...
  var _key = exports.multibox_open_key(ctxt, sk, max)
  if(_key) return exports.multibox_open_body(ctxt, _key)
}

},
"TZhD82oHTYdXvS5L6p4PGz8scF9rlqoYYWIXtimi4GY=":
function (require, module, exports, __dirname, __filename) {
exports.AbstractLevelDOWN = require('./abstract-leveldown')
exports.AbstractIterator = require('./abstract-iterator')
exports.AbstractChainedBatch = require('./abstract-chained-batch')

},
"TaQlRWsarAhCsgdA53CNohbTKeqfyqGyJ1PcxCBKISo=":
function (require, module, exports, __dirname, __filename) {
// Generated automatically by nearley, version 2.15.1
// http://github.com/Hardmath123/nearley
(function () {
function id(x) { return x[0]; }
var grammar = {
    Lexer: undefined,
    ParserRules: [
    {"name": "multiaddress$ebnf$1", "symbols": []},
    {"name": "multiaddress$ebnf$1$subexpression$1", "symbols": [{"literal":";"}, "address"]},
    {"name": "multiaddress$ebnf$1", "symbols": ["multiaddress$ebnf$1", "multiaddress$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "multiaddress", "symbols": ["address", "multiaddress$ebnf$1"], "postprocess": d => [d[0]].concat(d[1].map(function (e) { return e[1] }))},
    {"name": "address$ebnf$1", "symbols": []},
    {"name": "address$ebnf$1$subexpression$1", "symbols": [{"literal":"~"}, "protocol"]},
    {"name": "address$ebnf$1", "symbols": ["address$ebnf$1", "address$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "address", "symbols": ["protocol", "address$ebnf$1"], "postprocess": d => [d[0]].concat(d[1].map(function (e) { return e[1] }))},
    {"name": "protocol$ebnf$1", "symbols": []},
    {"name": "protocol$ebnf$1$subexpression$1", "symbols": [{"literal":":"}, "data"]},
    {"name": "protocol$ebnf$1", "symbols": ["protocol$ebnf$1", "protocol$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "protocol", "symbols": ["name", "protocol$ebnf$1"], "postprocess": (d) => { return {name: d[0], data: d[1].map(e =>  e[1] )} }},
    {"name": "name$ebnf$1", "symbols": [/[a-z\-0-9]/]},
    {"name": "name$ebnf$1", "symbols": ["name$ebnf$1", /[a-z\-0-9]/], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "name", "symbols": [/[a-z]/, "name$ebnf$1"], "postprocess": d => d[0]+d[1].join('')},
    {"name": "data$ebnf$1", "symbols": []},
    {"name": "data$ebnf$1$subexpression$1", "symbols": ["char"]},
    {"name": "data$ebnf$1$subexpression$1", "symbols": ["escaped_char"]},
    {"name": "data$ebnf$1", "symbols": ["data$ebnf$1", "data$ebnf$1$subexpression$1"], "postprocess": function arrpush(d) {return d[0].concat([d[1]]);}},
    {"name": "data", "symbols": ["data$ebnf$1"], "postprocess": d => d[0].join('')},
    {"name": "char", "symbols": [/["-9]/]},
    {"name": "char", "symbols": [/[<-}]/], "postprocess": d => d[0]},
    {"name": "escaped_char$subexpression$1$string$1", "symbols": [{"literal":"!"}, {"literal":"!"}], "postprocess": function joiner(d) {return d.join('');}},
    {"name": "escaped_char$subexpression$1", "symbols": ["escaped_char$subexpression$1$string$1"]},
    {"name": "escaped_char$subexpression$1$string$2", "symbols": [{"literal":"!"}, {"literal":"~"}], "postprocess": function joiner(d) {return d.join('');}},
    {"name": "escaped_char$subexpression$1", "symbols": ["escaped_char$subexpression$1$string$2"]},
    {"name": "escaped_char$subexpression$1$string$3", "symbols": [{"literal":"!"}, {"literal":":"}], "postprocess": function joiner(d) {return d.join('');}},
    {"name": "escaped_char$subexpression$1", "symbols": ["escaped_char$subexpression$1$string$3"]},
    {"name": "escaped_char$subexpression$1$string$4", "symbols": [{"literal":"!"}, {"literal":";"}], "postprocess": function joiner(d) {return d.join('');}},
    {"name": "escaped_char$subexpression$1", "symbols": ["escaped_char$subexpression$1$string$4"]},
    {"name": "escaped_char", "symbols": ["escaped_char$subexpression$1"], "postprocess": d => d[0][0][1]}
]
  , ParserStart: "multiaddress"
}
if (typeof module !== 'undefined'&& typeof module.exports !== 'undefined') {
   module.exports = grammar;
} else {
   window.grammar = grammar;
}
})();

},
"TdQ7+GuIb2rcFqo0svDTonuS7PZa3LhyJOVM05TSAkw=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var keysShim;
if (!Object.keys) {
	// modified from https://github.com/es-shims/es5-shim
	var has = Object.prototype.hasOwnProperty;
	var toStr = Object.prototype.toString;
	var isArgs = require('./isArguments'); // eslint-disable-line global-require
	var isEnumerable = Object.prototype.propertyIsEnumerable;
	var hasDontEnumBug = !isEnumerable.call({ toString: null }, 'toString');
	var hasProtoEnumBug = isEnumerable.call(function () {}, 'prototype');
	var dontEnums = [
		'toString',
		'toLocaleString',
		'valueOf',
		'hasOwnProperty',
		'isPrototypeOf',
		'propertyIsEnumerable',
		'constructor'
	];
	var equalsConstructorPrototype = function (o) {
		var ctor = o.constructor;
		return ctor && ctor.prototype === o;
	};
	var excludedKeys = {
		$applicationCache: true,
		$console: true,
		$external: true,
		$frame: true,
		$frameElement: true,
		$frames: true,
		$innerHeight: true,
		$innerWidth: true,
		$onmozfullscreenchange: true,
		$onmozfullscreenerror: true,
		$outerHeight: true,
		$outerWidth: true,
		$pageXOffset: true,
		$pageYOffset: true,
		$parent: true,
		$scrollLeft: true,
		$scrollTop: true,
		$scrollX: true,
		$scrollY: true,
		$self: true,
		$webkitIndexedDB: true,
		$webkitStorageInfo: true,
		$window: true
	};
	var hasAutomationEqualityBug = (function () {
		/* global window */
		if (typeof window === 'undefined') { return false; }
		for (var k in window) {
			try {
				if (!excludedKeys['$' + k] && has.call(window, k) && window[k] !== null && typeof window[k] === 'object') {
					try {
						equalsConstructorPrototype(window[k]);
					} catch (e) {
						return true;
					}
				}
			} catch (e) {
				return true;
			}
		}
		return false;
	}());
	var equalsConstructorPrototypeIfNotBuggy = function (o) {
		/* global window */
		if (typeof window === 'undefined' || !hasAutomationEqualityBug) {
			return equalsConstructorPrototype(o);
		}
		try {
			return equalsConstructorPrototype(o);
		} catch (e) {
			return false;
		}
	};

	keysShim = function keys(object) {
		var isObject = object !== null && typeof object === 'object';
		var isFunction = toStr.call(object) === '[object Function]';
		var isArguments = isArgs(object);
		var isString = isObject && toStr.call(object) === '[object String]';
		var theKeys = [];

		if (!isObject && !isFunction && !isArguments) {
			throw new TypeError('Object.keys called on a non-object');
		}

		var skipProto = hasProtoEnumBug && isFunction;
		if (isString && object.length > 0 && !has.call(object, 0)) {
			for (var i = 0; i < object.length; ++i) {
				theKeys.push(String(i));
			}
		}

		if (isArguments && object.length > 0) {
			for (var j = 0; j < object.length; ++j) {
				theKeys.push(String(j));
			}
		} else {
			for (var name in object) {
				if (!(skipProto && name === 'prototype') && has.call(object, name)) {
					theKeys.push(String(name));
				}
			}
		}

		if (hasDontEnumBug) {
			var skipConstructor = equalsConstructorPrototypeIfNotBuggy(object);

			for (var k = 0; k < dontEnums.length; ++k) {
				if (!(skipConstructor && dontEnums[k] === 'constructor') && has.call(object, dontEnums[k])) {
					theKeys.push(dontEnums[k]);
				}
			}
		}
		return theKeys;
	};
}
module.exports = keysShim;

},
"Tj3G0OHbWKDXQga0Q/NVgtO3F75WoPbQMMNK9sKtn2I=":
function (require, module, exports, __dirname, __filename) {
/* eslint-env browser */

/**
 * This is the web browser implementation of `debug()`.
 */

exports.formatArgs = formatArgs;
exports.save = save;
exports.load = load;
exports.useColors = useColors;
exports.storage = localstorage();
exports.destroy = (() => {
	let warned = false;

	return () => {
		if (!warned) {
			warned = true;
			console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
		}
	};
})();

/**
 * Colors.
 */

exports.colors = [
	'#0000CC',
	'#0000FF',
	'#0033CC',
	'#0033FF',
	'#0066CC',
	'#0066FF',
	'#0099CC',
	'#0099FF',
	'#00CC00',
	'#00CC33',
	'#00CC66',
	'#00CC99',
	'#00CCCC',
	'#00CCFF',
	'#3300CC',
	'#3300FF',
	'#3333CC',
	'#3333FF',
	'#3366CC',
	'#3366FF',
	'#3399CC',
	'#3399FF',
	'#33CC00',
	'#33CC33',
	'#33CC66',
	'#33CC99',
	'#33CCCC',
	'#33CCFF',
	'#6600CC',
	'#6600FF',
	'#6633CC',
	'#6633FF',
	'#66CC00',
	'#66CC33',
	'#9900CC',
	'#9900FF',
	'#9933CC',
	'#9933FF',
	'#99CC00',
	'#99CC33',
	'#CC0000',
	'#CC0033',
	'#CC0066',
	'#CC0099',
	'#CC00CC',
	'#CC00FF',
	'#CC3300',
	'#CC3333',
	'#CC3366',
	'#CC3399',
	'#CC33CC',
	'#CC33FF',
	'#CC6600',
	'#CC6633',
	'#CC9900',
	'#CC9933',
	'#CCCC00',
	'#CCCC33',
	'#FF0000',
	'#FF0033',
	'#FF0066',
	'#FF0099',
	'#FF00CC',
	'#FF00FF',
	'#FF3300',
	'#FF3333',
	'#FF3366',
	'#FF3399',
	'#FF33CC',
	'#FF33FF',
	'#FF6600',
	'#FF6633',
	'#FF9900',
	'#FF9933',
	'#FFCC00',
	'#FFCC33'
];

/**
 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
 * and the Firebug extension (any Firefox version) are known
 * to support "%c" CSS customizations.
 *
 * TODO: add a `localStorage` variable to explicitly enable/disable colors
 */

// eslint-disable-next-line complexity
function useColors() {
	// NB: In an Electron preload script, document will be defined but not fully
	// initialized. Since we know we're in Chrome, we'll just detect this case
	// explicitly
	if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
		return true;
	}

	// Internet Explorer and Edge do not support colors.
	if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {
		return false;
	}

	// Is webkit? http://stackoverflow.com/a/16459606/376773
	// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
	return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||
		// Is firebug? http://stackoverflow.com/a/398120/376773
		(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
		// Is firefox >= v31?
		// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
		(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||
		// Double check webkit in userAgent just in case we are in a worker
		(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));
}

/**
 * Colorize log arguments if enabled.
 *
 * @api public
 */

function formatArgs(args) {
	args[0] = (this.useColors ? '%c' : '') +
		this.namespace +
		(this.useColors ? ' %c' : ' ') +
		args[0] +
		(this.useColors ? '%c ' : ' ') +
		'+' + module.exports.humanize(this.diff);

	if (!this.useColors) {
		return;
	}

	const c = 'color: ' + this.color;
	args.splice(1, 0, c, 'color: inherit');

	// The final "%c" is somewhat tricky, because there could be other
	// arguments passed either before or after the %c, so we need to
	// figure out the correct index to insert the CSS into
	let index = 0;
	let lastC = 0;
	args[0].replace(/%[a-zA-Z%]/g, match => {
		if (match === '%%') {
			return;
		}
		index++;
		if (match === '%c') {
			// We only are interested in the *last* %c
			// (the user may have provided their own)
			lastC = index;
		}
	});

	args.splice(lastC, 0, c);
}

/**
 * Invokes `console.debug()` when available.
 * No-op when `console.debug` is not a "function".
 * If `console.debug` is not available, falls back
 * to `console.log`.
 *
 * @api public
 */
exports.log = console.debug || console.log || (() => {});

/**
 * Save `namespaces`.
 *
 * @param {String} namespaces
 * @api private
 */
function save(namespaces) {
	try {
		if (namespaces) {
			exports.storage.setItem('debug', namespaces);
		} else {
			exports.storage.removeItem('debug');
		}
	} catch (error) {
		// Swallow
		// XXX (@Qix-) should we be logging these?
	}
}

/**
 * Load `namespaces`.
 *
 * @return {String} returns the previously persisted debug modes
 * @api private
 */
function load() {
	let r;
	try {
		r = exports.storage.getItem('debug');
	} catch (error) {
		// Swallow
		// XXX (@Qix-) should we be logging these?
	}

	// If debug isn't set in LS, and we're in Electron, try to load $DEBUG
	if (!r && typeof process !== 'undefined' && 'env' in process) {
		r = process.env.DEBUG;
	}

	return r;
}

/**
 * Localstorage attempts to return the localstorage.
 *
 * This is necessary because safari throws
 * when a user disables cookies/localstorage
 * and you attempt to access it.
 *
 * @return {LocalStorage}
 * @api private
 */

function localstorage() {
	try {
		// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
		// The Browser also has localStorage in the global context.
		return localStorage;
	} catch (error) {
		// Swallow
		// XXX (@Qix-) should we be logging these?
	}
}

module.exports = require('./common')(exports);

const {formatters} = module.exports;

/**
 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
 */

formatters.j = function (v) {
	try {
		return JSON.stringify(v);
	} catch (error) {
		return '[UnexpectedJSONParseError]: ' + error.message;
	}
};

},
"TkIiVGduanukayVt0UICnsqUxsxMJtLRz4fzVxkRQfY=":
function (require, module, exports, __dirname, __filename) {

var clean = require('to-no-case')

/**
 * Export.
 */

module.exports = toSpaceCase

/**
 * Convert a `string` to space case.
 *
 * @param {String} string
 * @return {String}
 */

function toSpaceCase(string) {
  return clean(string).replace(/[\W_]+(.|$)/g, function (matches, match) {
    return match ? ' ' + match : ''
  }).trim()
}

},
"TrERnD7szE2OiEG3fQYquvRXKzMoAfWxYXW8MxG12PE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

function posix(path) {
	return path.charAt(0) === '/';
}

function win32(path) {
	// https://github.com/nodejs/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56
	var splitDeviceRe = /^([a-zA-Z]:|[\\\/]{2}[^\\\/]+[\\\/]+[^\\\/]+)?([\\\/])?([\s\S]*?)$/;
	var result = splitDeviceRe.exec(path);
	var device = result[1] || '';
	var isUnc = Boolean(device && device.charAt(1) !== ':');

	// UNC paths are always absolute
	return Boolean(result[2] || isUnc);
}

module.exports = process.platform === 'win32' ? win32 : posix;
module.exports.posix = posix;
module.exports.win32 = win32;

},
"Trwq+KqeWzxsbUet+Omb+wC9uH2QMBcZNBUiXOCqCv4=":
function (require, module, exports, __dirname, __filename) {
var events = require('events')
var inherits = require('inherits')

var NOT_READABLE = defaultImpl(new Error('Not readable'))
var NOT_WRITABLE = defaultImpl(new Error('Not writable'))
var NOT_DELETABLE = defaultImpl(new Error('Not deletable'))
var NOT_STATABLE = defaultImpl(new Error('Not statable'))
var NO_OPEN_READABLE = defaultImpl(new Error('No readonly open'))

// NON_BLOCKING_OPS
var READ_OP = 0
var WRITE_OP = 1
var DEL_OP = 2
var STAT_OP = 3

// BLOCKING_OPS
var OPEN_OP = 4
var CLOSE_OP = 5
var DESTROY_OP = 6

module.exports = RandomAccess

function RandomAccess (opts) {
  if (!(this instanceof RandomAccess)) return new RandomAccess(opts)
  events.EventEmitter.call(this)

  this._queued = []
  this._pending = 0
  this._needsOpen = true

  this.opened = false
  this.closed = false
  this.destroyed = false

  if (opts) {
    if (opts.openReadonly) this._openReadonly = opts.openReadonly
    if (opts.open) this._open = opts.open
    if (opts.read) this._read = opts.read
    if (opts.write) this._write = opts.write
    if (opts.del) this._del = opts.del
    if (opts.stat) this._stat = opts.stat
    if (opts.close) this._close = opts.close
    if (opts.destroy) this._destroy = opts.destroy
  }

  this.preferReadonly = this._openReadonly !== NO_OPEN_READABLE
  this.readable = this._read !== NOT_READABLE
  this.writable = this._write !== NOT_WRITABLE
  this.deletable = this._del !== NOT_DELETABLE
  this.statable = this._stat !== NOT_STATABLE
}

inherits(RandomAccess, events.EventEmitter)

RandomAccess.prototype.read = function (offset, size, cb) {
  this.run(new Request(this, READ_OP, offset, size, null, cb))
}

RandomAccess.prototype._read = NOT_READABLE

RandomAccess.prototype.write = function (offset, data, cb) {
  if (!cb) cb = noop
  openWritable(this)
  this.run(new Request(this, WRITE_OP, offset, data.length, data, cb))
}

RandomAccess.prototype._write = NOT_WRITABLE

RandomAccess.prototype.del = function (offset, size, cb) {
  if (!cb) cb = noop
  openWritable(this)
  this.run(new Request(this, DEL_OP, offset, size, null, cb))
}

RandomAccess.prototype._del = NOT_DELETABLE

RandomAccess.prototype.stat = function (cb) {
  this.run(new Request(this, STAT_OP, 0, 0, null, cb))
}

RandomAccess.prototype._stat = NOT_STATABLE

RandomAccess.prototype.open = function (cb) {
  if (!cb) cb = noop
  if (this.opened && !this._needsOpen) return process.nextTick(cb, null)
  queueAndRun(this, new Request(this, OPEN_OP, 0, 0, null, cb))
}

RandomAccess.prototype._open = defaultImpl(null)
RandomAccess.prototype._openReadonly = NO_OPEN_READABLE

RandomAccess.prototype.close = function (cb) {
  if (!cb) cb = noop
  if (this.closed) return process.nextTick(cb, null)
  queueAndRun(this, new Request(this, CLOSE_OP, 0, 0, null, cb))
}

RandomAccess.prototype._close = defaultImpl(null)

RandomAccess.prototype.destroy = function (cb) {
  if (!cb) cb = noop
  if (!this.closed) this.close(noop)
  queueAndRun(this, new Request(this, DESTROY_OP, 0, 0, null, cb))
}

RandomAccess.prototype._destroy = defaultImpl(null)

RandomAccess.prototype.run = function (req) {
  if (this._needsOpen) this.open(noop)
  if (this._queued.length) this._queued.push(req)
  else req._run()
}

function noop () {}

function Request (self, type, offset, size, data, cb) {
  this.type = type
  this.offset = offset
  this.data = data
  this.size = size
  this.storage = self

  this._sync = false
  this._callback = cb
  this._openError = null
}

Request.prototype._maybeOpenError = function (err) {
  if (this.type !== OPEN_OP) return
  var queued = this.storage._queued
  for (var i = 0; i < queued.length; i++) queued[i]._openError = err
}

Request.prototype._unqueue = function (err) {
  var ra = this.storage
  var queued = ra._queued

  if (!err) {
    switch (this.type) {
      case OPEN_OP:
        if (!ra.opened) {
          ra.opened = true
          ra.emit('open')
        }
        break

      case CLOSE_OP:
        if (!ra.closed) {
          ra.closed = true
          ra.emit('close')
        }
        break

      case DESTROY_OP:
        if (!ra.destroyed) {
          ra.destroyed = true
          ra.emit('destroy')
        }
        break
    }
  } else {
    this._maybeOpenError(err)
  }

  if (queued.length && queued[0] === this) queued.shift()

  if (!--ra._pending) drainQueue(ra)
}

Request.prototype.callback = function (err, val) {
  if (this._sync) return nextTick(this, err, val)
  this._unqueue(err)
  this._callback(err, val)
}

Request.prototype._openAndNotClosed = function () {
  var ra = this.storage
  if (ra.opened && !ra.closed) return true
  if (!ra.opened) nextTick(this, this._openError || new Error('Not opened'))
  else if (ra.closed) nextTick(this, new Error('Closed'))
  return false
}

Request.prototype._open = function () {
  var ra = this.storage

  if (ra.opened && !ra._needsOpen) return nextTick(this, null)
  if (ra.closed) return nextTick(this, new Error('Closed'))

  ra._needsOpen = false
  if (ra.preferReadonly) ra._openReadonly(this)
  else ra._open(this)
}

Request.prototype._run = function () {
  var ra = this.storage
  ra._pending++

  this._sync = true

  switch (this.type) {
    case READ_OP:
      if (this._openAndNotClosed()) ra._read(this)
      break

    case WRITE_OP:
      if (this._openAndNotClosed()) ra._write(this)
      break

    case DEL_OP:
      if (this._openAndNotClosed()) ra._del(this)
      break

    case STAT_OP:
      if (this._openAndNotClosed()) ra._stat(this)
      break

    case OPEN_OP:
      this._open()
      break

    case CLOSE_OP:
      if (ra.closed || !ra.opened) nextTick(this, null)
      else ra._close(this)
      break

    case DESTROY_OP:
      if (ra.destroyed) nextTick(this, null)
      else ra._destroy(this)
      break
  }

  this._sync = false
}

function queueAndRun (self, req) {
  self._queued.push(req)
  if (!self._pending) req._run()
}

function drainQueue (self) {
  var queued = self._queued

  while (queued.length > 0) {
    var blocking = queued[0].type > 3
    if (!blocking || !self._pending) queued[0]._run()
    if (blocking) return
    queued.shift()
  }
}

function openWritable (self) {
  if (self.preferReadonly) {
    self._needsOpen = true
    self.preferReadonly = false
  }
}

function defaultImpl (err) {
  return overridable

  function overridable (req) {
    nextTick(req, err)
  }
}

function nextTick (req, err, val) {
  process.nextTick(nextTickCallback, req, err, val)
}

function nextTickCallback (req, err, val) {
  req.callback(err, val)
}

},
"TvkwrcolBlXf3iAG9u7v5JPPMp7w8L/ioeY+jniUqYw=":
function (require, module, exports, __dirname, __filename) {


module.exports = function (buf) {
  var len = buf.length, i

  for(i = len - 1; i >= 0 && buf[i] === 255; i--) buf[i] = 0
  if(~i) buf[i] = buf[i] + 1

  return buf
}

},
"TwkPhV9hSeGwbG7PtMFw4BiSVDnbnhbpxSVJGo6dtDI=":
function (require, module, exports, __dirname, __filename) {

module.exports = function () {
  var i = 0, looping = false
  return {
    resume: function () {
      looping = true
      while(!this.sink.paused)
        if(this.ended) {this.sink.end(this.ended === true ? null : this.ended); break}
        else           this.sink.write(i++)
      looping = false
    },
    abort: function (err) {
      this.ended = err || true
      if(!looping && this.sink) this.resume()
    },
    pipe: require('../pipe')
  }
}

},
"U+88cowEiM0rItWht3CR5K1FAforq1rFjy84GAJiddM=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

/**
 * Obv utility to run the `cb` once, as soon as the condition given by
 * `filter` is true.
 */
function onceWhen(obv, filter, cb) {
  if (!obv) return cb()
  let answered = false
  let remove
  remove = obv((x) => {
    if (answered) return
    if (!filter(x)) return

    answered = true
    cb()

    if (!remove) return
    setTimeout(() => {
      if (!remove) return
      remove()
      remove = null
    })
  })
}

module.exports = { onceWhen }

},
"U0JVStsh8WUeErhxvp+Nha2FHAoHxcPZOoCucg/Ivrk=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var getDay = Date.prototype.getDay;
var tryDateObject = function tryDateObject(value) {
	try {
		getDay.call(value);
		return true;
	} catch (e) {
		return false;
	}
};

var toStr = Object.prototype.toString;
var dateClass = '[object Date]';
var hasToStringTag = typeof Symbol === 'function' && typeof Symbol.toStringTag === 'symbol';

module.exports = function isDateObject(value) {
	if (typeof value !== 'object' || value === null) { return false; }
	return hasToStringTag ? tryDateObject(value) : toStr.call(value) === dateClass;
};

},
"U6nYZCDNxzQIeF2lKWe0N2R34WaQbuHvvYyYeU2Qe5c=":
function (require, module, exports, __dirname, __filename) {
/**
 * FastPriorityQueue.js : a fast heap-based priority queue  in JavaScript.
 * (c) the authors
 * Licensed under the Apache License, Version 2.0.
 *
 * Speed-optimized heap-based priority queue for modern browsers and JavaScript engines.
 *
 * Usage :
         Installation (in shell, if you use node):
         $ npm install fastpriorityqueue

         Running test program (in JavaScript):

         // var FastPriorityQueue = require("fastpriorityqueue");// in node
         var x = new FastPriorityQueue();
         x.add(1);
         x.add(0);
         x.add(5);
         x.add(4);
         x.add(3);
         x.peek(); // should return 0, leaves x unchanged
         x.size; // should return 5, leaves x unchanged
         while(!x.isEmpty()) {
           console.log(x.poll());
         } // will print 0 1 3 4 5
         x.trim(); // (optional) optimizes memory usage
 */
'use strict';

var defaultcomparator = function(a, b) {
  return a < b;
};

// the provided comparator function should take a, b and return *true* when a < b
function FastPriorityQueue(comparator) {
  if (!(this instanceof FastPriorityQueue)) return new FastPriorityQueue(comparator);
  this.array = [];
  this.size = 0;
  this.compare = comparator || defaultcomparator;
}

// copy the priority queue into another, and return it. Queue items are shallow-copied.
// Runs in `O(n)` time.
FastPriorityQueue.prototype.clone = function() {
  var fpq = new FastPriorityQueue(this.compare);
  fpq.size = this.size;
  fpq.array = this.array.slice(0, this.size);
  return fpq;
};

// Add an element into the queue
// runs in O(log n) time
FastPriorityQueue.prototype.add = function(myval) {
  var i = this.size;
  this.array[this.size] = myval;
  this.size += 1;
  var p;
  var ap;
  while (i > 0) {
    p = (i - 1) >> 1;
    ap = this.array[p];
    if (!this.compare(myval, ap)) {
      break;
    }
    this.array[i] = ap;
    i = p;
  }
  this.array[i] = myval;
};

// replace the content of the heap by provided array and "heapify it"
FastPriorityQueue.prototype.heapify = function(arr) {
  this.array = arr;
  this.size = arr.length;
  var i;
  for (i = this.size >> 1; i >= 0; i--) {
    this._percolateDown(i);
  }
};

// for internal use
FastPriorityQueue.prototype._percolateUp = function(i, force) {
  var myval = this.array[i];
  var p;
  var ap;
  while (i > 0) {
    p = (i - 1) >> 1;
    ap = this.array[p];
    // force will skip the compare
    if (!force && !this.compare(myval, ap)) {
      break;
    }
    this.array[i] = ap;
    i = p;
  }
  this.array[i] = myval;
};

// for internal use
FastPriorityQueue.prototype._percolateDown = function(i) {
  var size = this.size;
  var hsize = this.size >>> 1;
  var ai = this.array[i];
  var l;
  var r;
  var bestc;
  while (i < hsize) {
    l = (i << 1) + 1;
    r = l + 1;
    bestc = this.array[l];
    if (r < size) {
      if (this.compare(this.array[r], bestc)) {
        l = r;
        bestc = this.array[r];
      }
    }
    if (!this.compare(bestc, ai)) {
      break;
    }
    this.array[i] = bestc;
    i = l;
  }
  this.array[i] = ai;
};

// internal
// _removeAt(index) will remove the item at the given index from the queue,
// retaining balance. returns the removed item, or undefined if nothing is removed.
FastPriorityQueue.prototype._removeAt = function(index) {
  if (index > this.size - 1 || index < 0) return undefined;

  // impl1:
  //this.array.splice(index, 1);
  //this.heapify(this.array);
  // impl2:
  this._percolateUp(index, true);
  return this.poll();
};

// remove(myval) will remove an item matching the provided value from the
// queue, checked for equality by using the queue's comparator.
// return true if removed, false otherwise.
FastPriorityQueue.prototype.remove = function(myval) {
  for (var i = 0; i < this.size; i++) {
    if (!this.compare(this.array[i], myval) && !this.compare(myval, this.array[i])) {
      // items match, comparator returns false both ways, remove item
      this._removeAt(i);
      return true;
    }
  }
  return false;
};

// removeOne(callback) will execute the callback function for each item of the queue
// and will remove the first item for which the callback will return true.
// return the removed item, or undefined if nothing is removed.
FastPriorityQueue.prototype.removeOne = function(callback) {
  if (typeof callback !== "function") {
    return undefined;
  }
  for (var i = 0; i < this.size; i++) {
    if (callback(this.array[i])) {
      return this._removeAt(i);
    }
  }
};

// remove(callback[, limit]) will execute the callback function for each item of
// the queue and will remove each item for which the callback returns true, up to
// a max limit of removed items if specified or no limit if unspecified.
// return an array containing the removed items.
// The callback function should be a pure function.
FastPriorityQueue.prototype.removeMany = function(callback, limit) {
  // Skip unnecessary processing for edge cases
  if (typeof callback !== "function" || this.size < 1) {
    return [];
  }
  limit = limit ? Math.min(limit, this.size) : this.size;

  // Prepare the results container to hold up to the results limit
  var resultSize = 0;
  var result = new Array(limit);

  // Prepare a temporary array to hold items we'll traverse through and need to keep
  var tmpSize = 0;
  var tmp = new Array(this.size);

  while (resultSize < limit && !this.isEmpty()) {
    // Dequeue items into either the results or our temporary array
    var item = this.poll();
    if (callback(item)) {
      result[resultSize++] = item;
    } else {
      tmp[tmpSize++] = item;
    }
  }
  // Update the result array with the exact number of results
  result.length = resultSize;

  // Re-add all the items we can keep
  var i = 0;
  while (i < tmpSize) {
    this.add(tmp[i++]);
  }

  return result;
};

// Look at the top of the queue (one of the smallest elements) without removing it
// executes in constant time
//
// Calling peek on an empty priority queue returns
// the "undefined" value.
// https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/undefined
//
FastPriorityQueue.prototype.peek = function() {
  if (this.size == 0) return undefined;
  return this.array[0];
};

// remove the element on top of the heap (one of the smallest elements)
// runs in logarithmic time
//
// If the priority queue is empty, the function returns the
// "undefined" value.
// https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/undefined
//
// For long-running and large priority queues, or priority queues
// storing large objects, you may  want to call the trim function
// at strategic times to recover allocated memory.
FastPriorityQueue.prototype.poll = function() {
  if (this.size == 0) return undefined;
  var ans = this.array[0];
  if (this.size > 1) {
    this.array[0] = this.array[--this.size];
    this._percolateDown(0);
  } else {
    this.size -= 1;
  }
  return ans;
};

// This function adds the provided value to the heap, while removing
// and returning one of the smallest elements (like poll). The size of the queue
// thus remains unchanged.
FastPriorityQueue.prototype.replaceTop = function(myval) {
  if (this.size == 0) return undefined;
  var ans = this.array[0];
  this.array[0] = myval;
  this._percolateDown(0);
  return ans;
};

// recover unused memory (for long-running priority queues)
FastPriorityQueue.prototype.trim = function() {
  this.array = this.array.slice(0, this.size);
};

// Check whether the heap is empty
FastPriorityQueue.prototype.isEmpty = function() {
  return this.size === 0;
};

// iterate over the items in order, pass a callback that receives (item, index) as args.
// TODO once we transpile, uncomment
// if (Symbol && Symbol.iterator) {
//   FastPriorityQueue.prototype[Symbol.iterator] = function*() {
//     if (this.isEmpty()) return;
//     var fpq = this.clone();
//     while (!fpq.isEmpty()) {
//       yield fpq.poll();
//     }
//   };
// }
FastPriorityQueue.prototype.forEach = function(callback) {
  if (this.isEmpty() || typeof callback != 'function') return;
  var i = 0;
  var fpq = this.clone();
  while (!fpq.isEmpty()) {
    callback(fpq.poll(), i++);
  }
};

// return the k 'smallest' elements of the queue as an array,
// runs in O(k log k) time, the elements are not removed
// from the priority queue.
FastPriorityQueue.prototype.kSmallest = function(k) {
  if (this.size == 0) return [];
  k = Math.min(this.size, k);
  var fpq = new FastPriorityQueue(this.compare);
  const newSize = Math.min((k > 0 ? Math.pow(2, k - 1) : 0) + 1, this.size);
  fpq.size = newSize;
  fpq.array = this.array.slice(0, newSize);

  var smallest = new Array(k);
  for (var i = 0; i < k; i++) {
    smallest[i] = fpq.poll();
  }
  return smallest;
}

module.exports = FastPriorityQueue;

},
"UD5nc/WKn9BayHvna4+oiEjbyYAPCRVPUZGmdou2h/g=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const { Duplex } = require('stream');

/**
 * Emits the `'close'` event on a stream.
 *
 * @param {stream.Duplex} The stream.
 * @private
 */
function emitClose(stream) {
  stream.emit('close');
}

/**
 * The listener of the `'end'` event.
 *
 * @private
 */
function duplexOnEnd() {
  if (!this.destroyed && this._writableState.finished) {
    this.destroy();
  }
}

/**
 * The listener of the `'error'` event.
 *
 * @param {Error} err The error
 * @private
 */
function duplexOnError(err) {
  this.removeListener('error', duplexOnError);
  this.destroy();
  if (this.listenerCount('error') === 0) {
    // Do not suppress the throwing behavior.
    this.emit('error', err);
  }
}

/**
 * Wraps a `WebSocket` in a duplex stream.
 *
 * @param {WebSocket} ws The `WebSocket` to wrap
 * @param {Object} [options] The options for the `Duplex` constructor
 * @return {stream.Duplex} The duplex stream
 * @public
 */
function createWebSocketStream(ws, options) {
  let resumeOnReceiverDrain = true;

  function receiverOnDrain() {
    if (resumeOnReceiverDrain) ws._socket.resume();
  }

  if (ws.readyState === ws.CONNECTING) {
    ws.once('open', function open() {
      ws._receiver.removeAllListeners('drain');
      ws._receiver.on('drain', receiverOnDrain);
    });
  } else {
    ws._receiver.removeAllListeners('drain');
    ws._receiver.on('drain', receiverOnDrain);
  }

  const duplex = new Duplex({
    ...options,
    autoDestroy: false,
    emitClose: false,
    objectMode: false,
    writableObjectMode: false
  });

  ws.on('message', function message(msg) {
    if (!duplex.push(msg)) {
      resumeOnReceiverDrain = false;
      ws._socket.pause();
    }
  });

  ws.once('error', function error(err) {
    if (duplex.destroyed) return;

    duplex.destroy(err);
  });

  ws.once('close', function close() {
    if (duplex.destroyed) return;

    duplex.push(null);
  });

  duplex._destroy = function (err, callback) {
    if (ws.readyState === ws.CLOSED) {
      callback(err);
      process.nextTick(emitClose, duplex);
      return;
    }

    let called = false;

    ws.once('error', function error(err) {
      called = true;
      callback(err);
    });

    ws.once('close', function close() {
      if (!called) callback(err);
      process.nextTick(emitClose, duplex);
    });
    ws.terminate();
  };

  duplex._final = function (callback) {
    if (ws.readyState === ws.CONNECTING) {
      ws.once('open', function open() {
        duplex._final(callback);
      });
      return;
    }

    // If the value of the `_socket` property is `null` it means that `ws` is a
    // client websocket and the handshake failed. In fact, when this happens, a
    // socket is never assigned to the websocket. Wait for the `'error'` event
    // that will be emitted by the websocket.
    if (ws._socket === null) return;

    if (ws._socket._writableState.finished) {
      callback();
      if (duplex._readableState.endEmitted) duplex.destroy();
    } else {
      ws._socket.once('finish', function finish() {
        // `duplex` is not destroyed here because the `'end'` event will be
        // emitted on `duplex` after this `'finish'` event. The EOF signaling
        // `null` chunk is, in fact, pushed when the websocket emits `'close'`.
        callback();
      });
      ws.close();
    }
  };

  duplex._read = function () {
    if (ws.readyState === ws.OPEN && !resumeOnReceiverDrain) {
      resumeOnReceiverDrain = true;
      if (!ws._receiver._writableState.needDrain) ws._socket.resume();
    }
  };

  duplex._write = function (chunk, encoding, callback) {
    if (ws.readyState === ws.CONNECTING) {
      ws.once('open', function open() {
        duplex._write(chunk, encoding, callback);
      });
      return;
    }

    ws.send(chunk, callback);
  };

  duplex.on('end', duplexOnEnd);
  duplex.on('error', duplexOnError);
  return duplex;
}

module.exports = createWebSocketStream;

},
"UEa2KusXKPiwqCM8Ucgw1onALpA2a3nd+wzx931plQI=":
function (require, module, exports, __dirname, __filename) {
function flat(err) {
  if (!err) return err
  if (err === true) return true
  return {message: err.message, name: err.name, stack: err.stack}
}

function closedread (msg) {
  console.error('packet-stream asked to read after closed', msg)
}

module.exports = {
  flat: flat,
  closedread: closedread
}
},
"UYSNoj9/0kgnXgUE5YtPc5OwTrs+QkgByb7sJCNsGzY=":
function (require, module, exports, __dirname, __filename) {

var Source = require('./source')
var Sink = require('./sink')
var Duplex = require('./duplex')

module.exports = function (cont) {
  return Source(cont)
}

module.exports.Source = Source
module.exports.Sink = Sink
module.exports.Duplex = Duplex

},
"UbK8nUV6P8NcfQQyrdo9nDAi1JDjxR2CvS5vvABAeTA=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var bind = require('function-bind');
var GetIntrinsic = require('get-intrinsic');

var $apply = GetIntrinsic('%Function.prototype.apply%');
var $call = GetIntrinsic('%Function.prototype.call%');
var $reflectApply = GetIntrinsic('%Reflect.apply%', true) || bind.call($call, $apply);

var $gOPD = GetIntrinsic('%Object.getOwnPropertyDescriptor%', true);
var $defineProperty = GetIntrinsic('%Object.defineProperty%', true);
var $max = GetIntrinsic('%Math.max%');

if ($defineProperty) {
	try {
		$defineProperty({}, 'a', { value: 1 });
	} catch (e) {
		// IE 8 has a broken defineProperty
		$defineProperty = null;
	}
}

module.exports = function callBind(originalFunction) {
	var func = $reflectApply(bind, $call, arguments);
	if ($gOPD && $defineProperty) {
		var desc = $gOPD(func, 'length');
		if (desc.configurable) {
			// original length, plus the receiver, minus any additional arguments (after the receiver)
			$defineProperty(
				func,
				'length',
				{ value: 1 + $max(0, originalFunction.length - (arguments.length - 1)) }
			);
		}
	}
	return func;
};

var applyBind = function applyBind() {
	return $reflectApply(bind, $apply, arguments);
};

if ($defineProperty) {
	$defineProperty(module.exports, 'apply', { value: applyBind });
} else {
	module.exports.apply = applyBind;
}

},
"UggFUV0PxonAamVANWZjUucBPAR4EjlFkPAyZz+tqoo=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const Cache = require('hashlru')
const RAF = require('polyraf')
const Obv = require('obz')
const debounce = require('lodash.debounce')
const debug = require('debug')("async-flumelog")
const fs = require('fs')
const mutexify = require('mutexify')

const Stream = require("./stream")

// defaults
function alwaysTrue() { return true }
function id(e) { return e }
const _codec = { encode: id, decode: id, buffer: true }

module.exports = function (filename, opts) {
  const cache = new Cache(1024) // this is potentially 65mb!
  const raf = RAF(filename)
  const blockSize = opts && opts.blockSize || 65536
  const codec = opts && opts.codec || _codec
  const writeTimeout = opts && opts.writeTimeout || 250
  const validateRecord = opts && opts.validateRecord || alwaysTrue
  let self

  // offset of last written record
  const since = Obv()

  const waiting = []
  const waitingDrain = new Map() // blockIndex -> []
  const blocksToBeWritten = new Map() // blockIndex -> { block, fileOffset }
  let writingBlockIndex = -1

  let latestBlock = null
  let latestBlockIndex = null
  let nextWriteBlockOffset = null

  raf.stat(function (err, stat) {
    if (err) debug("failed to stat " + filename, err)

    const len = stat ? stat.size : -1

    if (len <= 0) {
      debug("empty file")
      latestBlock = Buffer.alloc(blockSize)
      latestBlockIndex = 0
      nextWriteBlockOffset = 0
      cache.set(0, latestBlock)
      since.set(-1)
      while(waiting.length) waiting.shift()()
    } else {
      raf.read(len - blockSize, blockSize, (err, buffer) => {
        if (err) throw err

        getLastGoodRecord(buffer, len - blockSize, (err, recordOffset) => {
          since.set(len - blockSize + recordOffset)

          latestBlock = buffer
          const recordLength = buffer.readUInt16LE(recordOffset)
          nextWriteBlockOffset = recordOffset + 2 + recordLength
          latestBlockIndex = len / blockSize - 1

          debug("opened file, since: %d", since.value)

          while(waiting.length) waiting.shift()()
        })
      })
    }
  })

  function getRecordOffset(offset) {
    return offset % blockSize
  }

  function getBlockIndex(offset) {
    return (offset - getRecordOffset(offset)) / blockSize
  }

  function getNextBlockIndex(offset) {
    return (getBlockIndex(offset) + 1) * blockSize
  }

  const writeLock = mutexify()
  
  function writeWithFSync(offset, block, successValue, cb) {
    writeLock((unlock) => {
      raf.write(offset, block, (err) => {
        if (err) return unlock(cb, err)

        if (raf.fd) {
          fs.fsync(raf.fd, (err) => {
            if (err) unlock(cb, err)
            else unlock(cb, null, successValue)
          })
        } else unlock(cb, null, successValue)
      })
    })
  }

  function fixBlock(buffer, i, offset, lastOk, cb) {
    debug("found record that does not validate, fixing last block", i)

    const goodData = buffer.slice(0, i)
    const newBlock = Buffer.alloc(blockSize)
    goodData.copy(newBlock, 0)

    writeWithFSync(offset, newBlock, lastOk, cb)
  }

  function getLastGoodRecord(buffer, offset, cb) {
    let lastOk = 0
    for (let i = 0; i < buffer.length;) {
      const length = buffer.readUInt16LE(i)
      if (length === 0)
        break
      else {
        if (i + 2 + length > blockSize) {
          // corrupt length data
          return fixBlock(buffer, i, offset, lastOk, cb)
        } else {
          const data = buffer.slice(i + 2, i + 2 + length)
          if (validateRecord(data)) {
            lastOk = i
            i += 2 + length
          } else {
            // corrupt message data
            return fixBlock(buffer, i, offset, lastOk, cb)
          }
        }
      }
    }

    cb(null, lastOk)
  }

  function getBlock(offset, cb) {
    const blockStart = offset - getRecordOffset(offset)
    const blockIndex = blockStart / blockSize

    var cachedBlock = cache.get(blockIndex)
    if (cachedBlock) {
      debug("getting offset %d from cache", offset)
      cb(null, cachedBlock)
    } else {
      debug("getting offset %d from disc", offset)
      raf.read(blockStart, blockSize, (err, buffer) => {
        cache.set(blockIndex, buffer)
        cb(err, buffer)
      })
    }
  }

  function getData(buffer, recordOffset, cb) {
    const length = buffer.readUInt16LE(recordOffset)
    const data = buffer.slice(recordOffset + 2, recordOffset + 2 + length)

    if (data.every(x => x === 0)) {
      const err = new Error('item has been deleted')
      err.code = 'flumelog:deleted'
      return cb(err)
    }
    else
      cb(null, codec.decode(data))
  }

  function get(offset, cb) {
    if (typeof offset !== 'number' || isNaN(offset))
      return cb(`Offset ${offset} is not a number`)
    else if (offset < 0)
      return cb(`Offset is ${offset} must be >= 0`)

    getBlock(offset, (err, buffer) => {
      if (err) return cb(err)
      getData(buffer, getRecordOffset(offset), cb)
    })
  }

  // nextOffset can take 3 values:
  // -1: end of stream
  //  0: need a new block
  // >0: next record within block
  function getDataNextOffset(buffer, offset) {
    const recordOffset = getRecordOffset(offset)
    const blockIndex = getBlockIndex(offset)

    const length = buffer.readUInt16LE(recordOffset)
    const data = buffer.slice(recordOffset + 2, recordOffset + 2 + length)

    const nextLength = buffer.readUInt16LE(recordOffset + 2 + length)
    let nextOffset = recordOffset + 2 + length + blockIndex * blockSize
    if (nextLength === 0 && getNextBlockIndex(offset) > since.value)
      nextOffset = -1
    else if (nextLength === 0)
      nextOffset = 0

    if (data.every(x => x === 0))
      return [nextOffset, null]
    else
      return [nextOffset, codec.decode(data)]
  }

  function del(offset, cb) {
    getBlock(offset, (err, buffer) => {
      if (err) return cb(err)

      const recordOffset = getRecordOffset(offset)
      const recordLength = buffer.readUInt16LE(recordOffset)
      const nullBytes = Buffer.alloc(recordLength)
      nullBytes.copy(buffer, recordOffset+2)

      // we write directly here to make normal write simpler
      writeWithFSync(offset - recordOffset, buffer, null, cb)
    })
  }

  function appendRecord(buffer, data, offset) {
    buffer.writeUInt16LE(data.length, offset)
    data.copy(buffer, offset+2)
  }

  function recordSize(buffer) {
    return buffer.length + 2
  }

  function appendSingle(data) {
    let encodedData = codec.encode(data)
    if (typeof encodedData === 'string')
      encodedData = Buffer.from(encodedData)

    // we always leave 2 bytes at the end as the last record must be
    // followed by a 0 (length) to signal end of record
    if (recordSize(encodedData) + 2 > blockSize)
      throw new Error("data larger than block size")

    if (nextWriteBlockOffset + recordSize(encodedData) + 2 > blockSize)
    {
      // doesn't fit
      const buffer = Buffer.alloc(blockSize)
      latestBlock = buffer
      latestBlockIndex += 1
      nextWriteBlockOffset = 0
      debug("data doesn't fit current block, creating new")
    }

    appendRecord(latestBlock, encodedData, nextWriteBlockOffset)
    cache.set(latestBlockIndex, latestBlock) // update cache
    const fileOffset = nextWriteBlockOffset + latestBlockIndex * blockSize
    nextWriteBlockOffset += recordSize(encodedData)
    blocksToBeWritten.set(latestBlockIndex, { block: latestBlock, fileOffset })
    scheduleWrite()
    debug("data inserted at offset %d", fileOffset)
    return fileOffset
  }

  function append(data, cb)
  {
    if (Array.isArray(data)) {
      let fileOffset = 0
      for (let i = 0, length = data.length; i < length; ++i)
        fileOffset = appendSingle(data[i])

      cb(null, fileOffset)
    } else
      cb(null, appendSingle(data))
  }

  function appendTransaction(dataArray, cb) {
    if (!Array.isArray(dataArray))
      return cb(new Error("appendTransaction expects first argument to be an array"))

    let size = 0
    const encodedDataArray = dataArray.map(data => {
      let encodedData = codec.encode(data)
      if (typeof encodedData === 'string')
        encodedData = Buffer.from(encodedData)
      size += recordSize(encodedData)
      return encodedData
    })

    // we always leave 2 bytes at the end as the last record must be
    // followed by a 0 (length) to signal end of record
    size += 2

    if (size > blockSize)
      return cb(new Error("data larger than block size"))

    if (nextWriteBlockOffset + size > blockSize)
    {
      // doesn't fit
      const buffer = Buffer.alloc(blockSize)
      latestBlock = buffer
      latestBlockIndex += 1
      nextWriteBlockOffset = 0
      debug("data doesn't fit current block, creating new")
    }

    const fileOffsets = []
    encodedDataArray.forEach(encodedData => {
      appendRecord(latestBlock, encodedData, nextWriteBlockOffset)
      cache.set(latestBlockIndex, latestBlock) // update cache
      const fileOffset = nextWriteBlockOffset + latestBlockIndex * blockSize
      fileOffsets.push(fileOffset)
      nextWriteBlockOffset += recordSize(encodedData)
      blocksToBeWritten.set(latestBlockIndex, { block: latestBlock, fileOffset })
      debug("data inserted at offset %d", fileOffset)
    })

    scheduleWrite()

    return cb(null, fileOffsets)
  }

  const scheduleWrite = debounce(write, writeTimeout)

  function writeBlock(blockIndex) {
    if (!blocksToBeWritten.has(blockIndex)) return
    writingBlockIndex = blockIndex
    const { block, fileOffset } = blocksToBeWritten.get(blockIndex)
    blocksToBeWritten.delete(blockIndex)

    debug("writing block of size: %d, to offset: %d",
          block.length, blockIndex * blockSize)
    writeWithFSync(blockIndex * blockSize, block, null, (err) => {
      const drainsBefore = (waitingDrain.get(blockIndex) || []).slice(0)
      writingBlockIndex = -1
      if (err) {
        debug("failed to write block %d", blockIndex)
        throw err
      } else {
        since.set(fileOffset)

        // write values to live streams
        self.streams.forEach(stream => {
          if (!stream.ended && stream.live && !stream.writing) {
            if (stream.cursor === -1)
              stream.cursor = 0
            else // the cursor still at last position
              stream.skipNext = true

            stream.writing = true
            stream.resume()
          }
        })

        debug("draining the waiting queue for %d, items: %d", blockIndex, drainsBefore.length)
        for (let i = 0; i < drainsBefore.length; ++i)
          drainsBefore[i]()

        // the resumed streams might have added more to waiting
        let drainsAfter = waitingDrain.get(blockIndex) || []
        if (drainsBefore.length === drainsAfter.length)
          waitingDrain.delete(blockIndex)
        else if (drainsAfter.length === 0)
          waitingDrain.delete(blockIndex)
        else
          waitingDrain.set(blockIndex, waitingDrain.get(blockIndex).slice(drainsBefore.length))

        write() // next!
      }
    })
  }

  function write() {
    // just one at a time
    if (blocksToBeWritten.size > 0)
      writeBlock(blocksToBeWritten.keys().next().value)
  }

  function close(cb) {
    self.onDrain(function () {
      while (self.streams.length)
        self.streams.shift().abort(new Error('async-flumelog: closed'))
      raf.close(cb)
    })
  }

  function onLoad (fn) {
    return function (arg, cb) {
      if (latestBlock === null)
        waiting.push(function () { fn(arg, cb) })
      else fn(arg, cb)
    }
  }

  function onReady(fn) {
    if (latestBlock !== null) fn()
    else waiting.push(fn)
  }

  function last(iterable) {
    let res = null
    for (let x of iterable) res = x
    return res
  }

  return self = {
    get: onLoad(get),
    del: onLoad(del),
    append: onLoad(append),
    appendTransaction: onLoad(appendTransaction),
    close: onLoad(close),
    since,
    onReady,

    onDrain: onLoad(function (fn) {
      if (blocksToBeWritten.size === 0 && writingBlockIndex === -1) fn()
      else {
        const latestBlockIndex = blocksToBeWritten.size > 0 ? last(blocksToBeWritten.keys()) : writingBlockIndex
        const drains = waitingDrain.get(latestBlockIndex) || []
        drains.push(fn)
        waitingDrain.set(latestBlockIndex, drains)
      }
    }),

    filename,

    // streaming
    getNextBlockIndex,
    getDataNextOffset,
    getBlock,
    stream: function (opts) {
      const stream = new Stream(self, opts)
      self.streams.push(stream)
      return stream
    },
    streams: [],
  }
}

},
"UlklLaXNgUZVmkgH4euWOojpke4AOCm639HrKUHDTjM=":
function (require, module, exports, __dirname, __filename) {
var Pushable = require('pull-pushable')

function FromEvent (name, emitter, onEnd) {
    if (!emitter) return function (ee, _onEnd) {
        return FromEvent(name, ee, _onEnd)
    }

    var stream = Pushable(function onStreamEnd (err) {
        emitter.removeListener(name, stream.push)
        if (typeof onEnd === 'function') onEnd(err)
    })

    emitter.on(name, stream.push)
    return stream
}

module.exports = FromEvent


},
"UmPkJSHiu8xxCj90vud+nsZcf3NuTOu0M/ZLtxMfiE8=":
function (require, module, exports, __dirname, __filename) {
'use strict'

function id (e) { return e }
var prop = require('../util/prop')
var filter = require('./filter')

//drop items you have already seen.
module.exports = function unique (field, invert) {
  field = prop(field) || id
  var seen = {}
  return filter(function (data) {
    var key = field(data)
    if(seen[key]) return !!invert //false, by default
    else seen[key] = true
    return !invert //true by default
  })
}


},
"V40Est4Tyde8PXipRJ0Lhj33IOy+qf0d6LstY4y3TAU=":
function (require, module, exports, __dirname, __filename) {
var TWOPOW32 = 0x100000000

exports.encodingLength = function () {
  return 6
}

exports.encode = function (num, buf, offset) {
  if (!buf) buf = Buffer.alloc(6)
  if (!offset) offset = 0

  var top = Math.floor(num / TWOPOW32)
  var rem = num - top * TWOPOW32

  buf.writeUInt16BE(top, offset)
  buf.writeUInt32BE(rem, offset + 2)
  return buf
}

exports.decode = function (buf, offset) {
  if (!offset) offset = 0

  var top = buf.readUInt16BE(offset)
  var rem = buf.readUInt32BE(offset + 2)

  return top * TWOPOW32 + rem
}

exports.encode.bytes = 6
exports.decode.bytes = 6

},
"V8LPVP6Dlm454X8QoU3/l04e5WR24JU3cf2+HlLflzE=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const debug = require('debug')('ssb:room-client');
const DuplexPair = require('pull-pair/duplex');
const error_duplex_1 = require("./error-duplex");
const ms_tunnel_1 = require("./ms-tunnel");
function hasConnInstalled(ssb) {
    var _a;
    return !!((_a = ssb.conn) === null || _a === void 0 ? void 0 : _a.connect);
}
module.exports = {
    name: 'tunnel',
    version: '1.0.0',
    manifest: {
        connect: 'duplex',
        ping: 'sync',
        announce: 'sync',
        leave: 'sync',
        endpoints: 'source',
        isRoom: 'async',
    },
    permissions: {
        anonymous: { allow: ['connect', 'ping'] },
    },
    init(ssb) {
        if (!hasConnInstalled(ssb)) {
            throw new Error('ssb-room-client plugin requires the ssb-conn plugin');
        }
        const rooms = new Map();
        ssb.multiserver.transport({
            name: 'tunnel',
            create: ms_tunnel_1.default(rooms, ssb),
        });
        return {
            connect(opts) {
                if (!opts)
                    return error_duplex_1.default('opts *must* be provided');
                debug('received incoming tunnel.connect(%o)', opts);
                const { target, portal, origin } = opts;
                if (target === ssb.id && rooms.has(portal)) {
                    debug('connect() will resolve because handler exists');
                    const handler = rooms.get(portal).handler;
                    const [ins, outs] = DuplexPair();
                    handler(ins, origin !== null && origin !== void 0 ? origin : this.id);
                    return outs;
                }
                else {
                    return error_duplex_1.default(`could not connect to ${target}`);
                }
            },
            ping() {
                return Date.now();
            },
            getRoomsMap() {
                return rooms;
            }
        };
    },
};

},
"V9biW5ejxgsBFYsweKD8cefoeL/9TUDncU9OpUflsbs=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const gossip_1 = require("./gossip");
const conn_1 = require("./conn");
const conn_scheduler_1 = require("./conn-scheduler");
module.exports = [conn_1.CONN, gossip_1.Gossip, conn_scheduler_1.ConnScheduler];

},
"VBd1fS+Iw8csaOw42aFWcU7x9+pn01qAvyerePYw8vw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const utils_1 = require("./utils");
const debug = require('debug')('ssb:room-client');
const pull = require('pull-stream');
const getSeverity = require('ssb-network-errors');
class RoomObserver {
    constructor(ssb, serverKey, address, rpc, roomMetadata, onConnect) {
        this.attendantsUpdated = (event) => {
            const room = this.roomKey;
            const roomName = typeof this.roomMetadata === 'object' ? this.roomMetadata.name : void 0;
            if (event.type === 'state') {
                debug('initial attendants in %s: %s', room, JSON.stringify(event.ids));
            }
            else if (event.type === 'joined') {
                debug('attendant joined %s: %s', room, event.id);
            }
            else if (event.type === 'left') {
                debug('attendant left %s: %s', room, event.id);
            }
            if (event.type === 'state') {
                this.attendants.clear();
                for (const key of event.ids) {
                    this.attendants.add(key);
                }
            }
            else if (event.type === 'joined') {
                this.attendants.add(event.id);
            }
            else if (event.type === 'left') {
                this.attendants.delete(event.id);
            }
            const onlineCount = this.attendants.size;
            this.ssb.conn.hub().update(this.address, { onlineCount });
            if (event.type === 'state') {
                for (const id of event.ids) {
                    this.notifyNewAttendant(id, room, roomName);
                }
            }
            else if (event.type === 'joined') {
                this.notifyNewAttendant(event.id, room, roomName);
            }
            else if (event.type === 'left') {
                const address = this.getAddress(event.id);
                debug('will disconnect and unstage %s', address);
                this.ssb.conn.unstage(address);
                this.ssb.conn.disconnect(address);
            }
        };
        this.attendantsEnded = (err) => {
            if (err && err !== true) {
                if (utils_1.muxrpcMissing(err)) {
                    this.attendantsDrain = void 0;
                    this.startEndpoints();
                    return;
                }
                this.handleStreamError(err);
            }
        };
        this.endpointsUpdated = (endpoints) => {
            const room = this.roomKey;
            const roomName = typeof this.roomMetadata === 'object' ? this.roomMetadata.name : void 0;
            debug('got endpoints from %s: %s', room, JSON.stringify(endpoints));
            const onlineCount = endpoints.length;
            this.ssb.conn.hub().update(this.address, { onlineCount });
            for (const entry of this.ssb.conn.staging().entries()) {
                const [addr, data] = entry;
                if (data.room === room && data.key && !endpoints.includes(data.key)) {
                    debug('will disconnect and unstage %s', addr);
                    this.ssb.conn.unstage(addr);
                    this.ssb.conn.disconnect(addr);
                }
            }
            for (const key of endpoints) {
                this.notifyNewAttendant(key, room, roomName);
            }
        };
        this.endpointsEnded = (err) => {
            if (err && err !== true) {
                this.handleStreamError(err);
            }
        };
        this.ssb = ssb;
        this.roomKey = serverKey;
        this.address = address;
        this.rpc = rpc;
        this.roomMetadata = roomMetadata;
        this.attendants = new Set();
        this.handler = (stream, id) => {
            stream.address = `tunnel:${this.roomKey}:${id}`;
            debug('handler will call onConnect for the stream.address: %s', stream.address);
            onConnect(stream);
        };
        if (typeof this.roomMetadata === 'object' &&
            this.roomMetadata &&
            Object.keys(this.roomMetadata).length >= 1) {
            const metadata = { type: 'room' };
            const { name, membership, features, _isRoom1 } = this.roomMetadata;
            if (name)
                metadata.name = name;
            if (membership)
                metadata.membership = true;
            if (_isRoom1)
                metadata.openInvites = true;
            if (Array.isArray(features)) {
                if (features.includes('room1'))
                    metadata.openInvites = true;
                if (features.includes('room2'))
                    metadata.supportsRoom2 = true;
                if (features.includes('alias'))
                    metadata.supportsAliases = true;
                if (features.includes('httpAuth'))
                    metadata.supportsHttpAuth = true;
                if (features.includes('httpInvite'))
                    metadata.supportsHttpInvite = true;
            }
            this.ssb.conn.db().update(this.address, metadata);
            this.ssb.conn.hub().update(this.address, metadata);
        }
        debug('announcing to portal: %s', this.roomKey);
        this.startAttendants();
    }
    startAttendants() {
        pull(this.rpc.room.attendants(), (this.attendantsDrain = pull.drain(this.attendantsUpdated, this.attendantsEnded)));
    }
    startEndpoints() {
        pull(this.rpc.tunnel.endpoints(), (this.endpointsDrain = pull.drain(this.endpointsUpdated, this.endpointsEnded)));
    }
    notifyNewAttendant(key, room, roomName) {
        if (key === room)
            return;
        if (key === this.ssb.id)
            return;
        const address = this.getAddress(key);
        this.ssb.roomClient._notifyDiscoveredAttendant({
            address,
            key,
            room,
            roomName,
        });
    }
    handleStreamError(err) {
        const severity = getSeverity(err);
        if (severity === 1) {
            this.close();
        }
        else if (severity >= 2) {
            console.error(`error getting updates from room ${this.roomKey} because ${err.message}`);
        }
    }
    getAddress(key) {
        const shs = key.substr(1, key.length - 9);
        return `tunnel:${this.roomKey}:${key}~shs:${shs}`;
    }
    cancel() {
        var _a, _b;
        (_a = this.attendantsDrain) === null || _a === void 0 ? void 0 : _a.abort();
        (_b = this.endpointsDrain) === null || _b === void 0 ? void 0 : _b.abort();
    }
    close() {
        var _a, _b;
        (_a = this.attendantsDrain) === null || _a === void 0 ? void 0 : _a.abort();
        (_b = this.endpointsDrain) === null || _b === void 0 ? void 0 : _b.abort();
        for (const key of this.attendants) {
            const address = this.getAddress(key);
            this.ssb.conn.unstage(address);
        }
        for (const [addr, data] of this.ssb.conn.staging().entries()) {
            if (data.room === this.roomKey) {
                this.ssb.conn.unstage(addr);
            }
        }
        this.rpc.close(true, (err) => {
            if (err)
                debug('error when closing connection with room: %o', err);
        });
        this.ssb.conn.disconnect(this.address, () => { });
    }
}
exports.default = RoomObserver;

},
"VEo9/bJDBkaCu4VkOSmU7ih/96nTK+a0IOAeIzWpJ9Q=":
function (require, module, exports, __dirname, __filename) {

function isEmpty (o) {
  for(var k in o) return false
  return true
}
module.exports = function (read, write) {

  var store = {}, dirty = {}, reading = {}, writing = false, waiting = []

  //this writes only once at a time.
  //at least, we want it to write at most once per file.
  //or maybe if it's written recently then wait.
  //anyway, this is good enough for now.

  function apply_write (key, value, err) {
    var _reading = reading[key]
    reading[key] = null
    while(_reading && _reading.length)
      _reading.shift()(err, value)
    _write()
  }

  function _write () {
    if(writing) return
    var d = 0
    //note, only one key is written at a time.
    for(var k in dirty) {
      if(dirty[k]) {
        dirty[k] = false
        writing = true
        return write(k, store[k], function (err) {
          writing = false
          _write()
        })
      }
    }
    //if we wrote something, we returned.
    //so clear todo list and fire listeners.
    dirty = {}
    while(waiting.length)
      waiting.shift()()
  }

  function has (key) {
    return store[key] !== undefined
  }
  var self
  return self = {
    has: has,
    ensure: function (key, cb) {
      if(has(key)) cb(null, store[key])
      else if(reading[key])
        reading[key].push(cb)
      else {
        var cbs = reading[key] = [cb]
        read(key, function (err, value) {
          //unusual, but incase someone overwrites the value
          //while we are reading. see apply_write
          if(cbs !== reading[key]) return

          apply_write(key, store[key] = value, err)
        })
      }
    },
    get: function (key, cb) {
      if(cb) self.ensure(key, cb)
      else return store[key]
    },
    //if set is called during a read,
    //cb the readers immediately, and cancel the current read.
    set: function (key, value) {
      store[key] = value
      //not urgent, but save this if we are not doing anything.
      dirty[key] = true
      apply_write(key, value)
    },
    onDrain: function (cb) {
      if(isEmpty(dirty)) cb()
      else waiting.push(cb)
    }
  }
}






},
"VKsqB5mOnvwfeWZ+5SZQR58i5tbyvTu5ximxQm9bGQY=":
function (require, module, exports, __dirname, __filename) {
exports.parse = exports.decode = decode

exports.stringify = exports.encode = encode

exports.safe = safe
exports.unsafe = unsafe

var eol = typeof process !== 'undefined' &&
  process.platform === 'win32' ? '\r\n' : '\n'

function encode (obj, opt) {
  var children = []
  var out = ''

  if (typeof opt === 'string') {
    opt = {
      section: opt,
      whitespace: false,
    }
  } else {
    opt = opt || {}
    opt.whitespace = opt.whitespace === true
  }

  var separator = opt.whitespace ? ' = ' : '='

  Object.keys(obj).forEach(function (k, _, __) {
    var val = obj[k]
    if (val && Array.isArray(val)) {
      val.forEach(function (item) {
        out += safe(k + '[]') + separator + safe(item) + '\n'
      })
    } else if (val && typeof val === 'object')
      children.push(k)
    else
      out += safe(k) + separator + safe(val) + eol
  })

  if (opt.section && out.length)
    out = '[' + safe(opt.section) + ']' + eol + out

  children.forEach(function (k, _, __) {
    var nk = dotSplit(k).join('\\.')
    var section = (opt.section ? opt.section + '.' : '') + nk
    var child = encode(obj[k], {
      section: section,
      whitespace: opt.whitespace,
    })
    if (out.length && child.length)
      out += eol

    out += child
  })

  return out
}

function dotSplit (str) {
  return str.replace(/\1/g, '\u0002LITERAL\\1LITERAL\u0002')
    .replace(/\\\./g, '\u0001')
    .split(/\./).map(function (part) {
      return part.replace(/\1/g, '\\.')
        .replace(/\2LITERAL\\1LITERAL\2/g, '\u0001')
    })
}

function decode (str) {
  var out = {}
  var p = out
  var section = null
  //          section     |key      = value
  var re = /^\[([^\]]*)\]$|^([^=]+)(=(.*))?$/i
  var lines = str.split(/[\r\n]+/g)

  lines.forEach(function (line, _, __) {
    if (!line || line.match(/^\s*[;#]/))
      return
    var match = line.match(re)
    if (!match)
      return
    if (match[1] !== undefined) {
      section = unsafe(match[1])
      if (section === '__proto__') {
        // not allowed
        // keep parsing the section, but don't attach it.
        p = {}
        return
      }
      p = out[section] = out[section] || {}
      return
    }
    var key = unsafe(match[2])
    if (key === '__proto__')
      return
    var value = match[3] ? unsafe(match[4]) : true
    switch (value) {
      case 'true':
      case 'false':
      case 'null': value = JSON.parse(value)
    }

    // Convert keys with '[]' suffix to an array
    if (key.length > 2 && key.slice(-2) === '[]') {
      key = key.substring(0, key.length - 2)
      if (key === '__proto__')
        return
      if (!p[key])
        p[key] = []
      else if (!Array.isArray(p[key]))
        p[key] = [p[key]]
    }

    // safeguard against resetting a previously defined
    // array by accidentally forgetting the brackets
    if (Array.isArray(p[key]))
      p[key].push(value)
    else
      p[key] = value
  })

  // {a:{y:1},"a.b":{x:2}} --> {a:{y:1,b:{x:2}}}
  // use a filter to return the keys that have to be deleted.
  Object.keys(out).filter(function (k, _, __) {
    if (!out[k] ||
      typeof out[k] !== 'object' ||
      Array.isArray(out[k]))
      return false

    // see if the parent section is also an object.
    // if so, add it to that, and mark this one for deletion
    var parts = dotSplit(k)
    var p = out
    var l = parts.pop()
    var nl = l.replace(/\\\./g, '.')
    parts.forEach(function (part, _, __) {
      if (part === '__proto__')
        return
      if (!p[part] || typeof p[part] !== 'object')
        p[part] = {}
      p = p[part]
    })
    if (p === out && nl === l)
      return false

    p[nl] = out[k]
    return true
  }).forEach(function (del, _, __) {
    delete out[del]
  })

  return out
}

function isQuoted (val) {
  return (val.charAt(0) === '"' && val.slice(-1) === '"') ||
    (val.charAt(0) === "'" && val.slice(-1) === "'")
}

function safe (val) {
  return (typeof val !== 'string' ||
    val.match(/[=\r\n]/) ||
    val.match(/^\[/) ||
    (val.length > 1 &&
     isQuoted(val)) ||
    val !== val.trim())
    ? JSON.stringify(val)
    : val.replace(/;/g, '\\;').replace(/#/g, '\\#')
}

function unsafe (val, doUnesc) {
  val = (val || '').trim()
  if (isQuoted(val)) {
    // remove the single quotes before calling JSON.parse
    if (val.charAt(0) === "'")
      val = val.substr(1, val.length - 2)

    try {
      val = JSON.parse(val)
    } catch (_) {}
  } else {
    // walk the val to find the first not-escaped ; character
    var esc = false
    var unesc = ''
    for (var i = 0, l = val.length; i < l; i++) {
      var c = val.charAt(i)
      if (esc) {
        if ('\\;#'.indexOf(c) !== -1)
          unesc += c
        else
          unesc += '\\' + c

        esc = false
      } else if (';#'.indexOf(c) !== -1)
        break
      else if (c === '\\')
        esc = true
      else
        unesc += c
    }
    if (esc)
      unesc += '\\'

    return unesc.trim()
  }
  return val
}

},
"VU+1WBMeN1j/WKmx0ycNlhOeh0AXVNh2+kF4NmPAPAI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.BufferTokenizer = void 0;
const peek_readable_1 = require("peek-readable");
const AbstractTokenizer_1 = require("./AbstractTokenizer");
class BufferTokenizer extends AbstractTokenizer_1.AbstractTokenizer {
    /**
     * Construct BufferTokenizer
     * @param uint8Array - Uint8Array to tokenize
     * @param fileInfo - Pass additional file information to the tokenizer
     */
    constructor(uint8Array, fileInfo) {
        super(fileInfo);
        this.uint8Array = uint8Array;
        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;
    }
    /**
     * Read buffer from tokenizer
     * @param uint8Array - Uint8Array to tokenize
     * @param options - Read behaviour options
     * @returns {Promise<number>}
     */
    async readBuffer(uint8Array, options) {
        if (options && options.position) {
            if (options.position < this.position) {
                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');
            }
            this.position = options.position;
        }
        const bytesRead = await this.peekBuffer(uint8Array, options);
        this.position += bytesRead;
        return bytesRead;
    }
    /**
     * Peek (read ahead) buffer from tokenizer
     * @param uint8Array
     * @param options - Read behaviour options
     * @returns {Promise<number>}
     */
    async peekBuffer(uint8Array, options) {
        const normOptions = this.normalizeOptions(uint8Array, options);
        const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);
        if ((!normOptions.mayBeLess) && bytes2read < normOptions.length) {
            throw new peek_readable_1.EndOfStreamError();
        }
        else {
            uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);
            return bytes2read;
        }
    }
    async close() {
        // empty
    }
}
exports.BufferTokenizer = BufferTokenizer;

},
"VVUHV3nLLb95odzcH12MZg9hHpE4e0UwHt9yLqgzvok=":
function (require, module, exports, __dirname, __filename) {
module.exports = {
    encode: require('./encode.js')
  , decode: require('./decode.js')
  , encodingLength: require('./length.js')
}

},
"VVxKYk0CPjdV6fWNP3XafEyJmhI7gOTkfgAlYGWx7bY=":
function (require, module, exports, __dirname, __filename) {
var util = require('multiblob/util')
var isBlob = require('ssb-ref').isBlob
var MultiBlob = require('multiblob')

function desigil (hash) {
  return isBlob(hash) ? hash.substring(1) : hash
}

function resigil (hash) {
  return isBlob(hash) ? hash : '&'+hash
}

module.exports = function (dir) {
  return MultiBlob({
    dir: dir,
    alg: 'sha256',
    encode: function (buf, alg) {
      return resigil(util.encode(buf, alg))
    },
    decode: function (str) {
      return util.decode(desigil(str))
    },
    isHash: isBlob
  })
}



},
"VZhpcvXzyURvh2xXbhzTD9TwTNJlJ++7Wtg0Y3x0Dkw=":
function (require, module, exports, __dirname, __filename) {
/**
 * Helpers.
 */

var s = 1000;
var m = s * 60;
var h = m * 60;
var d = h * 24;
var w = d * 7;
var y = d * 365.25;

/**
 * Parse or format the given `val`.
 *
 * Options:
 *
 *  - `long` verbose formatting [false]
 *
 * @param {String|Number} val
 * @param {Object} [options]
 * @throws {Error} throw an error if val is not a non-empty string or a number
 * @return {String|Number}
 * @api public
 */

module.exports = function(val, options) {
  options = options || {};
  var type = typeof val;
  if (type === 'string' && val.length > 0) {
    return parse(val);
  } else if (type === 'number' && isFinite(val)) {
    return options.long ? fmtLong(val) : fmtShort(val);
  }
  throw new Error(
    'val is not a non-empty string or a valid number. val=' +
      JSON.stringify(val)
  );
};

/**
 * Parse the given `str` and return milliseconds.
 *
 * @param {String} str
 * @return {Number}
 * @api private
 */

function parse(str) {
  str = String(str);
  if (str.length > 100) {
    return;
  }
  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
    str
  );
  if (!match) {
    return;
  }
  var n = parseFloat(match[1]);
  var type = (match[2] || 'ms').toLowerCase();
  switch (type) {
    case 'years':
    case 'year':
    case 'yrs':
    case 'yr':
    case 'y':
      return n * y;
    case 'weeks':
    case 'week':
    case 'w':
      return n * w;
    case 'days':
    case 'day':
    case 'd':
      return n * d;
    case 'hours':
    case 'hour':
    case 'hrs':
    case 'hr':
    case 'h':
      return n * h;
    case 'minutes':
    case 'minute':
    case 'mins':
    case 'min':
    case 'm':
      return n * m;
    case 'seconds':
    case 'second':
    case 'secs':
    case 'sec':
    case 's':
      return n * s;
    case 'milliseconds':
    case 'millisecond':
    case 'msecs':
    case 'msec':
    case 'ms':
      return n;
    default:
      return undefined;
  }
}

/**
 * Short format for `ms`.
 *
 * @param {Number} ms
 * @return {String}
 * @api private
 */

function fmtShort(ms) {
  var msAbs = Math.abs(ms);
  if (msAbs >= d) {
    return Math.round(ms / d) + 'd';
  }
  if (msAbs >= h) {
    return Math.round(ms / h) + 'h';
  }
  if (msAbs >= m) {
    return Math.round(ms / m) + 'm';
  }
  if (msAbs >= s) {
    return Math.round(ms / s) + 's';
  }
  return ms + 'ms';
}

/**
 * Long format for `ms`.
 *
 * @param {Number} ms
 * @return {String}
 * @api private
 */

function fmtLong(ms) {
  var msAbs = Math.abs(ms);
  if (msAbs >= d) {
    return plural(ms, msAbs, d, 'day');
  }
  if (msAbs >= h) {
    return plural(ms, msAbs, h, 'hour');
  }
  if (msAbs >= m) {
    return plural(ms, msAbs, m, 'minute');
  }
  if (msAbs >= s) {
    return plural(ms, msAbs, s, 'second');
  }
  return ms + ' ms';
}

/**
 * Pluralization helper.
 */

function plural(ms, msAbs, n, name) {
  var isPlural = msAbs >= n * 1.5;
  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
}

},
"Vb6mMU0vc4x3R8riil6ujf6QXdnLhd83zDfmivCKls8=":
function (require, module, exports, __dirname, __filename) {
module.exports = function () {
    for (var i = 0; i < arguments.length; i++) {
        if (arguments[i] !== undefined) return arguments[i];
    }
};

},
"VdIW5uG3T5zrCyaC7sTb6OKb9zvW+ObUAQo0Tx6GfH4=":
function (require, module, exports, __dirname, __filename) {
var EventEmitter = require('events').EventEmitter
var inherits = require('util').inherits
var extend = require('xtend')
var DeferredLevelDOWN = require('deferred-leveldown')
var IteratorStream = require('level-iterator-stream')
var Batch = require('./batch')
var errors = require('level-errors')
var assert = require('assert')
var promisify = require('./promisify')
var getCallback = require('./common').getCallback
var getOptions = require('./common').getOptions

var WriteError = errors.WriteError
var ReadError = errors.ReadError
var NotFoundError = errors.NotFoundError
var OpenError = errors.OpenError
var InitializationError = errors.InitializationError

// Possible AbstractLevelDOWN#status values:
//  - 'new'     - newly created, not opened or closed
//  - 'opening' - waiting for the database to be opened, post open()
//  - 'open'    - successfully opened the database, available for use
//  - 'closing' - waiting for the database to be closed, post close()
//  - 'closed'  - database has been successfully closed, should not be
//                 used except for another open() operation

function LevelUP (db, options, callback) {
  if (!(this instanceof LevelUP)) {
    return new LevelUP(db, options, callback)
  }

  var error

  EventEmitter.call(this)
  this.setMaxListeners(Infinity)

  if (typeof options === 'function') {
    callback = options
    options = {}
  }

  options = options || {}

  if (!db || typeof db !== 'object') {
    error = new InitializationError('First argument must be an abstract-leveldown compliant store')
    if (typeof callback === 'function') {
      return process.nextTick(callback, error)
    }
    throw error
  }

  assert.strictEqual(typeof db.status, 'string', '.status required, old abstract-leveldown')

  this.options = getOptions(options)
  this._db = db
  this.db = new DeferredLevelDOWN(db)
  this.open(callback)
}

LevelUP.prototype.emit = EventEmitter.prototype.emit
LevelUP.prototype.once = EventEmitter.prototype.once
inherits(LevelUP, EventEmitter)

LevelUP.prototype.open = function (opts, callback) {
  var self = this
  var promise

  if (typeof opts === 'function') {
    callback = opts
    opts = null
  }

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (!opts) {
    opts = this.options
  }

  if (this.isOpen()) {
    process.nextTick(callback, null, self)
    return promise
  }

  if (this._isOpening()) {
    this.once('open', function () { callback(null, self) })
    return promise
  }

  this.emit('opening')

  this.db.open(opts, function (err) {
    if (err) {
      return callback(new OpenError(err))
    }
    self.db = self._db
    callback(null, self)
    self.emit('open')
    self.emit('ready')
  })

  return promise
}

LevelUP.prototype.close = function (callback) {
  var self = this
  var promise

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (this.isOpen()) {
    this.db.close(function () {
      self.emit('closed')
      callback.apply(null, arguments)
    })
    this.emit('closing')
    this.db = new DeferredLevelDOWN(this._db)
  } else if (this.isClosed()) {
    process.nextTick(callback)
  } else if (this.db.status === 'closing') {
    this.once('closed', callback)
  } else if (this._isOpening()) {
    this.once('open', function () {
      self.close(callback)
    })
  }

  return promise
}

LevelUP.prototype.isOpen = function () {
  return this.db.status === 'open'
}

LevelUP.prototype._isOpening = function () {
  return this.db.status === 'opening'
}

LevelUP.prototype.isClosed = function () {
  return (/^clos|new/).test(this.db.status)
}

LevelUP.prototype.get = function (key, options, callback) {
  if (key === null || key === undefined) {
    throw new ReadError('get() requires a key argument')
  }

  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.get(key, options, function (err, value) {
    if (err) {
      if ((/notfound/i).test(err) || err.notFound) {
        err = new NotFoundError('Key not found in database [' + key + ']', err)
      } else {
        err = new ReadError(err)
      }
      return callback(err)
    }
    callback(null, value)
  })

  return promise
}

LevelUP.prototype.put = function (key, value, options, callback) {
  if (key === null || key === undefined) {
    throw new WriteError('put() requires a key argument')
  }

  var self = this
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.put(key, value, options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('put', key, value)
    callback()
  })

  return promise
}

LevelUP.prototype.del = function (key, options, callback) {
  if (key === null || key === undefined) {
    throw new WriteError('del() requires a key argument')
  }

  var self = this
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.del(key, options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('del', key)
    callback()
  })

  return promise
}

LevelUP.prototype.batch = function (arr, options, callback) {
  if (!arguments.length) {
    return new Batch(this)
  }

  if (!Array.isArray(arr)) {
    throw new WriteError('batch() requires an array argument')
  }

  var self = this
  var promise

  callback = getCallback(options, callback)

  if (!callback) {
    callback = promisify()
    promise = callback.promise
  }

  if (maybeError(this, callback)) { return promise }

  options = getOptions(options)

  this.db.batch(arr, options, function (err) {
    if (err) {
      return callback(new WriteError(err))
    }
    self.emit('batch', arr)
    callback()
  })

  return promise
}

LevelUP.prototype.iterator = function (options) {
  return this.db.iterator(options)
}

LevelUP.prototype.readStream =
LevelUP.prototype.createReadStream = function (options) {
  options = extend({ keys: true, values: true }, options)
  if (typeof options.limit !== 'number') { options.limit = -1 }
  return new IteratorStream(this.db.iterator(options), options)
}

LevelUP.prototype.keyStream =
LevelUP.prototype.createKeyStream = function (options) {
  return this.createReadStream(extend(options, { keys: true, values: false }))
}

LevelUP.prototype.valueStream =
LevelUP.prototype.createValueStream = function (options) {
  return this.createReadStream(extend(options, { keys: false, values: true }))
}

LevelUP.prototype.toString = function () {
  return 'LevelUP'
}

function maybeError (db, callback) {
  if (!db._isOpening() && !db.isOpen()) {
    process.nextTick(callback, new ReadError('Database is not open'))
    return true
  }
}

LevelUP.errors = errors
module.exports = LevelUP.default = LevelUP

},
"VeEkjVfnqryqbxUNCx17+zBHU1JEsoDbTRoFhNgl6sM=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (args, opts) {
    if (!opts) opts = {};
    
    var flags = { bools : {}, strings : {}, unknownFn: null };

    if (typeof opts['unknown'] === 'function') {
        flags.unknownFn = opts['unknown'];
    }

    if (typeof opts['boolean'] === 'boolean' && opts['boolean']) {
      flags.allBools = true;
    } else {
      [].concat(opts['boolean']).filter(Boolean).forEach(function (key) {
          flags.bools[key] = true;
      });
    }
    
    var aliases = {};
    Object.keys(opts.alias || {}).forEach(function (key) {
        aliases[key] = [].concat(opts.alias[key]);
        aliases[key].forEach(function (x) {
            aliases[x] = [key].concat(aliases[key].filter(function (y) {
                return x !== y;
            }));
        });
    });

    [].concat(opts.string).filter(Boolean).forEach(function (key) {
        flags.strings[key] = true;
        if (aliases[key]) {
            flags.strings[aliases[key]] = true;
        }
     });

    var defaults = opts['default'] || {};
    
    var argv = { _ : [] };
    Object.keys(flags.bools).forEach(function (key) {
        setArg(key, defaults[key] === undefined ? false : defaults[key]);
    });
    
    var notFlags = [];

    if (args.indexOf('--') !== -1) {
        notFlags = args.slice(args.indexOf('--')+1);
        args = args.slice(0, args.indexOf('--'));
    }

    function argDefined(key, arg) {
        return (flags.allBools && /^--[^=]+$/.test(arg)) ||
            flags.strings[key] || flags.bools[key] || aliases[key];
    }

    function setArg (key, val, arg) {
        if (arg && flags.unknownFn && !argDefined(key, arg)) {
            if (flags.unknownFn(arg) === false) return;
        }

        var value = !flags.strings[key] && isNumber(val)
            ? Number(val) : val
        ;
        setKey(argv, key.split('.'), value);
        
        (aliases[key] || []).forEach(function (x) {
            setKey(argv, x.split('.'), value);
        });
    }

    function setKey (obj, keys, value) {
        var o = obj;
        keys.slice(0,-1).forEach(function (key) {
            if (o[key] === undefined) o[key] = {};
            o = o[key];
        });

        var key = keys[keys.length - 1];
        if (o[key] === undefined || flags.bools[key] || typeof o[key] === 'boolean') {
            o[key] = value;
        }
        else if (Array.isArray(o[key])) {
            o[key].push(value);
        }
        else {
            o[key] = [ o[key], value ];
        }
    }
    
    function aliasIsBoolean(key) {
      return aliases[key].some(function (x) {
          return flags.bools[x];
      });
    }

    for (var i = 0; i < args.length; i++) {
        var arg = args[i];
        
        if (/^--.+=/.test(arg)) {
            // Using [\s\S] instead of . because js doesn't support the
            // 'dotall' regex modifier. See:
            // http://stackoverflow.com/a/1068308/13216
            var m = arg.match(/^--([^=]+)=([\s\S]*)$/);
            var key = m[1];
            var value = m[2];
            if (flags.bools[key]) {
                value = value !== 'false';
            }
            setArg(key, value, arg);
        }
        else if (/^--no-.+/.test(arg)) {
            var key = arg.match(/^--no-(.+)/)[1];
            setArg(key, false, arg);
        }
        else if (/^--.+/.test(arg)) {
            var key = arg.match(/^--(.+)/)[1];
            var next = args[i + 1];
            if (next !== undefined && !/^-/.test(next)
            && !flags.bools[key]
            && !flags.allBools
            && (aliases[key] ? !aliasIsBoolean(key) : true)) {
                setArg(key, next, arg);
                i++;
            }
            else if (/^(true|false)$/.test(next)) {
                setArg(key, next === 'true', arg);
                i++;
            }
            else {
                setArg(key, flags.strings[key] ? '' : true, arg);
            }
        }
        else if (/^-[^-]+/.test(arg)) {
            var letters = arg.slice(1,-1).split('');
            
            var broken = false;
            for (var j = 0; j < letters.length; j++) {
                var next = arg.slice(j+2);
                
                if (next === '-') {
                    setArg(letters[j], next, arg)
                    continue;
                }
                
                if (/[A-Za-z]/.test(letters[j]) && /=/.test(next)) {
                    setArg(letters[j], next.split('=')[1], arg);
                    broken = true;
                    break;
                }
                
                if (/[A-Za-z]/.test(letters[j])
                && /-?\d+(\.\d*)?(e-?\d+)?$/.test(next)) {
                    setArg(letters[j], next, arg);
                    broken = true;
                    break;
                }
                
                if (letters[j+1] && letters[j+1].match(/\W/)) {
                    setArg(letters[j], arg.slice(j+2), arg);
                    broken = true;
                    break;
                }
                else {
                    setArg(letters[j], flags.strings[letters[j]] ? '' : true, arg);
                }
            }
            
            var key = arg.slice(-1)[0];
            if (!broken && key !== '-') {
                if (args[i+1] && !/^(-|--)[^-]/.test(args[i+1])
                && !flags.bools[key]
                && (aliases[key] ? !aliasIsBoolean(key) : true)) {
                    setArg(key, args[i+1], arg);
                    i++;
                }
                else if (args[i+1] && /true|false/.test(args[i+1])) {
                    setArg(key, args[i+1] === 'true', arg);
                    i++;
                }
                else {
                    setArg(key, flags.strings[key] ? '' : true, arg);
                }
            }
        }
        else {
            if (!flags.unknownFn || flags.unknownFn(arg) !== false) {
                argv._.push(
                    flags.strings['_'] || !isNumber(arg) ? arg : Number(arg)
                );
            }
            if (opts.stopEarly) {
                argv._.push.apply(argv._, args.slice(i + 1));
                break;
            }
        }
    }
    
    Object.keys(defaults).forEach(function (key) {
        if (!hasKey(argv, key.split('.'))) {
            setKey(argv, key.split('.'), defaults[key]);
            
            (aliases[key] || []).forEach(function (x) {
                setKey(argv, x.split('.'), defaults[key]);
            });
        }
    });
    
    if (opts['--']) {
        argv['--'] = new Array();
        notFlags.forEach(function(key) {
            argv['--'].push(key);
        });
    }
    else {
        notFlags.forEach(function(key) {
            argv._.push(key);
        });
    }

    return argv;
};

function hasKey (obj, keys) {
    var o = obj;
    keys.slice(0,-1).forEach(function (key) {
        o = (o[key] || {});
    });

    var key = keys[keys.length - 1];
    return key in o;
}

function isNumber (x) {
    if (typeof x === 'number') return true;
    if (/^0x[0-9a-f]+$/i.test(x)) return true;
    return /^[-+]?(?:\d+(?:\.\d*)?|\.\d+)(e[-+]?\d+)?$/.test(x);
}


},
"VkDj/t9A1iltFCn2XW8+NX9qu1tBksktxzBCUwWnZ6U=":
function (require, module, exports, __dirname, __filename) {
var traverse = module.exports = function (obj) {
    return new Traverse(obj);
};

function Traverse (obj) {
    this.value = obj;
}

Traverse.prototype.get = function (ps) {
    var node = this.value;
    for (var i = 0; i < ps.length; i ++) {
        var key = ps[i];
        if (!node || !hasOwnProperty.call(node, key)) {
            node = undefined;
            break;
        }
        node = node[key];
    }
    return node;
};

Traverse.prototype.has = function (ps) {
    var node = this.value;
    for (var i = 0; i < ps.length; i ++) {
        var key = ps[i];
        if (!node || !hasOwnProperty.call(node, key)) {
            return false;
        }
        node = node[key];
    }
    return true;
};

Traverse.prototype.set = function (ps, value) {
    var node = this.value;
    for (var i = 0; i < ps.length - 1; i ++) {
        var key = ps[i];
        if (!hasOwnProperty.call(node, key)) node[key] = {};
        node = node[key];
    }
    node[ps[i]] = value;
    return value;
};

Traverse.prototype.map = function (cb) {
    return walk(this.value, cb, true);
};

Traverse.prototype.forEach = function (cb) {
    this.value = walk(this.value, cb, false);
    return this.value;
};

Traverse.prototype.reduce = function (cb, init) {
    var skip = arguments.length === 1;
    var acc = skip ? this.value : init;
    this.forEach(function (x) {
        if (!this.isRoot || !skip) {
            acc = cb.call(this, acc, x);
        }
    });
    return acc;
};

Traverse.prototype.paths = function () {
    var acc = [];
    this.forEach(function (x) {
        acc.push(this.path); 
    });
    return acc;
};

Traverse.prototype.nodes = function () {
    var acc = [];
    this.forEach(function (x) {
        acc.push(this.node);
    });
    return acc;
};

Traverse.prototype.clone = function () {
    var parents = [], nodes = [];
    
    return (function clone (src) {
        for (var i = 0; i < parents.length; i++) {
            if (parents[i] === src) {
                return nodes[i];
            }
        }
        
        if (typeof src === 'object' && src !== null) {
            var dst = copy(src);
            
            parents.push(src);
            nodes.push(dst);
            
            forEach(objectKeys(src), function (key) {
                dst[key] = clone(src[key]);
            });
            
            parents.pop();
            nodes.pop();
            return dst;
        }
        else {
            return src;
        }
    })(this.value);
};

function walk (root, cb, immutable) {
    var path = [];
    var parents = [];
    var alive = true;
    
    return (function walker (node_) {
        var node = immutable ? copy(node_) : node_;
        var modifiers = {};
        
        var keepGoing = true;
        
        var state = {
            node : node,
            node_ : node_,
            path : [].concat(path),
            parent : parents[parents.length - 1],
            parents : parents,
            key : path.slice(-1)[0],
            isRoot : path.length === 0,
            level : path.length,
            circular : null,
            update : function (x, stopHere) {
                if (!state.isRoot) {
                    state.parent.node[state.key] = x;
                }
                state.node = x;
                if (stopHere) keepGoing = false;
            },
            'delete' : function (stopHere) {
                delete state.parent.node[state.key];
                if (stopHere) keepGoing = false;
            },
            remove : function (stopHere) {
                if (isArray(state.parent.node)) {
                    state.parent.node.splice(state.key, 1);
                }
                else {
                    delete state.parent.node[state.key];
                }
                if (stopHere) keepGoing = false;
            },
            keys : null,
            before : function (f) { modifiers.before = f },
            after : function (f) { modifiers.after = f },
            pre : function (f) { modifiers.pre = f },
            post : function (f) { modifiers.post = f },
            stop : function () { alive = false },
            block : function () { keepGoing = false }
        };
        
        if (!alive) return state;
        
        function updateState() {
            if (typeof state.node === 'object' && state.node !== null) {
                if (!state.keys || state.node_ !== state.node) {
                    state.keys = objectKeys(state.node)
                }
                
                state.isLeaf = state.keys.length == 0;
                
                for (var i = 0; i < parents.length; i++) {
                    if (parents[i].node_ === node_) {
                        state.circular = parents[i];
                        break;
                    }
                }
            }
            else {
                state.isLeaf = true;
                state.keys = null;
            }
            
            state.notLeaf = !state.isLeaf;
            state.notRoot = !state.isRoot;
        }
        
        updateState();
        
        // use return values to update if defined
        var ret = cb.call(state, state.node);
        if (ret !== undefined && state.update) state.update(ret);
        
        if (modifiers.before) modifiers.before.call(state, state.node);
        
        if (!keepGoing) return state;
        
        if (typeof state.node == 'object'
        && state.node !== null && !state.circular) {
            parents.push(state);
            
            updateState();
            
            forEach(state.keys, function (key, i) {
                path.push(key);
                
                if (modifiers.pre) modifiers.pre.call(state, state.node[key], key);
                
                var child = walker(state.node[key]);
                if (immutable && hasOwnProperty.call(state.node, key)) {
                    state.node[key] = child.node;
                }
                
                child.isLast = i == state.keys.length - 1;
                child.isFirst = i == 0;
                
                if (modifiers.post) modifiers.post.call(state, child);
                
                path.pop();
            });
            parents.pop();
        }
        
        if (modifiers.after) modifiers.after.call(state, state.node);
        
        return state;
    })(root).node;
}

function copy (src) {
    if (typeof src === 'object' && src !== null) {
        var dst;
        
        if (isArray(src)) {
            dst = [];
        }
        else if (isDate(src)) {
            dst = new Date(src.getTime ? src.getTime() : src);
        }
        else if (isRegExp(src)) {
            dst = new RegExp(src);
        }
        else if (isError(src)) {
            dst = { message: src.message };
        }
        else if (isBoolean(src)) {
            dst = new Boolean(src);
        }
        else if (isNumber(src)) {
            dst = new Number(src);
        }
        else if (isString(src)) {
            dst = new String(src);
        }
        else if (Object.create && Object.getPrototypeOf) {
            dst = Object.create(Object.getPrototypeOf(src));
        }
        else if (src.constructor === Object) {
            dst = {};
        }
        else {
            var proto =
                (src.constructor && src.constructor.prototype)
                || src.__proto__
                || {}
            ;
            var T = function () {};
            T.prototype = proto;
            dst = new T;
        }
        
        forEach(objectKeys(src), function (key) {
            dst[key] = src[key];
        });
        return dst;
    }
    else return src;
}

var objectKeys = Object.keys || function keys (obj) {
    var res = [];
    for (var key in obj) res.push(key)
    return res;
};

function toS (obj) { return Object.prototype.toString.call(obj) }
function isDate (obj) { return toS(obj) === '[object Date]' }
function isRegExp (obj) { return toS(obj) === '[object RegExp]' }
function isError (obj) { return toS(obj) === '[object Error]' }
function isBoolean (obj) { return toS(obj) === '[object Boolean]' }
function isNumber (obj) { return toS(obj) === '[object Number]' }
function isString (obj) { return toS(obj) === '[object String]' }

var isArray = Array.isArray || function isArray (xs) {
    return Object.prototype.toString.call(xs) === '[object Array]';
};

var forEach = function (xs, fn) {
    if (xs.forEach) return xs.forEach(fn)
    else for (var i = 0; i < xs.length; i++) {
        fn(xs[i], i, xs);
    }
};

forEach(objectKeys(Traverse.prototype), function (key) {
    traverse[key] = function (obj) {
        var args = [].slice.call(arguments, 1);
        var t = new Traverse(obj);
        return t[key].apply(t, args);
    };
});

var hasOwnProperty = Object.hasOwnProperty || function (obj, key) {
    return key in obj;
};

},
"VxLGQbDfv8iToKc7T3UZLO4UYh0A9WqJ8LE0LcxC1y4=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const OffsetLog = require('async-append-only-log')
const bipf = require('bipf')
const TooHot = require('too-hot')
const { BLOCK_SIZE, newLogPath, tooHotOpts } = require('./defaults')

module.exports = function (dir, config, privateIndex) {
  config = config || {}
  config.db2 = config.db2 || {}

  const log = OffsetLog(newLogPath(dir), {
    blockSize: BLOCK_SIZE,
    validateRecord: (d) => {
      try {
        bipf.decode(d, 0)
        return true
      } catch (ex) {
        return false
      }
    },
  })

  log.add = function (key, value, cb) {
    const kvt = {
      key,
      value,
      timestamp: Date.now(),
    }
    const buf = Buffer.alloc(bipf.encodingLength(kvt))
    bipf.encode(kvt, buf, 0)
    log.append(buf, (err) => {
      if (err) cb(err)
      else cb(null, kvt)
    })
  }

  log.addTransaction = function (keys, values, cb) {
    let buffers = []
    let kvts = []

    for (let i = 0; i < keys.length; ++i) {
      const kvt = {
        key: keys[i],
        value: values[i],
        timestamp: Date.now(),
      }
      const buf = Buffer.alloc(bipf.encodingLength(kvt))
      bipf.encode(kvt, buf, 0)
      buffers.push(buf)
      kvts.push(kvt)
    }

    log.appendTransaction(buffers, (err) => {
      if (err) cb(err)
      else cb(null, kvts)
    })
  }

  // monkey-patch log.get to decrypt the msg
  const originalGet = log.get
  log.get = function (offset, cb) {
    originalGet(offset, (err, buffer) => {
      if (err) return cb(err)
      else {
        const record = { offset, value: buffer }
        cb(null, privateIndex.decrypt(record, false).value)
      }
    })
  }

  // monkey-patch log.stream to temporarily pause when the CPU is too busy,
  // and to decrypt the msg
  const originalStream = log.stream
  log.stream = function (opts) {
    const shouldDecrypt = opts.decrypt === false ? false : true
    const tooHot = config.db2.maxCpu ? TooHot(tooHotOpts(config)) : () => false
    const s = originalStream(opts)
    const originalPipe = s.pipe.bind(s)
    s.pipe = function pipe(o) {
      let originalWrite = o.write.bind(o)
      o.write = (record) => {
        const hot = tooHot()
        if (hot && !s.sink.paused) {
          s.sink.paused = true
          hot.then(() => {
            if (shouldDecrypt) originalWrite(privateIndex.decrypt(record, true))
            else originalWrite(record)
            s.sink.paused = false
            s.resume()
          })
        } else {
          if (shouldDecrypt) originalWrite(privateIndex.decrypt(record, true))
          else originalWrite(record)
        }
      }
      return originalPipe(o)
    }
    return s
  }

  return log
}

},
"W/Rc8J/ztYuBMQPCdVlUyu/nbqIy/zpUblr1JVUR7JE=":
function (require, module, exports, __dirname, __filename) {
// Unique ID creation requires a high quality random # generator.  In node.js
// this is pretty straight-forward - we use the crypto API.

var crypto = require('crypto');

module.exports = function nodeRNG() {
  return crypto.randomBytes(16);
};

},
"W2QzrBcmZMMApQOfZWHTSIHxffcHacJGjk+rEC6QzbE=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.sortByStateChange = void 0;
function sortByStateChange(peers) {
    return peers.sort((a, b) => a[1].stateChange - b[1].stateChange);
}
exports.sortByStateChange = sortByStateChange;

},
"W6Gkc1Dc5VviwZjHkd9S+gE7rCrY19zX1ncmwIpCMfE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

/* eslint complexity: [2, 18], max-statements: [2, 33] */
module.exports = function hasSymbols() {
	if (typeof Symbol !== 'function' || typeof Object.getOwnPropertySymbols !== 'function') { return false; }
	if (typeof Symbol.iterator === 'symbol') { return true; }

	var obj = {};
	var sym = Symbol('test');
	var symObj = Object(sym);
	if (typeof sym === 'string') { return false; }

	if (Object.prototype.toString.call(sym) !== '[object Symbol]') { return false; }
	if (Object.prototype.toString.call(symObj) !== '[object Symbol]') { return false; }

	// temp disabled per https://github.com/ljharb/object.assign/issues/17
	// if (sym instanceof Symbol) { return false; }
	// temp disabled per https://github.com/WebReflection/get-own-property-symbols/issues/4
	// if (!(symObj instanceof Symbol)) { return false; }

	// if (typeof Symbol.prototype.toString !== 'function') { return false; }
	// if (String(sym) !== Symbol.prototype.toString.call(sym)) { return false; }

	var symVal = 42;
	obj[sym] = symVal;
	for (sym in obj) { return false; } // eslint-disable-line no-restricted-syntax, no-unreachable-loop
	if (typeof Object.keys === 'function' && Object.keys(obj).length !== 0) { return false; }

	if (typeof Object.getOwnPropertyNames === 'function' && Object.getOwnPropertyNames(obj).length !== 0) { return false; }

	var syms = Object.getOwnPropertySymbols(obj);
	if (syms.length !== 1 || syms[0] !== sym) { return false; }

	if (!Object.prototype.propertyIsEnumerable.call(obj, sym)) { return false; }

	if (typeof Object.getOwnPropertyDescriptor === 'function') {
		var descriptor = Object.getOwnPropertyDescriptor(obj, sym);
		if (descriptor.value !== symVal || descriptor.enumerable !== true) { return false; }
	}

	return true;
};

},
"WBfMm1Uw5mOe+TPWn1xOQAiPJA9UKbNbdqgQCN2lBSs=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var uint48be = require('uint48be')
var int53 = require('int53')

module.exports = {
  32: {
    byteWidth: 4,
    encode: function(buf, value, offset) {
      buf.writeUInt32BE(value, offset)
    },
    decode: function(buf, offset) {
      return buf.readUInt32BE(offset)
    },
    decodeAsync: function(blocks, offset, cb) {
      blocks.readUInt32BE(offset, cb) 
    }
  },
  48: {
    byteWidth: 6,
    encode: function(buf, value, offset) {
      uint48be.encode(value, buf, offset)
    },
    decode: function(buf, offset) {
      return uint48be.decode(buf, offset)
    },
    decodeAsync: function(blocks, offset, cb) {
      blocks.readUInt48BE(offset, cb) 
    }
  },
  53: {
    byteWidth: 8,
    encode: function(buf, value, offset) {
      int53.writeUInt64BE(value, buf, offset)
    },
    decode: function(buf, offset) {
      return int53.readUInt64BE(buf, offset)
    },
    decodeAsync: function(blocks, offset, cb) {
      blocks.readUInt64BE(offset, cb)
    }
  }
}

},
"WLbVp5KKu/6DuSzVUw9IqoqvaxRknrerO3lh6mcu+sU=":
function (require, module, exports, __dirname, __filename) {

module.exports = function () {

  var buffers = [], length = 0

  //just used for debugging...
  function calcLength () {
    return buffers.reduce(function (a, b) {
      return a + b.length
    }, 0)
  }

  return {
    length: length,
    data: this,
    add: function (data) {
      if(!Buffer.isBuffer(data))
        throw new Error('data must be a buffer, was: ' + JSON.stringify(data))
      this.length = length = length + data.length
      buffers.push(data)
      return this
    },
    has: function (n) {
      if(null == n) return length > 0
      return length >= n
    },
    get: function (n) {
      var _length
      if(n == null || n === length) {
        length = 0
        var _buffers = buffers
        buffers = []
        if(_buffers.length == 1)
          return _buffers[0]
        else
          return Buffer.concat(_buffers)
      } else if (buffers.length > 1 && n <= (_length = buffers[0].length)) {
        var buf = buffers[0].slice(0, n)
        if(n === _length) {
          buffers.shift()
        }
        else {
          buffers[0] = buffers[0].slice(n, _length)
        }
        length -= n
        return buf
      }  else if(n < length) {
        var out = [], len = 0

        while((len + buffers[0].length) < n) {
          var b = buffers.shift()
          len += b.length
          out.push(b)
        }

        if(len < n) {
          out.push(buffers[0].slice(0, n - len))
          buffers[0] = buffers[0].slice(n - len, buffers[0].length)
          this.length = length = length - n
        }
        return Buffer.concat(out)
      }
      else
        throw new Error('could not get ' + n + ' bytes')
    }
  }

}






},
"WOWZfRqweYHJ1ub617U6ZmC/iTQqnmHa1jBQyCJIS5I=":
function (require, module, exports, __dirname, __filename) {

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = require('ms');
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;
		let namespacesCache;
		let enabledCache;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => {
				if (enableOverride !== null) {
					return enableOverride;
				}
				if (namespacesCache !== createDebug.namespaces) {
					namespacesCache = createDebug.namespaces;
					enabledCache = createDebug.enabled(namespace);
				}

				return enabledCache;
			},
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);
		createDebug.namespaces = namespaces;

		createDebug.names = [];
		createDebug.skips = [];

		let i;
		const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
		const len = split.length;

		for (i = 0; i < len; i++) {
			if (!split[i]) {
				// ignore empty strings
				continue;
			}

			namespaces = split[i].replace(/\*/g, '.*?');

			if (namespaces[0] === '-') {
				createDebug.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));
			} else {
				createDebug.names.push(new RegExp('^' + namespaces + '$'));
			}
		}
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names.map(toNamespace),
			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		if (name[name.length - 1] === '*') {
			return true;
		}

		let i;
		let len;

		for (i = 0, len = createDebug.skips.length; i < len; i++) {
			if (createDebug.skips[i].test(name)) {
				return false;
			}
		}

		for (i = 0, len = createDebug.names.length; i < len; i++) {
			if (createDebug.names[i].test(name)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Convert regexp to namespace
	*
	* @param {RegExp} regxep
	* @return {String} namespace
	* @api private
	*/
	function toNamespace(regexp) {
		return regexp.toString()
			.substring(2, regexp.toString().length - 2)
			.replace(/\.\*\?$/, '*');
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

module.exports = setup;

},
"WQemjJngdxdOE8GpYenbA59hGEMDR2UCBcRusVYXHXo=":
function (require, module, exports, __dirname, __filename) {
var duplex = require('./duplex')
var source = require('./source')
var sink = require('./sink')

function transform (push) {
  return function (read) {
    var reader = source(push)
    sink(push)(read)
    return reader
  }
}

exports = module.exports = function (push, cb) {
  if(push.write && push.resume)
    return duplex(push, cb)
  else if(push.write && !push.resume)
    return sink(push, cb)
  else
    return source(push)
}

exports.source = source
exports.sink = sink
exports.duplex = duplex
exports.transform = transform


},
"Wa4og6G+jxcCWRTrlcuAb1r4ZfO5vm0oEaTcKtvHoU0=":
function (require, module, exports, __dirname, __filename) {
module.exports = function z(target) {
  if (!target) return
  return Object.defineProperty(target, 'z', {
    value: function (f) {
      if (typeof f === 'function') return z(f(this.valueOf()));
    },
    writable: true,
    configurable: true,
  });
};

},
"WbGGkbXE072ELwpIugZuNTPk/+pFO11qXzmSHyh8Vls=":
function (require, module, exports, __dirname, __filename) {

function isObject(o) {
  return o && 'object' === typeof o
}

var isArray = Array.isArray

function isUndefined (u) {
  return 'undefined' === typeof u
}

var find = exports.find = function find(ary, test) {
  for(var i in ary)
    if(test(ary[i], i, ary)) return ary[i]
}

exports = module.exports = merge
exports.merge = exports

var clone = exports.clone = function clone (obj, mapper) {
  function map(v, k) {
    return isObject(v) ? clone(v, mapper) : mapper(v, k)
  }
  if(isArray(obj))
    return obj.map(map)
  else if(isObject(obj)) {
    var o = {}
    for(var k in obj)
      o[k] = map(obj[k], k)
    return o
  }
  else
    return map(obj)
}

var mergeKeys = exports.mergeKeys = function (a, b, iter) {
  var o = {}
  for(var k in a) {
    if(!isUndefined(a[k]))
      o[k] = iter(a[k], b[k], k)
  }
  for(var k in b) {
    if(isUndefined(a[k]))
      o[k] = iter(undefined, b[k], k)
  }
  return o
}

var mergeArrays = exports.mergeArrays = function (a, b, iter) {
  var o = []
  a.forEach(function (v, i) {
    var j = b.indexOf(v)
    o.push(iter(v, b[j], o.length))
  })
  b.forEach(function (v, i) {
    var j = a.indexOf(v)
    if(!~j)
      o.push(iter(undefined, b[i], o.length))
  })
  return o
}

function merge (a, b, merge) {

  //merge a and b objects

  merge = merge || function (x, y) {
    return y == null ? x : y
  }

  function merger(a, b, k) {

    if(isArray(a) && isArray(b))
      return mergeArrays(a, b, merger)
    else if(isObject(a) && isObject(b)) {
      return mergeKeys(a, b, merger)
    }
    else
      return merge(a, b, k)

  }

  return merger(a, b, undefined)


}

},
"WnTlvJMMNqdemuhLQd96nqNpx/uankm2sZOa5NkSU1M=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "的",
    "一",
    "是",
    "在",
    "不",
    "了",
    "有",
    "和",
    "人",
    "这",
    "中",
    "大",
    "为",
    "上",
    "个",
    "国",
    "我",
    "以",
    "要",
    "他",
    "时",
    "来",
    "用",
    "们",
    "生",
    "到",
    "作",
    "地",
    "于",
    "出",
    "就",
    "分",
    "对",
    "成",
    "会",
    "可",
    "主",
    "发",
    "年",
    "动",
    "同",
    "工",
    "也",
    "能",
    "下",
    "过",
    "子",
    "说",
    "产",
    "种",
    "面",
    "而",
    "方",
    "后",
    "多",
    "定",
    "行",
    "学",
    "法",
    "所",
    "民",
    "得",
    "经",
    "十",
    "三",
    "之",
    "进",
    "着",
    "等",
    "部",
    "度",
    "家",
    "电",
    "力",
    "里",
    "如",
    "水",
    "化",
    "高",
    "自",
    "二",
    "理",
    "起",
    "小",
    "物",
    "现",
    "实",
    "加",
    "量",
    "都",
    "两",
    "体",
    "制",
    "机",
    "当",
    "使",
    "点",
    "从",
    "业",
    "本",
    "去",
    "把",
    "性",
    "好",
    "应",
    "开",
    "它",
    "合",
    "还",
    "因",
    "由",
    "其",
    "些",
    "然",
    "前",
    "外",
    "天",
    "政",
    "四",
    "日",
    "那",
    "社",
    "义",
    "事",
    "平",
    "形",
    "相",
    "全",
    "表",
    "间",
    "样",
    "与",
    "关",
    "各",
    "重",
    "新",
    "线",
    "内",
    "数",
    "正",
    "心",
    "反",
    "你",
    "明",
    "看",
    "原",
    "又",
    "么",
    "利",
    "比",
    "或",
    "但",
    "质",
    "气",
    "第",
    "向",
    "道",
    "命",
    "此",
    "变",
    "条",
    "只",
    "没",
    "结",
    "解",
    "问",
    "意",
    "建",
    "月",
    "公",
    "无",
    "系",
    "军",
    "很",
    "情",
    "者",
    "最",
    "立",
    "代",
    "想",
    "已",
    "通",
    "并",
    "提",
    "直",
    "题",
    "党",
    "程",
    "展",
    "五",
    "果",
    "料",
    "象",
    "员",
    "革",
    "位",
    "入",
    "常",
    "文",
    "总",
    "次",
    "品",
    "式",
    "活",
    "设",
    "及",
    "管",
    "特",
    "件",
    "长",
    "求",
    "老",
    "头",
    "基",
    "资",
    "边",
    "流",
    "路",
    "级",
    "少",
    "图",
    "山",
    "统",
    "接",
    "知",
    "较",
    "将",
    "组",
    "见",
    "计",
    "别",
    "她",
    "手",
    "角",
    "期",
    "根",
    "论",
    "运",
    "农",
    "指",
    "几",
    "九",
    "区",
    "强",
    "放",
    "决",
    "西",
    "被",
    "干",
    "做",
    "必",
    "战",
    "先",
    "回",
    "则",
    "任",
    "取",
    "据",
    "处",
    "队",
    "南",
    "给",
    "色",
    "光",
    "门",
    "即",
    "保",
    "治",
    "北",
    "造",
    "百",
    "规",
    "热",
    "领",
    "七",
    "海",
    "口",
    "东",
    "导",
    "器",
    "压",
    "志",
    "世",
    "金",
    "增",
    "争",
    "济",
    "阶",
    "油",
    "思",
    "术",
    "极",
    "交",
    "受",
    "联",
    "什",
    "认",
    "六",
    "共",
    "权",
    "收",
    "证",
    "改",
    "清",
    "美",
    "再",
    "采",
    "转",
    "更",
    "单",
    "风",
    "切",
    "打",
    "白",
    "教",
    "速",
    "花",
    "带",
    "安",
    "场",
    "身",
    "车",
    "例",
    "真",
    "务",
    "具",
    "万",
    "每",
    "目",
    "至",
    "达",
    "走",
    "积",
    "示",
    "议",
    "声",
    "报",
    "斗",
    "完",
    "类",
    "八",
    "离",
    "华",
    "名",
    "确",
    "才",
    "科",
    "张",
    "信",
    "马",
    "节",
    "话",
    "米",
    "整",
    "空",
    "元",
    "况",
    "今",
    "集",
    "温",
    "传",
    "土",
    "许",
    "步",
    "群",
    "广",
    "石",
    "记",
    "需",
    "段",
    "研",
    "界",
    "拉",
    "林",
    "律",
    "叫",
    "且",
    "究",
    "观",
    "越",
    "织",
    "装",
    "影",
    "算",
    "低",
    "持",
    "音",
    "众",
    "书",
    "布",
    "复",
    "容",
    "儿",
    "须",
    "际",
    "商",
    "非",
    "验",
    "连",
    "断",
    "深",
    "难",
    "近",
    "矿",
    "千",
    "周",
    "委",
    "素",
    "技",
    "备",
    "半",
    "办",
    "青",
    "省",
    "列",
    "习",
    "响",
    "约",
    "支",
    "般",
    "史",
    "感",
    "劳",
    "便",
    "团",
    "往",
    "酸",
    "历",
    "市",
    "克",
    "何",
    "除",
    "消",
    "构",
    "府",
    "称",
    "太",
    "准",
    "精",
    "值",
    "号",
    "率",
    "族",
    "维",
    "划",
    "选",
    "标",
    "写",
    "存",
    "候",
    "毛",
    "亲",
    "快",
    "效",
    "斯",
    "院",
    "查",
    "江",
    "型",
    "眼",
    "王",
    "按",
    "格",
    "养",
    "易",
    "置",
    "派",
    "层",
    "片",
    "始",
    "却",
    "专",
    "状",
    "育",
    "厂",
    "京",
    "识",
    "适",
    "属",
    "圆",
    "包",
    "火",
    "住",
    "调",
    "满",
    "县",
    "局",
    "照",
    "参",
    "红",
    "细",
    "引",
    "听",
    "该",
    "铁",
    "价",
    "严",
    "首",
    "底",
    "液",
    "官",
    "德",
    "随",
    "病",
    "苏",
    "失",
    "尔",
    "死",
    "讲",
    "配",
    "女",
    "黄",
    "推",
    "显",
    "谈",
    "罪",
    "神",
    "艺",
    "呢",
    "席",
    "含",
    "企",
    "望",
    "密",
    "批",
    "营",
    "项",
    "防",
    "举",
    "球",
    "英",
    "氧",
    "势",
    "告",
    "李",
    "台",
    "落",
    "木",
    "帮",
    "轮",
    "破",
    "亚",
    "师",
    "围",
    "注",
    "远",
    "字",
    "材",
    "排",
    "供",
    "河",
    "态",
    "封",
    "另",
    "施",
    "减",
    "树",
    "溶",
    "怎",
    "止",
    "案",
    "言",
    "士",
    "均",
    "武",
    "固",
    "叶",
    "鱼",
    "波",
    "视",
    "仅",
    "费",
    "紧",
    "爱",
    "左",
    "章",
    "早",
    "朝",
    "害",
    "续",
    "轻",
    "服",
    "试",
    "食",
    "充",
    "兵",
    "源",
    "判",
    "护",
    "司",
    "足",
    "某",
    "练",
    "差",
    "致",
    "板",
    "田",
    "降",
    "黑",
    "犯",
    "负",
    "击",
    "范",
    "继",
    "兴",
    "似",
    "余",
    "坚",
    "曲",
    "输",
    "修",
    "故",
    "城",
    "夫",
    "够",
    "送",
    "笔",
    "船",
    "占",
    "右",
    "财",
    "吃",
    "富",
    "春",
    "职",
    "觉",
    "汉",
    "画",
    "功",
    "巴",
    "跟",
    "虽",
    "杂",
    "飞",
    "检",
    "吸",
    "助",
    "升",
    "阳",
    "互",
    "初",
    "创",
    "抗",
    "考",
    "投",
    "坏",
    "策",
    "古",
    "径",
    "换",
    "未",
    "跑",
    "留",
    "钢",
    "曾",
    "端",
    "责",
    "站",
    "简",
    "述",
    "钱",
    "副",
    "尽",
    "帝",
    "射",
    "草",
    "冲",
    "承",
    "独",
    "令",
    "限",
    "阿",
    "宣",
    "环",
    "双",
    "请",
    "超",
    "微",
    "让",
    "控",
    "州",
    "良",
    "轴",
    "找",
    "否",
    "纪",
    "益",
    "依",
    "优",
    "顶",
    "础",
    "载",
    "倒",
    "房",
    "突",
    "坐",
    "粉",
    "敌",
    "略",
    "客",
    "袁",
    "冷",
    "胜",
    "绝",
    "析",
    "块",
    "剂",
    "测",
    "丝",
    "协",
    "诉",
    "念",
    "陈",
    "仍",
    "罗",
    "盐",
    "友",
    "洋",
    "错",
    "苦",
    "夜",
    "刑",
    "移",
    "频",
    "逐",
    "靠",
    "混",
    "母",
    "短",
    "皮",
    "终",
    "聚",
    "汽",
    "村",
    "云",
    "哪",
    "既",
    "距",
    "卫",
    "停",
    "烈",
    "央",
    "察",
    "烧",
    "迅",
    "境",
    "若",
    "印",
    "洲",
    "刻",
    "括",
    "激",
    "孔",
    "搞",
    "甚",
    "室",
    "待",
    "核",
    "校",
    "散",
    "侵",
    "吧",
    "甲",
    "游",
    "久",
    "菜",
    "味",
    "旧",
    "模",
    "湖",
    "货",
    "损",
    "预",
    "阻",
    "毫",
    "普",
    "稳",
    "乙",
    "妈",
    "植",
    "息",
    "扩",
    "银",
    "语",
    "挥",
    "酒",
    "守",
    "拿",
    "序",
    "纸",
    "医",
    "缺",
    "雨",
    "吗",
    "针",
    "刘",
    "啊",
    "急",
    "唱",
    "误",
    "训",
    "愿",
    "审",
    "附",
    "获",
    "茶",
    "鲜",
    "粮",
    "斤",
    "孩",
    "脱",
    "硫",
    "肥",
    "善",
    "龙",
    "演",
    "父",
    "渐",
    "血",
    "欢",
    "械",
    "掌",
    "歌",
    "沙",
    "刚",
    "攻",
    "谓",
    "盾",
    "讨",
    "晚",
    "粒",
    "乱",
    "燃",
    "矛",
    "乎",
    "杀",
    "药",
    "宁",
    "鲁",
    "贵",
    "钟",
    "煤",
    "读",
    "班",
    "伯",
    "香",
    "介",
    "迫",
    "句",
    "丰",
    "培",
    "握",
    "兰",
    "担",
    "弦",
    "蛋",
    "沉",
    "假",
    "穿",
    "执",
    "答",
    "乐",
    "谁",
    "顺",
    "烟",
    "缩",
    "征",
    "脸",
    "喜",
    "松",
    "脚",
    "困",
    "异",
    "免",
    "背",
    "星",
    "福",
    "买",
    "染",
    "井",
    "概",
    "慢",
    "怕",
    "磁",
    "倍",
    "祖",
    "皇",
    "促",
    "静",
    "补",
    "评",
    "翻",
    "肉",
    "践",
    "尼",
    "衣",
    "宽",
    "扬",
    "棉",
    "希",
    "伤",
    "操",
    "垂",
    "秋",
    "宜",
    "氢",
    "套",
    "督",
    "振",
    "架",
    "亮",
    "末",
    "宪",
    "庆",
    "编",
    "牛",
    "触",
    "映",
    "雷",
    "销",
    "诗",
    "座",
    "居",
    "抓",
    "裂",
    "胞",
    "呼",
    "娘",
    "景",
    "威",
    "绿",
    "晶",
    "厚",
    "盟",
    "衡",
    "鸡",
    "孙",
    "延",
    "危",
    "胶",
    "屋",
    "乡",
    "临",
    "陆",
    "顾",
    "掉",
    "呀",
    "灯",
    "岁",
    "措",
    "束",
    "耐",
    "剧",
    "玉",
    "赵",
    "跳",
    "哥",
    "季",
    "课",
    "凯",
    "胡",
    "额",
    "款",
    "绍",
    "卷",
    "齐",
    "伟",
    "蒸",
    "殖",
    "永",
    "宗",
    "苗",
    "川",
    "炉",
    "岩",
    "弱",
    "零",
    "杨",
    "奏",
    "沿",
    "露",
    "杆",
    "探",
    "滑",
    "镇",
    "饭",
    "浓",
    "航",
    "怀",
    "赶",
    "库",
    "夺",
    "伊",
    "灵",
    "税",
    "途",
    "灭",
    "赛",
    "归",
    "召",
    "鼓",
    "播",
    "盘",
    "裁",
    "险",
    "康",
    "唯",
    "录",
    "菌",
    "纯",
    "借",
    "糖",
    "盖",
    "横",
    "符",
    "私",
    "努",
    "堂",
    "域",
    "枪",
    "润",
    "幅",
    "哈",
    "竟",
    "熟",
    "虫",
    "泽",
    "脑",
    "壤",
    "碳",
    "欧",
    "遍",
    "侧",
    "寨",
    "敢",
    "彻",
    "虑",
    "斜",
    "薄",
    "庭",
    "纳",
    "弹",
    "饲",
    "伸",
    "折",
    "麦",
    "湿",
    "暗",
    "荷",
    "瓦",
    "塞",
    "床",
    "筑",
    "恶",
    "户",
    "访",
    "塔",
    "奇",
    "透",
    "梁",
    "刀",
    "旋",
    "迹",
    "卡",
    "氯",
    "遇",
    "份",
    "毒",
    "泥",
    "退",
    "洗",
    "摆",
    "灰",
    "彩",
    "卖",
    "耗",
    "夏",
    "择",
    "忙",
    "铜",
    "献",
    "硬",
    "予",
    "繁",
    "圈",
    "雪",
    "函",
    "亦",
    "抽",
    "篇",
    "阵",
    "阴",
    "丁",
    "尺",
    "追",
    "堆",
    "雄",
    "迎",
    "泛",
    "爸",
    "楼",
    "避",
    "谋",
    "吨",
    "野",
    "猪",
    "旗",
    "累",
    "偏",
    "典",
    "馆",
    "索",
    "秦",
    "脂",
    "潮",
    "爷",
    "豆",
    "忽",
    "托",
    "惊",
    "塑",
    "遗",
    "愈",
    "朱",
    "替",
    "纤",
    "粗",
    "倾",
    "尚",
    "痛",
    "楚",
    "谢",
    "奋",
    "购",
    "磨",
    "君",
    "池",
    "旁",
    "碎",
    "骨",
    "监",
    "捕",
    "弟",
    "暴",
    "割",
    "贯",
    "殊",
    "释",
    "词",
    "亡",
    "壁",
    "顿",
    "宝",
    "午",
    "尘",
    "闻",
    "揭",
    "炮",
    "残",
    "冬",
    "桥",
    "妇",
    "警",
    "综",
    "招",
    "吴",
    "付",
    "浮",
    "遭",
    "徐",
    "您",
    "摇",
    "谷",
    "赞",
    "箱",
    "隔",
    "订",
    "男",
    "吹",
    "园",
    "纷",
    "唐",
    "败",
    "宋",
    "玻",
    "巨",
    "耕",
    "坦",
    "荣",
    "闭",
    "湾",
    "键",
    "凡",
    "驻",
    "锅",
    "救",
    "恩",
    "剥",
    "凝",
    "碱",
    "齿",
    "截",
    "炼",
    "麻",
    "纺",
    "禁",
    "废",
    "盛",
    "版",
    "缓",
    "净",
    "睛",
    "昌",
    "婚",
    "涉",
    "筒",
    "嘴",
    "插",
    "岸",
    "朗",
    "庄",
    "街",
    "藏",
    "姑",
    "贸",
    "腐",
    "奴",
    "啦",
    "惯",
    "乘",
    "伙",
    "恢",
    "匀",
    "纱",
    "扎",
    "辩",
    "耳",
    "彪",
    "臣",
    "亿",
    "璃",
    "抵",
    "脉",
    "秀",
    "萨",
    "俄",
    "网",
    "舞",
    "店",
    "喷",
    "纵",
    "寸",
    "汗",
    "挂",
    "洪",
    "贺",
    "闪",
    "柬",
    "爆",
    "烯",
    "津",
    "稻",
    "墙",
    "软",
    "勇",
    "像",
    "滚",
    "厘",
    "蒙",
    "芳",
    "肯",
    "坡",
    "柱",
    "荡",
    "腿",
    "仪",
    "旅",
    "尾",
    "轧",
    "冰",
    "贡",
    "登",
    "黎",
    "削",
    "钻",
    "勒",
    "逃",
    "障",
    "氨",
    "郭",
    "峰",
    "币",
    "港",
    "伏",
    "轨",
    "亩",
    "毕",
    "擦",
    "莫",
    "刺",
    "浪",
    "秘",
    "援",
    "株",
    "健",
    "售",
    "股",
    "岛",
    "甘",
    "泡",
    "睡",
    "童",
    "铸",
    "汤",
    "阀",
    "休",
    "汇",
    "舍",
    "牧",
    "绕",
    "炸",
    "哲",
    "磷",
    "绩",
    "朋",
    "淡",
    "尖",
    "启",
    "陷",
    "柴",
    "呈",
    "徒",
    "颜",
    "泪",
    "稍",
    "忘",
    "泵",
    "蓝",
    "拖",
    "洞",
    "授",
    "镜",
    "辛",
    "壮",
    "锋",
    "贫",
    "虚",
    "弯",
    "摩",
    "泰",
    "幼",
    "廷",
    "尊",
    "窗",
    "纲",
    "弄",
    "隶",
    "疑",
    "氏",
    "宫",
    "姐",
    "震",
    "瑞",
    "怪",
    "尤",
    "琴",
    "循",
    "描",
    "膜",
    "违",
    "夹",
    "腰",
    "缘",
    "珠",
    "穷",
    "森",
    "枝",
    "竹",
    "沟",
    "催",
    "绳",
    "忆",
    "邦",
    "剩",
    "幸",
    "浆",
    "栏",
    "拥",
    "牙",
    "贮",
    "礼",
    "滤",
    "钠",
    "纹",
    "罢",
    "拍",
    "咱",
    "喊",
    "袖",
    "埃",
    "勤",
    "罚",
    "焦",
    "潜",
    "伍",
    "墨",
    "欲",
    "缝",
    "姓",
    "刊",
    "饱",
    "仿",
    "奖",
    "铝",
    "鬼",
    "丽",
    "跨",
    "默",
    "挖",
    "链",
    "扫",
    "喝",
    "袋",
    "炭",
    "污",
    "幕",
    "诸",
    "弧",
    "励",
    "梅",
    "奶",
    "洁",
    "灾",
    "舟",
    "鉴",
    "苯",
    "讼",
    "抱",
    "毁",
    "懂",
    "寒",
    "智",
    "埔",
    "寄",
    "届",
    "跃",
    "渡",
    "挑",
    "丹",
    "艰",
    "贝",
    "碰",
    "拔",
    "爹",
    "戴",
    "码",
    "梦",
    "芽",
    "熔",
    "赤",
    "渔",
    "哭",
    "敬",
    "颗",
    "奔",
    "铅",
    "仲",
    "虎",
    "稀",
    "妹",
    "乏",
    "珍",
    "申",
    "桌",
    "遵",
    "允",
    "隆",
    "螺",
    "仓",
    "魏",
    "锐",
    "晓",
    "氮",
    "兼",
    "隐",
    "碍",
    "赫",
    "拨",
    "忠",
    "肃",
    "缸",
    "牵",
    "抢",
    "博",
    "巧",
    "壳",
    "兄",
    "杜",
    "讯",
    "诚",
    "碧",
    "祥",
    "柯",
    "页",
    "巡",
    "矩",
    "悲",
    "灌",
    "龄",
    "伦",
    "票",
    "寻",
    "桂",
    "铺",
    "圣",
    "恐",
    "恰",
    "郑",
    "趣",
    "抬",
    "荒",
    "腾",
    "贴",
    "柔",
    "滴",
    "猛",
    "阔",
    "辆",
    "妻",
    "填",
    "撤",
    "储",
    "签",
    "闹",
    "扰",
    "紫",
    "砂",
    "递",
    "戏",
    "吊",
    "陶",
    "伐",
    "喂",
    "疗",
    "瓶",
    "婆",
    "抚",
    "臂",
    "摸",
    "忍",
    "虾",
    "蜡",
    "邻",
    "胸",
    "巩",
    "挤",
    "偶",
    "弃",
    "槽",
    "劲",
    "乳",
    "邓",
    "吉",
    "仁",
    "烂",
    "砖",
    "租",
    "乌",
    "舰",
    "伴",
    "瓜",
    "浅",
    "丙",
    "暂",
    "燥",
    "橡",
    "柳",
    "迷",
    "暖",
    "牌",
    "秧",
    "胆",
    "详",
    "簧",
    "踏",
    "瓷",
    "谱",
    "呆",
    "宾",
    "糊",
    "洛",
    "辉",
    "愤",
    "竞",
    "隙",
    "怒",
    "粘",
    "乃",
    "绪",
    "肩",
    "籍",
    "敏",
    "涂",
    "熙",
    "皆",
    "侦",
    "悬",
    "掘",
    "享",
    "纠",
    "醒",
    "狂",
    "锁",
    "淀",
    "恨",
    "牲",
    "霸",
    "爬",
    "赏",
    "逆",
    "玩",
    "陵",
    "祝",
    "秒",
    "浙",
    "貌",
    "役",
    "彼",
    "悉",
    "鸭",
    "趋",
    "凤",
    "晨",
    "畜",
    "辈",
    "秩",
    "卵",
    "署",
    "梯",
    "炎",
    "滩",
    "棋",
    "驱",
    "筛",
    "峡",
    "冒",
    "啥",
    "寿",
    "译",
    "浸",
    "泉",
    "帽",
    "迟",
    "硅",
    "疆",
    "贷",
    "漏",
    "稿",
    "冠",
    "嫩",
    "胁",
    "芯",
    "牢",
    "叛",
    "蚀",
    "奥",
    "鸣",
    "岭",
    "羊",
    "凭",
    "串",
    "塘",
    "绘",
    "酵",
    "融",
    "盆",
    "锡",
    "庙",
    "筹",
    "冻",
    "辅",
    "摄",
    "袭",
    "筋",
    "拒",
    "僚",
    "旱",
    "钾",
    "鸟",
    "漆",
    "沈",
    "眉",
    "疏",
    "添",
    "棒",
    "穗",
    "硝",
    "韩",
    "逼",
    "扭",
    "侨",
    "凉",
    "挺",
    "碗",
    "栽",
    "炒",
    "杯",
    "患",
    "馏",
    "劝",
    "豪",
    "辽",
    "勃",
    "鸿",
    "旦",
    "吏",
    "拜",
    "狗",
    "埋",
    "辊",
    "掩",
    "饮",
    "搬",
    "骂",
    "辞",
    "勾",
    "扣",
    "估",
    "蒋",
    "绒",
    "雾",
    "丈",
    "朵",
    "姆",
    "拟",
    "宇",
    "辑",
    "陕",
    "雕",
    "偿",
    "蓄",
    "崇",
    "剪",
    "倡",
    "厅",
    "咬",
    "驶",
    "薯",
    "刷",
    "斥",
    "番",
    "赋",
    "奉",
    "佛",
    "浇",
    "漫",
    "曼",
    "扇",
    "钙",
    "桃",
    "扶",
    "仔",
    "返",
    "俗",
    "亏",
    "腔",
    "鞋",
    "棱",
    "覆",
    "框",
    "悄",
    "叔",
    "撞",
    "骗",
    "勘",
    "旺",
    "沸",
    "孤",
    "吐",
    "孟",
    "渠",
    "屈",
    "疾",
    "妙",
    "惜",
    "仰",
    "狠",
    "胀",
    "谐",
    "抛",
    "霉",
    "桑",
    "岗",
    "嘛",
    "衰",
    "盗",
    "渗",
    "脏",
    "赖",
    "涌",
    "甜",
    "曹",
    "阅",
    "肌",
    "哩",
    "厉",
    "烃",
    "纬",
    "毅",
    "昨",
    "伪",
    "症",
    "煮",
    "叹",
    "钉",
    "搭",
    "茎",
    "笼",
    "酷",
    "偷",
    "弓",
    "锥",
    "恒",
    "杰",
    "坑",
    "鼻",
    "翼",
    "纶",
    "叙",
    "狱",
    "逮",
    "罐",
    "络",
    "棚",
    "抑",
    "膨",
    "蔬",
    "寺",
    "骤",
    "穆",
    "冶",
    "枯",
    "册",
    "尸",
    "凸",
    "绅",
    "坯",
    "牺",
    "焰",
    "轰",
    "欣",
    "晋",
    "瘦",
    "御",
    "锭",
    "锦",
    "丧",
    "旬",
    "锻",
    "垄",
    "搜",
    "扑",
    "邀",
    "亭",
    "酯",
    "迈",
    "舒",
    "脆",
    "酶",
    "闲",
    "忧",
    "酚",
    "顽",
    "羽",
    "涨",
    "卸",
    "仗",
    "陪",
    "辟",
    "惩",
    "杭",
    "姚",
    "肚",
    "捉",
    "飘",
    "漂",
    "昆",
    "欺",
    "吾",
    "郎",
    "烷",
    "汁",
    "呵",
    "饰",
    "萧",
    "雅",
    "邮",
    "迁",
    "燕",
    "撒",
    "姻",
    "赴",
    "宴",
    "烦",
    "债",
    "帐",
    "斑",
    "铃",
    "旨",
    "醇",
    "董",
    "饼",
    "雏",
    "姿",
    "拌",
    "傅",
    "腹",
    "妥",
    "揉",
    "贤",
    "拆",
    "歪",
    "葡",
    "胺",
    "丢",
    "浩",
    "徽",
    "昂",
    "垫",
    "挡",
    "览",
    "贪",
    "慰",
    "缴",
    "汪",
    "慌",
    "冯",
    "诺",
    "姜",
    "谊",
    "凶",
    "劣",
    "诬",
    "耀",
    "昏",
    "躺",
    "盈",
    "骑",
    "乔",
    "溪",
    "丛",
    "卢",
    "抹",
    "闷",
    "咨",
    "刮",
    "驾",
    "缆",
    "悟",
    "摘",
    "铒",
    "掷",
    "颇",
    "幻",
    "柄",
    "惠",
    "惨",
    "佳",
    "仇",
    "腊",
    "窝",
    "涤",
    "剑",
    "瞧",
    "堡",
    "泼",
    "葱",
    "罩",
    "霍",
    "捞",
    "胎",
    "苍",
    "滨",
    "俩",
    "捅",
    "湘",
    "砍",
    "霞",
    "邵",
    "萄",
    "疯",
    "淮",
    "遂",
    "熊",
    "粪",
    "烘",
    "宿",
    "档",
    "戈",
    "驳",
    "嫂",
    "裕",
    "徙",
    "箭",
    "捐",
    "肠",
    "撑",
    "晒",
    "辨",
    "殿",
    "莲",
    "摊",
    "搅",
    "酱",
    "屏",
    "疫",
    "哀",
    "蔡",
    "堵",
    "沫",
    "皱",
    "畅",
    "叠",
    "阁",
    "莱",
    "敲",
    "辖",
    "钩",
    "痕",
    "坝",
    "巷",
    "饿",
    "祸",
    "丘",
    "玄",
    "溜",
    "曰",
    "逻",
    "彭",
    "尝",
    "卿",
    "妨",
    "艇",
    "吞",
    "韦",
    "怨",
    "矮",
    "歇"
]

},
"X0uP+gxlB5CIVd6xBy1LxTe9b2hoZAqKp0rYk670Hmg=":
function (require, module, exports, __dirname, __filename) {
var ref = require('ssb-ref')
var ssbKeys = require('ssb-keys')
var isFeedId = ref.isFeedId
var timestamp = require('monotonic-timestamp')
var isCanonicalBase64 = require('is-canonical-base64')
var isEncryptedRx = isCanonicalBase64('','\\.box.*')
var isSignatureRx = isCanonicalBase64('','\\.sig.\\w+')

function isValidOrder (msg, signed) {
  var keys = Object.keys(msg)
  if(signed && keys.length !== 7) return false
  if(
    keys[0] !== 'previous' ||
    keys[3] !== 'timestamp' ||
    keys[4] !== 'hash' ||
    keys[5] !== 'content' ||
    (signed && keys[6] !== 'signature')
  ) return false
  //author and sequence may be swapped.
  if(!(
    (keys[1] === 'sequence' && keys[2] === 'author') ||
    (keys[1] === 'author' && keys[2] === 'sequence')
  ))
    return false
  return true
}

var encode = exports.encode = function (obj) {
  return JSON.stringify(obj, null, 2)
}

exports.initial = function () {
  return {
    validated: 0,
    queued: 0,
    queue: [],
    feeds: {},
    error: null
  }
}


function isString (s) {
  return s && 'string' === typeof s
}

function isInteger (n) {
  return ~~n === n
}

function isObject (o) {
  return o && 'object' === typeof o
}

function isEncrypted (str) {
  //NOTE: does not match end of string,
  //so future box version are accepted.
  //XXX check that base64 is canonical!
  return isString(str) && isEncryptedRx.test(str) ///^[0-9A-Za-z\/+]+={0,2}\.box/.test(str)
}

var isInvalidContent = exports.isInvalidContent = function (content) {
  if(!isEncrypted(content)) {
    var type = content.type
    if (!(isString(type) && type.length <= 52 && type.length >= 3)) {
      return new Error('type must be a string' +
        '3 <= type.length < 52, was:' + type
      )
    }
  }
  return false
}

var isSupportedHash = exports.isSupportedHash = function (msg) {
  return msg.hash === 'sha256'
}

var isSigMatchesCurve = exports.isSigMatchesCurve = function (msg) {
  if(!isSignatureRx.test(msg.signature)) return
  var curve = /\.(\w+)/.exec(msg.author)
  if(!(curve && curve[1])) return

  const signatureBase64Length = msg.signature.length - (curve[1].length + 5)

  if (signatureBase64Length !== 88) return
  if ('.sig.'+curve[1] !== msg.signature.substring(signatureBase64Length)) return

  return true
}

var isInvalidShape = exports.isInvalidShape = function (msg) {
  if(
    !isObject(msg) ||
    !isInteger(msg.sequence) ||
    !isFeedId(msg.author) ||
    !(isObject(msg.content) || isEncrypted(msg.content)) ||
    !isValidOrder(msg, false) || //false, because message may not be signed yet.
    !isSupportedHash(msg)
  )
    return new Error('message has invalid properties:'+JSON.stringify(msg, null, 2))

  //allow encrypted messages, where content is a base64 string.

  //NOTE: since this checks the length of javascript string,
  //it's not actually the byte length! it's the number of utf8 chars
  //for latin1 it's gonna be 8k, but if you use all utf8 you can
  //approach 32k. This is a weird legacy thing, obviously, that
  //we will fix at some point...
  var asJson = encode(msg)
  if (asJson.length > 8192) // 8kb
    return new Error('Encoded message must not be larger than 8192 bytes. Current size is '+asJson.length)

  return isInvalidContent(msg.content)
}

const isInvalidHmacKey = (hmacKey) => {
  if (hmacKey === undefined) return false
  if (hmacKey === null) return false
  const bytes = Buffer.isBuffer(hmacKey) ? hmacKey : Buffer.from(hmacKey, 'base64')

  if (typeof hmacKey === 'string') {
    if (bytes.toString('base64') !== hmacKey) return true
  }

  if (bytes.length !== 32) return true
  return false
}

function fatal(err) {
  err.fatal = true
  return err
}

exports.checkInvalidCheap = function (state, msg) {
  //the message is just invalid
  if(!ref.isFeedId(msg.author))
    return new Error('invalid message: must have author')
  if(!isSigMatchesCurve(msg))
    return new Error('invalid message: signature type must match author type')

  //state is id, sequence, timestamp
  if(state) {
    //most likely, we just tried to append two messages twice
    //or append another message after an error.
    if(msg.sequence != state.sequence + 1)
      return new Error('invalid message: expected sequence ' + (state.sequence + 1) + ' but got:'+ msg.sequence + 'in state:'+JSON.stringify(state)+', on feed:'+msg.author)
    //if we have the correct sequence and wrong previous,
    //this must be a fork!
    if(msg.previous != state.id)
      return fatal(new Error('invalid message: expected different previous message, on feed:'+msg.author))
    //and check type, and length, and some other stuff. finally check the signature.
  }
  else {
    if(msg.previous !== null)
      return fatal(new Error('initial message must have previous: null, on feed:'+msg.author))
    if(msg.sequence !== 1)
      return fatal(new Error('initial message must have sequence: 1, on feed:'+msg.author))
    if('number' !== typeof msg.timestamp)
      return fatal(new Error('initial message must have timestamp, on feed:'+msg.author))
  }
  if(!isValidOrder(msg, true))
    return fatal(new Error('message must have keys in allowed order'))

  return isInvalidShape(msg)
}

exports.checkInvalid = function (state, hmac_key, msg) {
  var err = exports.checkInvalidCheap(state, msg)
  if(err) return err

  if (isInvalidHmacKey(hmac_key)) {
    return fatal(new Error('invalid HMAC key'))
  }
  if(!ssbKeys.verifyObj({public: msg.author.substring(1)}, hmac_key, msg))
    return fatal(new Error('invalid signature'))
  return false //not invalid
}

/*
{
  //an array of messages which have been validated, but not written to the database yet.
  valid: [],
  //a map of information needed to know if something should be appeneded to the valid queue.
  feeds: {
    <feed>: {id, sequence, ts}
  },
  error: null
}
*/

exports.queue = function (state, msg) {
  state.error = exports.checkInvalidCheap(flatState(state.feeds[msg.author]), msg)

  if(state.error)
    return state
  state.feeds[msg.author] = state.feeds[msg.author] || {
    id: null, sequence: null, timestamp: null, queue: []
  }
  state.queued += 1
  state.feeds[msg.author].queue.push(exports.toKeyValueTimestamp(msg))
  return state
}

exports.toKeyValueTimestamp = function (msg, id) {
  return {
    key: id ? id : exports.id(msg),
    value: msg,
    timestamp: timestamp()
  }
}

function flatState (fstate) {
  if(!fstate) return null
  if(fstate.queue.length) {
    var last = fstate.queue[fstate.queue.length - 1]
    return {
      id: last.key,
      timestamp: last.value.timestamp,
      sequence: last.value.sequence
    }
  }
  else
    return fstate
}

exports.appendKVT = function (state, hmac_key, kvt) {
  var err
  var msg_id = kvt.key
  var msg = kvt.value
  var _state = flatState(state.feeds[msg.author])
  err = exports.checkInvalid(_state, hmac_key, msg)

  if(err)
    throw err
  else if(state.feeds[msg.author]) {
    var a = state.feeds[msg.author]
    a.id = msg_id
    a.sequence = msg.sequence
    a.timestamp = msg.timestamp
    var q = state.feeds[msg.author].queue
    state.validated += q.length
    state.queued -= q.length
    for (var i = 0; i < q.length; ++i)
      state.queue.push(q[i])
    q = []
  }
  else if(msg.sequence === 1) {
    state.feeds[msg.author] = {
      id: msg_id,
      sequence: msg.sequence,
      timestamp: msg.timestamp,
      queue: []
    }
  }

  state.queue.push(kvt)
  state.validated += 1
  return state
}

exports.append = function (state, hmac_key, msg) {
  return exports.appendKVT(state, hmac_key, exports.toKeyValueTimestamp(msg))
}

exports.checkInvalidOOO = function(msg, hmac_key) {
  if(!ref.isFeedId(msg.author))
    return new Error('invalid message: must have author')
  if(!isSigMatchesCurve(msg))
    return new Error('invalid message: signature type must match author type')
  if('number' !== typeof msg.timestamp)
    return fatal(new Error('message must have timestamp, on feed:'+msg.author))
  if(!isValidOrder(msg, true))
    return fatal(new Error('message must have keys in allowed order'))
  if (isInvalidShape(msg))
    return fatal(new Error('message has invalid shape'))
  if (isInvalidHmacKey(hmac_key))
    return fatal(new Error('invalid HMAC key'))
  if(!ssbKeys.verifyObj({public: msg.author.substring(1)}, hmac_key, msg))
    return fatal(new Error('invalid signature'))

  return false // ok
}

exports.appendOOO = function(state, hmac_key, msg) {

  state.error = exports.checkInvalidOOO(msg, hmac_key)
  if (state.error)
    return state

  var kvt = exports.toKeyValueTimestamp(msg)

  if (!state.feeds[msg.author]) {
    state.feeds[msg.author] = {
      id: kvt.key,
      sequence: msg.sequence,
      timestamp: msg.timestamp,
      queue: []
    }
  }

  state.queue.push(kvt)
  state.validated += 1
  return state
}

exports.validate = function (state, hmac_key, feed) {
  if(!isFeedId(feed)) throw new Error('validate takes a feedId')
  if(!state.feeds[feed] || !state.feeds[feed].queue.length) {
    return state
  }
  var kvt = state.feeds[feed].queue.pop()
  state.queued -= 1
  return exports.appendKVT(state, hmac_key, kvt)
}

//pass in your own timestamp, so it's completely deterministic
exports.create = function (state, keys, hmac_key, content, timestamp) {
  if(timestamp == null || isNaN(+timestamp)) throw new Error('timestamp must be provided')

  if(!isObject(content) && !isEncrypted(content))
    throw new Error('invalid message content, must be object or encrypted string')

  state = flatState(state)

  var msg = {
    previous: state ? state.id : null,
    sequence: state ? state.sequence + 1 : 1,
    author: keys.id,
    timestamp: +timestamp,
    hash: 'sha256',
    content: content
  }

  var err = isInvalidShape(msg)
  if(err) throw err
  return ssbKeys.signObj(keys, hmac_key, msg)
}

exports.id = function (msg) {
  return '%'+ssbKeys.hash(JSON.stringify(msg, null, 2))
}

exports.appendNew = function (state, hmac_key, keys, content, timestamp) {
  var msg = exports.create(state.feeds[keys.id], keys, hmac_key, content, timestamp)
  state = exports.append(state, hmac_key, msg)
  return state
}

},
"X5vv9ZQ0e6Z2W4Buw24laZvhQHYn4u6Rvl1gnkC6rLg=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var experimentalWarnings = new Set();

function emitExperimentalWarning(feature) {
  if (experimentalWarnings.has(feature)) return;
  var msg = feature + ' is an experimental feature. This feature could ' +
       'change at any time';
  experimentalWarnings.add(feature);
  process.emitWarning(msg, 'ExperimentalWarning');
}

function noop() {}

module.exports.emitExperimentalWarning = process.emitWarning
  ? emitExperimentalWarning
  : noop;

},
"XDQV/oeWHP/FA+mh10/izUwMLsV7fqT+8KS2Y/U+UrQ=":
function (require, module, exports, __dirname, __filename) {
'use strict';
module.exports = balanced;
function balanced(a, b, str) {
  if (a instanceof RegExp) a = maybeMatch(a, str);
  if (b instanceof RegExp) b = maybeMatch(b, str);

  var r = range(a, b, str);

  return r && {
    start: r[0],
    end: r[1],
    pre: str.slice(0, r[0]),
    body: str.slice(r[0] + a.length, r[1]),
    post: str.slice(r[1] + b.length)
  };
}

function maybeMatch(reg, str) {
  var m = str.match(reg);
  return m ? m[0] : null;
}

balanced.range = range;
function range(a, b, str) {
  var begs, beg, left, right, result;
  var ai = str.indexOf(a);
  var bi = str.indexOf(b, ai + 1);
  var i = ai;

  if (ai >= 0 && bi > 0) {
    begs = [];
    left = str.length;

    while (i >= 0 && !result) {
      if (i == ai) {
        begs.push(i);
        ai = str.indexOf(a, i + 1);
      } else if (begs.length == 1) {
        result = [ begs.pop(), bi ];
      } else {
        beg = begs.pop();
        if (beg < left) {
          left = beg;
          right = bi;
        }

        bi = str.indexOf(b, i + 1);
      }

      i = ai < bi && ai >= 0 ? ai : bi;
    }

    if (begs.length) {
      result = [ left, right ];
    }
  }

  return result;
}

},
"XEvlqTbwXBglNY9cRC3ZKqi62LfeapH9XI6oSQQ2tFI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
function muxrpc(type, perms) {
    return function DecorateManifestMethod(target, methodName) {
        var statics = target.constructor;
        if (target[methodName] && typeof target[methodName] !== 'function') {
            throw new Error('You can only use the @muxrpc decorator on methods, ' +
                'are you sure that is the case for `' +
                methodName +
                '`?');
        }
        // Augment the 'manifest' static field
        if (!statics.manifest) {
            statics.manifest = {};
        }
        statics.manifest[methodName] = type;
        // Augment the 'permissions' static field
        if (perms) {
            if (!statics.permissions) {
                statics.permissions = {};
            }
            for (var _i = 0, _a = Object.keys(perms); _i < _a.length; _i++) {
                var role = _a[_i];
                var decision = perms[role];
                if (!statics.permissions[role]) {
                    statics.permissions[role] = {};
                }
                if (!statics.permissions[role][decision]) {
                    statics.permissions[role][decision] = [];
                }
                statics.permissions[role][decision].push(methodName);
            }
        }
    };
}
exports.muxrpc = muxrpc;
function plugin(version) {
    return function DecorateSecretStackPlugin(constructor) {
        if (!version || typeof version !== 'string') {
            throw new Error('The @plugin decorator expects one argument: a `version` string');
        }
        // Set the 'version' static field
        constructor.version = version;
        // Set the 'init' static field
        constructor.init = function init() {
            var args = [];
            for (var _i = 0; _i < arguments.length; _i++) {
                args[_i] = arguments[_i];
            }
            var api = new (constructor.bind.apply(constructor, [void 0].concat(args)))();
            // Hide all other properties and methods, except
            // those declared in the manifest
            for (var property in api) {
                if (property in constructor.manifest) {
                    var propertyValue = api[property];
                    if (typeof propertyValue === 'function' && !Object.getOwnPropertyDescriptors(api)[property]) {
                        // not a this-bound method, bind it
                        propertyValue = propertyValue.bind(api);
                    }
                    Object.defineProperty(api, property, {
                        enumerable: true,
                        configurable: false,
                        writable: true,
                        value: propertyValue,
                    });
                }
                else {
                    Object.defineProperty(api, property, {
                        enumerable: false,
                        configurable: false,
                        writable: true,
                        value: api[property],
                    });
                }
            }
            for (var property in constructor.manifest) {
                Object.defineProperty(api, property, {
                    enumerable: true,
                    configurable: false,
                    writable: true,
                    value: api[property],
                });
            }
            return api;
        };
    };
}
exports.plugin = plugin;
//# sourceMappingURL=index.js.map
},
"Xm5jw7EUMBMShiOuJuDQxLUIWMF5s/Yfyc+u/PzIV9s=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "가격",
    "가끔",
    "가난",
    "가능",
    "가득",
    "가르침",
    "가뭄",
    "가방",
    "가상",
    "가슴",
    "가운데",
    "가을",
    "가이드",
    "가입",
    "가장",
    "가정",
    "가족",
    "가죽",
    "각오",
    "각자",
    "간격",
    "간부",
    "간섭",
    "간장",
    "간접",
    "간판",
    "갈등",
    "갈비",
    "갈색",
    "갈증",
    "감각",
    "감기",
    "감소",
    "감수성",
    "감자",
    "감정",
    "갑자기",
    "강남",
    "강당",
    "강도",
    "강력히",
    "강변",
    "강북",
    "강사",
    "강수량",
    "강아지",
    "강원도",
    "강의",
    "강제",
    "강조",
    "같이",
    "개구리",
    "개나리",
    "개방",
    "개별",
    "개선",
    "개성",
    "개인",
    "객관적",
    "거실",
    "거액",
    "거울",
    "거짓",
    "거품",
    "걱정",
    "건강",
    "건물",
    "건설",
    "건조",
    "건축",
    "걸음",
    "검사",
    "검토",
    "게시판",
    "게임",
    "겨울",
    "견해",
    "결과",
    "결국",
    "결론",
    "결석",
    "결승",
    "결심",
    "결정",
    "결혼",
    "경계",
    "경고",
    "경기",
    "경력",
    "경복궁",
    "경비",
    "경상도",
    "경영",
    "경우",
    "경쟁",
    "경제",
    "경주",
    "경찰",
    "경치",
    "경향",
    "경험",
    "계곡",
    "계단",
    "계란",
    "계산",
    "계속",
    "계약",
    "계절",
    "계층",
    "계획",
    "고객",
    "고구려",
    "고궁",
    "고급",
    "고등학생",
    "고무신",
    "고민",
    "고양이",
    "고장",
    "고전",
    "고집",
    "고춧가루",
    "고통",
    "고향",
    "곡식",
    "골목",
    "골짜기",
    "골프",
    "공간",
    "공개",
    "공격",
    "공군",
    "공급",
    "공기",
    "공동",
    "공무원",
    "공부",
    "공사",
    "공식",
    "공업",
    "공연",
    "공원",
    "공장",
    "공짜",
    "공책",
    "공통",
    "공포",
    "공항",
    "공휴일",
    "과목",
    "과일",
    "과장",
    "과정",
    "과학",
    "관객",
    "관계",
    "관광",
    "관념",
    "관람",
    "관련",
    "관리",
    "관습",
    "관심",
    "관점",
    "관찰",
    "광경",
    "광고",
    "광장",
    "광주",
    "괴로움",
    "굉장히",
    "교과서",
    "교문",
    "교복",
    "교실",
    "교양",
    "교육",
    "교장",
    "교직",
    "교통",
    "교환",
    "교훈",
    "구경",
    "구름",
    "구멍",
    "구별",
    "구분",
    "구석",
    "구성",
    "구속",
    "구역",
    "구입",
    "구청",
    "구체적",
    "국가",
    "국기",
    "국내",
    "국립",
    "국물",
    "국민",
    "국수",
    "국어",
    "국왕",
    "국적",
    "국제",
    "국회",
    "군대",
    "군사",
    "군인",
    "궁극적",
    "권리",
    "권위",
    "권투",
    "귀국",
    "귀신",
    "규정",
    "규칙",
    "균형",
    "그날",
    "그냥",
    "그늘",
    "그러나",
    "그룹",
    "그릇",
    "그림",
    "그제서야",
    "그토록",
    "극복",
    "극히",
    "근거",
    "근교",
    "근래",
    "근로",
    "근무",
    "근본",
    "근원",
    "근육",
    "근처",
    "글씨",
    "글자",
    "금강산",
    "금고",
    "금년",
    "금메달",
    "금액",
    "금연",
    "금요일",
    "금지",
    "긍정적",
    "기간",
    "기관",
    "기념",
    "기능",
    "기독교",
    "기둥",
    "기록",
    "기름",
    "기법",
    "기본",
    "기분",
    "기쁨",
    "기숙사",
    "기술",
    "기억",
    "기업",
    "기온",
    "기운",
    "기원",
    "기적",
    "기준",
    "기침",
    "기혼",
    "기획",
    "긴급",
    "긴장",
    "길이",
    "김밥",
    "김치",
    "김포공항",
    "깍두기",
    "깜빡",
    "깨달음",
    "깨소금",
    "껍질",
    "꼭대기",
    "꽃잎",
    "나들이",
    "나란히",
    "나머지",
    "나물",
    "나침반",
    "나흘",
    "낙엽",
    "난방",
    "날개",
    "날씨",
    "날짜",
    "남녀",
    "남대문",
    "남매",
    "남산",
    "남자",
    "남편",
    "남학생",
    "낭비",
    "낱말",
    "내년",
    "내용",
    "내일",
    "냄비",
    "냄새",
    "냇물",
    "냉동",
    "냉면",
    "냉방",
    "냉장고",
    "넥타이",
    "넷째",
    "노동",
    "노란색",
    "노력",
    "노인",
    "녹음",
    "녹차",
    "녹화",
    "논리",
    "논문",
    "논쟁",
    "놀이",
    "농구",
    "농담",
    "농민",
    "농부",
    "농업",
    "농장",
    "농촌",
    "높이",
    "눈동자",
    "눈물",
    "눈썹",
    "뉴욕",
    "느낌",
    "늑대",
    "능동적",
    "능력",
    "다방",
    "다양성",
    "다음",
    "다이어트",
    "다행",
    "단계",
    "단골",
    "단독",
    "단맛",
    "단순",
    "단어",
    "단위",
    "단점",
    "단체",
    "단추",
    "단편",
    "단풍",
    "달걀",
    "달러",
    "달력",
    "달리",
    "닭고기",
    "담당",
    "담배",
    "담요",
    "담임",
    "답변",
    "답장",
    "당근",
    "당분간",
    "당연히",
    "당장",
    "대규모",
    "대낮",
    "대단히",
    "대답",
    "대도시",
    "대략",
    "대량",
    "대륙",
    "대문",
    "대부분",
    "대신",
    "대응",
    "대장",
    "대전",
    "대접",
    "대중",
    "대책",
    "대출",
    "대충",
    "대통령",
    "대학",
    "대한민국",
    "대합실",
    "대형",
    "덩어리",
    "데이트",
    "도대체",
    "도덕",
    "도둑",
    "도망",
    "도서관",
    "도심",
    "도움",
    "도입",
    "도자기",
    "도저히",
    "도전",
    "도중",
    "도착",
    "독감",
    "독립",
    "독서",
    "독일",
    "독창적",
    "동화책",
    "뒷모습",
    "뒷산",
    "딸아이",
    "마누라",
    "마늘",
    "마당",
    "마라톤",
    "마련",
    "마무리",
    "마사지",
    "마약",
    "마요네즈",
    "마을",
    "마음",
    "마이크",
    "마중",
    "마지막",
    "마찬가지",
    "마찰",
    "마흔",
    "막걸리",
    "막내",
    "막상",
    "만남",
    "만두",
    "만세",
    "만약",
    "만일",
    "만점",
    "만족",
    "만화",
    "많이",
    "말기",
    "말씀",
    "말투",
    "맘대로",
    "망원경",
    "매년",
    "매달",
    "매력",
    "매번",
    "매스컴",
    "매일",
    "매장",
    "맥주",
    "먹이",
    "먼저",
    "먼지",
    "멀리",
    "메일",
    "며느리",
    "며칠",
    "면담",
    "멸치",
    "명단",
    "명령",
    "명예",
    "명의",
    "명절",
    "명칭",
    "명함",
    "모금",
    "모니터",
    "모델",
    "모든",
    "모범",
    "모습",
    "모양",
    "모임",
    "모조리",
    "모집",
    "모퉁이",
    "목걸이",
    "목록",
    "목사",
    "목소리",
    "목숨",
    "목적",
    "목표",
    "몰래",
    "몸매",
    "몸무게",
    "몸살",
    "몸속",
    "몸짓",
    "몸통",
    "몹시",
    "무관심",
    "무궁화",
    "무더위",
    "무덤",
    "무릎",
    "무슨",
    "무엇",
    "무역",
    "무용",
    "무조건",
    "무지개",
    "무척",
    "문구",
    "문득",
    "문법",
    "문서",
    "문제",
    "문학",
    "문화",
    "물가",
    "물건",
    "물결",
    "물고기",
    "물론",
    "물리학",
    "물음",
    "물질",
    "물체",
    "미국",
    "미디어",
    "미사일",
    "미술",
    "미역",
    "미용실",
    "미움",
    "미인",
    "미팅",
    "미혼",
    "민간",
    "민족",
    "민주",
    "믿음",
    "밀가루",
    "밀리미터",
    "밑바닥",
    "바가지",
    "바구니",
    "바나나",
    "바늘",
    "바닥",
    "바닷가",
    "바람",
    "바이러스",
    "바탕",
    "박물관",
    "박사",
    "박수",
    "반대",
    "반드시",
    "반말",
    "반발",
    "반성",
    "반응",
    "반장",
    "반죽",
    "반지",
    "반찬",
    "받침",
    "발가락",
    "발걸음",
    "발견",
    "발달",
    "발레",
    "발목",
    "발바닥",
    "발생",
    "발음",
    "발자국",
    "발전",
    "발톱",
    "발표",
    "밤하늘",
    "밥그릇",
    "밥맛",
    "밥상",
    "밥솥",
    "방금",
    "방면",
    "방문",
    "방바닥",
    "방법",
    "방송",
    "방식",
    "방안",
    "방울",
    "방지",
    "방학",
    "방해",
    "방향",
    "배경",
    "배꼽",
    "배달",
    "배드민턴",
    "백두산",
    "백색",
    "백성",
    "백인",
    "백제",
    "백화점",
    "버릇",
    "버섯",
    "버튼",
    "번개",
    "번역",
    "번지",
    "번호",
    "벌금",
    "벌레",
    "벌써",
    "범위",
    "범인",
    "범죄",
    "법률",
    "법원",
    "법적",
    "법칙",
    "베이징",
    "벨트",
    "변경",
    "변동",
    "변명",
    "변신",
    "변호사",
    "변화",
    "별도",
    "별명",
    "별일",
    "병실",
    "병아리",
    "병원",
    "보관",
    "보너스",
    "보라색",
    "보람",
    "보름",
    "보상",
    "보안",
    "보자기",
    "보장",
    "보전",
    "보존",
    "보통",
    "보편적",
    "보험",
    "복도",
    "복사",
    "복숭아",
    "복습",
    "볶음",
    "본격적",
    "본래",
    "본부",
    "본사",
    "본성",
    "본인",
    "본질",
    "볼펜",
    "봉사",
    "봉지",
    "봉투",
    "부근",
    "부끄러움",
    "부담",
    "부동산",
    "부문",
    "부분",
    "부산",
    "부상",
    "부엌",
    "부인",
    "부작용",
    "부장",
    "부정",
    "부족",
    "부지런히",
    "부친",
    "부탁",
    "부품",
    "부회장",
    "북부",
    "북한",
    "분노",
    "분량",
    "분리",
    "분명",
    "분석",
    "분야",
    "분위기",
    "분필",
    "분홍색",
    "불고기",
    "불과",
    "불교",
    "불꽃",
    "불만",
    "불법",
    "불빛",
    "불안",
    "불이익",
    "불행",
    "브랜드",
    "비극",
    "비난",
    "비닐",
    "비둘기",
    "비디오",
    "비로소",
    "비만",
    "비명",
    "비밀",
    "비바람",
    "비빔밥",
    "비상",
    "비용",
    "비율",
    "비중",
    "비타민",
    "비판",
    "빌딩",
    "빗물",
    "빗방울",
    "빗줄기",
    "빛깔",
    "빨간색",
    "빨래",
    "빨리",
    "사건",
    "사계절",
    "사나이",
    "사냥",
    "사람",
    "사랑",
    "사립",
    "사모님",
    "사물",
    "사방",
    "사상",
    "사생활",
    "사설",
    "사슴",
    "사실",
    "사업",
    "사용",
    "사월",
    "사장",
    "사전",
    "사진",
    "사촌",
    "사춘기",
    "사탕",
    "사투리",
    "사흘",
    "산길",
    "산부인과",
    "산업",
    "산책",
    "살림",
    "살인",
    "살짝",
    "삼계탕",
    "삼국",
    "삼십",
    "삼월",
    "삼촌",
    "상관",
    "상금",
    "상대",
    "상류",
    "상반기",
    "상상",
    "상식",
    "상업",
    "상인",
    "상자",
    "상점",
    "상처",
    "상추",
    "상태",
    "상표",
    "상품",
    "상황",
    "새벽",
    "색깔",
    "색연필",
    "생각",
    "생명",
    "생물",
    "생방송",
    "생산",
    "생선",
    "생신",
    "생일",
    "생활",
    "서랍",
    "서른",
    "서명",
    "서민",
    "서비스",
    "서양",
    "서울",
    "서적",
    "서점",
    "서쪽",
    "서클",
    "석사",
    "석유",
    "선거",
    "선물",
    "선배",
    "선생",
    "선수",
    "선원",
    "선장",
    "선전",
    "선택",
    "선풍기",
    "설거지",
    "설날",
    "설렁탕",
    "설명",
    "설문",
    "설사",
    "설악산",
    "설치",
    "설탕",
    "섭씨",
    "성공",
    "성당",
    "성명",
    "성별",
    "성인",
    "성장",
    "성적",
    "성질",
    "성함",
    "세금",
    "세미나",
    "세상",
    "세월",
    "세종대왕",
    "세탁",
    "센터",
    "센티미터",
    "셋째",
    "소규모",
    "소극적",
    "소금",
    "소나기",
    "소년",
    "소득",
    "소망",
    "소문",
    "소설",
    "소속",
    "소아과",
    "소용",
    "소원",
    "소음",
    "소중히",
    "소지품",
    "소질",
    "소풍",
    "소형",
    "속담",
    "속도",
    "속옷",
    "손가락",
    "손길",
    "손녀",
    "손님",
    "손등",
    "손목",
    "손뼉",
    "손실",
    "손질",
    "손톱",
    "손해",
    "솔직히",
    "솜씨",
    "송아지",
    "송이",
    "송편",
    "쇠고기",
    "쇼핑",
    "수건",
    "수년",
    "수단",
    "수돗물",
    "수동적",
    "수면",
    "수명",
    "수박",
    "수상",
    "수석",
    "수술",
    "수시로",
    "수업",
    "수염",
    "수영",
    "수입",
    "수준",
    "수집",
    "수출",
    "수컷",
    "수필",
    "수학",
    "수험생",
    "수화기",
    "숙녀",
    "숙소",
    "숙제",
    "순간",
    "순서",
    "순수",
    "순식간",
    "순위",
    "숟가락",
    "술병",
    "술집",
    "숫자",
    "스님",
    "스물",
    "스스로",
    "스승",
    "스웨터",
    "스위치",
    "스케이트",
    "스튜디오",
    "스트레스",
    "스포츠",
    "슬쩍",
    "슬픔",
    "습관",
    "습기",
    "승객",
    "승리",
    "승부",
    "승용차",
    "승진",
    "시각",
    "시간",
    "시골",
    "시금치",
    "시나리오",
    "시댁",
    "시리즈",
    "시멘트",
    "시민",
    "시부모",
    "시선",
    "시설",
    "시스템",
    "시아버지",
    "시어머니",
    "시월",
    "시인",
    "시일",
    "시작",
    "시장",
    "시절",
    "시점",
    "시중",
    "시즌",
    "시집",
    "시청",
    "시합",
    "시험",
    "식구",
    "식기",
    "식당",
    "식량",
    "식료품",
    "식물",
    "식빵",
    "식사",
    "식생활",
    "식초",
    "식탁",
    "식품",
    "신고",
    "신규",
    "신념",
    "신문",
    "신발",
    "신비",
    "신사",
    "신세",
    "신용",
    "신제품",
    "신청",
    "신체",
    "신화",
    "실감",
    "실내",
    "실력",
    "실례",
    "실망",
    "실수",
    "실습",
    "실시",
    "실장",
    "실정",
    "실질적",
    "실천",
    "실체",
    "실컷",
    "실태",
    "실패",
    "실험",
    "실현",
    "심리",
    "심부름",
    "심사",
    "심장",
    "심정",
    "심판",
    "쌍둥이",
    "씨름",
    "씨앗",
    "아가씨",
    "아나운서",
    "아드님",
    "아들",
    "아쉬움",
    "아스팔트",
    "아시아",
    "아울러",
    "아저씨",
    "아줌마",
    "아직",
    "아침",
    "아파트",
    "아프리카",
    "아픔",
    "아홉",
    "아흔",
    "악기",
    "악몽",
    "악수",
    "안개",
    "안경",
    "안과",
    "안내",
    "안녕",
    "안동",
    "안방",
    "안부",
    "안주",
    "알루미늄",
    "알코올",
    "암시",
    "암컷",
    "압력",
    "앞날",
    "앞문",
    "애인",
    "애정",
    "액수",
    "앨범",
    "야간",
    "야단",
    "야옹",
    "약간",
    "약국",
    "약속",
    "약수",
    "약점",
    "약품",
    "약혼녀",
    "양념",
    "양력",
    "양말",
    "양배추",
    "양주",
    "양파",
    "어둠",
    "어려움",
    "어른",
    "어젯밤",
    "어쨌든",
    "어쩌다가",
    "어쩐지",
    "언니",
    "언덕",
    "언론",
    "언어",
    "얼굴",
    "얼른",
    "얼음",
    "얼핏",
    "엄마",
    "업무",
    "업종",
    "업체",
    "엉덩이",
    "엉망",
    "엉터리",
    "엊그제",
    "에너지",
    "에어컨",
    "엔진",
    "여건",
    "여고생",
    "여관",
    "여군",
    "여권",
    "여대생",
    "여덟",
    "여동생",
    "여든",
    "여론",
    "여름",
    "여섯",
    "여성",
    "여왕",
    "여인",
    "여전히",
    "여직원",
    "여학생",
    "여행",
    "역사",
    "역시",
    "역할",
    "연결",
    "연구",
    "연극",
    "연기",
    "연락",
    "연설",
    "연세",
    "연속",
    "연습",
    "연애",
    "연예인",
    "연인",
    "연장",
    "연주",
    "연출",
    "연필",
    "연합",
    "연휴",
    "열기",
    "열매",
    "열쇠",
    "열심히",
    "열정",
    "열차",
    "열흘",
    "염려",
    "엽서",
    "영국",
    "영남",
    "영상",
    "영양",
    "영역",
    "영웅",
    "영원히",
    "영하",
    "영향",
    "영혼",
    "영화",
    "옆구리",
    "옆방",
    "옆집",
    "예감",
    "예금",
    "예방",
    "예산",
    "예상",
    "예선",
    "예술",
    "예습",
    "예식장",
    "예약",
    "예전",
    "예절",
    "예정",
    "예컨대",
    "옛날",
    "오늘",
    "오락",
    "오랫동안",
    "오렌지",
    "오로지",
    "오른발",
    "오븐",
    "오십",
    "오염",
    "오월",
    "오전",
    "오직",
    "오징어",
    "오페라",
    "오피스텔",
    "오히려",
    "옥상",
    "옥수수",
    "온갖",
    "온라인",
    "온몸",
    "온종일",
    "온통",
    "올가을",
    "올림픽",
    "올해",
    "옷차림",
    "와이셔츠",
    "와인",
    "완성",
    "완전",
    "왕비",
    "왕자",
    "왜냐하면",
    "왠지",
    "외갓집",
    "외국",
    "외로움",
    "외삼촌",
    "외출",
    "외침",
    "외할머니",
    "왼발",
    "왼손",
    "왼쪽",
    "요금",
    "요일",
    "요즘",
    "요청",
    "용기",
    "용서",
    "용어",
    "우산",
    "우선",
    "우승",
    "우연히",
    "우정",
    "우체국",
    "우편",
    "운동",
    "운명",
    "운반",
    "운전",
    "운행",
    "울산",
    "울음",
    "움직임",
    "웃어른",
    "웃음",
    "워낙",
    "원고",
    "원래",
    "원서",
    "원숭이",
    "원인",
    "원장",
    "원피스",
    "월급",
    "월드컵",
    "월세",
    "월요일",
    "웨이터",
    "위반",
    "위법",
    "위성",
    "위원",
    "위험",
    "위협",
    "윗사람",
    "유난히",
    "유럽",
    "유명",
    "유물",
    "유산",
    "유적",
    "유치원",
    "유학",
    "유행",
    "유형",
    "육군",
    "육상",
    "육십",
    "육체",
    "은행",
    "음력",
    "음료",
    "음반",
    "음성",
    "음식",
    "음악",
    "음주",
    "의견",
    "의논",
    "의문",
    "의복",
    "의식",
    "의심",
    "의외로",
    "의욕",
    "의원",
    "의학",
    "이것",
    "이곳",
    "이념",
    "이놈",
    "이달",
    "이대로",
    "이동",
    "이렇게",
    "이력서",
    "이론적",
    "이름",
    "이민",
    "이발소",
    "이별",
    "이불",
    "이빨",
    "이상",
    "이성",
    "이슬",
    "이야기",
    "이용",
    "이웃",
    "이월",
    "이윽고",
    "이익",
    "이전",
    "이중",
    "이튿날",
    "이틀",
    "이혼",
    "인간",
    "인격",
    "인공",
    "인구",
    "인근",
    "인기",
    "인도",
    "인류",
    "인물",
    "인생",
    "인쇄",
    "인연",
    "인원",
    "인재",
    "인종",
    "인천",
    "인체",
    "인터넷",
    "인하",
    "인형",
    "일곱",
    "일기",
    "일단",
    "일대",
    "일등",
    "일반",
    "일본",
    "일부",
    "일상",
    "일생",
    "일손",
    "일요일",
    "일월",
    "일정",
    "일종",
    "일주일",
    "일찍",
    "일체",
    "일치",
    "일행",
    "일회용",
    "임금",
    "임무",
    "입대",
    "입력",
    "입맛",
    "입사",
    "입술",
    "입시",
    "입원",
    "입장",
    "입학",
    "자가용",
    "자격",
    "자극",
    "자동",
    "자랑",
    "자부심",
    "자식",
    "자신",
    "자연",
    "자원",
    "자율",
    "자전거",
    "자정",
    "자존심",
    "자판",
    "작가",
    "작년",
    "작성",
    "작업",
    "작용",
    "작은딸",
    "작품",
    "잔디",
    "잔뜩",
    "잔치",
    "잘못",
    "잠깐",
    "잠수함",
    "잠시",
    "잠옷",
    "잠자리",
    "잡지",
    "장관",
    "장군",
    "장기간",
    "장래",
    "장례",
    "장르",
    "장마",
    "장면",
    "장모",
    "장미",
    "장비",
    "장사",
    "장소",
    "장식",
    "장애인",
    "장인",
    "장점",
    "장차",
    "장학금",
    "재능",
    "재빨리",
    "재산",
    "재생",
    "재작년",
    "재정",
    "재채기",
    "재판",
    "재학",
    "재활용",
    "저것",
    "저고리",
    "저곳",
    "저녁",
    "저런",
    "저렇게",
    "저번",
    "저울",
    "저절로",
    "저축",
    "적극",
    "적당히",
    "적성",
    "적용",
    "적응",
    "전개",
    "전공",
    "전기",
    "전달",
    "전라도",
    "전망",
    "전문",
    "전반",
    "전부",
    "전세",
    "전시",
    "전용",
    "전자",
    "전쟁",
    "전주",
    "전철",
    "전체",
    "전통",
    "전혀",
    "전후",
    "절대",
    "절망",
    "절반",
    "절약",
    "절차",
    "점검",
    "점수",
    "점심",
    "점원",
    "점점",
    "점차",
    "접근",
    "접시",
    "접촉",
    "젓가락",
    "정거장",
    "정도",
    "정류장",
    "정리",
    "정말",
    "정면",
    "정문",
    "정반대",
    "정보",
    "정부",
    "정비",
    "정상",
    "정성",
    "정오",
    "정원",
    "정장",
    "정지",
    "정치",
    "정확히",
    "제공",
    "제과점",
    "제대로",
    "제목",
    "제발",
    "제법",
    "제삿날",
    "제안",
    "제일",
    "제작",
    "제주도",
    "제출",
    "제품",
    "제한",
    "조각",
    "조건",
    "조금",
    "조깅",
    "조명",
    "조미료",
    "조상",
    "조선",
    "조용히",
    "조절",
    "조정",
    "조직",
    "존댓말",
    "존재",
    "졸업",
    "졸음",
    "종교",
    "종로",
    "종류",
    "종소리",
    "종업원",
    "종종",
    "종합",
    "좌석",
    "죄인",
    "주관적",
    "주름",
    "주말",
    "주머니",
    "주먹",
    "주문",
    "주민",
    "주방",
    "주변",
    "주식",
    "주인",
    "주일",
    "주장",
    "주전자",
    "주택",
    "준비",
    "줄거리",
    "줄기",
    "줄무늬",
    "중간",
    "중계방송",
    "중국",
    "중년",
    "중단",
    "중독",
    "중반",
    "중부",
    "중세",
    "중소기업",
    "중순",
    "중앙",
    "중요",
    "중학교",
    "즉석",
    "즉시",
    "즐거움",
    "증가",
    "증거",
    "증권",
    "증상",
    "증세",
    "지각",
    "지갑",
    "지경",
    "지극히",
    "지금",
    "지급",
    "지능",
    "지름길",
    "지리산",
    "지방",
    "지붕",
    "지식",
    "지역",
    "지우개",
    "지원",
    "지적",
    "지점",
    "지진",
    "지출",
    "직선",
    "직업",
    "직원",
    "직장",
    "진급",
    "진동",
    "진로",
    "진료",
    "진리",
    "진짜",
    "진찰",
    "진출",
    "진통",
    "진행",
    "질문",
    "질병",
    "질서",
    "짐작",
    "집단",
    "집안",
    "집중",
    "짜증",
    "찌꺼기",
    "차남",
    "차라리",
    "차량",
    "차림",
    "차별",
    "차선",
    "차츰",
    "착각",
    "찬물",
    "찬성",
    "참가",
    "참기름",
    "참새",
    "참석",
    "참여",
    "참외",
    "참조",
    "찻잔",
    "창가",
    "창고",
    "창구",
    "창문",
    "창밖",
    "창작",
    "창조",
    "채널",
    "채점",
    "책가방",
    "책방",
    "책상",
    "책임",
    "챔피언",
    "처벌",
    "처음",
    "천국",
    "천둥",
    "천장",
    "천재",
    "천천히",
    "철도",
    "철저히",
    "철학",
    "첫날",
    "첫째",
    "청년",
    "청바지",
    "청소",
    "청춘",
    "체계",
    "체력",
    "체온",
    "체육",
    "체중",
    "체험",
    "초등학생",
    "초반",
    "초밥",
    "초상화",
    "초순",
    "초여름",
    "초원",
    "초저녁",
    "초점",
    "초청",
    "초콜릿",
    "촛불",
    "총각",
    "총리",
    "총장",
    "촬영",
    "최근",
    "최상",
    "최선",
    "최신",
    "최악",
    "최종",
    "추석",
    "추억",
    "추진",
    "추천",
    "추측",
    "축구",
    "축소",
    "축제",
    "축하",
    "출근",
    "출발",
    "출산",
    "출신",
    "출연",
    "출입",
    "출장",
    "출판",
    "충격",
    "충고",
    "충돌",
    "충분히",
    "충청도",
    "취업",
    "취직",
    "취향",
    "치약",
    "친구",
    "친척",
    "칠십",
    "칠월",
    "칠판",
    "침대",
    "침묵",
    "침실",
    "칫솔",
    "칭찬",
    "카메라",
    "카운터",
    "칼국수",
    "캐릭터",
    "캠퍼스",
    "캠페인",
    "커튼",
    "컨디션",
    "컬러",
    "컴퓨터",
    "코끼리",
    "코미디",
    "콘서트",
    "콜라",
    "콤플렉스",
    "콩나물",
    "쾌감",
    "쿠데타",
    "크림",
    "큰길",
    "큰딸",
    "큰소리",
    "큰아들",
    "큰어머니",
    "큰일",
    "큰절",
    "클래식",
    "클럽",
    "킬로",
    "타입",
    "타자기",
    "탁구",
    "탁자",
    "탄생",
    "태권도",
    "태양",
    "태풍",
    "택시",
    "탤런트",
    "터널",
    "터미널",
    "테니스",
    "테스트",
    "테이블",
    "텔레비전",
    "토론",
    "토마토",
    "토요일",
    "통계",
    "통과",
    "통로",
    "통신",
    "통역",
    "통일",
    "통장",
    "통제",
    "통증",
    "통합",
    "통화",
    "퇴근",
    "퇴원",
    "퇴직금",
    "튀김",
    "트럭",
    "특급",
    "특별",
    "특성",
    "특수",
    "특징",
    "특히",
    "튼튼히",
    "티셔츠",
    "파란색",
    "파일",
    "파출소",
    "판결",
    "판단",
    "판매",
    "판사",
    "팔십",
    "팔월",
    "팝송",
    "패션",
    "팩스",
    "팩시밀리",
    "팬티",
    "퍼센트",
    "페인트",
    "편견",
    "편의",
    "편지",
    "편히",
    "평가",
    "평균",
    "평생",
    "평소",
    "평양",
    "평일",
    "평화",
    "포스터",
    "포인트",
    "포장",
    "포함",
    "표면",
    "표정",
    "표준",
    "표현",
    "품목",
    "품질",
    "풍경",
    "풍속",
    "풍습",
    "프랑스",
    "프린터",
    "플라스틱",
    "피곤",
    "피망",
    "피아노",
    "필름",
    "필수",
    "필요",
    "필자",
    "필통",
    "핑계",
    "하느님",
    "하늘",
    "하드웨어",
    "하룻밤",
    "하반기",
    "하숙집",
    "하순",
    "하여튼",
    "하지만",
    "하천",
    "하품",
    "하필",
    "학과",
    "학교",
    "학급",
    "학기",
    "학년",
    "학력",
    "학번",
    "학부모",
    "학비",
    "학생",
    "학술",
    "학습",
    "학용품",
    "학원",
    "학위",
    "학자",
    "학점",
    "한계",
    "한글",
    "한꺼번에",
    "한낮",
    "한눈",
    "한동안",
    "한때",
    "한라산",
    "한마디",
    "한문",
    "한번",
    "한복",
    "한식",
    "한여름",
    "한쪽",
    "할머니",
    "할아버지",
    "할인",
    "함께",
    "함부로",
    "합격",
    "합리적",
    "항공",
    "항구",
    "항상",
    "항의",
    "해결",
    "해군",
    "해답",
    "해당",
    "해물",
    "해석",
    "해설",
    "해수욕장",
    "해안",
    "핵심",
    "핸드백",
    "햄버거",
    "햇볕",
    "햇살",
    "행동",
    "행복",
    "행사",
    "행운",
    "행위",
    "향기",
    "향상",
    "향수",
    "허락",
    "허용",
    "헬기",
    "현관",
    "현금",
    "현대",
    "현상",
    "현실",
    "현장",
    "현재",
    "현지",
    "혈액",
    "협력",
    "형부",
    "형사",
    "형수",
    "형식",
    "형제",
    "형태",
    "형편",
    "혜택",
    "호기심",
    "호남",
    "호랑이",
    "호박",
    "호텔",
    "호흡",
    "혹시",
    "홀로",
    "홈페이지",
    "홍보",
    "홍수",
    "홍차",
    "화면",
    "화분",
    "화살",
    "화요일",
    "화장",
    "화학",
    "확보",
    "확인",
    "확장",
    "확정",
    "환갑",
    "환경",
    "환영",
    "환율",
    "환자",
    "활기",
    "활동",
    "활발히",
    "활용",
    "활짝",
    "회견",
    "회관",
    "회복",
    "회색",
    "회원",
    "회장",
    "회전",
    "횟수",
    "횡단보도",
    "효율적",
    "후반",
    "후춧가루",
    "훈련",
    "훨씬",
    "휴식",
    "휴일",
    "흉내",
    "흐름",
    "흑백",
    "흑인",
    "흔적",
    "흔히",
    "흥미",
    "흥분",
    "희곡",
    "희망",
    "희생",
    "흰색",
    "힘껏"
]

},
"XpAmElnGd0xgrvHyA0J6tXyfvC5SYVReo9axfzxLZy8=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const currify = require('currify');

/*
    S_IRUSR   0000400   protection: readable by owner
    S_IWUSR   0000200   writable by owner
    S_IXUSR   0000100   executable by owner
    S_IRGRP   0000040   readable by group
    S_IWGRP   0000020   writable by group
    S_IXGRP   0000010   executable by group
    S_IROTH   0000004   readable by all
    S_IWOTH   0000002   writable by all
    S_IXOTH   0000001   executable by all
*/

const R = {
    name: 'r',
    value: 4,
};

const W = {
    name: 'w',
    value: 2,
};

const X = {
    name: 'x',
    value: 1,
};

const getModeName = currify((value, m) => {
    if (value & m.value)
        return m.name;
    
    return '-';
});

const toStrMode = currify((fn, value) => {
    return [R, W, X]
        .map(fn(value))
        .join('');
});


/**
 * Функция переводит права из цыфрового вида в символьный
 * @param perms - строка с правами доступа
 * к файлу в 8-миричной системе
 */
module.exports.symbolic = (perms) => {
    let permissions = '';
    const is = typeof perms !== 'undefined';
    
    if (!is)
        return permissions;
    
    const permsStr = perms.slice(-3);
    
    /* Переводим в двоичную систему */
    const owner = Number(permsStr[0]).toString(2);
    const group = Number(permsStr[1]).toString(2);
    const all   = Number(permsStr[2]).toString(2);
    
    const allPermissions = [
        owner,
        group,
        all,
    ];
    
    return allPermissions
        .map(toStrMode(getModeName))
        .join(' ');
};

/**
 * Функция конвертирует права доступа к файлам из символьного вида
 * в цыфровой
 */
module.exports.numeric = (perms) => {
    const length = perms && perms.length === 11;
    
    if (!length)
        throw Error('permissions should be in format "xxx xxx xxx"');
    
    const R = 4;
    const W = 2;
    const X = 1;
    const N = 0;
    
    const owner =
        (perms[0]  === 'r' ? R : N) +
        (perms[1]  === 'w' ? W : N) +
        (perms[2]  === 'x' ? X : N);
    
    const group =
        (perms[4]  === 'r' ? R : N) +
        (perms[5]  === 'w' ? W : N) +
        (perms[6]  === 'x' ? X : N);
     
    const all =
        (perms[8]  === 'r' ? R : N) +
        (perms[9]  === 'w' ? W : N) +
        (perms[10] === 'x' ? X : N);
    
    /* добавляем 2 цифры до 5 */
    return '00' + owner + group + all;
};


},
"XuAW+tXD3JQOEIun7Wse5aJTjgCWFU7RezxH/G/6kpU=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bipf = require('bipf')
const traverse = require('traverse')
const promisify = require('promisify-4loc')
const pull = require('pull-stream')
const multicb = require('multicb')
const pullAwaitable = require('pull-awaitable')
const cat = require('pull-cat')
const { safeFilename } = require('./files')

//#region Helper functions and util operators

function copyMeta(orig, dest) {
  if (orig.meta) {
    dest.meta = orig.meta
  }
}

function updateMeta(orig, key, value) {
  const res = Object.assign({}, orig)
  res.meta[key] = value
  return res
}

function extractMeta(orig) {
  const meta = orig.meta
  return meta
}

const seekFromDescCache = new Map()
function seekFromDesc(desc) {
  if (seekFromDescCache.has(desc)) {
    return seekFromDescCache.get(desc)
  }
  const keys = desc.split('.').map((str) => Buffer.from(str))
  // The 2nd arg `start` is to support plucks too
  const fn = function (buffer, start = 0) {
    var p = start
    for (let key of keys) {
      p = bipf.seekKey(buffer, p, key)
      if (p < 0) return -1
    }
    return p
  }
  seekFromDescCache.set(desc, fn)
  return fn
}

function getIndexName(opts, indexType, valueName) {
  return safeFilename(
    opts.prefix
      ? opts.useMap
        ? indexType + '__map'
        : indexType
      : indexType + '_' + valueName
  )
}

function query(...cbs) {
  let res = cbs[0]
  for (let i = 1, n = cbs.length; i < n; i++) if (cbs[i]) res = cbs[i](res)
  return res
}

function debug() {
  return (ops) => {
    const meta = JSON.stringify(ops.meta, (key, val) =>
      key === 'jitdb' ? void 0 : val
    )
    console.log(
      'debug',
      JSON.stringify(
        ops,
        (key, val) => {
          if (key === 'meta') return void 0
          else if (key === 'task' && typeof val === 'function')
            return '[Function]'
          else if (key === 'value' && val.type === 'Buffer')
            return Buffer.from(val.data).toString()
          else return val
        },
        2
      ),
      meta === '{}' ? '' : 'meta: ' + meta
    )
    return ops
  }
}

//#endregion
//#region "Unit operators": they create objects that JITDB interprets

function slowEqual(seekDesc, target, opts) {
  opts = opts || {}
  const seek = seekFromDesc(seekDesc)
  const value = bipf.allocAndEncode(target)
  const valueName = !target ? '' : `${target}`
  const indexType = seekDesc.replace(/\./g, '_')
  const indexName = getIndexName(opts, indexType, valueName)
  return {
    type: 'EQUAL',
    data: {
      seek,
      value,
      indexType,
      indexName,
      useMap: opts.useMap,
      indexAll: opts.indexAll,
      prefix: opts.prefix,
      prefixOffset: opts.prefixOffset,
    },
  }
}

function equal(seek, target, opts) {
  opts = opts || {}
  if (!opts.indexType)
    throw new Error('equal() operator needs an indexType in the 3rd arg')
  const value = bipf.allocAndEncode(target)
  const valueName = !target ? '' : `${target}`
  const indexType = opts.indexType
  const indexName = getIndexName(opts, indexType, valueName)
  return {
    type: 'EQUAL',
    data: {
      seek,
      value,
      indexType,
      indexName,
      useMap: opts.useMap,
      indexAll: opts.indexAll,
      prefix: opts.prefix,
      prefixOffset: opts.prefixOffset,
    },
  }
}

function slowPredicate(seekDesc, fn, opts) {
  opts = opts || {}
  const seek = seekFromDesc(seekDesc)
  if (typeof fn !== 'function')
    throw new Error('predicate() needs a predicate function in the 2rd arg')
  const value = fn
  const indexType = seekDesc.replace(/\./g, '_')
  const name = opts.name || fn.name
  if (!name) throw new Error('predicate() needs opts.name')
  const indexName = safeFilename(indexType + '__pred_' + name)
  return {
    type: 'PREDICATE',
    data: {
      seek,
      value,
      indexType,
      indexName,
    },
  }
}

function predicate(seek, fn, opts) {
  opts = opts || {}
  if (!opts.indexType)
    throw new Error('predicate() operator needs an indexType in the 3rd arg')
  if (typeof fn !== 'function')
    throw new Error('predicate() needs a predicate function in the 2rd arg')
  const value = fn
  const indexType = opts.indexType
  const name = opts.name || fn.name
  if (!name) throw new Error('predicate() needs opts.name')
  const indexName = safeFilename(indexType + '__pred_' + name)
  return {
    type: 'PREDICATE',
    data: {
      seek,
      value,
      indexType,
      indexName,
    },
  }
}

function slowAbsent(seekDesc) {
  const seek = seekFromDesc(seekDesc)
  const indexType = seekDesc.replace(/\./g, '_')
  const indexName = safeFilename(indexType + '__absent')
  return {
    type: 'ABSENT',
    data: {
      seek,
      indexType,
      indexName,
    },
  }
}

function absent(seek, opts) {
  opts = opts || {}
  if (!opts.indexType)
    throw new Error('absent() operator needs an indexType in the 3rd arg')
  const indexType = opts.indexType
  const indexName = safeFilename(indexType + '__absent')
  return {
    type: 'ABSENT',
    data: {
      seek,
      indexType,
      indexName,
    },
  }
}

function slowIncludes(seekDesc, target, opts) {
  opts = opts || {}
  const seek = seekFromDesc(seekDesc)
  const value = bipf.allocAndEncode(target)
  if (!value) throw new Error('slowIncludes() 2nd arg needs to be truthy')
  const valueName = !target ? '' : `${target}`
  const indexType = seekDesc.replace(/\./g, '_')
  const indexName = safeFilename(indexType + '_' + valueName)
  const pluck =
    opts.pluck && typeof opts.pluck === 'string'
      ? seekFromDesc(opts.pluck)
      : opts.pluck
  return {
    type: 'INCLUDES',
    data: {
      seek,
      value,
      indexType,
      indexName,
      indexAll: opts.indexAll,
      pluck,
    },
  }
}

function includes(seek, target, opts) {
  opts = opts || {}
  if (!opts.indexType)
    throw new Error('includes() operator needs an indexType in the 3rd arg')
  const value = bipf.allocAndEncode(target)
  if (!value) throw new Error('includes() 2nd arg needs to be truthy')
  const valueName = !target ? '' : `${target}`
  const indexType = opts.indexType
  const indexName = safeFilename(indexType + '_' + valueName)
  return {
    type: 'INCLUDES',
    data: {
      seek,
      value,
      indexType,
      indexName,
      indexAll: opts.indexAll,
      pluck: opts.pluck,
    },
  }
}

function gt(value, indexName) {
  if (typeof value !== 'number') throw new Error('gt() needs a number arg')
  return {
    type: 'GT',
    data: {
      value,
      indexName,
    },
  }
}

function gte(value, indexName) {
  if (typeof value !== 'number') throw new Error('gte() needs a number arg')
  return {
    type: 'GTE',
    data: {
      value,
      indexName,
    },
  }
}

function lt(value, indexName) {
  if (typeof value !== 'number') throw new Error('lt() needs a number arg')
  return {
    type: 'LT',
    data: {
      value,
      indexName,
    },
  }
}

function lte(value, indexName) {
  if (typeof value !== 'number') throw new Error('lte() needs a number arg')
  return {
    type: 'LTE',
    data: {
      value,
      indexName,
    },
  }
}

function seqs(values) {
  return {
    type: 'SEQS',
    seqs: values,
  }
}

function liveSeqs(pullStream) {
  return {
    type: 'LIVESEQS',
    stream: pullStream,
  }
}

function offsets(values) {
  return {
    type: 'OFFSETS',
    offsets: values,
  }
}

function deferred(task) {
  return {
    type: 'DEFERRED',
    task,
  }
}

//#endregion
//#region "Combinator operators": they build composite operations

function not(ops) {
  return {
    type: 'NOT',
    data: [ops],
  }
}

function and(...args) {
  const validargs = args.filter((arg) => !!arg)
  if (validargs.length === 0) return {}
  if (validargs.length === 1) return validargs[0]
  return { type: 'AND', data: validargs }
}

function or(...args) {
  const validargs = args.filter((arg) => !!arg)
  if (validargs.length === 0) return {}
  if (validargs.length === 1) return validargs[0]
  return { type: 'OR', data: validargs }
}

function where(...args) {
  return (prevOp) => {
    if (args.length !== 1) throw new Error('where() accepts only one argument')
    const nextOp = args[0]
    if (!nextOp) return prevOp
    const res = prevOp.type ? { type: 'AND', data: [prevOp, nextOp] } : nextOp
    copyMeta(prevOp, res)
    return res
  }
}

//#endregion
//#region "Special operators": they only update meta

function fromDB(jitdb) {
  return {
    meta: { jitdb },
  }
}

function live(opts) {
  if (opts && opts.old) return (ops) => updateMeta(ops, 'live', 'liveAndOld')
  else return (ops) => updateMeta(ops, 'live', 'liveOnly')
}

function count() {
  return (ops) => updateMeta(ops, 'count', true)
}

function descending() {
  return (ops) => updateMeta(ops, 'descending', true)
}

function startFrom(seq) {
  return (ops) => updateMeta(ops, 'seq', seq)
}

function paginate(pageSize) {
  return (ops) => updateMeta(ops, 'pageSize', pageSize)
}

function batch(batchSize) {
  return (ops) => updateMeta(ops, 'batchSize', batchSize)
}

function asOffsets() {
  return (ops) => updateMeta(ops, 'asOffsets', true)
}

//#endregion
//#region "Consumer operators": they execute the query tree

function executeDeferredOps(ops, meta) {
  // Collect all deferred tasks and their object-traversal paths
  const allDeferred = []
  traverse.forEach(ops, function (val) {
    if (!val) return
    // this.block() means don't traverse inside these, they won't have DEFERRED
    if (this.key === 'meta' && val.jitdb) return this.block()
    if (val.type === 'DEFERRED' && val.task) {
      allDeferred.push([this.path, val.task])
    }
    if (!(Array.isArray(val) || val.type === 'AND' || val.type === 'OR')) {
      this.block()
    }
  })
  if (allDeferred.length === 0) return pull.values([ops])

  // State needed throughout the execution of the `readable`
  const done = multicb({ pluck: 1 })
  let completed = false
  const abortListeners = []
  function addAbortListener(listener) {
    abortListeners.push(listener)
  }

  return function readable(end, cb) {
    if (end) {
      while (abortListeners.length) abortListeners.shift()()
      cb(end)
      return
    }
    if (completed) {
      cb(true)
      return
    }

    // Execute all deferred tasks and collect the results (and the paths)
    for (const [path, task] of allDeferred) {
      const taskCB = done()
      task(
        meta,
        (err, result) => {
          if (err) taskCB(err)
          else if (!result) taskCB(null, [path, {}])
          else if (typeof result === 'function') taskCB(null, [path, result()])
          else taskCB(null, [path, result])
        },
        addAbortListener
      )
    }

    // When all tasks are done...
    done((err, results) => {
      if (err) return cb(err)

      // Replace/mutate all deferreds with their respective results
      for (const [path, result] of results) {
        result.meta = meta
        if (path.length === 0) ops = result
        else traverse.set(ops, path, result)
      }
      completed = true
      cb(null, ops)
    })
  }
}

function toCallback(cb) {
  return (rawOps) => {
    const meta = extractMeta(rawOps)
    const readable = executeDeferredOps(rawOps, meta)
    readable(null, (end, ops) => {
      if (end) return cb(end)

      const seq = meta.seq || 0
      const { pageSize, descending, asOffsets } = meta
      if (meta.count) meta.jitdb.count(ops, seq, descending, cb)
      else if (pageSize)
        meta.jitdb.paginate(ops, seq, pageSize, descending, asOffsets, cb)
      else meta.jitdb.all(ops, seq, descending, asOffsets, cb)
    })
  }
}

function toPromise() {
  return (rawOps) => {
    return promisify((cb) => toCallback(cb)(rawOps))()
  }
}

function toPullStream() {
  return (rawOps) => {
    const meta = extractMeta(rawOps)

    function paginateStream(ops) {
      let seq = meta.seq || 0
      let total = Infinity
      const limit = meta.pageSize || meta.batchSize || 20
      let shouldEnd = false
      function readable(end, cb) {
        if (end) return cb(end)
        if (seq >= total || shouldEnd) return cb(true)
        if (meta.count) {
          shouldEnd = true
          meta.jitdb.count(ops, seq, meta.descending, cb)
        } else {
          meta.jitdb.paginate(
            ops,
            seq,
            limit,
            meta.descending,
            meta.asOffsets,
            (err, answer) => {
              if (err) return cb(err)
              else if (answer.total === 0) cb(true)
              else {
                total = answer.total
                seq += limit
                cb(null, answer.results)
              }
            }
          )
        }
      }
      if (meta.pageSize || meta.count) {
        return readable
      } else {
        // Flatten the "pages" (arrays) into individual messages
        return pull(readable, pull.map(pull.values), pull.flatten())
      }
    }

    return pull(
      executeDeferredOps(rawOps, meta),
      pull.map((ops) => {
        if (meta.live === 'liveOnly') return meta.jitdb.live(ops)
        else if (meta.live === 'liveAndOld')
          return cat([paginateStream(ops), meta.jitdb.live(ops)])
        else return paginateStream(ops)
      }),
      pull.flatten()
    )
  }
}

// `async function*` supported in Node 10+ and browsers (except IE11)
function toAsyncIter() {
  return async function* (rawOps) {
    const ps = toPullStream()(rawOps)
    for await (let x of pullAwaitable(ps)) yield x
  }
}

//#endregion

module.exports = {
  fromDB,
  query,

  live,
  slowEqual,
  equal,
  slowPredicate,
  predicate,
  slowAbsent,
  absent,
  slowIncludes,
  includes,
  where,
  not,
  gt,
  gte,
  lt,
  lte,
  and,
  or,
  deferred,
  liveSeqs,

  seqs,
  offsets,

  descending,
  count,
  startFrom,
  paginate,
  batch,
  asOffsets,
  toCallback,
  toPullStream,
  toPromise,
  toAsyncIter,

  debug,
}

},
"Xz71w1g5FDlgcpQB1RsYHmnE9+BZfKrwfQyi9hcFlUM=":
function (require, module, exports, __dirname, __filename) {
var of = require("./of")

module.exports = either

//  either := (source: Continuable<A>,
//             left: (Error, cb?: Callback<B>) => Continuable<B>,
//             right?: (A) => Continuable<B>)
//      => Continuable<B>
function either(cont, left, right) {
    right = right || of

    return function continuable(callback) {
        cont(function (err, value) {
            if (!err) {
                return right(value)(callback)
            }

            // the left function takes either a callback or
            // it returns a continuable. Both are valid
            var cont = left(err, callback)

            if (cont) {
                cont(callback)
            }
        })
    }
}

},
"Y+2gkwdLlIBxgdH77po/jb0qOji4zCh4KcQRf87J2Mw=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const pull = require('pull-stream')
const EBTIndex = require('../indexes/ebt')
const { onceWhen } = require('../utils')

exports.init = function (sbot, config) {
  sbot.db.registerIndex(EBTIndex)
  if (!sbot.post) sbot.post = sbot.db.post
  sbot.getAtSequence = (key, cb) => {
    sbot.db.onDrain('ebt', () => {
      sbot.db.getIndex('ebt').getMessageFromAuthorSequence(key, cb)
    })
  }
  sbot.add = sbot.db.add
  sbot.getVectorClock = function (cb) {
    onceWhen(
      sbot.db2migrate && sbot.db2migrate.synchronized,
      (isSynced) => isSynced,
      () => {
        sbot.db.onDrain('base', () => {
          const clock = {}
          pull(
            sbot.db.getAllLatest(),
            pull.through(({ key, value }) => {
              const authorId = key
              const { sequence } = value
              clock[authorId] = sequence
            }),
            pull.collect((err) => {
              if (err) return cb(err)
              cb(null, clock)
            })
          )
        })
      }
    )
  }
}

},
"Y/mK/q7HVIcAcgijekW/+GtvjwUHdEMkHs05wj09wd0=":
function (require, module, exports, __dirname, __filename) {

module.exports = function (streams) {
  if(!Array.isArray(streams))
    streams = [].slice.call(arguments)
  var queue = []
  var ended = []
  var err
  return function (end, cb) {
    var n = streams.length
    queue = []
    streams.forEach(function (stream, i) {
      if(ended[i]) return next()
      stream(null, function (end, data) {
        if(end) ended[i] = end, queue[i] = null
        else    queue[i] = data
        next()
      })
    })

    function next() {
      if(--n) return
      var l = streams.length, end = 0
      while(l--)
        if(ended[l]) end ++

      if(end === streams.length)
        cb(true)
      else cb(null, queue)
    }
  }
}


},
"Y6njsb3hYiFuo65OiDuJsxZxHsViNUW9zbNVD9KiL5U=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

module.exports = class DebouncingBatchAdd {
  constructor(addBatch, period) {
    this.addBatch = addBatch
    this.period = period
    this.queueByAuthor = new Map()
    this.timestampsByAuthor = new Map()
    this.timer = null
  }

  flush(authorId) {
    const queue = this.queueByAuthor.get(authorId)
    const n = queue.length
    const msgVals = queue.map((x) => x[0])
    // Clear the queue memory BEFORE the callbacks trigger more queue additions
    this.queueByAuthor.delete(authorId)
    this.timestampsByAuthor.delete(authorId)
    // Add the messages in the queue
    this.addBatch(msgVals, (err, kvts) => {
      if (err) {
        for (let i = 0; i < n; ++i) {
          const cb = queue[i][1]
          cb(err)
        }
      } else if (kvts.length !== n) {
        for (let i = 0; i < n; ++i) {
          const cb = queue[i][1]
          cb(new Error(`unexpected addBatch mismatch: ${kvts.length}} != ${n}`))
        }
      } else {
        for (let i = 0; i < n; ++i) {
          const kvt = kvts[i]
          const cb = queue[i][1]
          cb(null, kvt)
        }
      }
    })
  }

  scheduleFlush() {
    // Timer is already enabled
    if (this.timer) return

    this.timer = setInterval(() => {
      // Turn off the timer if there is nothing to flush
      if (this.queueByAuthor.size === 0) {
        clearInterval(this.timer)
        this.timer = null
      }
      // For each author, flush if enough time has passed
      else {
        const now = Date.now()
        for (const authorId of this.queueByAuthor.keys()) {
          const lastAdded = this.timestampsByAuthor.get(authorId)
          if (now - lastAdded > this.period) {
            this.flush(authorId)
          }
        }
      }
    }, this.period * 0.5)
  }

  add(msgVal, cb) {
    const authorId = msgVal.author
    const queue = this.queueByAuthor.get(authorId) || []
    queue.push([msgVal, cb])
    this.queueByAuthor.set(authorId, queue)
    this.timestampsByAuthor.set(authorId, Date.now())
    this.scheduleFlush()
  }
}

},
"Y733ooKNRRAcMO7Z0Cip/iPeOfyYjt1YlNR5Gp1KlIg=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const fs = require("fs");
const path = require("path");
const os = require("os");
const migration_1 = require("./migration");
const atomic_file_codecs_1 = require("./atomic-file-codecs");
const atomic = require('atomic-file-rw');
const Notify = require('pull-notify');
const msAddress = require('multiserver-address');
const debug = require('debug')('ssb:conn-db');
const defaultOpts = {
    path: path.join(os.homedir(), '.ssb'),
    writeTimeout: 2000,
};
class ConnDB {
    constructor(opts) {
        var _a;
        const dirPath = (_a = opts.path) !== null && _a !== void 0 ? _a : defaultOpts.path;
        const legacyPath = path.join(dirPath, 'gossip.json');
        this._modernPath = path.join(dirPath, 'conn.json');
        this._map = new Map();
        this._notify = Notify();
        this._writeTimeout =
            typeof opts.writeTimeout === 'number'
                ? opts.writeTimeout
                : defaultOpts.writeTimeout;
        this._scheduledWriteTask = null;
        this._closed = false;
        this._loadedPromise = new Promise((resolve, reject) => {
            this._loadedResolve = resolve;
            this._loadedReject = reject;
        });
        this._init(this._modernPath, legacyPath);
    }
    _fileExists(path, cb) {
        if (typeof localStorage === 'undefined' || localStorage === null) {
            cb(fs.existsSync(path));
        }
        else {
            atomic.readFile(path, (err) => {
                if (err)
                    cb(false);
                else
                    cb(true);
            });
        }
    }
    _init(modernPath, legacyPath) {
        this._fileExists(modernPath, (modernExists) => {
            this._fileExists(legacyPath, (legacyExists) => {
                if (!modernExists && !legacyExists) {
                    atomic.writeFile(modernPath, '{}', 'utf8', () => { });
                    this._loadedResolve(true);
                    debug('Created new conn.json because there was no existing ' +
                        'conn.json nor gossip.json');
                    return;
                }
                if (!modernExists && legacyExists) {
                    atomic.readFile(legacyPath, 'utf8', (err, data) => {
                        if (err) {
                            this._loadedReject(err);
                            debug('Failed to load gossip.json, for creating conn.json');
                            return;
                        }
                        const oldVals = JSON.parse(data.toString());
                        const newVals = migration_1.migrateMany(oldVals);
                        const json = atomic_file_codecs_1.selfHealingJSONCodec.encode(newVals);
                        atomic.writeFile(modernPath, json, 'utf8', (err2) => {
                            if (err2) {
                                this._loadedReject(err2);
                                debug('Failed to create conn.json from an existing gossip.json');
                                return;
                            }
                            debug('Migrated gossip.json into conn.json');
                            this._load(newVals);
                        });
                    });
                    return;
                }
                if (modernExists) {
                    atomic.readFile(modernPath, 'utf8', (err, data) => {
                        if (err) {
                            this._loadedReject(err);
                            debug('Failed to load conn.json');
                            return;
                        }
                        const vals = atomic_file_codecs_1.selfHealingJSONCodec.decode(data);
                        this._load(vals);
                    });
                }
            });
        });
    }
    _load(vals) {
        for (const [addr, data] of Object.entries(vals)) {
            this._map.set(addr, data);
        }
        this._loadedResolve(true);
        debug('Loaded conn.json into ConnDB in memory');
    }
    _serialize() {
        const record = {};
        for (let [address, data] of this._map.entries()) {
            record[address] = data;
        }
        return record;
    }
    _write(cb) {
        if (!this._map)
            return;
        debug('Begun serializing and writing ConnDB into conn.json');
        const record = this._serialize();
        const json = atomic_file_codecs_1.selfHealingJSONCodec.encode(record);
        atomic.writeFile(this._modernPath, json, 'utf8', (err) => {
            if (!err)
                debug('Done serializing and writing ConnDB into conn.json');
            if (cb)
                cb(err);
        });
    }
    _cancelScheduleWrite() {
        if (this._scheduledWriteTask) {
            clearTimeout(this._scheduledWriteTask);
        }
    }
    _scheduleWrite() {
        this._cancelScheduleWrite();
        this._scheduledWriteTask = setTimeout(() => {
            this._write((_err) => {
                this._scheduledWriteTask = null;
            });
        }, this._writeTimeout);
    }
    _assertNotClosed() {
        if (this._closed) {
            throw new Error('This ConnDB instance is closed, create a new one.');
        }
    }
    _assertValidAddress(address) {
        if (!msAddress.check(address)) {
            throw new Error('The given address is not a valid multiserver-address');
        }
    }
    _assertValidData(data) {
        if (!data || typeof data !== 'object') {
            throw new Error('The given connection data should have been an object');
        }
    }
    replace(address, data) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        this._assertValidData(data);
        const existed = this._map.has(address);
        if (existed) {
            const { birth } = this._map.get(address);
            this._map.set(address, { birth: birth !== null && birth !== void 0 ? birth : Date.now(), ...data });
            this._notify({ type: 'update', address });
        }
        else {
            this._map.set(address, { birth: Date.now(), ...data });
            this._notify({ type: 'insert', address });
        }
        this._scheduleWrite();
        return this;
    }
    set(address, data) {
        var _a;
        this._assertNotClosed();
        this._assertValidAddress(address);
        this._assertValidData(data);
        const existed = this._map.has(address);
        if (existed) {
            const previous = this._map.get(address);
            this._map.set(address, {
                birth: (_a = previous.birth) !== null && _a !== void 0 ? _a : Date.now(),
                ...previous,
                ...data,
            });
            this._notify({ type: 'update', address });
        }
        else {
            this._map.set(address, { birth: Date.now(), ...data });
            this._notify({ type: 'insert', address });
        }
        this._scheduleWrite();
        return this;
    }
    update(address, x) {
        var _a;
        this._assertNotClosed();
        this._assertValidAddress(address);
        if (!x || (typeof x !== 'object' && typeof x !== 'function')) {
            throw new Error('update() expects an object or a function');
        }
        const existed = this._map.has(address);
        if (!existed)
            return this;
        const previous = this._map.get(address);
        const next = typeof x === 'function' ? x(previous) : x;
        this._map.set(address, {
            birth: (_a = previous.birth) !== null && _a !== void 0 ? _a : Date.now(),
            ...previous,
            ...next,
        });
        this._notify({ type: 'update', address });
        this._scheduleWrite();
        return this;
    }
    get(address) {
        this._assertNotClosed();
        return this._map.get(address);
    }
    getAddressForId(id) {
        this._assertNotClosed();
        for (let [address, data] of this._map.entries()) {
            if (data.key === id)
                return address;
        }
        return undefined;
    }
    has(address) {
        this._assertNotClosed();
        return this._map.has(address);
    }
    delete(address) {
        this._assertNotClosed();
        const hasDeleted = this._map.delete(address);
        if (hasDeleted) {
            this._notify({ type: 'delete', address });
            this._scheduleWrite();
        }
        return hasDeleted;
    }
    entries() {
        this._assertNotClosed();
        return this._map.entries();
    }
    listen() {
        this._assertNotClosed();
        return this._notify.listen();
    }
    loaded() {
        this._assertNotClosed();
        return this._loadedPromise;
    }
    close() {
        var _a;
        this._closed = true;
        this._cancelScheduleWrite();
        this._write();
        (_a = this._map) === null || _a === void 0 ? void 0 : _a.clear();
        this._map = void 0;
        this._notify = void 0;
        this._stateFile = void 0;
        debug('Closed the ConnDB instance');
    }
}
module.exports = ConnDB;

},
"Y7alFgoTddAX2MNgffGarBupf46LGYw+qR8Slbpn2mw=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var undefined;

var $SyntaxError = SyntaxError;
var $Function = Function;
var $TypeError = TypeError;

// eslint-disable-next-line consistent-return
var getEvalledConstructor = function (expressionSyntax) {
	try {
		return $Function('"use strict"; return (' + expressionSyntax + ').constructor;')();
	} catch (e) {}
};

var $gOPD = Object.getOwnPropertyDescriptor;
if ($gOPD) {
	try {
		$gOPD({}, '');
	} catch (e) {
		$gOPD = null; // this is IE 8, which has a broken gOPD
	}
}

var throwTypeError = function () {
	throw new $TypeError();
};
var ThrowTypeError = $gOPD
	? (function () {
		try {
			// eslint-disable-next-line no-unused-expressions, no-caller, no-restricted-properties
			arguments.callee; // IE 8 does not throw here
			return throwTypeError;
		} catch (calleeThrows) {
			try {
				// IE 8 throws on Object.getOwnPropertyDescriptor(arguments, '')
				return $gOPD(arguments, 'callee').get;
			} catch (gOPDthrows) {
				return throwTypeError;
			}
		}
	}())
	: throwTypeError;

var hasSymbols = require('has-symbols')();

var getProto = Object.getPrototypeOf || function (x) { return x.__proto__; }; // eslint-disable-line no-proto

var needsEval = {};

var TypedArray = typeof Uint8Array === 'undefined' ? undefined : getProto(Uint8Array);

var INTRINSICS = {
	'%AggregateError%': typeof AggregateError === 'undefined' ? undefined : AggregateError,
	'%Array%': Array,
	'%ArrayBuffer%': typeof ArrayBuffer === 'undefined' ? undefined : ArrayBuffer,
	'%ArrayIteratorPrototype%': hasSymbols ? getProto([][Symbol.iterator]()) : undefined,
	'%AsyncFromSyncIteratorPrototype%': undefined,
	'%AsyncFunction%': needsEval,
	'%AsyncGenerator%': needsEval,
	'%AsyncGeneratorFunction%': needsEval,
	'%AsyncIteratorPrototype%': needsEval,
	'%Atomics%': typeof Atomics === 'undefined' ? undefined : Atomics,
	'%BigInt%': typeof BigInt === 'undefined' ? undefined : BigInt,
	'%Boolean%': Boolean,
	'%DataView%': typeof DataView === 'undefined' ? undefined : DataView,
	'%Date%': Date,
	'%decodeURI%': decodeURI,
	'%decodeURIComponent%': decodeURIComponent,
	'%encodeURI%': encodeURI,
	'%encodeURIComponent%': encodeURIComponent,
	'%Error%': Error,
	'%eval%': eval, // eslint-disable-line no-eval
	'%EvalError%': EvalError,
	'%Float32Array%': typeof Float32Array === 'undefined' ? undefined : Float32Array,
	'%Float64Array%': typeof Float64Array === 'undefined' ? undefined : Float64Array,
	'%FinalizationRegistry%': typeof FinalizationRegistry === 'undefined' ? undefined : FinalizationRegistry,
	'%Function%': $Function,
	'%GeneratorFunction%': needsEval,
	'%Int8Array%': typeof Int8Array === 'undefined' ? undefined : Int8Array,
	'%Int16Array%': typeof Int16Array === 'undefined' ? undefined : Int16Array,
	'%Int32Array%': typeof Int32Array === 'undefined' ? undefined : Int32Array,
	'%isFinite%': isFinite,
	'%isNaN%': isNaN,
	'%IteratorPrototype%': hasSymbols ? getProto(getProto([][Symbol.iterator]())) : undefined,
	'%JSON%': typeof JSON === 'object' ? JSON : undefined,
	'%Map%': typeof Map === 'undefined' ? undefined : Map,
	'%MapIteratorPrototype%': typeof Map === 'undefined' || !hasSymbols ? undefined : getProto(new Map()[Symbol.iterator]()),
	'%Math%': Math,
	'%Number%': Number,
	'%Object%': Object,
	'%parseFloat%': parseFloat,
	'%parseInt%': parseInt,
	'%Promise%': typeof Promise === 'undefined' ? undefined : Promise,
	'%Proxy%': typeof Proxy === 'undefined' ? undefined : Proxy,
	'%RangeError%': RangeError,
	'%ReferenceError%': ReferenceError,
	'%Reflect%': typeof Reflect === 'undefined' ? undefined : Reflect,
	'%RegExp%': RegExp,
	'%Set%': typeof Set === 'undefined' ? undefined : Set,
	'%SetIteratorPrototype%': typeof Set === 'undefined' || !hasSymbols ? undefined : getProto(new Set()[Symbol.iterator]()),
	'%SharedArrayBuffer%': typeof SharedArrayBuffer === 'undefined' ? undefined : SharedArrayBuffer,
	'%String%': String,
	'%StringIteratorPrototype%': hasSymbols ? getProto(''[Symbol.iterator]()) : undefined,
	'%Symbol%': hasSymbols ? Symbol : undefined,
	'%SyntaxError%': $SyntaxError,
	'%ThrowTypeError%': ThrowTypeError,
	'%TypedArray%': TypedArray,
	'%TypeError%': $TypeError,
	'%Uint8Array%': typeof Uint8Array === 'undefined' ? undefined : Uint8Array,
	'%Uint8ClampedArray%': typeof Uint8ClampedArray === 'undefined' ? undefined : Uint8ClampedArray,
	'%Uint16Array%': typeof Uint16Array === 'undefined' ? undefined : Uint16Array,
	'%Uint32Array%': typeof Uint32Array === 'undefined' ? undefined : Uint32Array,
	'%URIError%': URIError,
	'%WeakMap%': typeof WeakMap === 'undefined' ? undefined : WeakMap,
	'%WeakRef%': typeof WeakRef === 'undefined' ? undefined : WeakRef,
	'%WeakSet%': typeof WeakSet === 'undefined' ? undefined : WeakSet
};

var doEval = function doEval(name) {
	var value;
	if (name === '%AsyncFunction%') {
		value = getEvalledConstructor('async function () {}');
	} else if (name === '%GeneratorFunction%') {
		value = getEvalledConstructor('function* () {}');
	} else if (name === '%AsyncGeneratorFunction%') {
		value = getEvalledConstructor('async function* () {}');
	} else if (name === '%AsyncGenerator%') {
		var fn = doEval('%AsyncGeneratorFunction%');
		if (fn) {
			value = fn.prototype;
		}
	} else if (name === '%AsyncIteratorPrototype%') {
		var gen = doEval('%AsyncGenerator%');
		if (gen) {
			value = getProto(gen.prototype);
		}
	}

	INTRINSICS[name] = value;

	return value;
};

var LEGACY_ALIASES = {
	'%ArrayBufferPrototype%': ['ArrayBuffer', 'prototype'],
	'%ArrayPrototype%': ['Array', 'prototype'],
	'%ArrayProto_entries%': ['Array', 'prototype', 'entries'],
	'%ArrayProto_forEach%': ['Array', 'prototype', 'forEach'],
	'%ArrayProto_keys%': ['Array', 'prototype', 'keys'],
	'%ArrayProto_values%': ['Array', 'prototype', 'values'],
	'%AsyncFunctionPrototype%': ['AsyncFunction', 'prototype'],
	'%AsyncGenerator%': ['AsyncGeneratorFunction', 'prototype'],
	'%AsyncGeneratorPrototype%': ['AsyncGeneratorFunction', 'prototype', 'prototype'],
	'%BooleanPrototype%': ['Boolean', 'prototype'],
	'%DataViewPrototype%': ['DataView', 'prototype'],
	'%DatePrototype%': ['Date', 'prototype'],
	'%ErrorPrototype%': ['Error', 'prototype'],
	'%EvalErrorPrototype%': ['EvalError', 'prototype'],
	'%Float32ArrayPrototype%': ['Float32Array', 'prototype'],
	'%Float64ArrayPrototype%': ['Float64Array', 'prototype'],
	'%FunctionPrototype%': ['Function', 'prototype'],
	'%Generator%': ['GeneratorFunction', 'prototype'],
	'%GeneratorPrototype%': ['GeneratorFunction', 'prototype', 'prototype'],
	'%Int8ArrayPrototype%': ['Int8Array', 'prototype'],
	'%Int16ArrayPrototype%': ['Int16Array', 'prototype'],
	'%Int32ArrayPrototype%': ['Int32Array', 'prototype'],
	'%JSONParse%': ['JSON', 'parse'],
	'%JSONStringify%': ['JSON', 'stringify'],
	'%MapPrototype%': ['Map', 'prototype'],
	'%NumberPrototype%': ['Number', 'prototype'],
	'%ObjectPrototype%': ['Object', 'prototype'],
	'%ObjProto_toString%': ['Object', 'prototype', 'toString'],
	'%ObjProto_valueOf%': ['Object', 'prototype', 'valueOf'],
	'%PromisePrototype%': ['Promise', 'prototype'],
	'%PromiseProto_then%': ['Promise', 'prototype', 'then'],
	'%Promise_all%': ['Promise', 'all'],
	'%Promise_reject%': ['Promise', 'reject'],
	'%Promise_resolve%': ['Promise', 'resolve'],
	'%RangeErrorPrototype%': ['RangeError', 'prototype'],
	'%ReferenceErrorPrototype%': ['ReferenceError', 'prototype'],
	'%RegExpPrototype%': ['RegExp', 'prototype'],
	'%SetPrototype%': ['Set', 'prototype'],
	'%SharedArrayBufferPrototype%': ['SharedArrayBuffer', 'prototype'],
	'%StringPrototype%': ['String', 'prototype'],
	'%SymbolPrototype%': ['Symbol', 'prototype'],
	'%SyntaxErrorPrototype%': ['SyntaxError', 'prototype'],
	'%TypedArrayPrototype%': ['TypedArray', 'prototype'],
	'%TypeErrorPrototype%': ['TypeError', 'prototype'],
	'%Uint8ArrayPrototype%': ['Uint8Array', 'prototype'],
	'%Uint8ClampedArrayPrototype%': ['Uint8ClampedArray', 'prototype'],
	'%Uint16ArrayPrototype%': ['Uint16Array', 'prototype'],
	'%Uint32ArrayPrototype%': ['Uint32Array', 'prototype'],
	'%URIErrorPrototype%': ['URIError', 'prototype'],
	'%WeakMapPrototype%': ['WeakMap', 'prototype'],
	'%WeakSetPrototype%': ['WeakSet', 'prototype']
};

var bind = require('function-bind');
var hasOwn = require('has');
var $concat = bind.call(Function.call, Array.prototype.concat);
var $spliceApply = bind.call(Function.apply, Array.prototype.splice);
var $replace = bind.call(Function.call, String.prototype.replace);
var $strSlice = bind.call(Function.call, String.prototype.slice);

/* adapted from https://github.com/lodash/lodash/blob/4.17.15/dist/lodash.js#L6735-L6744 */
var rePropName = /[^%.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|%$))/g;
var reEscapeChar = /\\(\\)?/g; /** Used to match backslashes in property paths. */
var stringToPath = function stringToPath(string) {
	var first = $strSlice(string, 0, 1);
	var last = $strSlice(string, -1);
	if (first === '%' && last !== '%') {
		throw new $SyntaxError('invalid intrinsic syntax, expected closing `%`');
	} else if (last === '%' && first !== '%') {
		throw new $SyntaxError('invalid intrinsic syntax, expected opening `%`');
	}
	var result = [];
	$replace(string, rePropName, function (match, number, quote, subString) {
		result[result.length] = quote ? $replace(subString, reEscapeChar, '$1') : number || match;
	});
	return result;
};
/* end adaptation */

var getBaseIntrinsic = function getBaseIntrinsic(name, allowMissing) {
	var intrinsicName = name;
	var alias;
	if (hasOwn(LEGACY_ALIASES, intrinsicName)) {
		alias = LEGACY_ALIASES[intrinsicName];
		intrinsicName = '%' + alias[0] + '%';
	}

	if (hasOwn(INTRINSICS, intrinsicName)) {
		var value = INTRINSICS[intrinsicName];
		if (value === needsEval) {
			value = doEval(intrinsicName);
		}
		if (typeof value === 'undefined' && !allowMissing) {
			throw new $TypeError('intrinsic ' + name + ' exists, but is not available. Please file an issue!');
		}

		return {
			alias: alias,
			name: intrinsicName,
			value: value
		};
	}

	throw new $SyntaxError('intrinsic ' + name + ' does not exist!');
};

module.exports = function GetIntrinsic(name, allowMissing) {
	if (typeof name !== 'string' || name.length === 0) {
		throw new $TypeError('intrinsic name must be a non-empty string');
	}
	if (arguments.length > 1 && typeof allowMissing !== 'boolean') {
		throw new $TypeError('"allowMissing" argument must be a boolean');
	}

	var parts = stringToPath(name);
	var intrinsicBaseName = parts.length > 0 ? parts[0] : '';

	var intrinsic = getBaseIntrinsic('%' + intrinsicBaseName + '%', allowMissing);
	var intrinsicRealName = intrinsic.name;
	var value = intrinsic.value;
	var skipFurtherCaching = false;

	var alias = intrinsic.alias;
	if (alias) {
		intrinsicBaseName = alias[0];
		$spliceApply(parts, $concat([0, 1], alias));
	}

	for (var i = 1, isOwn = true; i < parts.length; i += 1) {
		var part = parts[i];
		var first = $strSlice(part, 0, 1);
		var last = $strSlice(part, -1);
		if (
			(
				(first === '"' || first === "'" || first === '`')
				|| (last === '"' || last === "'" || last === '`')
			)
			&& first !== last
		) {
			throw new $SyntaxError('property names with quotes must have matching quotes');
		}
		if (part === 'constructor' || !isOwn) {
			skipFurtherCaching = true;
		}

		intrinsicBaseName += '.' + part;
		intrinsicRealName = '%' + intrinsicBaseName + '%';

		if (hasOwn(INTRINSICS, intrinsicRealName)) {
			value = INTRINSICS[intrinsicRealName];
		} else if (value != null) {
			if (!(part in value)) {
				if (!allowMissing) {
					throw new $TypeError('base intrinsic for ' + name + ' exists, but the property is not available.');
				}
				return void undefined;
			}
			if ($gOPD && (i + 1) >= parts.length) {
				var desc = $gOPD(value, part);
				isOwn = !!desc;

				// By convention, when a data property is converted to an accessor
				// property to emulate a data property that does not suffer from
				// the override mistake, that accessor's getter is marked with
				// an `originalValue` property. Here, when we detect this, we
				// uphold the illusion by pretending to see that original data
				// property, i.e., returning the value rather than the getter
				// itself.
				if (isOwn && 'get' in desc && !('originalValue' in desc.get)) {
					value = desc.get;
				} else {
					value = value[part];
				}
			} else {
				isOwn = hasOwn(value, part);
				value = value[part];
			}

			if (isOwn && !skipFurtherCaching) {
				INTRINSICS[intrinsicRealName] = value;
			}
		}
	}
	return value;
};

},
"YJqQ01wDN9jF/GrwCbS6vh2UN9TGTJiQnnpE6imE6NE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

module.exports = getUsage;

function getUsage(oldUsage) {
  var usage;
  if (oldUsage && oldUsage._start) {
    usage = Object.assign({}, process.cpuUsage(oldUsage._start.cpuUsage));
    usage.time = Date.now() - oldUsage._start.time;
  } else {
    usage = Object.assign({}, process.cpuUsage());
    usage.time = process.uptime() * 1000; // s to ms
  }
  usage.percent = (usage.system + usage.user) / (usage.time * 10);
  Object.defineProperty(usage, '_start', {
    value: {
      cpuUsage: process.cpuUsage(),
      time: Date.now()
    }
  });
  return usage;
}

},
"YKLr15FMcHiQbeYbxK+mGPhQKx/vSknqkbaxIbn2uo0=":
function (require, module, exports, __dirname, __filename) {
var Obv = require('obv')
var Drain = require('pull-stream/sinks/drain')
var Once = require('pull-stream/sources/once')
var path = require('path')
var deepEqual = require('deep-equal')
var Notify = require('pull-notify')
var AsyncSingle = require('async-single')

/*
Replication Ideas.

//value is skipped if seq is the same. or value option is false, or max > 
getState({seq, value}, cb(null, {seq: _seq, value: value}))

*/

function isEmpty (o) {
  if(o == null) return
  for(var k in o) return false
  return true
}

function isObject (o) {
  return o && 'object' === typeof o
}

function isFunction (f) {
  return 'function' === typeof f
}

function id (e) { return e }

module.exports = function (Store) {
return function (version, reduce, map, codec, initial, writeInterval = null) {
  var opts
  if(isObject(reduce)) {
    opts = reduce
    reduce = opts.reduce
    map = opts.map
    codec = opts.codec
    initial = opts.initial
  }
  else opts = {}
  //timers for updating the state file.
  //always wait min ms after a write,
  //up to max since first write?
  opts.min = opts.min || 100
  opts.max = opts.max || 500


  if(isFunction(version))
    throw new Error('version must be a number')

  map = map || id
  var notify = Notify()
  return function (log, name) { //name is where this view is mounted
    var acc, since = Obv()
    var value = Obv(), state

    //if we are in sync, and have not written recently, then write the current state.

    // if the log is persisted,
    // then also save the reduce state.
    // save whenever the view gets in sync with the log,
    // as long as it hasn't beet updated in 1 minute.


    var w = AsyncSingle(function (value, cb) {
      if(state) {
        if(value) state.set(value, cb)
        else state.destroy(cb)
      } else cb()
    }, opts)

    function write () {
      w.write({
        seq: since.value,
        version: version,
        value: value.value
      })
    }

    //depending on the function, the reduction may not change on every update.
    //but currently, we still need to rewrite the file to reflect that.
    //(or accept that we'll have to reprocess some items)
    //might be good to have a cheap way to update the seq. maybe put it in the filename,
    //so filenames monotonically increase, instead of write to `name~` and then `mv name~ name`

    if(log.filename) {
      var dir = path.dirname(log.filename)
      state = Store(dir, name, codec)
      state.get(function (err, data) {
        if(err || data == null || isEmpty(data) || data.version !== version) {
          since.set(-1) //overwrite old data.
          value.set(initial)
        }
        else {
          value.set(data.value)
          since.set(data.seq)
        }
      })
    }
    else {
      write = function (){}
      since.set(-1)
      value.set(initial)
    }

    let closeStream = () => {}

    return {
      since: since,
      value: value,
      methods: {get: 'async', stream: 'source', value: 'sync'},
      get: function (opts, cb) {
        if('function' === typeof opts) {
          cb = opts, opts = null
        }
        if(!opts || isEmpty(opts))
          cb(null, value.value)
        else if(isObject(opts)) {
          since.once(function (v) {
            //ways to call:
            //check seq => seq, version, size
            //get seq,value => seq, version, value
            cb(null,
              opts.values === false ? {seq: v, version: version, size: state && state.size || null}
            : opts.meta === false ? value.value
            : {seq: v, version: version, value: value.value}
            )
          })
        }
      },
      stream: function (opts) {
        opts = opts || {}
        //todo: send the HASH of the value, and only resend it if it is different!
        if(opts.live !== true)
          return Once(value.value)
        var source = notify.listen()
        //start by sending the current value...
        source.push(value.value)
        return source
      },
      createSink: function (cb) {
        closeStream = cb;
        let count = 0
        return Drain(function (data) {
          var _data = map(data.value, data.seq)
          if(_data != null) value.set(reduce(value.value, _data, data.seq))
          since.set(data.seq)
          notify(_data)

          // If we are now in sync with the log, write.
          const inSyncWithLog = since.value === log.since.value

          // Alternatively, write every 10,000 messages.
          const periodicWrite = writeInterval && count % writeInterval == 0

          if(inSyncWithLog || periodicWrite) {
            write()
          }

          count += 1
        }, cb)
      },
      destroy: function (cb) {
        value.set(initial)
        since.set(-1)
        w.write(initial)
        closeStream()
        w.close(cb)
      },
      close: function (cb) {
        notify.abort(true)
        if(!since.value || !state) return cb()
        w.close(cb)
      }
    }
  }
}}



},
"Yfjgf9nNTJ9CcTEHyc6w417HHM0GOBsjZOOC/ojsBVA=":
function (require, module, exports, __dirname, __filename) {
module.exports = function abortCb(cb, abort, onAbort) {
  cb(abort)
  onAbort && onAbort(abort === true ? null: abort)
  return
}


},
"YsRLNpaHVsekqDxmv6eFRmnmCsCseBfg5r2pRfJUDZk=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// A bit simpler than readable streams.
// Implement an async ._write(chunk, encoding, cb), and it'll handle all
// the drain event emission and buffering.
'use strict';

module.exports = Writable;
/* <replacement> */

function WriteReq(chunk, encoding, cb) {
  this.chunk = chunk;
  this.encoding = encoding;
  this.callback = cb;
  this.next = null;
} // It seems a linked list but it is not
// there will be only 2 of these for each stream


function CorkedRequest(state) {
  var _this = this;

  this.next = null;
  this.entry = null;

  this.finish = function () {
    onCorkedFinish(_this, state);
  };
}
/* </replacement> */

/*<replacement>*/


var Duplex;
/*</replacement>*/

Writable.WritableState = WritableState;
/*<replacement>*/

var internalUtil = {
  deprecate: require('util-deprecate')
};
/*</replacement>*/

/*<replacement>*/

var Stream = require('./internal/streams/stream');
/*</replacement>*/


var Buffer = require('buffer').Buffer;

var OurUint8Array = global.Uint8Array || function () {};

function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}

function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}

var destroyImpl = require('./internal/streams/destroy');

var _require = require('./internal/streams/state'),
    getHighWaterMark = _require.getHighWaterMark;

var _require$codes = require('../errors').codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,
    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;

require('inherits')(Writable, Stream);

function nop() {}

function WritableState(options, stream, isDuplex) {
  Duplex = Duplex || require('./_stream_duplex');
  options = options || {}; // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream,
  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.

  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream
  // contains buffers or objects.

  this.objectMode = !!options.objectMode;
  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false
  // Note: 0 is a valid value, means that we always return false if
  // the entire buffer is not flushed immediately on write()

  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called

  this.finalCalled = false; // drain event flag.

  this.needDrain = false; // at the start of calling end()

  this.ending = false; // when end() has been called, and returned

  this.ended = false; // when 'finish' is emitted

  this.finished = false; // has it been destroyed

  this.destroyed = false; // should we decode strings into buffers before passing to _write?
  // this is here so that some node-core streams can optimize string
  // handling at a lower level.

  var noDecode = options.decodeStrings === false;
  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.

  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement
  // of how much we're waiting to get pushed to some underlying
  // socket or file.

  this.length = 0; // a flag to see when we're in the middle of a write.

  this.writing = false; // when true all writes will be buffered until .uncork() call

  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,
  // or on a later tick.  We set this to true at first, because any
  // actions that shouldn't happen until "later" should generally also
  // not happen before the first write call.

  this.sync = true; // a flag to know if we're processing previously buffered items, which
  // may call the _write() callback in the same tick, so that we don't
  // end up in an overlapped onwrite situation.

  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)

  this.onwrite = function (er) {
    onwrite(stream, er);
  }; // the callback that the user supplies to write(chunk,encoding,cb)


  this.writecb = null; // the amount that is being written when _write is called.

  this.writelen = 0;
  this.bufferedRequest = null;
  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks
  // this must be 0 before 'finish' can be emitted

  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs
  // This is relevant for synchronous Transform streams

  this.prefinished = false; // True if the error was already emitted and should not be thrown again

  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.

  this.emitClose = options.emitClose !== false; // count buffered requests

  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always
  // one allocated and free to use, and we maintain at most two

  this.corkedRequestsFree = new CorkedRequest(this);
}

WritableState.prototype.getBuffer = function getBuffer() {
  var current = this.bufferedRequest;
  var out = [];

  while (current) {
    out.push(current);
    current = current.next;
  }

  return out;
};

(function () {
  try {
    Object.defineProperty(WritableState.prototype, 'buffer', {
      get: internalUtil.deprecate(function writableStateBufferGetter() {
        return this.getBuffer();
      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')
    });
  } catch (_) {}
})(); // Test _writableState for inheritance to account for Duplex streams,
// whose prototype chain only points to Readable.


var realHasInstance;

if (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {
  realHasInstance = Function.prototype[Symbol.hasInstance];
  Object.defineProperty(Writable, Symbol.hasInstance, {
    value: function value(object) {
      if (realHasInstance.call(this, object)) return true;
      if (this !== Writable) return false;
      return object && object._writableState instanceof WritableState;
    }
  });
} else {
  realHasInstance = function realHasInstance(object) {
    return object instanceof this;
  };
}

function Writable(options) {
  Duplex = Duplex || require('./_stream_duplex'); // Writable ctor is applied to Duplexes, too.
  // `realHasInstance` is necessary because using plain `instanceof`
  // would return false, as no `_writableState` property is attached.
  // Trying to use the custom `instanceof` for Writable here will also break the
  // Node.js LazyTransform implementation, which has a non-trivial getter for
  // `_writableState` that would lead to infinite recursion.
  // Checking for a Stream.Duplex instance is faster here instead of inside
  // the WritableState constructor, at least with V8 6.5

  var isDuplex = this instanceof Duplex;
  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);
  this._writableState = new WritableState(options, this, isDuplex); // legacy.

  this.writable = true;

  if (options) {
    if (typeof options.write === 'function') this._write = options.write;
    if (typeof options.writev === 'function') this._writev = options.writev;
    if (typeof options.destroy === 'function') this._destroy = options.destroy;
    if (typeof options.final === 'function') this._final = options.final;
  }

  Stream.call(this);
} // Otherwise people can pipe Writable streams, which is just wrong.


Writable.prototype.pipe = function () {
  this.emit('error', new ERR_STREAM_CANNOT_PIPE());
};

function writeAfterEnd(stream, cb) {
  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb

  stream.emit('error', er);
  process.nextTick(cb, er);
} // Checks that a user-supplied chunk is valid, especially for the particular
// mode the stream is in. Currently this means that `null` is never accepted
// and undefined/non-string values are only allowed in object mode.


function validChunk(stream, state, chunk, cb) {
  var er;

  if (chunk === null) {
    er = new ERR_STREAM_NULL_VALUES();
  } else if (typeof chunk !== 'string' && !state.objectMode) {
    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);
  }

  if (er) {
    stream.emit('error', er);
    process.nextTick(cb, er);
    return false;
  }

  return true;
}

Writable.prototype.write = function (chunk, encoding, cb) {
  var state = this._writableState;
  var ret = false;

  var isBuf = !state.objectMode && _isUint8Array(chunk);

  if (isBuf && !Buffer.isBuffer(chunk)) {
    chunk = _uint8ArrayToBuffer(chunk);
  }

  if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;
  if (typeof cb !== 'function') cb = nop;
  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {
    state.pendingcb++;
    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);
  }
  return ret;
};

Writable.prototype.cork = function () {
  this._writableState.corked++;
};

Writable.prototype.uncork = function () {
  var state = this._writableState;

  if (state.corked) {
    state.corked--;
    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);
  }
};

Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
  // node::ParseEncoding() requires lower case.
  if (typeof encoding === 'string') encoding = encoding.toLowerCase();
  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);
  this._writableState.defaultEncoding = encoding;
  return this;
};

Object.defineProperty(Writable.prototype, 'writableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState && this._writableState.getBuffer();
  }
});

function decodeChunk(state, chunk, encoding) {
  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {
    chunk = Buffer.from(chunk, encoding);
  }

  return chunk;
}

Object.defineProperty(Writable.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.highWaterMark;
  }
}); // if we're already writing something, then just put this
// in the queue, and wait our turn.  Otherwise, call _write
// If we return false, then we need a drain event, so set that flag.

function writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {
  if (!isBuf) {
    var newChunk = decodeChunk(state, chunk, encoding);

    if (chunk !== newChunk) {
      isBuf = true;
      encoding = 'buffer';
      chunk = newChunk;
    }
  }

  var len = state.objectMode ? 1 : chunk.length;
  state.length += len;
  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.

  if (!ret) state.needDrain = true;

  if (state.writing || state.corked) {
    var last = state.lastBufferedRequest;
    state.lastBufferedRequest = {
      chunk: chunk,
      encoding: encoding,
      isBuf: isBuf,
      callback: cb,
      next: null
    };

    if (last) {
      last.next = state.lastBufferedRequest;
    } else {
      state.bufferedRequest = state.lastBufferedRequest;
    }

    state.bufferedRequestCount += 1;
  } else {
    doWrite(stream, state, false, len, chunk, encoding, cb);
  }

  return ret;
}

function doWrite(stream, state, writev, len, chunk, encoding, cb) {
  state.writelen = len;
  state.writecb = cb;
  state.writing = true;
  state.sync = true;
  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);
  state.sync = false;
}

function onwriteError(stream, state, sync, er, cb) {
  --state.pendingcb;

  if (sync) {
    // defer the callback if we are being called synchronously
    // to avoid piling up things on the stack
    process.nextTick(cb, er); // this can emit finish, and it will always happen
    // after error

    process.nextTick(finishMaybe, stream, state);
    stream._writableState.errorEmitted = true;
    stream.emit('error', er);
  } else {
    // the caller expect this to happen before if
    // it is async
    cb(er);
    stream._writableState.errorEmitted = true;
    stream.emit('error', er); // this can emit finish, but finish must
    // always follow error

    finishMaybe(stream, state);
  }
}

function onwriteStateUpdate(state) {
  state.writing = false;
  state.writecb = null;
  state.length -= state.writelen;
  state.writelen = 0;
}

function onwrite(stream, er) {
  var state = stream._writableState;
  var sync = state.sync;
  var cb = state.writecb;
  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();
  onwriteStateUpdate(state);
  if (er) onwriteError(stream, state, sync, er, cb);else {
    // Check if we're actually ready to finish, but don't emit yet
    var finished = needFinish(state) || stream.destroyed;

    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {
      clearBuffer(stream, state);
    }

    if (sync) {
      process.nextTick(afterWrite, stream, state, finished, cb);
    } else {
      afterWrite(stream, state, finished, cb);
    }
  }
}

function afterWrite(stream, state, finished, cb) {
  if (!finished) onwriteDrain(stream, state);
  state.pendingcb--;
  cb();
  finishMaybe(stream, state);
} // Must force callback to be called on nextTick, so that we don't
// emit 'drain' before the write() consumer gets the 'false' return
// value, and has a chance to attach a 'drain' listener.


function onwriteDrain(stream, state) {
  if (state.length === 0 && state.needDrain) {
    state.needDrain = false;
    stream.emit('drain');
  }
} // if there's something in the buffer waiting, then process it


function clearBuffer(stream, state) {
  state.bufferProcessing = true;
  var entry = state.bufferedRequest;

  if (stream._writev && entry && entry.next) {
    // Fast case, write everything using _writev()
    var l = state.bufferedRequestCount;
    var buffer = new Array(l);
    var holder = state.corkedRequestsFree;
    holder.entry = entry;
    var count = 0;
    var allBuffers = true;

    while (entry) {
      buffer[count] = entry;
      if (!entry.isBuf) allBuffers = false;
      entry = entry.next;
      count += 1;
    }

    buffer.allBuffers = allBuffers;
    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time
    // as the hot path ends with doWrite

    state.pendingcb++;
    state.lastBufferedRequest = null;

    if (holder.next) {
      state.corkedRequestsFree = holder.next;
      holder.next = null;
    } else {
      state.corkedRequestsFree = new CorkedRequest(state);
    }

    state.bufferedRequestCount = 0;
  } else {
    // Slow case, write chunks one-by-one
    while (entry) {
      var chunk = entry.chunk;
      var encoding = entry.encoding;
      var cb = entry.callback;
      var len = state.objectMode ? 1 : chunk.length;
      doWrite(stream, state, false, len, chunk, encoding, cb);
      entry = entry.next;
      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then
      // it means that we need to wait until it does.
      // also, that means that the chunk and cb are currently
      // being processed, so move the buffer counter past them.

      if (state.writing) {
        break;
      }
    }

    if (entry === null) state.lastBufferedRequest = null;
  }

  state.bufferedRequest = entry;
  state.bufferProcessing = false;
}

Writable.prototype._write = function (chunk, encoding, cb) {
  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));
};

Writable.prototype._writev = null;

Writable.prototype.end = function (chunk, encoding, cb) {
  var state = this._writableState;

  if (typeof chunk === 'function') {
    cb = chunk;
    chunk = null;
    encoding = null;
  } else if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks

  if (state.corked) {
    state.corked = 1;
    this.uncork();
  } // ignore unnecessary end() calls.


  if (!state.ending) endWritable(this, state, cb);
  return this;
};

Object.defineProperty(Writable.prototype, 'writableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.length;
  }
});

function needFinish(state) {
  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;
}

function callFinal(stream, state) {
  stream._final(function (err) {
    state.pendingcb--;

    if (err) {
      stream.emit('error', err);
    }

    state.prefinished = true;
    stream.emit('prefinish');
    finishMaybe(stream, state);
  });
}

function prefinish(stream, state) {
  if (!state.prefinished && !state.finalCalled) {
    if (typeof stream._final === 'function' && !state.destroyed) {
      state.pendingcb++;
      state.finalCalled = true;
      process.nextTick(callFinal, stream, state);
    } else {
      state.prefinished = true;
      stream.emit('prefinish');
    }
  }
}

function finishMaybe(stream, state) {
  var need = needFinish(state);

  if (need) {
    prefinish(stream, state);

    if (state.pendingcb === 0) {
      state.finished = true;
      stream.emit('finish');
    }
  }

  return need;
}

function endWritable(stream, state, cb) {
  state.ending = true;
  finishMaybe(stream, state);

  if (cb) {
    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);
  }

  state.ended = true;
  stream.writable = false;
}

function onCorkedFinish(corkReq, state, err) {
  var entry = corkReq.entry;
  corkReq.entry = null;

  while (entry) {
    var cb = entry.callback;
    state.pendingcb--;
    cb(err);
    entry = entry.next;
  } // reuse the free corkReq.


  state.corkedRequestsFree.next = corkReq;
}

Object.defineProperty(Writable.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._writableState === undefined) {
      return false;
    }

    return this._writableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._writableState) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._writableState.destroyed = value;
  }
});
Writable.prototype.destroy = destroyImpl.destroy;
Writable.prototype._undestroy = destroyImpl.undestroy;

Writable.prototype._destroy = function (err, cb) {
  cb(err);
};
},
"Yu76t+DKfnA75RFAqcScJ3XCdzDeuPe8X0/wXqLI3ak=":
function (require, module, exports, __dirname, __filename) {
module.exports = chain

// chain := (Continuable<A>, lambda:(A) => Continuable<B>) => Continuable<B>
function chain(source, lambda) {
    return function continuable(callback) {
        source(function continuation(err, value) {
            if (err) {
                return callback(err)
            }

            lambda(value)(callback)
        })
    }
}

},
"Z2vAVtzqrB1GE1WJkJBbyiqQStPlUVHJPZyBuSu9YTI=":
function (require, module, exports, __dirname, __filename) {

exports.utf8 = exports['utf-8'] = {
  encode: function(data){
    return isBinary(data)
      ? data
      : String(data);
  },
  decode: identity,
  buffer: false,
  type: 'utf8'
};

exports.json = {
  encode: JSON.stringify,
  decode: JSON.parse,
  buffer: false,
  type: 'json'
};

exports.binary = {
  encode: function(data){
    return isBinary(data)
      ? data
      : new Buffer(data);      
  },
  decode: identity,
  buffer: true,
  type: 'binary'
};

exports.none = {
  encode: function(data){
    return data;
  },
  decode: function(data){
    return data;
  },
  buffer: false,
  type: 'id'
};

exports.id = exports.none;

var bufferEncodings = [
  'hex',
  'ascii',
  'base64',
  'ucs2',
  'ucs-2',
  'utf16le',
  'utf-16le'
];

bufferEncodings.forEach(function(type){
  exports[type] = {
    encode: function(data){
      return isBinary(data)
        ? data
        : new Buffer(data, type);
    },
    decode: function(buffer){
      return buffer.toString(type);
    },
    buffer: true,
    type: type
  };
});

function identity(value){
  return value;
}

function isBinary(data){
  return data === undefined
    || data === null
    || Buffer.isBuffer(data);
}


},
"Z3VmD9lJ5/XB3h2+m5IE1aSFTJQtfWQjZ1/v0+KDm/U=":
function (require, module, exports, __dirname, __filename) {
module.exports = pullAsync

function pullAsync (continuable) {
  var done
  return function (abort, cb) {
    if (abort) return cb(abort)
    if (done) return cb(true)
    continuable(function (err, data) {
      done = true
      cb(err, data)
    })
  }
}

},
"Z8EKDfGEpOQukRahaYVq29rf5GC4NqI89BA8V8zLEjM=":
function (require, module, exports, __dirname, __filename) {
var nextTick = require('./next-tick')

function AbstractChainedBatch (db) {
  if (typeof db !== 'object' || db === null) {
    throw new TypeError('First argument must be an abstract-leveldown compliant store')
  }

  this.db = db
  this._operations = []
  this._written = false
}

AbstractChainedBatch.prototype._checkWritten = function () {
  if (this._written) {
    throw new Error('write() already called on this batch')
  }
}

AbstractChainedBatch.prototype.put = function (key, value) {
  this._checkWritten()

  var err = this.db._checkKey(key) || this.db._checkValue(value)
  if (err) throw err

  key = this.db._serializeKey(key)
  value = this.db._serializeValue(value)

  this._put(key, value)

  return this
}

AbstractChainedBatch.prototype._put = function (key, value) {
  this._operations.push({ type: 'put', key: key, value: value })
}

AbstractChainedBatch.prototype.del = function (key) {
  this._checkWritten()

  var err = this.db._checkKey(key)
  if (err) throw err

  key = this.db._serializeKey(key)
  this._del(key)

  return this
}

AbstractChainedBatch.prototype._del = function (key) {
  this._operations.push({ type: 'del', key: key })
}

AbstractChainedBatch.prototype.clear = function () {
  this._checkWritten()
  this._clear()

  return this
}

AbstractChainedBatch.prototype._clear = function () {
  this._operations = []
}

AbstractChainedBatch.prototype.write = function (options, callback) {
  this._checkWritten()

  if (typeof options === 'function') { callback = options }
  if (typeof callback !== 'function') {
    throw new Error('write() requires a callback argument')
  }
  if (typeof options !== 'object' || options === null) {
    options = {}
  }

  this._written = true
  this._write(options, callback)
}

AbstractChainedBatch.prototype._write = function (options, callback) {
  this.db._batch(this._operations, options, callback)
}

// Expose browser-compatible nextTick for dependents
AbstractChainedBatch.prototype._nextTick = nextTick

module.exports = AbstractChainedBatch

},
"ZKFfBH8Bf9Oof9cEuVd6bgdILtilMIjs4TK3LNLl0aY=":
function (require, module, exports, __dirname, __filename) {
var Buffer = require('buffer').Buffer

exports.utf8 = exports['utf-8'] = {
  encode: function (data) {
    return isBinary(data) ? data : String(data)
  },
  decode: identity,
  buffer: false,
  type: 'utf8'
}

exports.json = {
  encode: JSON.stringify,
  decode: JSON.parse,
  buffer: false,
  type: 'json'
}

exports.binary = {
  encode: function (data) {
    return isBinary(data) ? data : Buffer.from(data)
  },
  decode: identity,
  buffer: true,
  type: 'binary'
}

exports.none = {
  encode: identity,
  decode: identity,
  buffer: false,
  type: 'id'
}

exports.id = exports.none

var bufferEncodings = [
  'hex',
  'ascii',
  'base64',
  'ucs2',
  'ucs-2',
  'utf16le',
  'utf-16le'
]

bufferEncodings.forEach(function (type) {
  exports[type] = {
    encode: function (data) {
      return isBinary(data) ? data : Buffer.from(data, type)
    },
    decode: function (buffer) {
      return buffer.toString(type)
    },
    buffer: true,
    type: type
  }
})

function identity (value) {
  return value
}

function isBinary (data) {
  return data === undefined || data === null || Buffer.isBuffer(data)
}

},
"ZKX6Qcb3mXNjf+WN4k2IR1RbvXXvHr7UAvLJdvzySis=":
function (require, module, exports, __dirname, __filename) {
var rng = require('./lib/rng');
var bytesToUuid = require('./lib/bytesToUuid');

function v4(options, buf, offset) {
  var i = buf && offset || 0;

  if (typeof(options) == 'string') {
    buf = options === 'binary' ? new Array(16) : null;
    options = null;
  }
  options = options || {};

  var rnds = options.random || (options.rng || rng)();

  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`
  rnds[6] = (rnds[6] & 0x0f) | 0x40;
  rnds[8] = (rnds[8] & 0x3f) | 0x80;

  // Copy bytes to buffer, if provided
  if (buf) {
    for (var ii = 0; ii < 16; ++ii) {
      buf[i + ii] = rnds[ii];
    }
  }

  return buf || bytesToUuid(rnds);
}

module.exports = v4;

},
"ZQGeyoGWehJ+sTnQlD8XmfkV8Z0qWHZuiH0HCNvlwvU=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const EventEmitter = require('events');
const { createHash } = require('crypto');
const { createServer, STATUS_CODES } = require('http');

const PerMessageDeflate = require('./permessage-deflate');
const WebSocket = require('./websocket');
const { format, parse } = require('./extension');
const { GUID, kWebSocket } = require('./constants');

const keyRegex = /^[+/0-9A-Za-z]{22}==$/;

/**
 * Class representing a WebSocket server.
 *
 * @extends EventEmitter
 */
class WebSocketServer extends EventEmitter {
  /**
   * Create a `WebSocketServer` instance.
   *
   * @param {Object} options Configuration options
   * @param {Number} [options.backlog=511] The maximum length of the queue of
   *     pending connections
   * @param {Boolean} [options.clientTracking=true] Specifies whether or not to
   *     track clients
   * @param {Function} [options.handleProtocols] A hook to handle protocols
   * @param {String} [options.host] The hostname where to bind the server
   * @param {Number} [options.maxPayload=104857600] The maximum allowed message
   *     size
   * @param {Boolean} [options.noServer=false] Enable no server mode
   * @param {String} [options.path] Accept only connections matching this path
   * @param {(Boolean|Object)} [options.perMessageDeflate=false] Enable/disable
   *     permessage-deflate
   * @param {Number} [options.port] The port where to bind the server
   * @param {http.Server} [options.server] A pre-created HTTP/S server to use
   * @param {Function} [options.verifyClient] A hook to reject connections
   * @param {Function} [callback] A listener for the `listening` event
   */
  constructor(options, callback) {
    super();

    options = {
      maxPayload: 100 * 1024 * 1024,
      perMessageDeflate: false,
      handleProtocols: null,
      clientTracking: true,
      verifyClient: null,
      noServer: false,
      backlog: null, // use default (511 as implemented in net.js)
      server: null,
      host: null,
      path: null,
      port: null,
      ...options
    };

    if (options.port == null && !options.server && !options.noServer) {
      throw new TypeError(
        'One of the "port", "server", or "noServer" options must be specified'
      );
    }

    if (options.port != null) {
      this._server = createServer((req, res) => {
        const body = STATUS_CODES[426];

        res.writeHead(426, {
          'Content-Length': body.length,
          'Content-Type': 'text/plain'
        });
        res.end(body);
      });
      this._server.listen(
        options.port,
        options.host,
        options.backlog,
        callback
      );
    } else if (options.server) {
      this._server = options.server;
    }

    if (this._server) {
      const emitConnection = this.emit.bind(this, 'connection');

      this._removeListeners = addListeners(this._server, {
        listening: this.emit.bind(this, 'listening'),
        error: this.emit.bind(this, 'error'),
        upgrade: (req, socket, head) => {
          this.handleUpgrade(req, socket, head, emitConnection);
        }
      });
    }

    if (options.perMessageDeflate === true) options.perMessageDeflate = {};
    if (options.clientTracking) this.clients = new Set();
    this.options = options;
  }

  /**
   * Returns the bound address, the address family name, and port of the server
   * as reported by the operating system if listening on an IP socket.
   * If the server is listening on a pipe or UNIX domain socket, the name is
   * returned as a string.
   *
   * @return {(Object|String|null)} The address of the server
   * @public
   */
  address() {
    if (this.options.noServer) {
      throw new Error('The server is operating in "noServer" mode');
    }

    if (!this._server) return null;
    return this._server.address();
  }

  /**
   * Close the server.
   *
   * @param {Function} [cb] Callback
   * @public
   */
  close(cb) {
    if (cb) this.once('close', cb);

    //
    // Terminate all associated clients.
    //
    if (this.clients) {
      for (const client of this.clients) client.terminate();
    }

    const server = this._server;

    if (server) {
      this._removeListeners();
      this._removeListeners = this._server = null;

      //
      // Close the http server if it was internally created.
      //
      if (this.options.port != null) {
        server.close(() => this.emit('close'));
        return;
      }
    }

    process.nextTick(emitClose, this);
  }

  /**
   * See if a given request should be handled by this server instance.
   *
   * @param {http.IncomingMessage} req Request object to inspect
   * @return {Boolean} `true` if the request is valid, else `false`
   * @public
   */
  shouldHandle(req) {
    if (this.options.path) {
      const index = req.url.indexOf('?');
      const pathname = index !== -1 ? req.url.slice(0, index) : req.url;

      if (pathname !== this.options.path) return false;
    }

    return true;
  }

  /**
   * Handle a HTTP Upgrade request.
   *
   * @param {http.IncomingMessage} req The request object
   * @param {net.Socket} socket The network socket between the server and client
   * @param {Buffer} head The first packet of the upgraded stream
   * @param {Function} cb Callback
   * @public
   */
  handleUpgrade(req, socket, head, cb) {
    socket.on('error', socketOnError);

    const key =
      req.headers['sec-websocket-key'] !== undefined
        ? req.headers['sec-websocket-key'].trim()
        : false;
    const version = +req.headers['sec-websocket-version'];
    const extensions = {};

    if (
      req.method !== 'GET' ||
      req.headers.upgrade.toLowerCase() !== 'websocket' ||
      !key ||
      !keyRegex.test(key) ||
      (version !== 8 && version !== 13) ||
      !this.shouldHandle(req)
    ) {
      return abortHandshake(socket, 400);
    }

    if (this.options.perMessageDeflate) {
      const perMessageDeflate = new PerMessageDeflate(
        this.options.perMessageDeflate,
        true,
        this.options.maxPayload
      );

      try {
        const offers = parse(req.headers['sec-websocket-extensions']);

        if (offers[PerMessageDeflate.extensionName]) {
          perMessageDeflate.accept(offers[PerMessageDeflate.extensionName]);
          extensions[PerMessageDeflate.extensionName] = perMessageDeflate;
        }
      } catch (err) {
        return abortHandshake(socket, 400);
      }
    }

    //
    // Optionally call external client verification handler.
    //
    if (this.options.verifyClient) {
      const info = {
        origin:
          req.headers[`${version === 8 ? 'sec-websocket-origin' : 'origin'}`],
        secure: !!(req.socket.authorized || req.socket.encrypted),
        req
      };

      if (this.options.verifyClient.length === 2) {
        this.options.verifyClient(info, (verified, code, message, headers) => {
          if (!verified) {
            return abortHandshake(socket, code || 401, message, headers);
          }

          this.completeUpgrade(key, extensions, req, socket, head, cb);
        });
        return;
      }

      if (!this.options.verifyClient(info)) return abortHandshake(socket, 401);
    }

    this.completeUpgrade(key, extensions, req, socket, head, cb);
  }

  /**
   * Upgrade the connection to WebSocket.
   *
   * @param {String} key The value of the `Sec-WebSocket-Key` header
   * @param {Object} extensions The accepted extensions
   * @param {http.IncomingMessage} req The request object
   * @param {net.Socket} socket The network socket between the server and client
   * @param {Buffer} head The first packet of the upgraded stream
   * @param {Function} cb Callback
   * @throws {Error} If called more than once with the same socket
   * @private
   */
  completeUpgrade(key, extensions, req, socket, head, cb) {
    //
    // Destroy the socket if the client has already sent a FIN packet.
    //
    if (!socket.readable || !socket.writable) return socket.destroy();

    if (socket[kWebSocket]) {
      throw new Error(
        'server.handleUpgrade() was called more than once with the same ' +
          'socket, possibly due to a misconfiguration'
      );
    }

    const digest = createHash('sha1')
      .update(key + GUID)
      .digest('base64');

    const headers = [
      'HTTP/1.1 101 Switching Protocols',
      'Upgrade: websocket',
      'Connection: Upgrade',
      `Sec-WebSocket-Accept: ${digest}`
    ];

    const ws = new WebSocket(null);
    let protocol = req.headers['sec-websocket-protocol'];

    if (protocol) {
      protocol = protocol.trim().split(/ *, */);

      //
      // Optionally call external protocol selection handler.
      //
      if (this.options.handleProtocols) {
        protocol = this.options.handleProtocols(protocol, req);
      } else {
        protocol = protocol[0];
      }

      if (protocol) {
        headers.push(`Sec-WebSocket-Protocol: ${protocol}`);
        ws._protocol = protocol;
      }
    }

    if (extensions[PerMessageDeflate.extensionName]) {
      const params = extensions[PerMessageDeflate.extensionName].params;
      const value = format({
        [PerMessageDeflate.extensionName]: [params]
      });
      headers.push(`Sec-WebSocket-Extensions: ${value}`);
      ws._extensions = extensions;
    }

    //
    // Allow external modification/inspection of handshake headers.
    //
    this.emit('headers', headers, req);

    socket.write(headers.concat('\r\n').join('\r\n'));
    socket.removeListener('error', socketOnError);

    ws.setSocket(socket, head, this.options.maxPayload);

    if (this.clients) {
      this.clients.add(ws);
      ws.on('close', () => this.clients.delete(ws));
    }

    cb(ws, req);
  }
}

module.exports = WebSocketServer;

/**
 * Add event listeners on an `EventEmitter` using a map of <event, listener>
 * pairs.
 *
 * @param {EventEmitter} server The event emitter
 * @param {Object.<String, Function>} map The listeners to add
 * @return {Function} A function that will remove the added listeners when
 *     called
 * @private
 */
function addListeners(server, map) {
  for (const event of Object.keys(map)) server.on(event, map[event]);

  return function removeListeners() {
    for (const event of Object.keys(map)) {
      server.removeListener(event, map[event]);
    }
  };
}

/**
 * Emit a `'close'` event on an `EventEmitter`.
 *
 * @param {EventEmitter} server The event emitter
 * @private
 */
function emitClose(server) {
  server.emit('close');
}

/**
 * Handle premature socket errors.
 *
 * @private
 */
function socketOnError() {
  this.destroy();
}

/**
 * Close the connection when preconditions are not fulfilled.
 *
 * @param {net.Socket} socket The socket of the upgrade request
 * @param {Number} code The HTTP response status code
 * @param {String} [message] The HTTP response body
 * @param {Object} [headers] Additional HTTP response headers
 * @private
 */
function abortHandshake(socket, code, message, headers) {
  if (socket.writable) {
    message = message || STATUS_CODES[code];
    headers = {
      Connection: 'close',
      'Content-Type': 'text/html',
      'Content-Length': Buffer.byteLength(message),
      ...headers
    };

    socket.write(
      `HTTP/1.1 ${code} ${STATUS_CODES[code]}\r\n` +
        Object.keys(headers)
          .map((h) => `${h}: ${headers[h]}`)
          .join('\r\n') +
        '\r\n\r\n' +
        message
    );
  }

  socket.removeListener('error', socketOnError);
  socket.destroy();
}

},
"ZdPm2t7pUKePjhZjN5q0oZY+S8+mSyOn1She1B8PMSg=":
function (require, module, exports, __dirname, __filename) {
var fs = require('fs')

module.exports = function (filename, suffix, isBuffer) {
  suffix = suffix || '~'
  return {
    get: function (cb) {
      fs.readFile(filename, isBuffer ? null : 'utf8', cb)
    },
    set: function (value, cb) {
      fs.writeFile(filename+suffix, value, function (err) {
        if(err) cb(err)
        else fs.rename(filename+suffix, filename, function (err) {
          if(err) cb(err)
          else cb(null, value)
        })
      })
    },
    destroy: function (cb) {
      fs.unlink(filename, function (err) {
        if(err) return cb(err)
        else cb()
      })
    }
  }
}




},
"Zun2enq2ObP2KBPIWHJ6YL3JFIc7ICDOqYlmTNn4kWI=":
function (require, module, exports, __dirname, __filename) {
/**
 * TypedFastBitSet.js : a fast bit set implementation in JavaScript.
 * (c) the authors
 * Licensed under the Apache License, Version 2.0.
 *
 * Speed-optimized BitSet implementation for modern browsers and JavaScript engines.
 *
 * A BitSet is an ideal data structure to implement a Set when values being stored are
 * reasonably small integers. It can be orders of magnitude faster than a generic set implementation.
 * The FastBitSet implementation optimizes for speed, leveraging commonly available features
 * like typed arrays.
 *
 * Simple usage :
 *  const b = new TypedFastBitSet();// initially empty
 *         // will throw exception if typed arrays are not supported
 *  b.add(1);// add the value "1"
 *  b.has(1); // check that the value is present! (will return true)
 *  b.add(2);
 *  console.log(""+b);// should display {1,2}
 *  b.add(10);
 *  b.array(); // would return [1,2,10]
 *
 *  let c = new FastBitSet([1,2,3,10]); // create bitset initialized with values 1,2,3,10
 *  c.difference(b); // from c, remove elements that are in b (modifies c)
 *  c.difference2(b); // from c, remove elements that are in b (modifies b)
 *  c.change(b); // c will contain elements that are in b or in c, but not both
 *  const su = c.union_size(b);// compute the size of the union (bitsets are unchanged)
 *  c.union(b); // c will contain all elements that are in c and b
 *  const s1 = c.intersection_size(b);// compute the size of the intersection (bitsets are unchanged)
 *  c.intersection(b); // c will only contain elements that are in both c and b
 *  c = b.clone(); // create a (deep) copy of b and assign it to c.
 *  c.equals(b); // check whether c and b are equal

 *   See README.md file for a more complete description.
 *
 * You can install the library under node with the command line
 *   npm install typedfastbitset
 */
"use strict";

function isIterable(obj) {
  if (obj == null) {
    return false;
  }
  return obj[Symbol.iterator] !== undefined;
}
// you can provide an iterable
// an exception is thrown if typed arrays are not supported
function TypedFastBitSet(iterable) {
  this.words = new Uint32Array(8);
  if (isIterable(iterable)) {
    for (const key of iterable) {
      this.add(key);
    }
  }
}

// Returns a new TypedFastBitset given a Uint32Array
// of words
TypedFastBitSet.fromWords = function (words) {
  const bs = Object.create(TypedFastBitSet.prototype);
  bs.words = words;
  return bs;
};

// Add the value (Set the bit at index to true)
TypedFastBitSet.prototype.add = function (index) {
  this.resize(index);
  this.words[index >>> 5] |= 1 << index;
};

// If the value was not in the set, add it, otherwise remove it (flip bit at index)
TypedFastBitSet.prototype.flip = function (index) {
  this.resize(index);
  this.words[index >>> 5] ^= 1 << index;
};

// Remove all values, reset memory usage
TypedFastBitSet.prototype.clear = function () {
  this.words = new Uint32Array(8);
};

// Set the bit at index to false
TypedFastBitSet.prototype.remove = function (index) {
  this.resize(index);
  this.words[index >>> 5] &= ~(1 << index);
};

// Set bits from start (inclusive) to end (exclusive)
TypedFastBitSet.prototype.addRange = function (start, end) {
  if (start >= end) {
    return;
  }

  if (this.words.length << 5 <= end) {
    this.resize(end);
  }

  const firstword = start >> 5;
  const endword = (end - 1) >> 5;

  if (firstword === endword) {
    this.words[firstword] |= (~0 << start) & (~0 >>> -end);
    return;
  }
  this.words[firstword] |= ~0 << start;
  this.words.fill(~0, firstword + 1, endword);
  this.words[endword] |= ~0 >>> -end;
};

// Remove bits from start (inclusive) to end (exclusive)
TypedFastBitSet.prototype.removeRange = function (start, end) {
  start = Math.min(start, (this.words.length << 5) - 1);
  end = Math.min(end, (this.words.length << 5) - 1);

  if (start >= end) {
    return;
  }
  const firstword = start >> 5;
  const endword = (end - 1) >> 5;

  if (firstword === endword) {
    this.words[firstword] &= ~((~0 << start) & (~0 >>> -end));
    return;
  }
  this.words[firstword] &= ~(~0 << start);
  this.words.fill(0, firstword + 1, endword);
  this.words[endword] &= ~(~0 >>> -end);
};

// Return true if no bit is set
TypedFastBitSet.prototype.isEmpty = function (index) {
  const c = this.words.length;
  for (let i = 0; i < c; i++) {
    if (this.words[i] !== 0) return false;
  }
  return true;
};

// Is the value contained in the set? Is the bit at index true or false? Returns a boolean
TypedFastBitSet.prototype.has = function (index) {
  return (this.words[index >>> 5] & (1 << index)) !== 0;
};

// Tries to add the value (Set the bit at index to true), return 1 if the
// value was added, return 0 if the value was already present
TypedFastBitSet.prototype.checkedAdd = function (index) {
  this.resize(index);
  const word = this.words[index >>> 5];
  const newword = word | (1 << index);
  this.words[index >>> 5] = newword;
  return (newword ^ word) >>> index;
};

// Reduce the memory usage to a minimum
TypedFastBitSet.prototype.trim = function () {
  var nl = this.words.length;
  while (nl > 0 && this.words[nl - 1] === 0) {
    nl--;
  }
  this.words = this.words.slice(0, nl);
};

// Resize the bitset so that we can write a value at index
TypedFastBitSet.prototype.resize = function (index) {
  if (this.words.length << 5 > index) return;
  const count = (index + 32) >>> 5; // just what is needed
  const newwords = new Uint32Array(count << 1);
  newwords.set(this.words); // hopefully, this copy is fast
  this.words = newwords;
};

// fast function to compute the Hamming weight of a 32-bit unsigned integer
TypedFastBitSet.prototype.hammingWeight = function (v) {
  v -= (v >>> 1) & 0x55555555; // works with signed or unsigned shifts
  v = (v & 0x33333333) + ((v >>> 2) & 0x33333333);
  return (((v + (v >>> 4)) & 0xf0f0f0f) * 0x1010101) >>> 24;
};

// fast function to compute the Hamming weight of four 32-bit unsigned integers
TypedFastBitSet.prototype.hammingWeight4 = function (v1, v2, v3, v4) {
  v1 -= (v1 >>> 1) & 0x55555555; // works with signed or unsigned shifts
  v2 -= (v2 >>> 1) & 0x55555555; // works with signed or unsigned shifts
  v3 -= (v3 >>> 1) & 0x55555555; // works with signed or unsigned shifts
  v4 -= (v4 >>> 1) & 0x55555555; // works with signed or unsigned shifts

  v1 = (v1 & 0x33333333) + ((v1 >>> 2) & 0x33333333);
  v2 = (v2 & 0x33333333) + ((v2 >>> 2) & 0x33333333);
  v3 = (v3 & 0x33333333) + ((v3 >>> 2) & 0x33333333);
  v4 = (v4 & 0x33333333) + ((v4 >>> 2) & 0x33333333);

  v1 = (v1 + (v1 >>> 4)) & 0xf0f0f0f;
  v2 = (v2 + (v2 >>> 4)) & 0xf0f0f0f;
  v3 = (v3 + (v3 >>> 4)) & 0xf0f0f0f;
  v4 = (v4 + (v4 >>> 4)) & 0xf0f0f0f;
  return ((v1 + v2 + v3 + v4) * 0x1010101) >>> 24;
};

// How many values stored in the set? How many set bits?
TypedFastBitSet.prototype.size = function () {
  let answer = 0;
  const c = this.words.length;
  let k = 0 | 0;
  for (; k + 4 < c; k += 4) {
    answer += this.hammingWeight4(
      this.words[k] | 0,
      this.words[k + 1] | 0,
      this.words[k + 2] | 0,
      this.words[k + 3] | 0
    );
  }

  for (; k < c; ++k) {
    answer += this.hammingWeight(this.words[k] | 0);
  }
  return answer;
};

// Return an array with the set bit locations (values)
TypedFastBitSet.prototype.array = function () {
  const answer = new Array(this.size());
  let pos = 0 | 0;
  const c = this.words.length;
  for (let k = 0; k < c; ++k) {
    let w = this.words[k];
    while (w != 0) {
      const t = w & -w;
      answer[pos++] = (k << 5) + this.hammingWeight((t - 1) | 0);
      w ^= t;
    }
  }
  return answer;
};

// Return an array with the set bit locations (values)
TypedFastBitSet.prototype.forEach = function (fnc) {
  const c = this.words.length;
  for (let k = 0; k < c; ++k) {
    let w = this.words[k];
    while (w != 0) {
      const t = w & -w;
      fnc(((k << 5) + this.hammingWeight(t - 1)) | 0);
      w ^= t;
    }
  }
};

// Returns an iterator of set bit locations (values)
TypedFastBitSet.prototype[Symbol.iterator] = function* () {
  const c = this.words.length;
  for (let k = 0; k < c; ++k) {
    let w = this.words[k];
    while (w != 0) {
      const t = w & -w;
      yield (k << 5) + this.hammingWeight((t - 1) | 0);
      w ^= t;
    }
  }
};

// Creates a copy of this bitmap
TypedFastBitSet.prototype.clone = function () {
  const clone = Object.create(TypedFastBitSet.prototype);
  clone.words = new Uint32Array(this.words);
  return clone;
};

// Check if this bitset intersects with another one,
// no bitmap is modified
TypedFastBitSet.prototype.intersects = function (otherbitmap) {
  const newcount = Math.min(this.words.length, otherbitmap.words.length);
  for (let k = 0 | 0; k < newcount; ++k) {
    if ((this.words[k] & otherbitmap.words[k]) !== 0) return true;
  }
  return false;
};

// Computes the intersection between this bitset and another one,
// the current bitmap is modified  (and returned by the function)
TypedFastBitSet.prototype.intersection = function (otherbitmap) {
  const newcount = Math.min(this.words.length, otherbitmap.words.length);
  let k = 0 | 0;
  for (; k + 7 < newcount; k += 8) {
    this.words[k] &= otherbitmap.words[k];
    this.words[k + 1] &= otherbitmap.words[k + 1];
    this.words[k + 2] &= otherbitmap.words[k + 2];
    this.words[k + 3] &= otherbitmap.words[k + 3];
    this.words[k + 4] &= otherbitmap.words[k + 4];
    this.words[k + 5] &= otherbitmap.words[k + 5];
    this.words[k + 6] &= otherbitmap.words[k + 6];
    this.words[k + 7] &= otherbitmap.words[k + 7];
  }
  for (; k < newcount; ++k) {
    this.words[k] &= otherbitmap.words[k];
  }
  const c = this.words.length;
  for (let k = newcount; k < c; ++k) {
    this.words[k] = 0;
  }
  return this;
};

// Computes the size of the intersection between this bitset and another one
TypedFastBitSet.prototype.intersection_size = function (otherbitmap) {
  const newcount = Math.min(this.words.length, otherbitmap.words.length);
  let answer = 0 | 0;
  for (let k = 0 | 0; k < newcount; ++k) {
    answer += this.hammingWeight(this.words[k] & otherbitmap.words[k]);
  }
  return answer;
};

// Computes the intersection between this bitset and another one,
// a new bitmap is generated
TypedFastBitSet.prototype.new_intersection = function (otherbitmap) {
  const answer = Object.create(TypedFastBitSet.prototype);
  const count = Math.min(this.words.length, otherbitmap.words.length);
  answer.words = new Uint32Array(count);
  let k = 0 | 0;
  for (; k + 7 < count; k += 8) {
    answer.words[k] = this.words[k] & otherbitmap.words[k];
    answer.words[k + 1] = this.words[k + 1] & otherbitmap.words[k + 1];
    answer.words[k + 2] = this.words[k + 2] & otherbitmap.words[k + 2];
    answer.words[k + 3] = this.words[k + 3] & otherbitmap.words[k + 3];
    answer.words[k + 4] = this.words[k + 4] & otherbitmap.words[k + 4];
    answer.words[k + 5] = this.words[k + 5] & otherbitmap.words[k + 5];
    answer.words[k + 6] = this.words[k + 6] & otherbitmap.words[k + 6];
    answer.words[k + 7] = this.words[k + 7] & otherbitmap.words[k + 7];
  }
  for (; k < count; ++k) {
    answer.words[k] = this.words[k] & otherbitmap.words[k];
  }
  return answer;
};

// Computes the intersection between this bitset and another one,
// the current bitmap is modified
TypedFastBitSet.prototype.equals = function (otherbitmap) {
  const mcount = Math.min(this.words.length, otherbitmap.words.length);
  for (let k = 0 | 0; k < mcount; ++k) {
    if (this.words[k] != otherbitmap.words[k]) return false;
  }
  if (this.words.length < otherbitmap.words.length) {
    const c = otherbitmap.words.length;
    for (let k = this.words.length; k < c; ++k) {
      if (otherbitmap.words[k] != 0) return false;
    }
  } else if (otherbitmap.words.length < this.words.length) {
    const c = this.words.length;
    for (let k = otherbitmap.words.length; k < c; ++k) {
      if (this.words[k] != 0) return false;
    }
  }
  return true;
};

// Computes the difference between this bitset and another one,
// the current bitset is modified (and returned by the function)
TypedFastBitSet.prototype.difference = function (otherbitmap) {
  const newcount = Math.min(this.words.length, otherbitmap.words.length);
  let k = 0 | 0;
  for (; k + 7 < newcount; k += 8) {
    this.words[k] &= ~otherbitmap.words[k];
    this.words[k + 1] &= ~otherbitmap.words[k + 1];
    this.words[k + 2] &= ~otherbitmap.words[k + 2];
    this.words[k + 3] &= ~otherbitmap.words[k + 3];
    this.words[k + 4] &= ~otherbitmap.words[k + 4];
    this.words[k + 5] &= ~otherbitmap.words[k + 5];
    this.words[k + 6] &= ~otherbitmap.words[k + 6];
    this.words[k + 7] &= ~otherbitmap.words[k + 7];
  }
  for (; k < newcount; ++k) {
    this.words[k] &= ~otherbitmap.words[k];
  }
  return this;
};

// Computes the difference between this bitset and another one,
// the other bitset is modified (and returned by the function)
// (for this set A and other set B,
//   this computes B = A - B  and returns B)
TypedFastBitSet.prototype.difference2 = function (otherbitmap) {
  const mincount = Math.min(this.words.length, otherbitmap.words.length);
  otherbitmap.resize((this.words.length << 5) - 1);
  let k = 0 | 0;
  for (; k + 7 < mincount; k += 8) {
    otherbitmap.words[k] = this.words[k] & ~otherbitmap.words[k];
    otherbitmap.words[k + 1] = this.words[k + 1] & ~otherbitmap.words[k + 1];
    otherbitmap.words[k + 2] = this.words[k + 2] & ~otherbitmap.words[k + 2];
    otherbitmap.words[k + 3] = this.words[k + 3] & ~otherbitmap.words[k + 3];
    otherbitmap.words[k + 4] = this.words[k + 4] & ~otherbitmap.words[k + 4];
    otherbitmap.words[k + 5] = this.words[k + 5] & ~otherbitmap.words[k + 5];
    otherbitmap.words[k + 6] = this.words[k + 6] & ~otherbitmap.words[k + 6];
    otherbitmap.words[k + 7] = this.words[k + 7] & ~otherbitmap.words[k + 7];
  }
  for (; k < mincount; ++k) {
    otherbitmap.words[k] = this.words[k] & ~otherbitmap.words[k];
  }
  // remaining words are all part of difference
  for (; k < this.words.length; ++k) {
    otherbitmap.words[k] = this.words[k];
  }
  otherbitmap.words.fill(0, k);
  return otherbitmap;
};

// Computes the difference between this bitset and another one,
// a new bitmap is generated
TypedFastBitSet.prototype.new_difference = function (otherbitmap) {
  return this.clone().difference(otherbitmap); // should be fast enough
};

// Computes the size of the difference between this bitset and another one
TypedFastBitSet.prototype.difference_size = function (otherbitmap) {
  const newcount = Math.min(this.words.length, otherbitmap.words.length);
  let answer = 0 | 0;
  let k = 0 | 0;
  for (; k < newcount; ++k) {
    answer += this.hammingWeight(this.words[k] & ~otherbitmap.words[k]);
  }
  const c = this.words.length;
  for (; k < c; ++k) {
    answer += this.hammingWeight(this.words[k]);
  }
  return answer;
};

// Computes the changed elements (XOR) between this bitset and another one,
// the current bitset is modified (and returned by the function)
TypedFastBitSet.prototype.change = function (otherbitmap) {
  const mincount = Math.min(this.words.length, otherbitmap.words.length);
  this.resize((otherbitmap.words.length << 5) - 1);
  let k = 0 | 0;
  for (; k + 7 < mincount; k += 8) {
    this.words[k] ^= otherbitmap.words[k];
    this.words[k + 1] ^= otherbitmap.words[k + 1];
    this.words[k + 2] ^= otherbitmap.words[k + 2];
    this.words[k + 3] ^= otherbitmap.words[k + 3];
    this.words[k + 4] ^= otherbitmap.words[k + 4];
    this.words[k + 5] ^= otherbitmap.words[k + 5];
    this.words[k + 6] ^= otherbitmap.words[k + 6];
    this.words[k + 7] ^= otherbitmap.words[k + 7];
  }
  for (; k < mincount; ++k) {
    this.words[k] ^= otherbitmap.words[k];
  }
  // remaining words are all part of change
  for (; k < otherbitmap.words.length; ++k) {
    this.words[k] = otherbitmap.words[k];
  }
  return this;
};

// Computes the change between this bitset and another one,
// a new bitmap is generated
TypedFastBitSet.prototype.new_change = function (otherbitmap) {
  const answer = Object.create(TypedFastBitSet.prototype);
  const count = Math.max(this.words.length, otherbitmap.words.length);
  answer.words = new Uint32Array(count);
  const mcount = Math.min(this.words.length, otherbitmap.words.length);
  let k = 0;
  for (; k + 7 < mcount; k += 8) {
    answer.words[k] = this.words[k] ^ otherbitmap.words[k];
    answer.words[k + 1] = this.words[k + 1] ^ otherbitmap.words[k + 1];
    answer.words[k + 2] = this.words[k + 2] ^ otherbitmap.words[k + 2];
    answer.words[k + 3] = this.words[k + 3] ^ otherbitmap.words[k + 3];
    answer.words[k + 4] = this.words[k + 4] ^ otherbitmap.words[k + 4];
    answer.words[k + 5] = this.words[k + 5] ^ otherbitmap.words[k + 5];
    answer.words[k + 6] = this.words[k + 6] ^ otherbitmap.words[k + 6];
    answer.words[k + 7] = this.words[k + 7] ^ otherbitmap.words[k + 7];
  }
  for (; k < mcount; ++k) {
    answer.words[k] = this.words[k] ^ otherbitmap.words[k];
  }

  const c = this.words.length;
  for (k = mcount; k < c; ++k) {
    answer.words[k] = this.words[k];
  }
  const c2 = otherbitmap.words.length;
  for (k = mcount; k < c2; ++k) {
    answer.words[k] = otherbitmap.words[k];
  }
  return answer;
};

// Computes the number of changed elements between this bitset and another one
TypedFastBitSet.prototype.change_size = function (otherbitmap) {
  const mincount = Math.min(this.words.length, otherbitmap.words.length);
  let answer = 0 | 0;
  let k = 0 | 0;
  for (; k < mincount; ++k) {
    answer += this.hammingWeight(this.words[k] ^ otherbitmap.words[k]);
  }
  const longer =
    this.words.length > otherbitmap.words.length ? this : otherbitmap;
  const c = longer.words.length;
  for (; k < c; ++k) {
    answer += this.hammingWeight(longer.words[k]);
  }
  return answer;
};

// Returns a string representation
TypedFastBitSet.prototype.toString = function () {
  return "{" + this.array().join(",") + "}";
};

// Computes the union between this bitset and another one,
// the current bitset is modified  (and returned by the function)
TypedFastBitSet.prototype.union = function (otherbitmap) {
  const mcount = Math.min(this.words.length, otherbitmap.words.length);
  let k = 0 | 0;
  for (; k + 7 < mcount; k += 8) {
    this.words[k] |= otherbitmap.words[k];
    this.words[k + 1] |= otherbitmap.words[k + 1];
    this.words[k + 2] |= otherbitmap.words[k + 2];
    this.words[k + 3] |= otherbitmap.words[k + 3];
    this.words[k + 4] |= otherbitmap.words[k + 4];
    this.words[k + 5] |= otherbitmap.words[k + 5];
    this.words[k + 6] |= otherbitmap.words[k + 6];
    this.words[k + 7] |= otherbitmap.words[k + 7];
  }
  for (; k < mcount; ++k) {
    this.words[k] |= otherbitmap.words[k];
  }
  if (this.words.length < otherbitmap.words.length) {
    this.resize((otherbitmap.words.length << 5) - 1);
    const c = otherbitmap.words.length;
    for (let k = mcount; k < c; ++k) {
      this.words[k] = otherbitmap.words[k];
    }
  }
  return this;
};

// Computes the union between this bitset and another one,
// a new bitmap is generated
TypedFastBitSet.prototype.new_union = function (otherbitmap) {
  const answer = Object.create(TypedFastBitSet.prototype);
  const count = Math.max(this.words.length, otherbitmap.words.length);
  answer.words = new Uint32Array(count);
  const mcount = Math.min(this.words.length, otherbitmap.words.length);
  for (let k = 0; k < mcount; ++k) {
    answer.words[k] = this.words[k] | otherbitmap.words[k];
  }
  const c = this.words.length;
  for (let k = mcount; k < c; ++k) {
    answer.words[k] = this.words[k];
  }
  const c2 = otherbitmap.words.length;
  for (let k = mcount; k < c2; ++k) {
    answer.words[k] = otherbitmap.words[k];
  }
  return answer;
};

// Computes the size union between this bitset and another one
TypedFastBitSet.prototype.union_size = function (otherbitmap) {
  const mcount = Math.min(this.words.length, otherbitmap.words.length);
  let answer = 0 | 0;
  for (let k = 0 | 0; k < mcount; ++k) {
    answer += this.hammingWeight(this.words[k] | otherbitmap.words[k]);
  }
  if (this.words.length < otherbitmap.words.length) {
    const c = otherbitmap.words.length;
    for (let k = this.words.length; k < c; ++k) {
      answer += this.hammingWeight(otherbitmap.words[k] | 0);
    }
  } else {
    const c = this.words.length;
    for (let k = otherbitmap.words.length; k < c; ++k) {
      answer += this.hammingWeight(this.words[k] | 0);
    }
  }
  return answer;
};

module.exports = TypedFastBitSet;

},
"a/nu45IpqmisPmpxF3w4fIMh7/H4MkKjXz58Ncue7Bs=":
function (require, module, exports, __dirname, __filename) {
var concatMap = require('concat-map');
var balanced = require('balanced-match');

module.exports = expandTop;

var escSlash = '\0SLASH'+Math.random()+'\0';
var escOpen = '\0OPEN'+Math.random()+'\0';
var escClose = '\0CLOSE'+Math.random()+'\0';
var escComma = '\0COMMA'+Math.random()+'\0';
var escPeriod = '\0PERIOD'+Math.random()+'\0';

function numeric(str) {
  return parseInt(str, 10) == str
    ? parseInt(str, 10)
    : str.charCodeAt(0);
}

function escapeBraces(str) {
  return str.split('\\\\').join(escSlash)
            .split('\\{').join(escOpen)
            .split('\\}').join(escClose)
            .split('\\,').join(escComma)
            .split('\\.').join(escPeriod);
}

function unescapeBraces(str) {
  return str.split(escSlash).join('\\')
            .split(escOpen).join('{')
            .split(escClose).join('}')
            .split(escComma).join(',')
            .split(escPeriod).join('.');
}


// Basically just str.split(","), but handling cases
// where we have nested braced sections, which should be
// treated as individual members, like {a,{b,c},d}
function parseCommaParts(str) {
  if (!str)
    return [''];

  var parts = [];
  var m = balanced('{', '}', str);

  if (!m)
    return str.split(',');

  var pre = m.pre;
  var body = m.body;
  var post = m.post;
  var p = pre.split(',');

  p[p.length-1] += '{' + body + '}';
  var postParts = parseCommaParts(post);
  if (post.length) {
    p[p.length-1] += postParts.shift();
    p.push.apply(p, postParts);
  }

  parts.push.apply(parts, p);

  return parts;
}

function expandTop(str) {
  if (!str)
    return [];

  // I don't know why Bash 4.3 does this, but it does.
  // Anything starting with {} will have the first two bytes preserved
  // but *only* at the top level, so {},a}b will not expand to anything,
  // but a{},b}c will be expanded to [a}c,abc].
  // One could argue that this is a bug in Bash, but since the goal of
  // this module is to match Bash's rules, we escape a leading {}
  if (str.substr(0, 2) === '{}') {
    str = '\\{\\}' + str.substr(2);
  }

  return expand(escapeBraces(str), true).map(unescapeBraces);
}

function identity(e) {
  return e;
}

function embrace(str) {
  return '{' + str + '}';
}
function isPadded(el) {
  return /^-?0\d/.test(el);
}

function lte(i, y) {
  return i <= y;
}
function gte(i, y) {
  return i >= y;
}

function expand(str, isTop) {
  var expansions = [];

  var m = balanced('{', '}', str);
  if (!m || /\$$/.test(m.pre)) return [str];

  var isNumericSequence = /^-?\d+\.\.-?\d+(?:\.\.-?\d+)?$/.test(m.body);
  var isAlphaSequence = /^[a-zA-Z]\.\.[a-zA-Z](?:\.\.-?\d+)?$/.test(m.body);
  var isSequence = isNumericSequence || isAlphaSequence;
  var isOptions = m.body.indexOf(',') >= 0;
  if (!isSequence && !isOptions) {
    // {a},b}
    if (m.post.match(/,.*\}/)) {
      str = m.pre + '{' + m.body + escClose + m.post;
      return expand(str);
    }
    return [str];
  }

  var n;
  if (isSequence) {
    n = m.body.split(/\.\./);
  } else {
    n = parseCommaParts(m.body);
    if (n.length === 1) {
      // x{{a,b}}y ==> x{a}y x{b}y
      n = expand(n[0], false).map(embrace);
      if (n.length === 1) {
        var post = m.post.length
          ? expand(m.post, false)
          : [''];
        return post.map(function(p) {
          return m.pre + n[0] + p;
        });
      }
    }
  }

  // at this point, n is the parts, and we know it's not a comma set
  // with a single entry.

  // no need to expand pre, since it is guaranteed to be free of brace-sets
  var pre = m.pre;
  var post = m.post.length
    ? expand(m.post, false)
    : [''];

  var N;

  if (isSequence) {
    var x = numeric(n[0]);
    var y = numeric(n[1]);
    var width = Math.max(n[0].length, n[1].length)
    var incr = n.length == 3
      ? Math.abs(numeric(n[2]))
      : 1;
    var test = lte;
    var reverse = y < x;
    if (reverse) {
      incr *= -1;
      test = gte;
    }
    var pad = n.some(isPadded);

    N = [];

    for (var i = x; test(i, y); i += incr) {
      var c;
      if (isAlphaSequence) {
        c = String.fromCharCode(i);
        if (c === '\\')
          c = '';
      } else {
        c = String(i);
        if (pad) {
          var need = width - c.length;
          if (need > 0) {
            var z = new Array(need + 1).join('0');
            if (i < 0)
              c = '-' + z + c.slice(1);
            else
              c = z + c;
          }
        }
      }
      N.push(c);
    }
  } else {
    N = concatMap(n, function(el) { return expand(el, false) });
  }

  for (var j = 0; j < N.length; j++) {
    for (var k = 0; k < post.length; k++) {
      var expansion = pre + N[j] + post[k];
      if (!isTop || isSequence || expansion)
        expansions.push(expansion);
    }
  }

  return expansions;
}


},
"a4dQTVAat0MdbsRjIcZTnAYaw7p1Z2s+IjRNF1moctk=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const {promisify} = require('util');
const {lstat, readdir} = require('fs').promises;
const path = require('path');
const {EventEmitter} = require('events');

const format = require('format-io');
const tryToCatch = require('try-to-catch');

/*  The lstat() function shall be equivalent to stat(),
    except when path refers to a symbolic link. In that case lstat()
    shall return information about the link, while stat() shall return
    information about the file the link references.
*/

module.exports = promisify((dir, options, callback) => {
    const emitter = new EventEmitter();
    
    let total = 0;
    let type;
    
    if (!callback) {
        callback = options;
        options = {};
    } else {
        type = options.type;
    }
    
    emitter.on('file', (file, stat) => {
        total += stat.size;
    });
    
    emitter.on('error', callback);
    
    emitter.on('end', () => {
        if (type === 'raw')
            return callback(null, total);
        
        callback(null, format.size(total));
    });
    
    processDir(dir, options, emitter);
});

function processDir(dir, options, emitter) {
    const {stopOnError} = options;
    let wasError = false;
    let asyncRunning = 0;
    let fileCounter = 1;
    
    const execCallBack = () => {
        const isError = wasError && stopOnError;
        const isDone = !fileCounter && !asyncRunning;
        
        if (!isDone || isError)
            return;
        
        emitter.emit('end');
    };
    
    getDirInfo(dir);
    
    async function getDirInfo(dir) {
        const [error, stat] = await tryToCatch(lstat, dir);
        
        --fileCounter;
        
        if (error && stopOnError) {
            wasError = true;
            emitter.emit('error', error);
            return;
        }
        
        if (error)
            return execCallBack();
        
        const isDir = stat.isDirectory();
        
        if (!isDir) {
            emitter.emit('file', dir, stat);
            execCallBack();
            return;
        }
        
        ++asyncRunning;
        
        execCallBack();
        
        const [readError, files] = await tryToCatch(readdir, dir);
        
        asyncRunning--;
        
        if (!readError)
            return onReaddir(dir, files);
        
        if (readError && stopOnError) {
            wasError = true;
            emitter.emit('error', readError);
        }
        
        execCallBack();
    }
    
    function onReaddir(dir, files) {
        const n = files.length;
        
        fileCounter += n;
        
        if (!n)
            return execCallBack();
        
        for (const file of files) {
            const dirPath = path.join(dir, file);
            getDirInfo(dirPath);
        }
    }
}


},
"a60+g8So8RPPxA7ydX7LxyfmfF4W6oRHzcbhKvKxVUo=":
function (require, module, exports, __dirname, __filename) {
'use strict';

/**
 * Class representing an event.
 *
 * @private
 */
class Event {
  /**
   * Create a new `Event`.
   *
   * @param {String} type The name of the event
   * @param {Object} target A reference to the target to which the event was
   *     dispatched
   */
  constructor(type, target) {
    this.target = target;
    this.type = type;
  }
}

/**
 * Class representing a message event.
 *
 * @extends Event
 * @private
 */
class MessageEvent extends Event {
  /**
   * Create a new `MessageEvent`.
   *
   * @param {(String|Buffer|ArrayBuffer|Buffer[])} data The received data
   * @param {WebSocket} target A reference to the target to which the event was
   *     dispatched
   */
  constructor(data, target) {
    super('message', target);

    this.data = data;
  }
}

/**
 * Class representing a close event.
 *
 * @extends Event
 * @private
 */
class CloseEvent extends Event {
  /**
   * Create a new `CloseEvent`.
   *
   * @param {Number} code The status code explaining why the connection is being
   *     closed
   * @param {String} reason A human-readable string explaining why the
   *     connection is closing
   * @param {WebSocket} target A reference to the target to which the event was
   *     dispatched
   */
  constructor(code, reason, target) {
    super('close', target);

    this.wasClean = target._closeFrameReceived && target._closeFrameSent;
    this.reason = reason;
    this.code = code;
  }
}

/**
 * Class representing an open event.
 *
 * @extends Event
 * @private
 */
class OpenEvent extends Event {
  /**
   * Create a new `OpenEvent`.
   *
   * @param {WebSocket} target A reference to the target to which the event was
   *     dispatched
   */
  constructor(target) {
    super('open', target);
  }
}

/**
 * Class representing an error event.
 *
 * @extends Event
 * @private
 */
class ErrorEvent extends Event {
  /**
   * Create a new `ErrorEvent`.
   *
   * @param {Object} error The error that generated this event
   * @param {WebSocket} target A reference to the target to which the event was
   *     dispatched
   */
  constructor(error, target) {
    super('error', target);

    this.message = error.message;
    this.error = error;
  }
}

/**
 * This provides methods for emulating the `EventTarget` interface. It's not
 * meant to be used directly.
 *
 * @mixin
 */
const EventTarget = {
  /**
   * Register an event listener.
   *
   * @param {String} type A string representing the event type to listen for
   * @param {Function} listener The listener to add
   * @param {Object} [options] An options object specifies characteristics about
   *     the event listener
   * @param {Boolean} [options.once=false] A `Boolean`` indicating that the
   *     listener should be invoked at most once after being added. If `true`,
   *     the listener would be automatically removed when invoked.
   * @public
   */
  addEventListener(type, listener, options) {
    if (typeof listener !== 'function') return;

    function onMessage(data) {
      listener.call(this, new MessageEvent(data, this));
    }

    function onClose(code, message) {
      listener.call(this, new CloseEvent(code, message, this));
    }

    function onError(error) {
      listener.call(this, new ErrorEvent(error, this));
    }

    function onOpen() {
      listener.call(this, new OpenEvent(this));
    }

    const method = options && options.once ? 'once' : 'on';

    if (type === 'message') {
      onMessage._listener = listener;
      this[method](type, onMessage);
    } else if (type === 'close') {
      onClose._listener = listener;
      this[method](type, onClose);
    } else if (type === 'error') {
      onError._listener = listener;
      this[method](type, onError);
    } else if (type === 'open') {
      onOpen._listener = listener;
      this[method](type, onOpen);
    } else {
      this[method](type, listener);
    }
  },

  /**
   * Remove an event listener.
   *
   * @param {String} type A string representing the event type to remove
   * @param {Function} listener The listener to remove
   * @public
   */
  removeEventListener(type, listener) {
    const listeners = this.listeners(type);

    for (let i = 0; i < listeners.length; i++) {
      if (listeners[i] === listener || listeners[i]._listener === listener) {
        this.removeListener(type, listeners[i]);
      }
    }
  }
};

module.exports = EventTarget;

},
"a6mujEb8qBzOC6yEE+qyF1FCbTGyqLm4GMFAFsaMsxM=":
function (require, module, exports, __dirname, __filename) {
var createError = require('errno').create
var LevelUPError = createError('LevelUPError')
var NotFoundError = createError('NotFoundError', LevelUPError)

NotFoundError.prototype.notFound = true
NotFoundError.prototype.status = 404

module.exports = {
  LevelUPError: LevelUPError,
  InitializationError: createError('InitializationError', LevelUPError),
  OpenError: createError('OpenError', LevelUPError),
  ReadError: createError('ReadError', LevelUPError),
  WriteError: createError('WriteError', LevelUPError),
  NotFoundError: NotFoundError,
  EncodingError: createError('EncodingError', LevelUPError)
}

},
"aITDRdeWC8dzHMyx3Ae8V8JCuUZnIKb9O9CDUiymt/A=":
function (require, module, exports, __dirname, __filename) {
const v3 = require('./v3')

module.exports = function (events) {
  function timestamp () {
    return Date.now()
  }

  function EBTStream (peer, remote, version, client, isMsg, onClose) {
    this.paused = true //start out paused
    this.remote = remote
    this.peer = peer
    this.version = version
    this.peer.state = events.connect(this.peer.state, {
      id: remote,
      ts: timestamp(),
      client: client
    })
    this.ended = false
    this._onClose = onClose
    this.isMsg = isMsg
    this.sink = this.source = null
  }

  EBTStream.prototype.clock = function (clock) {
    this.peer.state = events.peerClock(this.peer.state, {
      id: this.remote,
      value: clock,
      ts: timestamp()
    })
    this.paused = false
    this.peer.update()
    if (this.source) this.source.resume()
  }

  EBTStream.prototype.write = function (data) {
    if (this.peer.logging) {
      if (Buffer.isBuffer(data))
        console.log("EBT:recv binary (" + this.peer.id + ")", "0x" + data.toString('hex'))
      else
        console.log("EBT:recv json (" + this.peer.id + ")", JSON.stringify(data, null, 2))
    }

    if (this.ended) throw new Error('write after ebt stream ended:'+this.remote)

    if (this.isMsg(data)) {
      this.peer.state = events.receive(this.peer.state, {
        id: this.remote,
        value: data,
        ts: timestamp()
      })
    } else {
      this.peer.state = events.notes(this.peer.state, {
        id: this.remote,
        value: data,
        ts: timestamp()
      })
    }

    this.peer.update(this.remote)
  }

  EBTStream.prototype.abort = EBTStream.prototype.end = function (err) {
    this.ended = true
    //check if we have already ended
    if (!this.peer.state.peers[this.remote]) return

    if (this.peer.logging) console.log('EBT:dcon', this.remote)

    var peerState = this.peer.state.peers[this.remote]
    this.peer.state = events.disconnect(this.peer.state, {
      id: this.remote,
      ts: timestamp()
    })
    if (this._onClose) this._onClose(peerState)
    //remove from the peer...
    delete this.peer.streams[this.remote]
    if (this.source && !this.source.ended) this.source.abort(err)
    if (this.sink && !this.sink.ended) this.sink.end(err)
  }

  EBTStream.prototype.canSend = function () {
    var state = this.peer.state.peers[this.remote]
    return (
      this.sink &&
        !this.sink.paused &&
        !this.ended && (
          //missing state means this peer was blocked,
          //end immediately.
          state.blocked || state.msgs.length || state.notes
        )
    )
  }

  EBTStream.prototype.resume = function () {
    if (!this.sink || this.sink.paused) return

    var state = this.peer.state.peers[this.remote]
    while (this.canSend()) {
      if (state.blocked) {
        this.end()
      } else if (state.msgs.length) {
        if (this.peer.logging) {
          if (Buffer.isBuffer(state.msgs[0]))
            console.log("EBT:send binary (" + this.peer.id + ")", "0x" + state.msgs[0].toString('hex'))
          else
            console.log("EBT:send json (" + this.peer.id + ")", JSON.stringify(state.msgs[0], null, 2))
        }
        this.sink.write(state.msgs.shift())
      } else {
        var notes = state.notes
        state.notes = null
        if (this.peer.logging) {
          const formattedNotes = {}
          for (let feed in notes) {
            const seq = notes[feed]
            formattedNotes[feed] = {
              seq,
              sequence: v3.getSequence(seq),
              rx: v3.getReceive(seq)
            }
          }
          console.log("EBT:send notes (" + this.peer.id + ")", formattedNotes)
        }
        this.sink.write(notes)
      }
    }
  }

  EBTStream.prototype.pipe = require('push-stream/pipe')

  return EBTStream
}

},
"aOTU69E8jG8wUt0LNSy+XontoUma4esbabwnky9IjBw=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const push = require('push-stream')
const ssbKeys = require('ssb-keys')
const validate = require('ssb-validate') // TODO: remove this eventually
const validate2 =
  typeof localStorage === 'undefined' || localStorage === null
    ? require('ssb-validate2-rsjs-node')
    : require('ssb-validate2')
const SSBURI = require('ssb-uri2')
const bipf = require('bipf')
const pull = require('pull-stream')
const paramap = require('pull-paramap')
const Ref = require('ssb-ref')
const Obv = require('obz')
const promisify = require('promisify-4loc')
const jitdbOperators = require('jitdb/operators')
const bendyButt = require('ssb-bendy-butt')
const JITDb = require('jitdb')
const Debug = require('debug')
const multicb = require('multicb')
const mutexify = require('mutexify')

const operators = require('./operators')
const { indexesPath } = require('./defaults')
const { onceWhen } = require('./utils')
const DebouncingBatchAdd = require('./debounce-batch')
const Log = require('./log')
const Status = require('./status')
const makeBaseIndex = require('./indexes/base')
const KeysIndex = require('./indexes/keys')
const PrivateIndex = require('./indexes/private')

const { where, fromDB, key, author, deferred, toCallback, asOffsets } =
  operators

exports.name = 'db'

exports.version = '1.9.1'

exports.manifest = {
  get: 'async',
  add: 'async',
  publish: 'async',
  publishAs: 'async',
  del: 'async',
  deleteFeed: 'async',
  addTransaction: 'async',
  addOOO: 'async',
  addBatch: 'async',
  addOOOBatch: 'async',
  getStatus: 'sync',

  // `query` should be `sync`, but secret-stack is automagically converting it
  // to async because of secret-stack/utils.js#hookOptionalCB. Eventually we
  // should include an option `synconly` in secret-stack that bypasses the hook,
  // but for now we leave the `query` API *implicitly* available in the plugin:

  // query: 'sync',
}

exports.init = function (sbot, config) {
  let self
  config = config || {}
  config.db2 = config.db2 || {}
  const indexes = {}
  const dir = config.path
  const privateIndex = PrivateIndex(dir, sbot, config)
  const log = Log(dir, config, privateIndex)
  const jitdb = JITDb(log, indexesPath(dir))
  const status = Status(log, jitdb)
  const debug = Debug('ssb:db2')
  const post = Obv()
  const hmacKey = null
  const stateFeedsReady = Obv().set(false)
  const state = {}

  sbot.close.hook(function (fn, args) {
    close((err) => {
      fn.apply(this, args)
    })
  })

  registerIndex(makeBaseIndex(privateIndex))
  registerIndex(KeysIndex)

  loadStateFeeds()

  function setStateFeedsReady(x) {
    stateFeedsReady.set(x)
  }

  function loadStateFeeds(cb) {
    // restore current state
    validate2.ready(() => {
      onDrain('base', () => {
        pull(
          indexes.base.getAllLatest(),
          paramap((latest, cb) => {
            getMsgByOffset(latest.value.offset, (err, kvt) => {
              if (err) cb(err)
              else cb(null, kvt)
            })
          }, 8),
          pull.collect((err, kvts) => {
            if (err) return console.error('loadStateFeeds failed: ' + err)
            for (const kvt of kvts) {
              updateState(kvt)
            }
            debug('getAllLatest is done setting up initial validate state')
            if (!stateFeedsReady.value) stateFeedsReady.set(true)
            if (cb) cb()
          })
        )
      })
    })
  }

  function updateState(kvt) {
    state[kvt.value.author] = PrivateIndex.reEncrypt(kvt)
  }

  // Crunch stats numbers to produce one number for the "indexing" progress
  status.obv((stats) => {
    const logSize = Math.max(1, stats.log) // 1 prevents division by zero
    const nums = Object.values(stats.indexes).concat(Object.values(stats.jit))
    const N = Math.max(1, nums.length) // 1 prevents division by zero
    const progress = Math.min(
      nums
        .map((offset) => Math.max(0, offset)) // avoid -1 numbers
        .map((offset) => offset / logSize) // this index's progress
        .reduce((acc, x) => acc + x, 0) / N, // avg = (sum of all progress) / N
      1 // never go above 1
    )
    sbot.emit('ssb:db2:indexing:progress', progress)
  })

  function guardAgainstDuplicateLogs(methodName) {
    if (sbot.db2migrate && sbot.db2migrate.doesOldLogExist()) {
      return new Error(
        'ssb-db2: refusing to ' +
          methodName +
          ' because the old log still exists. ' +
          'This is to protect your feed from forking ' +
          'into an irrecoverable state.'
      )
    }
  }

  function getHelper(id, onlyValue, cb) {
    self.query(
      where(key(id)),
      toCallback((err, results) => {
        if (err) return cb(err)
        else if (results.length)
          return cb(null, onlyValue ? results[0].value : results[0])
        else return cb(new Error('Key not found in database ' + id))
      })
    )
  }

  function get(id, cb) {
    getHelper(id, true, cb)
  }

  function getMsg(id, cb) {
    getHelper(id, false, cb)
  }

  function getMsgByOffset(offset, cb) {
    log.get(offset, (err, buf) => {
      if (err) return cb(err)
      cb(null, bipf.decode(buf, 0))
    })
  }

  const debouncePeriod = config.db2.addDebounce || 250
  const debouncer = new DebouncingBatchAdd(addBatch, debouncePeriod)

  function addOOOBatch(msgVals, cb) {
    const guard = guardAgainstDuplicateLogs('addOOOBatch()')
    if (guard) return cb(guard)

    onceWhen(
      stateFeedsReady,
      (ready) => ready === true,
      () => {
        validate2.validateOOOBatch(hmacKey, msgVals, (err, keys) => {
          if (err) return cb(err)

          const done = multicb({ pluck: 1 })
          for (var i = 0; i < msgVals.length; ++i)
            log.add(keys[i], msgVals[i], done())

          done(cb)
        })
      }
    )
  }

  function addTransaction(msgVals, oooMsgVals, cb) {
    const guard = guardAgainstDuplicateLogs('addTransaction()')
    if (guard) return cb(guard)

    oooMsgVals = oooMsgVals || []
    msgVals = msgVals || []

    onceWhen(
      stateFeedsReady,
      (ready) => ready === true,
      () => {
        const done = multicb({ pluck: 1 })

        if (msgVals.length > 0) {
          const author = msgVals[0].author
          if (!Ref.isFeedId(author))
            return cb(
              new Error('addTransaction() does not support feed ID ' + author)
            )

          const latestMsgVal = state[author] ? state[author].value : null
          validate2.validateBatch(hmacKey, msgVals, latestMsgVal, done())
        } else {
          done()(null, [])
        }

        validate2.validateOOOBatch(hmacKey, oooMsgVals, done())

        done((err, keys) => {
          if (err) return cb(err)

          const [msgKeys, oooKeys] = keys

          if (msgKeys.length > 0) {
            const lastIndex = msgKeys.length - 1
            updateState({
              key: msgKeys[lastIndex],
              value: msgVals[lastIndex],
            })
          }

          log.addTransaction(
            msgKeys.concat(oooKeys),
            msgVals.concat(oooMsgVals),
            (err, kvts) => {
              if (err) return cb(err)

              kvts.forEach((kvt) => post.set(kvt))
              cb(null, kvts)
            }
          )
        })
      }
    )
  }

  function add(msgVal, cb) {
    const guard = guardAgainstDuplicateLogs('add()')
    if (guard) return cb(guard)

    onceWhen(
      stateFeedsReady,
      (ready) => ready === true,
      () => {
        if (Ref.isFeedId(msgVal.author)) {
          debouncer.add(msgVal, cb)
        } else if (SSBURI.isBendyButtV1FeedSSBURI(msgVal.author)) {
          addImmediately(msgVal, cb)
        } else {
          cb(new Error('Unknown feed format: ' + msgVal.author))
        }
      }
    )
  }

  function addBatch(msgVals, cb) {
    const guard = guardAgainstDuplicateLogs('addBatch()')
    if (guard) return cb(guard)

    if (msgVals.length === 0) {
      return cb(null, [])
    }
    const author = msgVals[0].author
    if (!Ref.isFeedId(author)) {
      return cb(new Error('addBatch() does not support feed ID ' + author))
    }

    onceWhen(
      stateFeedsReady,
      (ready) => ready === true,
      () => {
        const latestMsgVal = state[author] ? state[author].value : null
        validate2.validateBatch(hmacKey, msgVals, latestMsgVal, (err, keys) => {
          if (err) return cb(err)

          const done = multicb({ pluck: 1 })
          for (var i = 0; i < msgVals.length; ++i) {
            const isLast = i === msgVals.length - 1

            if (isLast) updateState({ key: keys[i], value: msgVals[i] })

            log.add(keys[i], msgVals[i], (err, kvt) => {
              if (err) return done()(err)

              post.set(kvt)
              done()(null, kvt)
            })
          }

          done(cb)
        })
      }
    )
  }

  function encryptContent(keys, content) {
    if (sbot.box2 && content.recps.every(sbot.box2.supportsBox2)) {
      const feedState = state[keys.id]
      return sbot.box2.encryptClassic(
        keys,
        content,
        feedState ? feedState.key : null
      )
    } else return ssbKeys.box(content, content.recps)
  }

  function addImmediately(msgVal, cb) {
    const guard = guardAgainstDuplicateLogs('addImmediately()')
    if (guard) return cb(guard)

    onceWhen(
      stateFeedsReady,
      (ready) => ready === true,
      () => {
        if (Ref.isFeedId(msgVal.author)) {
          const previous = (state[msgVal.author] || { value: null }).value
          validate2.validateSingle(hmacKey, msgVal, previous, (err, key) => {
            if (err) {
              debug(
                `validation failed for classic message in addImmediately(): ${err.message}`
              )
              return cb(err)
            }
            updateState({ key, value: msgVal })
            log.add(key, msgVal, (err, kvt) => {
              if (err) return cb(err)

              post.set(kvt)
              cb(null, kvt)
            })
          })
        } else if (SSBURI.isBendyButtV1FeedSSBURI(msgVal.author)) {
          const previous = (state[msgVal.author] || { value: null }).value
          const err = bendyButt.validateSingle(msgVal, previous, hmacKey)
          if (err) {
            debug(
              `validation failed for bendy butt message in addImmediately(): ${err.message}`
            )
            return cb(err)
          }
          const key = bendyButt.hash(msgVal)
          updateState({ key, value: msgVal })
          log.add(key, msgVal, (err, kvt) => {
            if (err) return cb(err)

            post.set(kvt)
            cb(null, kvt)
          })
        } else {
          cb(new Error('Unknown feed format: ' + msgVal.author))
        }
      }
    )
  }

  function addOOO(msgVal, cb) {
    const guard = guardAgainstDuplicateLogs('addOOO()')
    if (guard) return cb(guard)

    validate2.validateOOOBatch(hmacKey, [msgVal], (err, keys) => {
      if (err) return cb(err)
      const key = keys[0]
      get(key, (err, data) => {
        if (data) return cb(null, data)
        log.add(key, msgVal, (err, data) => {
          if (err) return cb(err)
          cb(null, data)
        })
      })
    })
  }

  function publish(content, cb) {
    const guard = guardAgainstDuplicateLogs('publish()')
    if (guard) return cb(guard)

    publishAs(config.keys, content, cb)
  }

  function publishAs(keys, content, cb) {
    const guard = guardAgainstDuplicateLogs('publishAs()')
    if (guard) return cb(guard)

    if (!Ref.isFeedId(keys.id)) {
      return cb(
        new Error('publishAs() does not support feed format: ' + keys.id)
      )
    }

    onceWhen(
      stateFeedsReady,
      (ready) => ready === true,
      () => {
        if (content.recps) {
          try {
            content = encryptContent(keys, content)
          } catch (ex) {
            return cb(ex)
          }
        }
        const latestKVT = state[keys.id]
        const msgVal = validate.create(
          latestKVT ? { queue: [latestKVT] } : null,
          keys,
          hmacKey,
          content,
          Date.now()
        )
        addImmediately(msgVal, cb)
      }
    )
  }

  function del(msgId, cb) {
    const guard = guardAgainstDuplicateLogs('del()')
    if (guard) return cb(guard)

    self.query(
      where(key(msgId)),
      asOffsets(),
      toCallback((err, results) => {
        if (err) return cb(err)
        if (results.length === 0)
          return cb(
            new Error('cannot delete ' + msgId + ' because it was not found')
          )

        indexes['keys'].delMsg(msgId)
        log.del(results[0], cb)
      })
    )
  }

  function deleteFeed(feedId, cb) {
    const guard = guardAgainstDuplicateLogs('deleteFeed()')
    if (guard) return cb(guard)

    jitdb.all(author(feedId), 0, false, true, (err, offsets) => {
      push(
        push.values(offsets),
        push.asyncMap((offset, cb) => {
          log.del(offset, cb)
        }),
        push.collect((err) => {
          if (err) cb(err)
          else {
            delete state[feedId]
            indexes.base.removeFeedFromLatest(feedId, cb)
          }
        })
      )
    })
  }

  function clearIndexes() {
    for (const indexName in indexes) indexes[indexName].remove(() => {})
  }

  function registerIndex(Index) {
    const index = new Index(log, dir)

    if (indexes[index.name]) throw 'Index already exists'

    index.offset((o) => status.updateIndex(index.name, o))

    indexes[index.name] = index
  }

  function updateIndexes() {
    const start = Date.now()

    const indexesArr = Object.values(indexes)

    const lowestOffset = Math.min(
      ...indexesArr.map((idx) => idx.offset.value),
      privateIndex.latestOffset.value
    )
    debug(`lowest offset for all indexes is ${lowestOffset}`)

    log.stream({ gt: lowestOffset }).pipe({
      paused: false,
      write(record) {
        indexesArr.forEach((idx) => idx.onRecord(record, false))
      },
      end() {
        debug(`updateIndexes() scan time: ${Date.now() - start}ms`)
        const writeTasks = indexesArr.map((idx) =>
          promisify(idx.flush.bind(idx))()
        )
        Promise.all(writeTasks).then(() => {
          debug('updateIndexes() live streaming')
          log.stream({ gt: indexes['base'].offset.value, live: true }).pipe({
            paused: false,
            write(record) {
              indexesArr.forEach((idx) => idx.onRecord(record, true))
            },
          })
        })
      },
    })
  }

  function onDrain(indexName, cb) {
    if (!cb) {
      // default
      cb = indexName
      indexName = 'base'
    }

    // setTimeout to make sure extra indexes from secret-stack are also included
    setTimeout(() => {
      onIndexesStateLoaded(() => {
        log.onDrain(() => {
          const index = indexes[indexName]
          if (!index) return cb('Unknown index:' + indexName)

          status.updateLog()

          if (index.offset.value === log.since.value) {
            status.updateIndex(indexName, index.offset.value)
            cb()
          } else {
            const remove = index.offset(() => {
              if (index.offset.value === log.since.value) {
                remove()
                status.updateIndex(indexName, index.offset.value)
                cb()
              }
            })
          }
        })
      })
    })
  }

  function onIndexesStateLoaded(cb) {
    if (!onIndexesStateLoaded.promise) {
      const stateLoadedPromises = [privateIndex.stateLoaded]
      for (const indexName in indexes) {
        stateLoadedPromises.push(indexes[indexName].stateLoaded)
      }
      onIndexesStateLoaded.promise = Promise.all(stateLoadedPromises)
    }
    onIndexesStateLoaded.promise.then(cb)
  }

  // setTimeout to make sure extra indexes from secret-stack are also included
  const timer = setTimeout(() => {
    onIndexesStateLoaded(updateIndexes)
  })
  if (timer.unref) timer.unref()

  function close(cb) {
    const tasks = []
    for (const indexName in indexes) {
      const index = indexes[indexName]
      tasks.push(promisify(index.close.bind(index))())
    }
    Promise.all(tasks)
      .then(() => promisify(log.close)())
      .then(cb, cb)
  }

  // override query() from jitdb to implicitly call fromDB()
  function query(first, ...rest) {
    // Before running the query, the log needs to be migrated/synced with the
    // old log and it should be 'drained'
    const waitUntilReady = deferred((meta, cb) => {
      if (sbot.db2migrate) {
        sbot.db2migrate.synchronized((isSynced) => {
          if (isSynced) onDrain(cb)
        })
      } else {
        onDrain(cb)
      }
    })

    if (first && first.meta) {
      return jitdbOperators.query(first, where(waitUntilReady), ...rest)
    } else {
      const ops = fromDB(jitdb)
      ops.meta.db = this
      return jitdbOperators.query(ops, where(waitUntilReady), first, ...rest)
    }
  }

  function reindexOffset(data, cb) {
    jitdb.reindex(data.offset, (err) => {
      if (err) return cb(err)

      for (const indexName in indexes) {
        const idx = indexes[indexName]
        if (idx.indexesContent()) idx.processRecord(data, data.seq)
      }

      cb(null, data.offset)
    })
  }

  const reindexingLock = mutexify()

  function reindexEncrypted(cb) {
    reindexingLock((unlock) => {
      const offsets = privateIndex.missingDecrypt()
      const keysIndex = indexes['keys']
      const B_KEY = Buffer.from('key')
      const B_META = Buffer.from('meta')
      const B_PRIVATE = Buffer.from('private')

      push(
        push.values(offsets),
        push.asyncMap((offset, cb) => {
          log.get(offset, (err, buf) => {
            if (err) return cb(err)

            const pMeta = bipf.seekKey(buf, 0, B_META)
            if (pMeta < 0) return cb()
            const pPrivate = bipf.seekKey(buf, pMeta, B_PRIVATE)
            if (pPrivate < 0) return cb()

            // check if we can decrypt the record
            if (!bipf.decode(buf, pPrivate)) return cb()

            const pKey = bipf.seekKey(buf, 0, B_KEY)
            if (pKey < 0) return cb()
            const key = bipf.decode(buf, pKey)

            onDrain('keys', () => {
              keysIndex.getSeq(key, (err, seqNum) => {
                if (err) return cb(err)

                const seq = parseInt(seqNum, 10)

                reindexOffset({ offset, seq, value: buf }, cb)
              })
            })
          })
        }),
        push.collect((err, result) => {
          unlock(cb, err, result)
        })
      )
    })
  }

  return (self = {
    // Public API:
    get,
    getMsg,
    query,
    del,
    deleteFeed,
    add,
    publish,
    publishAs,
    addTransaction,
    addOOO,
    addOOOBatch,
    getStatus: () => status.obv,
    operators,
    post,
    reindexEncrypted,

    // used for partial replication in browser, will be removed soon!
    setPost: post.set,

    // needed primarily internally by other plugins in this project:
    addBatch,
    addImmediately,
    getLatest: indexes.base.getLatest.bind(indexes.base),
    getAllLatest: indexes.base.getAllLatest.bind(indexes.base),
    getLog: () => log,
    registerIndex,
    setStateFeedsReady,
    loadStateFeeds,
    stateFeedsReady,
    getState: () => state,
    getIndexes: () => indexes,
    getIndex: (index) => indexes[index],
    clearIndexes,
    onDrain,
    getJITDB: () => jitdb,
  })
}

},
"an9dxouVGOFt+pPYLCmIvQ3cMN+eGDewAEmBPGhlX6s=":
function (require, module, exports, __dirname, __filename) {

var Source = require('./source')
var Sink = require('./sink')

module.exports = function () {

  var source = Source()
  var sink = Sink()

  return {
    source: source,
    sink: sink,
    resolve: function (duplex) {
      source.resolve(duplex.source)
      sink.resolve(duplex.sink)

    }
  }


}

},
"ap3iIy8iwWqq+wjloxfLq1T76n5Jxge27khF9jPmU2s=":
function (require, module, exports, __dirname, __filename) {

var core = require('./core')
var util = require('./util')

for(var k in core)
  exports[k] = core[k]
for(var k in util)
  exports[k] = util[k]


},
"bDJXRfHwQQgCZLXZdgjYSo4HwvJzGOortTI8nFRPCeA=":
function (require, module, exports, __dirname, __filename) {

module.exports = function () {
  var read, reader, cb, abort, stream

  function delayed (_read) {
    //if we already have the stream, go!
    if(stream) return stream(_read)

    read = _read
    return function (_abort, _cb) {
      if(reader) reader(_abort, _cb)
      else abort = _abort, cb = _cb

    }
  }

  delayed.resolve = function (_stream) {
    if(stream) throw new Error('already resolved')
    stream = _stream
    if(!stream) throw new Error('resolve *must* be passed a transform stream')
    if(read) {
      reader = stream(read)
      if(cb) reader(abort, cb)
    }
  }

  return delayed
}

},
"bI0k9SzCVzz5dVL+uB02I/IWuLjMRUMnD7lcERIsmxw=":
function (require, module, exports, __dirname, __filename) {
//phases:
// 1 client sends challenge
// 2 server sends challenge
// 3 client sends hello (include proof they know the server)
// 4 server decides if they want client to connect with them
// 5 server sends acknowledgement to client

module.exports = {
  serverErrorOnChallenge:
    "shs.client: error when expecting server to accept challenge (phase 1).\n" +
    "possibly the server is busy, does not speak shs or uses a different application cap",

  serverInvalidChallenge:
    "shs.client: server responded with invalid challenge (phase 2). possibly server does not speak shs",

  serverHungUp:
    "shs.client: server hung up when we sent hello (phase 3).\n" +
    "Possibly we dailed a wrong number, or the server does not wish to talk to us.",

  serverAcceptInvalid:
    "shs.client: the server's response accepting us our hello (phase 5) was invalid, so we hung up",

  clientErrorOnChallenge:
    "shs.server: error when waiting for client to send challenge (phase 1)",

  clientInvalidChallenge:
    "shs.server: client sent invalid challenge (phase 1), possibly they tried to speak a different protocol or had wrong application cap",

  //we got a networking error:
  clientErrorOnHello:
    "shs.server: error when expecting client to say hello (phase 2)",

  clientInvalidHello:
    "shs.server: client hello invalid (phase 3). they dailed a wrong number - they didn't have our public key",

  clientUnauthorized:
    "shs.server: we did not authorize the client (phase 4), so we hung up.",

  serverErrorOnAuthorization:
    "shs.server: while trying to decide if the client should be authorized (phase 4), we got an error on the server. This could be a database error",
}





},
"bKeiwBPcHhuAkoiYhf8ZZ5xBOLX8kYKqzCBsJjRU+dY=":
function (require, module, exports, __dirname, __filename) {
/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */
var byteToHex = [];
for (var i = 0; i < 256; ++i) {
  byteToHex[i] = (i + 0x100).toString(16).substr(1);
}

function bytesToUuid(buf, offset) {
  var i = offset || 0;
  var bth = byteToHex;
  // join used to fix memory issue caused by concatenation: https://bugs.chromium.org/p/v8/issues/detail?id=3175#c4
  return ([bth[buf[i++]], bth[buf[i++]], 
	bth[buf[i++]], bth[buf[i++]], '-',
	bth[buf[i++]], bth[buf[i++]], '-',
	bth[buf[i++]], bth[buf[i++]], '-',
	bth[buf[i++]], bth[buf[i++]], '-',
	bth[buf[i++]], bth[buf[i++]],
	bth[buf[i++]], bth[buf[i++]],
	bth[buf[i++]], bth[buf[i++]]]).join('');
}

module.exports = bytesToUuid;

},
"bOmx5DpyWdyV3euSt80OhJemBxqnjA32D+vFtO7fPGQ=":
function (require, module, exports, __dirname, __filename) {
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});

exports.default = function (model, calc) {
  var fn = function fn(buf, previous) {
    return calc(buf, previous) >>> 0;
  };
  fn.signed = calc;
  fn.unsigned = fn;
  fn.model = model;

  return fn;
};

},
"bPnKnRHY9Y1+/6jYdrKcxU1emBLzYFJiw4mTfEX3SLQ=":
function (require, module, exports, __dirname, __filename) {
const RAF = require('random-access-file')

module.exports = function (filename, opts) {
  if('string' === typeof filename) {
    const raf = RAF(filename, opts)
    raf.filename = filename
    return raf
  }
  return filename
}




},
"bS4BElfJ23YQoMLX1jW0G0bQjV6BBWZxV0dwKr4wOfQ=":
function (require, module, exports, __dirname, __filename) {
var pull = require('pull-stream/pull')
var looper = require('looper')

function destroy (stream) {
  if(!stream.destroy)
    console.error(
      'warning, stream-to-pull-stream: \n'
    + 'the wrapped node-stream does not implement `destroy`, \n'
    + 'this may cause resource leaks.'
    )
  else stream.destroy()

}

function write(read, stream, cb) {
  var ended, closed = false, did
  function done () {
    if(did) return
    did = true
    cb && cb(ended === true ? null : ended)
  }

  function onClose () {
    if(closed) return
    closed = true
    cleanup()
    if(!ended) read(ended = true, done)
    else       done()
  }
  function onError (err) {
    cleanup()
    if(!ended) read(ended = err, done)
  }
  function cleanup() {
    stream.on('finish', onClose)
    stream.removeListener('close', onClose)
    stream.removeListener('error', onError)
  }
  stream.on('close', onClose)
  stream.on('finish', onClose)
  stream.on('error', onError)
  process.nextTick(function () {
    looper(function (next) {
      read(null, function (end, data) {
        ended = ended || end
        //you can't "end" a stdout stream, so this needs to be handled specially.
        if(end === true)
          return stream._isStdio ? done() : stream.end()

        if(ended = ended || end) {
          destroy(stream)
          return done(ended)
        }

        //I noticed a problem streaming to the terminal:
        //sometimes the end got cut off, creating invalid output.
        //it seems that stdout always emits "drain" when it ends.
        //so this seems to work, but i have been unable to reproduce this test
        //automatically, so you need to run ./test/stdout.js a few times and the end is valid json.
        if(stream._isStdio)
          stream.write(data, function () { next() })
        else {
          var pause = stream.write(data)
          if(pause === false)
            stream.once('drain', next)
          else next()
        }
      })
    })
  })
}

function first (emitter, events, handler) {
  function listener (val) {
    events.forEach(function (e) {
      emitter.removeListener(e, listener)
    })
    handler(val)
  }
  events.forEach(function (e) {
    emitter.on(e, listener)
  })
  return emitter
}

function read2(stream) {
  var ended = false, waiting = false
  var _cb

  function read () {
    var data = stream.read()
    if(data !== null && _cb) {
      var cb = _cb; _cb = null
      cb(null, data)
    }
  }

  stream.on('readable', function () {
    waiting = true
    _cb && read()
  })
  .on('end', function () {
    ended = true
    _cb && _cb(ended)
  })
  .on('error', function (err) {
    ended = err
    _cb && _cb(ended)
  })

  return function (end, cb) {
    _cb = cb
    if(ended)
      cb(ended)
    else if(waiting)
      read()
  }
}

function read1(stream) {
  var buffer = [], cbs = [], ended, paused = false

  var draining
  function drain() {
    while((buffer.length || ended) && cbs.length)
      cbs.shift()(buffer.length ? null : ended, buffer.shift())
    if(!buffer.length && (paused)) {
      paused = false
      stream.resume()
    }
  }

  stream.on('data', function (data) {
    buffer.push(data)
    drain()
    if(buffer.length && stream.pause) {
      paused = true
      stream.pause()
    }
  })
  stream.on('end', function () {
    ended = true
    drain()
  })
  stream.on('close', function () {
    ended = true
    drain()
  })
  stream.on('error', function (err) {
    ended = err
    drain()
  })
  return function (abort, cb) {
    if(!cb) throw new Error('*must* provide cb')
    if(abort) {
      function onAbort () {
        while(cbs.length) cbs.shift()(abort)
        cb(abort)
      }
      //if the stream happens to have already ended, then we don't need to abort.
      if(ended) return onAbort()
      stream.once('close', onAbort)
      destroy(stream)
    }
    else {
      cbs.push(cb)
      drain()
    }
  }
}

var read = read1

var sink = function (stream, cb) {
  return function (read) {
    return write(read, stream, cb)
  }
}

var source = function (stream) {
  return read1(stream)
}

exports = module.exports = function (stream, cb) {
  return (
    (stream.writable && stream.write)
    ? stream.readable
      ? function(_read) {
          write(_read, stream, cb);
          return read1(stream)
        }
      : sink(stream, cb)
    : source(stream)
  )
}

exports.sink = sink
exports.source = source
exports.read = read
exports.read1 = read1
exports.read2 = read2
exports.duplex = function (stream, cb) {
  return {
    source: source(stream),
    sink: sink(stream, cb)
  }
}
exports.transform = function (stream) {
  return function (read) {
    var _source = source(stream)
    sink(stream)(read); return _source
  }
}










},
"bbXxctzqyJ5s8kKXUtlW3DmtqpGRJC7Hl1slGC0p3lA=":
function (require, module, exports, __dirname, __filename) {
'use strict'
module.exports = function reduce (acc, value) {
  //handle when called without initial
  if('number' === typeof acc)
    return reduce(reduce(null, acc), value)
  //set initial if initial was null
  else if(null == acc)
    return {
      mean: value,
      stdev: 0,

      count: 1,
      sum: value,
      sqsum: value*value
    }

  var sum = (acc.sum||0) + value
  var count = (acc.count||0) + 1
  var sq = value*value
  var sqsum = (acc.sqsum||0) + sq

  acc.mean = sum/count
  acc.stdev = Math.sqrt(sqsum/count - acc.mean*acc.mean)

  acc.count = count
  acc.sum = sum
  acc.sqsum = sqsum

  return acc
}

module.exports.initial = require('./initial')

},
"bdLIeMr12r3Y6t1FkL3yngdaHzmbPIQdtI/UzAK1ffw=":
function (require, module, exports, __dirname, __filename) {
module.exports = function prop (key) {
  return key && (
    'string' == typeof key
    ? function (data) { return data[key] }
    : 'object' === typeof key && 'function' === typeof key.exec //regexp
    ? function (data) { var v = key.exec(data); return v && v[0] }
    : key
  )
}

},
"bk9dbSa68ZTPS7tNghEARu1iFSBbQSxXp7UJfcFiPqw=":
function (require, module, exports, __dirname, __filename) {
var path = require('path');
var fs = require('fs');
var _0777 = parseInt('0777', 8);

module.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;

function mkdirP (p, opts, f, made) {
    if (typeof opts === 'function') {
        f = opts;
        opts = {};
    }
    else if (!opts || typeof opts !== 'object') {
        opts = { mode: opts };
    }
    
    var mode = opts.mode;
    var xfs = opts.fs || fs;
    
    if (mode === undefined) {
        mode = _0777 & (~process.umask());
    }
    if (!made) made = null;
    
    var cb = f || function () {};
    p = path.resolve(p);
    
    xfs.mkdir(p, mode, function (er) {
        if (!er) {
            made = made || p;
            return cb(null, made);
        }
        switch (er.code) {
            case 'ENOENT':
                mkdirP(path.dirname(p), opts, function (er, made) {
                    if (er) cb(er, made);
                    else mkdirP(p, opts, cb, made);
                });
                break;

            // In the case of any other error, just see if there's a dir
            // there already.  If so, then hooray!  If not, then something
            // is borked.
            default:
                xfs.stat(p, function (er2, stat) {
                    // if the stat fails, then that's super weird.
                    // let the original error be the failure reason.
                    if (er2 || !stat.isDirectory()) cb(er, made)
                    else cb(null, made);
                });
                break;
        }
    });
}

mkdirP.sync = function sync (p, opts, made) {
    if (!opts || typeof opts !== 'object') {
        opts = { mode: opts };
    }
    
    var mode = opts.mode;
    var xfs = opts.fs || fs;
    
    if (mode === undefined) {
        mode = _0777 & (~process.umask());
    }
    if (!made) made = null;

    p = path.resolve(p);

    try {
        xfs.mkdirSync(p, mode);
        made = made || p;
    }
    catch (err0) {
        switch (err0.code) {
            case 'ENOENT' :
                made = sync(path.dirname(p), opts, made);
                sync(p, opts, made);
                break;

            // In the case of any other error, just see if there's a dir
            // there already.  If so, then hooray!  If not, then something
            // is borked.
            default:
                var stat;
                try {
                    stat = xfs.statSync(p);
                }
                catch (err1) {
                    throw err0;
                }
                if (!stat.isDirectory()) throw err0;
                break;
        }
    }

    return made;
};

},
"byhOw55nanqCNv+PSJd65soXJsKlCG/12A/L8eaXGdI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.CONN = void 0;
const ConnDB = require("ssb-conn-db");
const ConnHub = require("ssb-conn-hub");
const ConnStaging = require("ssb-conn-staging");
const ConnQuery = require("ssb-conn-query");
const secret_stack_decorators_1 = require("secret-stack-decorators");
const interpool_glue_1 = require("./interpool-glue");
const ping = require('pull-ping');
let CONN = class CONN {
    constructor(ssb, cfg) {
        this.remember = (address, data = {}) => {
            this._db.set(address, data);
        };
        this.forget = (address) => {
            this._db.delete(address);
        };
        this.dbPeers = () => [...this._db.entries()];
        this.connect = (address, b, c) => {
            if (c && (typeof b === 'function' || !b)) {
                throw new Error('CONN.connect() received incorrect arguments');
            }
            const last = !!c ? c : b;
            const cb = (typeof last === 'function' ? last : null);
            const data = (typeof b === 'object' ? b : {});
            this._hub.connect(address, data).then(result => cb === null || cb === void 0 ? void 0 : cb(null, result), err => cb === null || cb === void 0 ? void 0 : cb(err));
        };
        this.disconnect = (address, cb) => {
            this._hub.disconnect(address).then(result => cb === null || cb === void 0 ? void 0 : cb(null, result), err => cb === null || cb === void 0 ? void 0 : cb(err));
        };
        this.peers = () => this._hub.liveEntries();
        this.stage = (address, data = { type: 'internet' }) => {
            if (!!this._hub.getState(address))
                return false;
            if (data.key) {
                for (const other of this._hub.entries()) {
                    if (other[1].key === data.key)
                        return false;
                }
            }
            return this._staging.stage(address, data);
        };
        this.unstage = (address) => {
            return this._staging.unstage(address);
        };
        this.stagedPeers = () => this._staging.liveEntries();
        this.start = () => {
            return this.startScheduler();
        };
        this.stop = () => {
            this.stopScheduler();
        };
        this.ping = () => {
            var _a, _b;
            const MIN = 10e3;
            const DEFAULT = 5 * 60e3;
            const MAX = 30 * 60e3;
            let timeout = (_b = (_a = this.config.timers) === null || _a === void 0 ? void 0 : _a.ping) !== null && _b !== void 0 ? _b : DEFAULT;
            timeout = Math.max(MIN, Math.min(timeout, MAX));
            return ping({ timeout });
        };
        this.db = () => this._db;
        this.hub = () => this._hub;
        this.staging = () => this._staging;
        this.query = () => this._query;
        this.ssb = ssb;
        this.config = cfg;
        this._db = new ConnDB({ path: this.config.path, writeTimeout: 1e3 });
        this._hub = new ConnHub(this.ssb);
        this._staging = new ConnStaging();
        this._query = new ConnQuery(this._db, this._hub, this._staging);
        this.initialize();
    }
    initialize() {
        this.setupCloseHook();
        this.maybeAutoStartScheduler();
        interpool_glue_1.interpoolGlue(this._db, this._hub, this._staging);
    }
    setupCloseHook() {
        const that = this;
        this.ssb.close.hook(function (fn, args) {
            that.stopScheduler();
            that._db.close();
            that._hub.close();
            that._staging.close();
            return fn.apply(this, args);
        });
    }
    maybeAutoStartScheduler() {
        var _a;
        if (((_a = this.config.conn) === null || _a === void 0 ? void 0 : _a.autostart) === false) {
        }
        else {
            this.startScheduler();
        }
    }
    async startScheduler() {
        await this._db.loaded();
        if (this.ssb.connScheduler) {
            this.ssb.connScheduler.start();
        }
        else {
            setTimeout(() => {
                if (this.ssb.connScheduler) {
                    this.ssb.connScheduler.start();
                }
                else {
                    console.error('There is no ConnScheduler! ' +
                        'The CONN plugin will remain in manual mode.');
                }
            }, 100);
        }
    }
    stopScheduler() {
        if (this.ssb.connScheduler)
            this.ssb.connScheduler.stop();
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "remember", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "forget", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "dbPeers", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('async')
], CONN.prototype, "connect", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('async')
], CONN.prototype, "disconnect", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], CONN.prototype, "peers", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "stage", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "unstage", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], CONN.prototype, "stagedPeers", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "start", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "stop", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('duplex', { anonymous: 'allow' })
], CONN.prototype, "ping", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "db", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "hub", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "staging", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], CONN.prototype, "query", void 0);
CONN = __decorate([
    secret_stack_decorators_1.plugin('1.0.0')
], CONN);
exports.CONN = CONN;

},
"bys7gyuw7IkQA/zIhbOomEwqgmjqI0BfEI8jDozx2ao=":
function (require, module, exports, __dirname, __filename) {
var mutexify = function () {
  var queue = []
  var used = null

  var call = function () {
    used(release)
  }

  var acquire = function (fn) {
    if (used) return queue.push(fn)
    used = fn
    acquire.locked = true
    process.nextTick(call)
    return 0
  }

  acquire.locked = false

  var release = function (fn, err, value) {
    used = null
    acquire.locked = false
    if (queue.length) acquire(queue.shift())
    if (fn) fn(err, value)
  }

  return acquire
}

module.exports = mutexify

},
"c/yWyBKxh4cbx8bANGSprF2IPO+vHX4nIQDOGVaDfaw=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var hasToStringTag = typeof Symbol === 'function' && typeof Symbol.toStringTag === 'symbol';
var callBound = require('call-bind/callBound');

var $toString = callBound('Object.prototype.toString');

var isStandardArguments = function isArguments(value) {
	if (hasToStringTag && value && typeof value === 'object' && Symbol.toStringTag in value) {
		return false;
	}
	return $toString(value) === '[object Arguments]';
};

var isLegacyArguments = function isArguments(value) {
	if (isStandardArguments(value)) {
		return true;
	}
	return value !== null &&
		typeof value === 'object' &&
		typeof value.length === 'number' &&
		value.length >= 0 &&
		$toString(value) !== '[object Array]' &&
		$toString(value.callee) === '[object Function]';
};

var supportsStandardArguments = (function () {
	return isStandardArguments(arguments);
}());

isStandardArguments.isLegacyArguments = isLegacyArguments; // for tests

module.exports = supportsStandardArguments ? isStandardArguments : isLegacyArguments;

},
"c5vsbLOT8Bh1wlNBZu7WkHMoeU9MkAEeIxXyh6rNOtY=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
// browserify by default only pulls in files that are hard coded in requires
// In order of last to first in this file, the default wordlist will be chosen
// based on what is present. (Bundles may remove wordlists they don't need)
const wordlists = {};
exports.wordlists = wordlists;
let _default;
exports._default = _default;
try {
    exports._default = _default = require('./wordlists/czech.json');
    wordlists.czech = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/chinese_simplified.json');
    wordlists.chinese_simplified = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/chinese_traditional.json');
    wordlists.chinese_traditional = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/korean.json');
    wordlists.korean = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/french.json');
    wordlists.french = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/italian.json');
    wordlists.italian = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/spanish.json');
    wordlists.spanish = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/japanese.json');
    wordlists.japanese = _default;
    wordlists.JA = _default;
}
catch (err) { }
try {
    exports._default = _default = require('./wordlists/english.json');
    wordlists.english = _default;
    wordlists.EN = _default;
}
catch (err) { }

},
"cCjMqVsvEkNFvVuBbg2BhOe30gj+Cqdus430PoZE/QM=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const codes = {};

function createErrorType(code, message, Base) {
  if (!Base) {
    Base = Error
  }

  function getMessage (arg1, arg2, arg3) {
    if (typeof message === 'string') {
      return message
    } else {
      return message(arg1, arg2, arg3)
    }
  }

  class NodeError extends Base {
    constructor (arg1, arg2, arg3) {
      super(getMessage(arg1, arg2, arg3));
    }
  }

  NodeError.prototype.name = Base.name;
  NodeError.prototype.code = code;

  codes[code] = NodeError;
}

// https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js
function oneOf(expected, thing) {
  if (Array.isArray(expected)) {
    const len = expected.length;
    expected = expected.map((i) => String(i));
    if (len > 2) {
      return `one of ${thing} ${expected.slice(0, len - 1).join(', ')}, or ` +
             expected[len - 1];
    } else if (len === 2) {
      return `one of ${thing} ${expected[0]} or ${expected[1]}`;
    } else {
      return `of ${thing} ${expected[0]}`;
    }
  } else {
    return `of ${thing} ${String(expected)}`;
  }
}

// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith
function startsWith(str, search, pos) {
	return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;
}

// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith
function endsWith(str, search, this_len) {
	if (this_len === undefined || this_len > str.length) {
		this_len = str.length;
	}
	return str.substring(this_len - search.length, this_len) === search;
}

// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes
function includes(str, search, start) {
  if (typeof start !== 'number') {
    start = 0;
  }

  if (start + search.length > str.length) {
    return false;
  } else {
    return str.indexOf(search, start) !== -1;
  }
}

createErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {
  return 'The value "' + value + '" is invalid for option "' + name + '"'
}, TypeError);
createErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {
  // determiner: 'must be' or 'must not be'
  let determiner;
  if (typeof expected === 'string' && startsWith(expected, 'not ')) {
    determiner = 'must not be';
    expected = expected.replace(/^not /, '');
  } else {
    determiner = 'must be';
  }

  let msg;
  if (endsWith(name, ' argument')) {
    // For cases like 'first argument'
    msg = `The ${name} ${determiner} ${oneOf(expected, 'type')}`;
  } else {
    const type = includes(name, '.') ? 'property' : 'argument';
    msg = `The "${name}" ${type} ${determiner} ${oneOf(expected, 'type')}`;
  }

  msg += `. Received type ${typeof actual}`;
  return msg;
}, TypeError);
createErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');
createErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {
  return 'The ' + name + ' method is not implemented'
});
createErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');
createErrorType('ERR_STREAM_DESTROYED', function (name) {
  return 'Cannot call ' + name + ' after a stream was destroyed';
});
createErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');
createErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');
createErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');
createErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);
createErrorType('ERR_UNKNOWN_ENCODING', function (arg) {
  return 'Unknown encoding: ' + arg
}, TypeError);
createErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');

module.exports.codes = codes;

},
"cPKgI7c06cC2sPF+pkS7aV1xs7hZBRBui9WWBSdSJpg=":
function (require, module, exports, __dirname, __filename) {
var rurl = require('relative-url')
var map = {http:'ws', https:'wss'}
var def = 'ws'
module.exports = function (url, location) {
  return rurl(url, location, map, def)
}



},
"cUcDZGydcEeG7OZbDlZ9NHMSXmFv72yWPwbfK+vil60=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const run = require("promisify-tuple");
const pull = require('pull-stream');
const cat = require('pull-cat');
const Notify = require('pull-notify');
const IP = require('ip');
const msNetPlugin = require('multiserver/plugins/net')({});
const msAddress = require('multiserver-address');
const Ref = require('ssb-ref');
const debug = require('debug')('ssb:conn-hub');
function noop() { }
function inferPeerType(address, meta) {
    if (address.startsWith('bt:'))
        return 'bt';
    if (address.startsWith('dht:') || meta === 'dht')
        return 'dht';
    if (address.startsWith('tunnel:'))
        return 'tunnel';
    if (address.startsWith('net:')) {
        const netAddr = address.split('~')[0];
        const parsed = msNetPlugin.parse(netAddr);
        if (parsed === null || parsed === void 0 ? void 0 : parsed.host) {
            if (IP.isPrivate(parsed.host))
                return 'lan';
            else
                return 'internet';
        }
    }
    return;
}
class ConnHub {
    constructor(server) {
        this._onRpcConnect = (rpc, isClient) => {
            var _a;
            if (rpc.id === this._server.id)
                return;
            if (this._server.ready && !this._server.ready()) {
                rpc.close(true, noop);
                return;
            }
            const peer = this._getPeerByKey(rpc.id);
            if (!peer && isClient) {
                rpc._connectRetries = (_a = rpc._connectRetries) !== null && _a !== void 0 ? _a : 0;
                if (isClient && rpc._connectRetries < 4) {
                    setTimeout(() => {
                        this._onRpcConnect(rpc, isClient);
                    }, 200);
                    rpc._connectRetries += 1;
                }
                else if (isClient) {
                    debug('our secret-stack initiated an RPC connection with %s but not ' +
                        'through the ssb-conn-hub connect() API', rpc.id);
                }
                return;
            }
            if (!peer) {
                debug('peer %s initiated an RPC connection with us', rpc.id);
            }
            const [address, data] = !peer
                ? [rpc.stream.address, { key: rpc.id }]
                : peer;
            if (!data.type) {
                data.inferredType = inferPeerType(address, rpc.stream.meta);
            }
            const key = data.key;
            const state = 'connected';
            const disconnect = (cb) => rpc.close(true, cb !== null && cb !== void 0 ? cb : noop);
            this._setPeer(address, { ...data, state, disconnect });
            this._rpcs.set(address, rpc);
            debug('connected to %s', address);
            this._notifyEvent({
                type: state,
                address,
                key,
                details: { rpc, isClient },
            });
            this._updateLiveEntries();
            rpc.on('closed', () => {
                this._rpcs.delete(address);
                this._peers.delete(address);
                debug('disconnected from %s', address);
                this._notifyEvent({ type: 'disconnected', address, key });
                this._updateLiveEntries();
            });
        };
        this._server = server;
        this._closed = false;
        this._connectRetries = new Set();
        this._peers = new Map();
        this._rpcs = new Map();
        this._notifyEvent = Notify();
        this._notifyEntries = Notify();
        this._init();
    }
    _init() {
        this._server.addListener('rpc:connect', this._onRpcConnect);
    }
    _assertNotClosed() {
        if (this._closed) {
            throw new Error('This ConnHub instance is closed, create a new one.');
        }
    }
    _assertValidAddress(address) {
        if (!msAddress.check(address)) {
            throw new Error('The given address is not a valid multiserver-address');
        }
    }
    _updateLiveEntries() {
        this._notifyEntries(Array.from(this._peers.entries()));
    }
    _setPeer(address, data) {
        const now = Date.now();
        const hubUpdated = now;
        const previousData = this._peers.get(address);
        if (previousData) {
            Object.keys(data).forEach((key) => {
                const k = key;
                if (typeof data[k] === 'undefined')
                    delete data[k];
            });
            this._peers.set(address, { ...previousData, hubUpdated, ...data });
        }
        else if (!data.state) {
            debug('unexpected control flow, we cannot add a peer without state');
        }
        else {
            const hubBirth = now;
            this._peers.set(address, { ...data, hubBirth, hubUpdated });
        }
    }
    _getPeerByKey(key) {
        for (let [address, data] of this._peers.entries()) {
            if (data.key === key)
                return [address, data];
        }
        return undefined;
    }
    async connect(address, data) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        if (this._peers.has(address)) {
            const peer = this._peers.get(address);
            if (peer.state === 'connected') {
                if (this._rpcs.has(address))
                    return this._rpcs.get(address);
                else
                    return false;
            }
            else if (peer.state === 'connecting') {
                return new Promise((resolve, reject) => {
                    let drainer;
                    setTimeout(() => {
                        if (drainer)
                            drainer.abort();
                        resolve(false);
                    }, 60e3);
                    pull(this._notifyEvent.listen(), pull.filter((ev) => ev.type === 'connected' && ev.address === address), pull.take(1), (drainer = pull.drain((ev) => {
                        resolve(ev.details.rpc);
                    }, (err) => {
                        if (err && err !== true)
                            reject(err);
                    })));
                });
            }
            else if (peer.state === 'disconnecting') {
                this._connectRetries.add(address);
                return false;
            }
            else {
                debug('unexpected control flow, peer %o has bad state', peer);
            }
        }
        const state = 'connecting';
        const key = Ref.getKeyFromAddress(address);
        if (data) {
            this._setPeer(address, { ...data, state, key });
        }
        else {
            this._setPeer(address, { state, key });
        }
        debug('connecting to %s', address);
        this._notifyEvent({ type: state, address, key });
        this._updateLiveEntries();
        const [err, rpc] = await run(this._server.connect)(address);
        if (err) {
            this._peers.delete(address);
            debug('failed to connect to %s because: %s', address, err.message);
            this._notifyEvent({
                type: 'connecting-failed',
                address,
                key,
                details: err,
            });
            this._updateLiveEntries();
            throw err;
        }
        const peer = this._peers.get(address);
        if (!peer || peer.state !== 'connected') {
            const state = 'connected';
            this._setPeer(address, { state, key });
            debug('connected to %s', address);
            this._notifyEvent({
                type: state,
                address,
                key,
                details: { rpc },
            });
            this._updateLiveEntries();
        }
        this._rpcs.set(address, rpc);
        return rpc;
    }
    async disconnect(address) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        if (!this._peers.has(address))
            return false;
        const peer = this._peers.get(address);
        const key = Ref.getKeyFromAddress(address);
        const prevState = peer.state;
        if (prevState !== 'disconnecting') {
            const state = 'disconnecting';
            this._setPeer(address, { state, key });
            debug('disconnecting from %s', address);
            this._notifyEvent({ type: state, address, key });
            this._updateLiveEntries();
        }
        if (peer.disconnect) {
            const [err] = await run(peer.disconnect)();
            if (err) {
                debug('failed to disconnect from %s because: %s', address, err.message);
                this._notifyEvent({
                    type: 'disconnecting-failed',
                    address,
                    key,
                    details: err,
                });
                this._setPeer(address, { state: prevState, key });
                this._updateLiveEntries();
                throw err;
            }
        }
        this._peers.delete(address);
        debug('disconnected from %s', address);
        this._notifyEvent({ type: 'disconnected', address, key });
        this._updateLiveEntries();
        if (this._connectRetries.has(address)) {
            this._connectRetries.delete(address);
            this.connect(address);
        }
        return true;
    }
    update(address, data) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        if (this._peers.has(address)) {
            this._setPeer(address, data);
            this._updateLiveEntries();
            return true;
        }
        else {
            return false;
        }
    }
    reset() {
        this._assertNotClosed();
        for (var id in this._server.peers) {
            if (id !== this._server.id) {
                for (let peer of this._server.peers[id]) {
                    peer.close(true, noop);
                }
            }
        }
    }
    entries() {
        this._assertNotClosed();
        return this._peers.entries();
    }
    liveEntries() {
        this._assertNotClosed();
        return cat([
            pull.values([Array.from(this._peers.entries())]),
            this._notifyEntries.listen(),
        ]);
    }
    getState(address) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        if (!this._peers.has(address))
            return undefined;
        return this._peers.get(address).state;
    }
    listen() {
        this._assertNotClosed();
        return this._notifyEvent.listen();
    }
    close() {
        this._server.removeListener('rpc:connect', this._onRpcConnect);
        this._closed = true;
        this._peers.clear();
        this._rpcs.clear();
        this._notifyEvent.end();
        this._notifyEntries.end();
        debug('closed the ConnHub instance');
    }
}
module.exports = ConnHub;

},
"cWiRHqXeVRvq+fEtoyMhLslo+0Lo+LSr6dipuR/xuy8=":
function (require, module, exports, __dirname, __filename) {
var usage = require('cpu-percentage');

module.exports = function TooHot(opts) {
  var _opts = opts || {ceiling: 88, wait: 144, maxPause: Infinity};
  var ceiling = _opts.ceiling || 88;
  var wait = _opts.wait || 144;
  var maxPause = _opts.maxPause || Infinity;
  var start = (stats = usage());
  var lastResume = Date.now();
  var step = 2,
    i = 0;

  return function tooHot() {
    if (i++ % step) return false;

    stats = usage(start);
    if (
      stats.percent < ceiling || // "CPU is cold enough"
      Date.now() - lastResume > maxPause || // "remained paused for too long"
      stats.time < 20 // "we just now began draining"
    ) {
      step = step << 1 || 1;
      lastResume = Date.now();
      return false;
    } else {
      step = step >> 1 || 1;
      return new Promise((resolve) => {
        setTimeout(resolve, wait);
      });
    }
  };
};

},
"caOGScd0CCF0g/gfVdruHWZG1sZw49A0pEgss0U4huk=":
function (require, module, exports, __dirname, __filename) {
module.exports = extend

var hasOwnProperty = Object.prototype.hasOwnProperty;

function extend(target) {
    for (var i = 1; i < arguments.length; i++) {
        var source = arguments[i]

        for (var key in source) {
            if (hasOwnProperty.call(source, key)) {
                target[key] = source[key]
            }
        }
    }

    return target
}

},
"cdAjy5xVv/ggD4VyofSOVRaslZQ9sWo3Bfxvs1dxEUg=":
function (require, module, exports, __dirname, __filename) {
var sizes = {
  md5: 16,
  sha1: 20,
  sha224: 28,
  sha256: 32,
  sha384: 48,
  sha512: 64,
  rmd160: 20,
  ripemd160: 20
}

var createHmac = require('create-hmac')
var Buffer = require('safe-buffer').Buffer

var checkParameters = require('./precondition')
var defaultEncoding = require('./default-encoding')
var toBuffer = require('./to-buffer')

function pbkdf2 (password, salt, iterations, keylen, digest) {
  checkParameters(iterations, keylen)
  password = toBuffer(password, defaultEncoding, 'Password')
  salt = toBuffer(salt, defaultEncoding, 'Salt')

  digest = digest || 'sha1'

  var DK = Buffer.allocUnsafe(keylen)
  var block1 = Buffer.allocUnsafe(salt.length + 4)
  salt.copy(block1, 0, 0, salt.length)

  var destPos = 0
  var hLen = sizes[digest]
  var l = Math.ceil(keylen / hLen)

  for (var i = 1; i <= l; i++) {
    block1.writeUInt32BE(i, salt.length)

    var T = createHmac(digest, password).update(block1).digest()
    var U = T

    for (var j = 1; j < iterations; j++) {
      U = createHmac(digest, password).update(U).digest()
      for (var k = 0; k < hLen; k++) T[k] ^= U[k]
    }

    T.copy(DK, destPos)
    destPos += hLen
  }

  return DK
}

module.exports = pbkdf2

},
"cmcRqa+IsEsc2DIUeGXoK+grYAXQPGL4p7ftDNw4G6g=":
function (require, module, exports, __dirname, __filename) {

var looper = module.exports = function (fun) {
  (function next () {
    var loop = true, returned = false, sync = false
    do {
      sync = true; loop = false
      fun.call(this, function () {
        if(sync) loop = true
        else     next()
      })
      sync = false
    } while(loop)
  })()
}

},
"d0TtirgBvf3UcVRMDZWucNtL5cixueBZ6tNutLDnxsE=":
function (require, module, exports, __dirname, __filename) {
var levelup = require('levelup')
var encode = require('encoding-down')

function packager (leveldown) {
  function Level (location, options, callback) {
    if (typeof location === 'function') {
      callback = location
    } else if (typeof options === 'function') {
      callback = options
    }

    if (!isObject(options)) {
      options = isObject(location) ? location : {}
    }

    return levelup(encode(leveldown(location, options), options), options, callback)
  }

  function isObject (o) {
    return typeof o === 'object' && o !== null
  }

  ['destroy', 'repair'].forEach(function (m) {
    if (typeof leveldown[m] === 'function') {
      Level[m] = function () {
        leveldown[m].apply(leveldown, arguments)
      }
    }
  })

  Level.errors = levelup.errors

  return Level
}

module.exports = packager

},
"d2Q3v8BAehsqunv/JOnTXkdnnDEqadfrGzfQYC3mokY=":
function (require, module, exports, __dirname, __filename) {
//returns true there is an available network interface which is neither
//local loopback (localhost) or tunneling (probably cjdns)
//On my system, cjdns always appears even when there is no actual internet.
//and in that case, cjdns doesn't work anyway. maybe somebody has a setup
//where they _ONLY_ have a tun interface, so this test will fail.
//lets cross that bridge when we come to it though.

var os = require('os');
module.exports = function() {
  var interfaces;

  // in browser always assume we are connected
  if (typeof localStorage !== "undefined" && localStorage !== null)
    return true;

  try {
    interfaces = os.networkInterfaces();
  } catch (e) {
    // As of October 2016, Windows Subsystem for Linux (WSL) does not support
    // the os.networkInterfaces() call and throws instead. For this platform,
    // assume we are online.
    if (e.syscall === 'uv_interface_addresses') {
      return true;
    } else {
      throw e;
    }
  }

  for (var k in interfaces)
    if (
      'lo' !== k && //loopback
      !/^tun\d+$/.test(k) //cjdns
    )
      return true;
  return false;
};

},
"d42LqRx3ZCwjTOY8vKjBWHMdJm/xdE0/q8yxWKohP5U=":
function (require, module, exports, __dirname, __filename) {
exports.note = function note(seq, rx) {
  return seq === -1 ? -1 : seq << 1 | !rx
}

exports.getSequence = function getSequence(seq) {
  return !Number.isInteger(seq) ? -1 : seq >> 1
}

exports.getReplicate = function getReplicate(seq) {
  return seq !== -1
}

exports.getReceive = function getReceive(seq) {
  return !(seq & 1)
}

},
"d68VhD4qPjJCCjZV4iht/AQ3G9MJCPwVFEILLpteZw4=":
function (require, module, exports, __dirname, __filename) {
var Blake2s = require('blake2s')
var createHash = require('crypto').createHash
var pull = require('pull-stream')
var Read = require('pull-file')
var Catch = require('pull-catch')

var isBuffer = Buffer.isBuffer

var algs = {
  blake2s: function () { return new Blake2s() },
  sha256: function () { return createHash('sha256') }
}

exports.encode = function (buf, alg) {
  if(!isBuffer(buf)) throw new Error('hash should be a buffer, was:'+buf)
  return buf.toString('base64')+'.'+alg
}

exports.decode = function (str) {
  var i = str.indexOf('.')
  var alg = str.substring(i+1)
  return {hash: new Buffer(str.substring(0, i), 'base64'), alg: alg}
}

exports.createHash = function (alg, noCompat) {
  alg = alg || 'blake2s'
  var hash = algs[alg]()

  var hasher = pull.through(function (data) {
    data = isBuffer(data) ? data : new Buffer(data)
    hasher.size += data.length
    hash.update(data)
  }, function () {
    return hasher.digest = noCompat === true ? hash.digest() : hash.digest('base64') + '.' + alg
//    hasher.digest = digest
  })

  hasher.size = 0
  return hasher
}

function isString (s) {
  return 'string' === typeof s
}

exports.isHash = function (data) {
  return isString(data) && /^[A-Za-z0-9\/+]{43}=\.(?:blake2s|sha256)$/.test(data)
}

exports.algs = algs


/**
 * Wraps the `pull-file` function module with two changes: errors are redacted,
 * and any error except ENOENT (file not found) will be logged to the server.
 *
 * @param {...object} args - arguments to pass to `pull-file`
 *
 * @return {function} pull-stream source, to be consumed by a through or sink
 */

exports.readFile = function (...args) {
  return pull(
    Read(...args),
    Catch(err => {
      if (err.code !== 'ENOENT') {
        console.error(new Error(err))
      }

      err.message = 'could not get blob'

      return false // pass along error
    })
  )
};

exports.toArray = function (h) {
  return Array.isArray(h) ? h : [h]
}

exports.single = function (fn) {
  var waiting = {}
  function async (key, cb) {
    if(!waiting[key]) {
      waiting[key] = [cb]
      var cbs = waiting[key]
      fn(key, function done (err, result) {
        if(cbs.length)
        delete waiting[key]
        while(cbs.length) cbs.shift()(err, result)
      })
    }
    else
      waiting[key].push(cb)
  }

  //dump all the things that have been done already,
  //when something has been added?
  async.done = function (key, err, value) {
    if(!waiting[key]) return
    var cbs = waiting[key]
    delete waiting[key]
    while(cbs.length) cbs.shift()(err, result)
  }

  return async
}

},
"dB6plWSA+wZ+Wu8ZdK8m6fDoAxb21F0EnSh1rp6r444=":
function (require, module, exports, __dirname, __filename) {
'use strict';

module.exports.addSlashToEnd = (path) => {
    if (!path)
        throw Error('path could not be empty!');
    
    const length  = path.length - 1;
    const isSlash = path[length] === '/';
    
    if (isSlash)
        return path;
    
    return `${path}/`;
};

/** Функция получает короткие размеры
 * конвертируя байт в килобайты, мегабойты,
 * гигайбайты и терабайты
 * @pSize - размер в байтах
 */
module.exports.size = (size) => {
    const isNumber = typeof size === 'number';
    
    const l1KB = 1024;
    const l1MB = l1KB * l1KB;
    const l1GB = l1MB * l1KB;
    const l1TB = l1GB * l1KB;
    const l1PB = l1TB * l1KB;
    
    if (!isNumber)
        return size;
        
    if (size < l1KB)
        return size + 'b';
    
    if (size < l1MB)
        return (size / l1KB).toFixed(2) + 'kb';
    
    if (size < l1GB)
        return (size / l1MB).toFixed(2) + 'mb';
    
    if (size < l1TB)
        return (size / l1GB).toFixed(2) + 'gb';
    
    if (size < l1PB)
        return (size / l1TB).toFixed(2) + 'tb';
    
    return (size / l1PB).toFixed(2) + 'pb';
};

module.exports.permissions = require('./mode');


},
"dDt/2P1ewR3WpxgAZQplB59b0/CMurtcjfrfBtE411U=":
function (require, module, exports, __dirname, __filename) {
const {dirname} = require('path')

const findMade = (opts, parent, path = undefined) => {
  // we never want the 'made' return value to be a root directory
  if (path === parent)
    return Promise.resolve()

  return opts.statAsync(parent).then(
    st => st.isDirectory() ? path : undefined, // will fail later
    er => er.code === 'ENOENT'
      ? findMade(opts, dirname(parent), parent)
      : undefined
  )
}

const findMadeSync = (opts, parent, path = undefined) => {
  if (path === parent)
    return undefined

  try {
    return opts.statSync(parent).isDirectory() ? path : undefined
  } catch (er) {
    return er.code === 'ENOENT'
      ? findMadeSync(opts, dirname(parent), parent)
      : undefined
  }
}

module.exports = {findMade, findMadeSync}

},
"dIH/Ywl/qcXqdU37HimxIzdK3MCVuYWRAIZXx1HUZHI=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
function ErrorDuplex(message) {
    const err = new Error(message);
    return {
        source(_abort, cb) {
            cb(err);
        },
        sink(read) {
            read(err, () => { });
        },
    };
}
exports.default = ErrorDuplex;

},
"dJExb2QIXWVtCYEVjUZImSHXrDegUkHDIbJ8QrcZBWM=":
function (require, module, exports, __dirname, __filename) {

var endable = require('./endable')
var pull = require('pull-stream')
module.exports = function (stream, goodbye) {
  goodbye = goodbye || 'GOODBYE'
  var e = endable(goodbye)

  return {
    // when the source ends,
    // send the goodbye and then wait to recieve
    // the other goodbye.
    source: pull(stream.source, e),
    sink: pull(
      //when the goodbye is received, allow the source to end.
      pull.filter(function (data) {
        if(data !== goodbye) return true
        e.end()
      }),
      stream.sink
    )
  }

}

},
"dV6WHoG7ZmVmFkGbVk+bl0e5LeFHSPGmlDOLWta/68s=":
function (require, module, exports, __dirname, __filename) {
const util = require('util')
const AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN
const binding = require('./binding')
const ChainedBatch = require('./chained-batch')
const Iterator = require('./iterator')

function LevelDOWN (location) {
  if (!(this instanceof LevelDOWN)) {
    return new LevelDOWN(location)
  }

  if (typeof location !== 'string') {
    throw new Error('constructor requires a location string argument')
  }

  AbstractLevelDOWN.call(this, {
    bufferKeys: true,
    snapshots: true,
    permanence: true,
    seek: true,
    clear: true,
    createIfMissing: true,
    errorIfExists: true,
    additionalMethods: {
      approximateSize: true,
      compactRange: true
    }
  })

  this.location = location
  this.context = binding.db_init()
}

util.inherits(LevelDOWN, AbstractLevelDOWN)

LevelDOWN.prototype._open = function (options, callback) {
  binding.db_open(this.context, this.location, options, callback)
}

LevelDOWN.prototype._close = function (callback) {
  binding.db_close(this.context, callback)
}

LevelDOWN.prototype._serializeKey = function (key) {
  return Buffer.isBuffer(key) ? key : String(key)
}

LevelDOWN.prototype._serializeValue = function (value) {
  return Buffer.isBuffer(value) ? value : String(value)
}

LevelDOWN.prototype._put = function (key, value, options, callback) {
  binding.db_put(this.context, key, value, options, callback)
}

LevelDOWN.prototype._get = function (key, options, callback) {
  binding.db_get(this.context, key, options, callback)
}

LevelDOWN.prototype._del = function (key, options, callback) {
  binding.db_del(this.context, key, options, callback)
}

LevelDOWN.prototype._chainedBatch = function () {
  return new ChainedBatch(this)
}

LevelDOWN.prototype._batch = function (operations, options, callback) {
  binding.batch_do(this.context, operations, options, callback)
}

LevelDOWN.prototype.approximateSize = function (start, end, callback) {
  if (start == null ||
      end == null ||
      typeof start === 'function' ||
      typeof end === 'function') {
    throw new Error('approximateSize() requires valid `start` and `end` arguments')
  }

  if (typeof callback !== 'function') {
    throw new Error('approximateSize() requires a callback argument')
  }

  start = this._serializeKey(start)
  end = this._serializeKey(end)

  binding.db_approximate_size(this.context, start, end, callback)
}

LevelDOWN.prototype.compactRange = function (start, end, callback) {
  if (start == null ||
      end == null ||
      typeof start === 'function' ||
      typeof end === 'function') {
    throw new Error('compactRange() requires valid `start` and `end` arguments')
  }

  if (typeof callback !== 'function') {
    throw new Error('compactRange() requires a callback argument')
  }

  start = this._serializeKey(start)
  end = this._serializeKey(end)

  binding.db_compact_range(this.context, start, end, callback)
}

LevelDOWN.prototype.getProperty = function (property) {
  if (typeof property !== 'string') {
    throw new Error('getProperty() requires a valid `property` argument')
  }

  return binding.db_get_property(this.context, property)
}

LevelDOWN.prototype._iterator = function (options) {
  if (this.status !== 'open') {
    // Prevent segfault
    throw new Error('cannot call iterator() before open()')
  }

  return new Iterator(this, options)
}

LevelDOWN.destroy = function (location, callback) {
  if (arguments.length < 2) {
    throw new Error('destroy() requires `location` and `callback` arguments')
  }
  if (typeof location !== 'string') {
    throw new Error('destroy() requires a location string argument')
  }
  if (typeof callback !== 'function') {
    throw new Error('destroy() requires a callback function argument')
  }

  binding.destroy_db(location, callback)
}

LevelDOWN.repair = function (location, callback) {
  if (arguments.length < 2) {
    throw new Error('repair() requires `location` and `callback` arguments')
  }
  if (typeof location !== 'string') {
    throw new Error('repair() requires a location string argument')
  }
  if (typeof callback !== 'function') {
    throw new Error('repair() requires a callback function argument')
  }

  binding.repair_db(location, callback)
}

module.exports = LevelDOWN.default = LevelDOWN

},
"dVGMHXGHr0+GxeFblHAQzROahkySucGyG/RAHLAwgH8=":
function (require, module, exports, __dirname, __filename) {

var once = exports.once =
function (value) {
  return function (abort, cb) {
    if(abort) return cb(abort)
    if(value != null) {
      var _value = value; value = null
      cb(null, _value)
    } else
      cb(true)
  }
}

var depthFirst = exports.depthFirst =
function (start, createStream) {
  var reads = [], ended

  reads.unshift(once(start))

  return function next (end, cb) {
    if(!reads.length)
      return cb(true)
    if(ended)
      return cb(ended)

    reads[0](end, function (end, data) {
      if(end) {
        if(end !== true) {
          ended = end
          reads.shift()

          while(reads.length)
            reads.shift()(end, function () {})
          
          return cb(end)
        }
        //if this stream has ended, go to the next queue
        reads.shift()
        return next(null, cb)
      }
      reads.unshift(createStream(data))
      cb(end, data)
    })
  }
}
//width first is just like depth first,
//but push each new stream onto the end of the queue
var widthFirst = exports.widthFirst = 
function (start, createStream) {
  var reads = []

  reads.push(once(start))

  return function next (end, cb) {
    if(!reads.length)
      return cb(true)
    reads[0](end, function (end, data) {
      if(end) {
        reads.shift()
        return next(null, cb)
      }
      reads.push(createStream(data))
      cb(end, data)
    })
  }
}

//this came out different to the first (strm)
//attempt at leafFirst, but it's still a valid
//topological sort.
var leafFirst = exports.leafFirst = 
function (start, createStream) {
  var reads = []
  var output = []
  reads.push(once(start))
  
  return function next (end, cb) {
    reads[0](end, function (end, data) {
      if(end) {
        reads.shift()
        if(!output.length)
          return cb(true)
        return cb(null, output.shift())
      }
      reads.unshift(createStream(data))
      output.unshift(data)
      next(null, cb)
    })
  }
}


},
"ddprWwY0ASAXpiUsbhMDNd53deWgLxCBfQKvR6+ou40=":
function (require, module, exports, __dirname, __filename) {
// Ported from https://github.com/mafintosh/end-of-stream with
// permission from the author, Mathias Buus (@mafintosh).
'use strict';

var ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;

function once(callback) {
  var called = false;
  return function () {
    if (called) return;
    called = true;

    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
      args[_key] = arguments[_key];
    }

    callback.apply(this, args);
  };
}

function noop() {}

function isRequest(stream) {
  return stream.setHeader && typeof stream.abort === 'function';
}

function eos(stream, opts, callback) {
  if (typeof opts === 'function') return eos(stream, null, opts);
  if (!opts) opts = {};
  callback = once(callback || noop);
  var readable = opts.readable || opts.readable !== false && stream.readable;
  var writable = opts.writable || opts.writable !== false && stream.writable;

  var onlegacyfinish = function onlegacyfinish() {
    if (!stream.writable) onfinish();
  };

  var writableEnded = stream._writableState && stream._writableState.finished;

  var onfinish = function onfinish() {
    writable = false;
    writableEnded = true;
    if (!readable) callback.call(stream);
  };

  var readableEnded = stream._readableState && stream._readableState.endEmitted;

  var onend = function onend() {
    readable = false;
    readableEnded = true;
    if (!writable) callback.call(stream);
  };

  var onerror = function onerror(err) {
    callback.call(stream, err);
  };

  var onclose = function onclose() {
    var err;

    if (readable && !readableEnded) {
      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();
      return callback.call(stream, err);
    }

    if (writable && !writableEnded) {
      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();
      return callback.call(stream, err);
    }
  };

  var onrequest = function onrequest() {
    stream.req.on('finish', onfinish);
  };

  if (isRequest(stream)) {
    stream.on('complete', onfinish);
    stream.on('abort', onclose);
    if (stream.req) onrequest();else stream.on('request', onrequest);
  } else if (writable && !stream._writableState) {
    // legacy streams
    stream.on('end', onlegacyfinish);
    stream.on('close', onlegacyfinish);
  }

  stream.on('end', onend);
  stream.on('finish', onfinish);
  if (opts.error !== false) stream.on('error', onerror);
  stream.on('close', onclose);
  return function () {
    stream.removeListener('complete', onfinish);
    stream.removeListener('abort', onclose);
    stream.removeListener('request', onrequest);
    if (stream.req) stream.req.removeListener('finish', onfinish);
    stream.removeListener('end', onlegacyfinish);
    stream.removeListener('close', onlegacyfinish);
    stream.removeListener('finish', onfinish);
    stream.removeListener('end', onend);
    stream.removeListener('error', onerror);
    stream.removeListener('close', onclose);
  };
}

module.exports = eos;
},
"dpVWLXaRZ5A76CpYthU7h0fHQUSYHmoVilwIzah524E=":
function (require, module, exports, __dirname, __filename) {
var defined = require('defined')

module.exports = pullStringify

function pullStringify (options) {
  options = defined(options, {})

  // default is pretty double newline delimited json
  var open = defined(options.open, '')
  var prefix = defined(options.prefix, '')
  var suffix = defined(options.suffix, '\n\n')
  var close = defined(options.close, '')
  var indent = defined(options.indent, 2)
  var stringify = defined(options.stringify, JSON.stringify)

  var first = true, ended
  return function (read) {
    return function (end, cb) {
      if(ended) return cb(ended)
      read(null, function (end, data) {
        if(!end) {
          var f = first
          first = false

          var string = stringify(data, null, indent)
          cb(null, (f ? open : prefix) + string + suffix)
        } else {
          ended = end
          if(ended !== true) return cb(ended)
          cb(null, first ? open + close : close)
        }
      })
    }
  }
}

module.exports.lines =
module.exports.ldjson = function (stringify) {
  return pullStringify({
    suffix: '\n',
    indent: 0,
    stringify: stringify
  })
}

module.exports.array = function (stringify) {
  return pullStringify({
    open: '[',
    prefix: ',\n',
    suffix: '',
    close: ']\n',
    indent: 2,
    stringify: stringify
  })
}

},
"dsoOmx/gqDWsu7fYZl9qony5UFjn7F+z67O5wbOIMGo=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.passesGroupDebounce = exports.passesExpBackoff = void 0;
function passesExpBackoff(step, max = Infinity, timestamp = Date.now()) {
    return ([_addr, data]) => {
        const prevAttempt = data.stateChange || 0;
        const numFailures = data.failure || 0;
        const expBackoff = Math.min(Math.pow(2, numFailures) * step, max);
        const nextAttempt = prevAttempt + expBackoff;
        return nextAttempt < timestamp;
    };
}
exports.passesExpBackoff = passesExpBackoff;
function passesGroupDebounce(groupMin, timestamp = Date.now()) {
    return (group) => {
        const newestStateChange = group.reduce((max, [_addr, p]) => Math.max(max, p.stateChange || 0), 0);
        const minTimeThreshold = newestStateChange + groupMin;
        if (timestamp < minTimeThreshold)
            return [];
        else
            return group;
    };
}
exports.passesGroupDebounce = passesGroupDebounce;

},
"du21y+8inJ/P4nQDRHX/EG89baNvBz9s/Df9yIAsdy4=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var unique = require('./unique')

//passes an item through when you see it for the second time.
module.exports = function nonUnique (field) {
  return unique(field, true)
}

},
"e45PHnhDaGXDW35/LSAfzpkq3S3Qe/P9rnBeBkEIKIs=":
function (require, module, exports, __dirname, __filename) {
var native = require('crypto')

var checkParameters = require('./lib/precondition')
var defaultEncoding = require('./lib/default-encoding')
var toBuffer = require('./lib/to-buffer')

function nativePBKDF2 (password, salt, iterations, keylen, digest, callback) {
  checkParameters(iterations, keylen)
  password = toBuffer(password, defaultEncoding, 'Password')
  salt = toBuffer(salt, defaultEncoding, 'Salt')

  if (typeof digest === 'function') {
    callback = digest
    digest = 'sha1'
  }
  if (typeof callback !== 'function') throw new Error('No callback provided to pbkdf2')

  return native.pbkdf2(password, salt, iterations, keylen, digest, callback)
}

function nativePBKDF2Sync (password, salt, iterations, keylen, digest) {
  checkParameters(iterations, keylen)
  password = toBuffer(password, defaultEncoding, 'Password')
  salt = toBuffer(salt, defaultEncoding, 'Salt')
  digest = digest || 'sha1'
  return native.pbkdf2Sync(password, salt, iterations, keylen, digest)
}

/* istanbul ignore next */
if (!native.pbkdf2Sync || native.pbkdf2Sync.toString().indexOf('keylen, digest') === -1) {
  exports.pbkdf2Sync = require('./lib/sync')
  exports.pbkdf2 = require('./lib/async')

// native
} else {
  exports.pbkdf2Sync = nativePBKDF2Sync
  exports.pbkdf2 = nativePBKDF2
}

},
"eLukxUXKuOUKah/SVw+FOlmqz5YPDl0mTBK7RvmqowI=":
function (require, module, exports, __dirname, __filename) {
/**
 * lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright jQuery Foundation and other contributors <https://jquery.org/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the `TypeError` message for "Functions" methods. */
var FUNC_ERROR_TEXT = 'Expected a function';

/** Used as references for various `Number` constants. */
var NAN = 0 / 0;

/** `Object#toString` result references. */
var symbolTag = '[object Symbol]';

/** Used to match leading and trailing whitespace. */
var reTrim = /^\s+|\s+$/g;

/** Used to detect bad signed hexadecimal string values. */
var reIsBadHex = /^[-+]0x[0-9a-f]+$/i;

/** Used to detect binary string values. */
var reIsBinary = /^0b[01]+$/i;

/** Used to detect octal string values. */
var reIsOctal = /^0o[0-7]+$/i;

/** Built-in method references without a dependency on `root`. */
var freeParseInt = parseInt;

/** Detect free variable `global` from Node.js. */
var freeGlobal = typeof global == 'object' && global && global.Object === Object && global;

/** Detect free variable `self`. */
var freeSelf = typeof self == 'object' && self && self.Object === Object && self;

/** Used as a reference to the global object. */
var root = freeGlobal || freeSelf || Function('return this')();

/** Used for built-in method references. */
var objectProto = Object.prototype;

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var objectToString = objectProto.toString;

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeMax = Math.max,
    nativeMin = Math.min;

/**
 * Gets the timestamp of the number of milliseconds that have elapsed since
 * the Unix epoch (1 January 1970 00:00:00 UTC).
 *
 * @static
 * @memberOf _
 * @since 2.4.0
 * @category Date
 * @returns {number} Returns the timestamp.
 * @example
 *
 * _.defer(function(stamp) {
 *   console.log(_.now() - stamp);
 * }, _.now());
 * // => Logs the number of milliseconds it took for the deferred invocation.
 */
var now = function() {
  return root.Date.now();
};

/**
 * Creates a debounced function that delays invoking `func` until after `wait`
 * milliseconds have elapsed since the last time the debounced function was
 * invoked. The debounced function comes with a `cancel` method to cancel
 * delayed `func` invocations and a `flush` method to immediately invoke them.
 * Provide `options` to indicate whether `func` should be invoked on the
 * leading and/or trailing edge of the `wait` timeout. The `func` is invoked
 * with the last arguments provided to the debounced function. Subsequent
 * calls to the debounced function return the result of the last `func`
 * invocation.
 *
 * **Note:** If `leading` and `trailing` options are `true`, `func` is
 * invoked on the trailing edge of the timeout only if the debounced function
 * is invoked more than once during the `wait` timeout.
 *
 * If `wait` is `0` and `leading` is `false`, `func` invocation is deferred
 * until to the next tick, similar to `setTimeout` with a timeout of `0`.
 *
 * See [David Corbacho's article](https://css-tricks.com/debouncing-throttling-explained-examples/)
 * for details over the differences between `_.debounce` and `_.throttle`.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Function
 * @param {Function} func The function to debounce.
 * @param {number} [wait=0] The number of milliseconds to delay.
 * @param {Object} [options={}] The options object.
 * @param {boolean} [options.leading=false]
 *  Specify invoking on the leading edge of the timeout.
 * @param {number} [options.maxWait]
 *  The maximum time `func` is allowed to be delayed before it's invoked.
 * @param {boolean} [options.trailing=true]
 *  Specify invoking on the trailing edge of the timeout.
 * @returns {Function} Returns the new debounced function.
 * @example
 *
 * // Avoid costly calculations while the window size is in flux.
 * jQuery(window).on('resize', _.debounce(calculateLayout, 150));
 *
 * // Invoke `sendMail` when clicked, debouncing subsequent calls.
 * jQuery(element).on('click', _.debounce(sendMail, 300, {
 *   'leading': true,
 *   'trailing': false
 * }));
 *
 * // Ensure `batchLog` is invoked once after 1 second of debounced calls.
 * var debounced = _.debounce(batchLog, 250, { 'maxWait': 1000 });
 * var source = new EventSource('/stream');
 * jQuery(source).on('message', debounced);
 *
 * // Cancel the trailing debounced invocation.
 * jQuery(window).on('popstate', debounced.cancel);
 */
function debounce(func, wait, options) {
  var lastArgs,
      lastThis,
      maxWait,
      result,
      timerId,
      lastCallTime,
      lastInvokeTime = 0,
      leading = false,
      maxing = false,
      trailing = true;

  if (typeof func != 'function') {
    throw new TypeError(FUNC_ERROR_TEXT);
  }
  wait = toNumber(wait) || 0;
  if (isObject(options)) {
    leading = !!options.leading;
    maxing = 'maxWait' in options;
    maxWait = maxing ? nativeMax(toNumber(options.maxWait) || 0, wait) : maxWait;
    trailing = 'trailing' in options ? !!options.trailing : trailing;
  }

  function invokeFunc(time) {
    var args = lastArgs,
        thisArg = lastThis;

    lastArgs = lastThis = undefined;
    lastInvokeTime = time;
    result = func.apply(thisArg, args);
    return result;
  }

  function leadingEdge(time) {
    // Reset any `maxWait` timer.
    lastInvokeTime = time;
    // Start the timer for the trailing edge.
    timerId = setTimeout(timerExpired, wait);
    // Invoke the leading edge.
    return leading ? invokeFunc(time) : result;
  }

  function remainingWait(time) {
    var timeSinceLastCall = time - lastCallTime,
        timeSinceLastInvoke = time - lastInvokeTime,
        result = wait - timeSinceLastCall;

    return maxing ? nativeMin(result, maxWait - timeSinceLastInvoke) : result;
  }

  function shouldInvoke(time) {
    var timeSinceLastCall = time - lastCallTime,
        timeSinceLastInvoke = time - lastInvokeTime;

    // Either this is the first call, activity has stopped and we're at the
    // trailing edge, the system time has gone backwards and we're treating
    // it as the trailing edge, or we've hit the `maxWait` limit.
    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
      (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait));
  }

  function timerExpired() {
    var time = now();
    if (shouldInvoke(time)) {
      return trailingEdge(time);
    }
    // Restart the timer.
    timerId = setTimeout(timerExpired, remainingWait(time));
  }

  function trailingEdge(time) {
    timerId = undefined;

    // Only invoke if we have `lastArgs` which means `func` has been
    // debounced at least once.
    if (trailing && lastArgs) {
      return invokeFunc(time);
    }
    lastArgs = lastThis = undefined;
    return result;
  }

  function cancel() {
    if (timerId !== undefined) {
      clearTimeout(timerId);
    }
    lastInvokeTime = 0;
    lastArgs = lastCallTime = lastThis = timerId = undefined;
  }

  function flush() {
    return timerId === undefined ? result : trailingEdge(now());
  }

  function debounced() {
    var time = now(),
        isInvoking = shouldInvoke(time);

    lastArgs = arguments;
    lastThis = this;
    lastCallTime = time;

    if (isInvoking) {
      if (timerId === undefined) {
        return leadingEdge(lastCallTime);
      }
      if (maxing) {
        // Handle invocations in a tight loop.
        timerId = setTimeout(timerExpired, wait);
        return invokeFunc(lastCallTime);
      }
    }
    if (timerId === undefined) {
      timerId = setTimeout(timerExpired, wait);
    }
    return result;
  }
  debounced.cancel = cancel;
  debounced.flush = flush;
  return debounced;
}

/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */
function isObject(value) {
  var type = typeof value;
  return !!value && (type == 'object' || type == 'function');
}

/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */
function isObjectLike(value) {
  return !!value && typeof value == 'object';
}

/**
 * Checks if `value` is classified as a `Symbol` primitive or object.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.
 * @example
 *
 * _.isSymbol(Symbol.iterator);
 * // => true
 *
 * _.isSymbol('abc');
 * // => false
 */
function isSymbol(value) {
  return typeof value == 'symbol' ||
    (isObjectLike(value) && objectToString.call(value) == symbolTag);
}

/**
 * Converts `value` to a number.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to process.
 * @returns {number} Returns the number.
 * @example
 *
 * _.toNumber(3.2);
 * // => 3.2
 *
 * _.toNumber(Number.MIN_VALUE);
 * // => 5e-324
 *
 * _.toNumber(Infinity);
 * // => Infinity
 *
 * _.toNumber('3.2');
 * // => 3.2
 */
function toNumber(value) {
  if (typeof value == 'number') {
    return value;
  }
  if (isSymbol(value)) {
    return NAN;
  }
  if (isObject(value)) {
    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;
    value = isObject(other) ? (other + '') : other;
  }
  if (typeof value != 'string') {
    return value === 0 ? value : +value;
  }
  value = value.replace(reTrim, '');
  var isBinary = reIsBinary.test(value);
  return (isBinary || reIsOctal.test(value))
    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)
    : (reIsBadHex.test(value) ? NAN : +value);
}

module.exports = debounce;

},
"eT7gjeeuK+zTNhibZxQIfCYr/egK+GKqP9GX3OI2mUY=":
function (require, module, exports, __dirname, __filename) {
'use strict';

/**
 * Checks if a status code is allowed in a close frame.
 *
 * @param {Number} code The status code
 * @return {Boolean} `true` if the status code is valid, else `false`
 * @public
 */
function isValidStatusCode(code) {
  return (
    (code >= 1000 &&
      code <= 1014 &&
      code !== 1004 &&
      code !== 1005 &&
      code !== 1006) ||
    (code >= 3000 && code <= 4999)
  );
}

/**
 * Checks if a given buffer contains only correct UTF-8.
 * Ported from https://www.cl.cam.ac.uk/%7Emgk25/ucs/utf8_check.c by
 * Markus Kuhn.
 *
 * @param {Buffer} buf The buffer to check
 * @return {Boolean} `true` if `buf` contains only correct UTF-8, else `false`
 * @public
 */
function _isValidUTF8(buf) {
  const len = buf.length;
  let i = 0;

  while (i < len) {
    if (buf[i] < 0x80) {
      // 0xxxxxxx
      i++;
    } else if ((buf[i] & 0xe0) === 0xc0) {
      // 110xxxxx 10xxxxxx
      if (
        i + 1 === len ||
        (buf[i + 1] & 0xc0) !== 0x80 ||
        (buf[i] & 0xfe) === 0xc0 // Overlong
      ) {
        return false;
      } else {
        i += 2;
      }
    } else if ((buf[i] & 0xf0) === 0xe0) {
      // 1110xxxx 10xxxxxx 10xxxxxx
      if (
        i + 2 >= len ||
        (buf[i + 1] & 0xc0) !== 0x80 ||
        (buf[i + 2] & 0xc0) !== 0x80 ||
        (buf[i] === 0xe0 && (buf[i + 1] & 0xe0) === 0x80) || // Overlong
        (buf[i] === 0xed && (buf[i + 1] & 0xe0) === 0xa0) // Surrogate (U+D800 - U+DFFF)
      ) {
        return false;
      } else {
        i += 3;
      }
    } else if ((buf[i] & 0xf8) === 0xf0) {
      // 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
      if (
        i + 3 >= len ||
        (buf[i + 1] & 0xc0) !== 0x80 ||
        (buf[i + 2] & 0xc0) !== 0x80 ||
        (buf[i + 3] & 0xc0) !== 0x80 ||
        (buf[i] === 0xf0 && (buf[i + 1] & 0xf0) === 0x80) || // Overlong
        (buf[i] === 0xf4 && buf[i + 1] > 0x8f) ||
        buf[i] > 0xf4 // > U+10FFFF
      ) {
        return false;
      } else {
        i += 4;
      }
    } else {
      return false;
    }
  }

  return true;
}

try {
  let isValidUTF8 = require('utf-8-validate');

  /* istanbul ignore if */
  if (typeof isValidUTF8 === 'object') {
    isValidUTF8 = isValidUTF8.Validation.isValidUTF8; // utf-8-validate@<3.0.0
  }

  module.exports = {
    isValidStatusCode,
    isValidUTF8(buf) {
      return buf.length < 150 ? _isValidUTF8(buf) : isValidUTF8(buf);
    }
  };
} catch (e) /* istanbul ignore next */ {
  module.exports = {
    isValidStatusCode,
    isValidUTF8: _isValidUTF8
  };
}

},
"egOl/fDE75Wnpj5bapQSJLvp9M2hIv8gaHq2sbDicns=":
function (require, module, exports, __dirname, __filename) {
function AbstractIterator (db) {
  if (typeof db !== 'object' || db === null) {
    throw new TypeError('First argument must be an abstract-leveldown compliant store')
  }

  this.db = db
  this._ended = false
  this._nexting = false
}

AbstractIterator.prototype.next = function (callback) {
  var self = this

  if (typeof callback !== 'function') {
    throw new Error('next() requires a callback argument')
  }

  if (self._ended) {
    process.nextTick(callback, new Error('cannot call next() after end()'))
    return self
  }

  if (self._nexting) {
    process.nextTick(callback, new Error('cannot call next() before previous next() has completed'))
    return self
  }

  self._nexting = true
  self._next(function () {
    self._nexting = false
    callback.apply(null, arguments)
  })

  return self
}

AbstractIterator.prototype._next = function (callback) {
  process.nextTick(callback)
}

AbstractIterator.prototype.seek = function (target) {
  if (this._ended) {
    throw new Error('cannot call seek() after end()')
  }
  if (this._nexting) {
    throw new Error('cannot call seek() before next() has completed')
  }

  target = this.db._serializeKey(target)
  this._seek(target)
}

AbstractIterator.prototype._seek = function (target) {}

AbstractIterator.prototype.end = function (callback) {
  if (typeof callback !== 'function') {
    throw new Error('end() requires a callback argument')
  }

  if (this._ended) {
    return process.nextTick(callback, new Error('end() already called on iterator'))
  }

  this._ended = true
  this._end(callback)
}

AbstractIterator.prototype._end = function (callback) {
  process.nextTick(callback)
}

module.exports = AbstractIterator

},
"ekwZ0QJdJmlyPdKpOc7X1VbYFe7f/2K/KIlwNluLJtw=":
function (require, module, exports, __dirname, __filename) {
var cc   = require('./lib/utils')
var join = require('path').join
var deepExtend = require('deep-extend')
var etc = '/etc'
var win = process.platform === "win32"
var home = win
           ? process.env.USERPROFILE
           : process.env.HOME

module.exports = function (name, defaults, argv, parse) {
  if('string' !== typeof name)
    throw new Error('rc(name): name *must* be string')
  if(!argv)
    argv = require('minimist')(process.argv.slice(2))
  defaults = (
      'string' === typeof defaults
    ? cc.json(defaults) : defaults
    ) || {}

  parse = parse || cc.parse

  var env = cc.env(name + '_')

  var configs = [defaults]
  var configFiles = []
  function addConfigFile (file) {
    if (configFiles.indexOf(file) >= 0) return
    var fileConfig = cc.file(file)
    if (fileConfig) {
      configs.push(parse(fileConfig))
      configFiles.push(file)
    }
  }

  // which files do we look at?
  if (!win)
   [join(etc, name, 'config'),
    join(etc, name + 'rc')].forEach(addConfigFile)
  if (home)
   [join(home, '.config', name, 'config'),
    join(home, '.config', name),
    join(home, '.' + name, 'config'),
    join(home, '.' + name + 'rc')].forEach(addConfigFile)
  addConfigFile(cc.find('.'+name+'rc'))
  if (env.config) addConfigFile(env.config)
  if (argv.config) addConfigFile(argv.config)

  return deepExtend.apply(null, configs.concat([
    env,
    argv,
    configFiles.length ? {configs: configFiles, config: configFiles[configFiles.length - 1]} : undefined,
  ]))
}

},
"elrpliqmrOwGvUbADflkmicUu1ThW0xWsL4t6rHibOM=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const { where, and, type, isPublic, descending, batch, toPullStream, } = require('ssb-db2/operators');
module.exports = {
    name: 'searchUtils',
    version: '1.0.0',
    manifest: {
        query: 'source',
    },
    permissions: {
        master: {
            allow: ['query'],
        },
    },
    init: function init(ssb) {
        const containsWords = ssb.search2.operator;
        return {
            query(text) {
                return pull(ssb.db.query(where(and(type('post'), isPublic(), containsWords(text))), descending(), batch(20), toPullStream()), pull.filter((msg) => 
                // We want to make sure that *exact* input is matched, *not* as a
                // word prefix, so we use a word boundary, except not literally `\b`
                // because it often doensn't work with Unicode (especially in
                // nodejs-mobile!), so we do this instead:
                new RegExp(text + '($|[ ,.;:!?\\-])', 'i').test(msg.value.content.text)), pull.asyncMap((msg, cb) => {
                    ssb.friends.isBlocking({ source: ssb.id, dest: msg.value.author }, (err, blocking) => {
                        if (err || blocking)
                            cb(null, null);
                        else
                            cb(null, msg);
                    });
                }), pull.filter());
            },
        };
    },
};
//# sourceMappingURL=searchUtils.js.map
},
"ey7OPvS1eLJkRyIib+2QnlKv5zFO5XmNMwghcUhmKZI=":
function (require, module, exports, __dirname, __filename) {
// from
// http://stackoverflow.com/questions/1344500/efficient-way-to-insert-a-number-into-a-sorted-array-of-numbers


module.exports = function insert(element, array, comparer) {
  comparer = comparer || strCompare;
  array.splice(locationOf(element, array, comparer) + 1, 0, element);
  return array;
}

function strCompare(a, b) {
  if (a === b) return 0
  return a < b ? -1 : 1;
}

function locationOf(element, array, comparer, start, end) {
    if (array.length === 0)
        return -1;

    start = start || 0;
    end = end || array.length;
    var pivot = (start + end) >> 1;

    var c = comparer(element, array[pivot]);
    if (end - start <= 1) return c == -1 ? pivot - 1 : pivot;

    switch (c) {
        case -1: return locationOf(element, array, comparer, start, pivot);
        case 0: return pivot;
        case 1: return locationOf(element, array, comparer, pivot, end);
    };
};

},
"fL5D0k4SZBTB3uNOuJrRc0PxkyYCr7Mlc2Yxf7Mnwtg=":
function (require, module, exports, __dirname, __filename) {
var os = require('os');

function each(network) {
  return Object.keys(network)
    .map(function(itrface) {
      return network[itrface]
        .filter(function(e) {
          return !e.internal;
        })
        .map(function(e) {
          return itrface + '/' + e.address;
        });
    })
    .reduce(function(a, b) {
      return a.concat(b);
    }, []);
}

module.exports = function(onNetwork, ref) {
  var init = each(os.networkInterfaces()).join(',');
  var int = setInterval(function(e) {
    var cur = each(os.networkInterfaces()).join(',');
    if (init !== cur) onNetwork((init = cur));
  }, 1000);

  //unreference the counter (only on node)
  if (!ref && int.unref) int.unref();
};

if (!module.parent)
  module.exports(function(addrs) {
    console.log(addrs);
  }, true);

},
"fSZoQc1wVUnyySCVITovHGKvuKIhknPw3RgaKdbXh9s=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "ábaco",
    "abdomen",
    "abeja",
    "abierto",
    "abogado",
    "abono",
    "aborto",
    "abrazo",
    "abrir",
    "abuelo",
    "abuso",
    "acabar",
    "academia",
    "acceso",
    "acción",
    "aceite",
    "acelga",
    "acento",
    "aceptar",
    "ácido",
    "aclarar",
    "acné",
    "acoger",
    "acoso",
    "activo",
    "acto",
    "actriz",
    "actuar",
    "acudir",
    "acuerdo",
    "acusar",
    "adicto",
    "admitir",
    "adoptar",
    "adorno",
    "aduana",
    "adulto",
    "aéreo",
    "afectar",
    "afición",
    "afinar",
    "afirmar",
    "ágil",
    "agitar",
    "agonía",
    "agosto",
    "agotar",
    "agregar",
    "agrio",
    "agua",
    "agudo",
    "águila",
    "aguja",
    "ahogo",
    "ahorro",
    "aire",
    "aislar",
    "ajedrez",
    "ajeno",
    "ajuste",
    "alacrán",
    "alambre",
    "alarma",
    "alba",
    "álbum",
    "alcalde",
    "aldea",
    "alegre",
    "alejar",
    "alerta",
    "aleta",
    "alfiler",
    "alga",
    "algodón",
    "aliado",
    "aliento",
    "alivio",
    "alma",
    "almeja",
    "almíbar",
    "altar",
    "alteza",
    "altivo",
    "alto",
    "altura",
    "alumno",
    "alzar",
    "amable",
    "amante",
    "amapola",
    "amargo",
    "amasar",
    "ámbar",
    "ámbito",
    "ameno",
    "amigo",
    "amistad",
    "amor",
    "amparo",
    "amplio",
    "ancho",
    "anciano",
    "ancla",
    "andar",
    "andén",
    "anemia",
    "ángulo",
    "anillo",
    "ánimo",
    "anís",
    "anotar",
    "antena",
    "antiguo",
    "antojo",
    "anual",
    "anular",
    "anuncio",
    "añadir",
    "añejo",
    "año",
    "apagar",
    "aparato",
    "apetito",
    "apio",
    "aplicar",
    "apodo",
    "aporte",
    "apoyo",
    "aprender",
    "aprobar",
    "apuesta",
    "apuro",
    "arado",
    "araña",
    "arar",
    "árbitro",
    "árbol",
    "arbusto",
    "archivo",
    "arco",
    "arder",
    "ardilla",
    "arduo",
    "área",
    "árido",
    "aries",
    "armonía",
    "arnés",
    "aroma",
    "arpa",
    "arpón",
    "arreglo",
    "arroz",
    "arruga",
    "arte",
    "artista",
    "asa",
    "asado",
    "asalto",
    "ascenso",
    "asegurar",
    "aseo",
    "asesor",
    "asiento",
    "asilo",
    "asistir",
    "asno",
    "asombro",
    "áspero",
    "astilla",
    "astro",
    "astuto",
    "asumir",
    "asunto",
    "atajo",
    "ataque",
    "atar",
    "atento",
    "ateo",
    "ático",
    "atleta",
    "átomo",
    "atraer",
    "atroz",
    "atún",
    "audaz",
    "audio",
    "auge",
    "aula",
    "aumento",
    "ausente",
    "autor",
    "aval",
    "avance",
    "avaro",
    "ave",
    "avellana",
    "avena",
    "avestruz",
    "avión",
    "aviso",
    "ayer",
    "ayuda",
    "ayuno",
    "azafrán",
    "azar",
    "azote",
    "azúcar",
    "azufre",
    "azul",
    "baba",
    "babor",
    "bache",
    "bahía",
    "baile",
    "bajar",
    "balanza",
    "balcón",
    "balde",
    "bambú",
    "banco",
    "banda",
    "baño",
    "barba",
    "barco",
    "barniz",
    "barro",
    "báscula",
    "bastón",
    "basura",
    "batalla",
    "batería",
    "batir",
    "batuta",
    "baúl",
    "bazar",
    "bebé",
    "bebida",
    "bello",
    "besar",
    "beso",
    "bestia",
    "bicho",
    "bien",
    "bingo",
    "blanco",
    "bloque",
    "blusa",
    "boa",
    "bobina",
    "bobo",
    "boca",
    "bocina",
    "boda",
    "bodega",
    "boina",
    "bola",
    "bolero",
    "bolsa",
    "bomba",
    "bondad",
    "bonito",
    "bono",
    "bonsái",
    "borde",
    "borrar",
    "bosque",
    "bote",
    "botín",
    "bóveda",
    "bozal",
    "bravo",
    "brazo",
    "brecha",
    "breve",
    "brillo",
    "brinco",
    "brisa",
    "broca",
    "broma",
    "bronce",
    "brote",
    "bruja",
    "brusco",
    "bruto",
    "buceo",
    "bucle",
    "bueno",
    "buey",
    "bufanda",
    "bufón",
    "búho",
    "buitre",
    "bulto",
    "burbuja",
    "burla",
    "burro",
    "buscar",
    "butaca",
    "buzón",
    "caballo",
    "cabeza",
    "cabina",
    "cabra",
    "cacao",
    "cadáver",
    "cadena",
    "caer",
    "café",
    "caída",
    "caimán",
    "caja",
    "cajón",
    "cal",
    "calamar",
    "calcio",
    "caldo",
    "calidad",
    "calle",
    "calma",
    "calor",
    "calvo",
    "cama",
    "cambio",
    "camello",
    "camino",
    "campo",
    "cáncer",
    "candil",
    "canela",
    "canguro",
    "canica",
    "canto",
    "caña",
    "cañón",
    "caoba",
    "caos",
    "capaz",
    "capitán",
    "capote",
    "captar",
    "capucha",
    "cara",
    "carbón",
    "cárcel",
    "careta",
    "carga",
    "cariño",
    "carne",
    "carpeta",
    "carro",
    "carta",
    "casa",
    "casco",
    "casero",
    "caspa",
    "castor",
    "catorce",
    "catre",
    "caudal",
    "causa",
    "cazo",
    "cebolla",
    "ceder",
    "cedro",
    "celda",
    "célebre",
    "celoso",
    "célula",
    "cemento",
    "ceniza",
    "centro",
    "cerca",
    "cerdo",
    "cereza",
    "cero",
    "cerrar",
    "certeza",
    "césped",
    "cetro",
    "chacal",
    "chaleco",
    "champú",
    "chancla",
    "chapa",
    "charla",
    "chico",
    "chiste",
    "chivo",
    "choque",
    "choza",
    "chuleta",
    "chupar",
    "ciclón",
    "ciego",
    "cielo",
    "cien",
    "cierto",
    "cifra",
    "cigarro",
    "cima",
    "cinco",
    "cine",
    "cinta",
    "ciprés",
    "circo",
    "ciruela",
    "cisne",
    "cita",
    "ciudad",
    "clamor",
    "clan",
    "claro",
    "clase",
    "clave",
    "cliente",
    "clima",
    "clínica",
    "cobre",
    "cocción",
    "cochino",
    "cocina",
    "coco",
    "código",
    "codo",
    "cofre",
    "coger",
    "cohete",
    "cojín",
    "cojo",
    "cola",
    "colcha",
    "colegio",
    "colgar",
    "colina",
    "collar",
    "colmo",
    "columna",
    "combate",
    "comer",
    "comida",
    "cómodo",
    "compra",
    "conde",
    "conejo",
    "conga",
    "conocer",
    "consejo",
    "contar",
    "copa",
    "copia",
    "corazón",
    "corbata",
    "corcho",
    "cordón",
    "corona",
    "correr",
    "coser",
    "cosmos",
    "costa",
    "cráneo",
    "cráter",
    "crear",
    "crecer",
    "creído",
    "crema",
    "cría",
    "crimen",
    "cripta",
    "crisis",
    "cromo",
    "crónica",
    "croqueta",
    "crudo",
    "cruz",
    "cuadro",
    "cuarto",
    "cuatro",
    "cubo",
    "cubrir",
    "cuchara",
    "cuello",
    "cuento",
    "cuerda",
    "cuesta",
    "cueva",
    "cuidar",
    "culebra",
    "culpa",
    "culto",
    "cumbre",
    "cumplir",
    "cuna",
    "cuneta",
    "cuota",
    "cupón",
    "cúpula",
    "curar",
    "curioso",
    "curso",
    "curva",
    "cutis",
    "dama",
    "danza",
    "dar",
    "dardo",
    "dátil",
    "deber",
    "débil",
    "década",
    "decir",
    "dedo",
    "defensa",
    "definir",
    "dejar",
    "delfín",
    "delgado",
    "delito",
    "demora",
    "denso",
    "dental",
    "deporte",
    "derecho",
    "derrota",
    "desayuno",
    "deseo",
    "desfile",
    "desnudo",
    "destino",
    "desvío",
    "detalle",
    "detener",
    "deuda",
    "día",
    "diablo",
    "diadema",
    "diamante",
    "diana",
    "diario",
    "dibujo",
    "dictar",
    "diente",
    "dieta",
    "diez",
    "difícil",
    "digno",
    "dilema",
    "diluir",
    "dinero",
    "directo",
    "dirigir",
    "disco",
    "diseño",
    "disfraz",
    "diva",
    "divino",
    "doble",
    "doce",
    "dolor",
    "domingo",
    "don",
    "donar",
    "dorado",
    "dormir",
    "dorso",
    "dos",
    "dosis",
    "dragón",
    "droga",
    "ducha",
    "duda",
    "duelo",
    "dueño",
    "dulce",
    "dúo",
    "duque",
    "durar",
    "dureza",
    "duro",
    "ébano",
    "ebrio",
    "echar",
    "eco",
    "ecuador",
    "edad",
    "edición",
    "edificio",
    "editor",
    "educar",
    "efecto",
    "eficaz",
    "eje",
    "ejemplo",
    "elefante",
    "elegir",
    "elemento",
    "elevar",
    "elipse",
    "élite",
    "elixir",
    "elogio",
    "eludir",
    "embudo",
    "emitir",
    "emoción",
    "empate",
    "empeño",
    "empleo",
    "empresa",
    "enano",
    "encargo",
    "enchufe",
    "encía",
    "enemigo",
    "enero",
    "enfado",
    "enfermo",
    "engaño",
    "enigma",
    "enlace",
    "enorme",
    "enredo",
    "ensayo",
    "enseñar",
    "entero",
    "entrar",
    "envase",
    "envío",
    "época",
    "equipo",
    "erizo",
    "escala",
    "escena",
    "escolar",
    "escribir",
    "escudo",
    "esencia",
    "esfera",
    "esfuerzo",
    "espada",
    "espejo",
    "espía",
    "esposa",
    "espuma",
    "esquí",
    "estar",
    "este",
    "estilo",
    "estufa",
    "etapa",
    "eterno",
    "ética",
    "etnia",
    "evadir",
    "evaluar",
    "evento",
    "evitar",
    "exacto",
    "examen",
    "exceso",
    "excusa",
    "exento",
    "exigir",
    "exilio",
    "existir",
    "éxito",
    "experto",
    "explicar",
    "exponer",
    "extremo",
    "fábrica",
    "fábula",
    "fachada",
    "fácil",
    "factor",
    "faena",
    "faja",
    "falda",
    "fallo",
    "falso",
    "faltar",
    "fama",
    "familia",
    "famoso",
    "faraón",
    "farmacia",
    "farol",
    "farsa",
    "fase",
    "fatiga",
    "fauna",
    "favor",
    "fax",
    "febrero",
    "fecha",
    "feliz",
    "feo",
    "feria",
    "feroz",
    "fértil",
    "fervor",
    "festín",
    "fiable",
    "fianza",
    "fiar",
    "fibra",
    "ficción",
    "ficha",
    "fideo",
    "fiebre",
    "fiel",
    "fiera",
    "fiesta",
    "figura",
    "fijar",
    "fijo",
    "fila",
    "filete",
    "filial",
    "filtro",
    "fin",
    "finca",
    "fingir",
    "finito",
    "firma",
    "flaco",
    "flauta",
    "flecha",
    "flor",
    "flota",
    "fluir",
    "flujo",
    "flúor",
    "fobia",
    "foca",
    "fogata",
    "fogón",
    "folio",
    "folleto",
    "fondo",
    "forma",
    "forro",
    "fortuna",
    "forzar",
    "fosa",
    "foto",
    "fracaso",
    "frágil",
    "franja",
    "frase",
    "fraude",
    "freír",
    "freno",
    "fresa",
    "frío",
    "frito",
    "fruta",
    "fuego",
    "fuente",
    "fuerza",
    "fuga",
    "fumar",
    "función",
    "funda",
    "furgón",
    "furia",
    "fusil",
    "fútbol",
    "futuro",
    "gacela",
    "gafas",
    "gaita",
    "gajo",
    "gala",
    "galería",
    "gallo",
    "gamba",
    "ganar",
    "gancho",
    "ganga",
    "ganso",
    "garaje",
    "garza",
    "gasolina",
    "gastar",
    "gato",
    "gavilán",
    "gemelo",
    "gemir",
    "gen",
    "género",
    "genio",
    "gente",
    "geranio",
    "gerente",
    "germen",
    "gesto",
    "gigante",
    "gimnasio",
    "girar",
    "giro",
    "glaciar",
    "globo",
    "gloria",
    "gol",
    "golfo",
    "goloso",
    "golpe",
    "goma",
    "gordo",
    "gorila",
    "gorra",
    "gota",
    "goteo",
    "gozar",
    "grada",
    "gráfico",
    "grano",
    "grasa",
    "gratis",
    "grave",
    "grieta",
    "grillo",
    "gripe",
    "gris",
    "grito",
    "grosor",
    "grúa",
    "grueso",
    "grumo",
    "grupo",
    "guante",
    "guapo",
    "guardia",
    "guerra",
    "guía",
    "guiño",
    "guion",
    "guiso",
    "guitarra",
    "gusano",
    "gustar",
    "haber",
    "hábil",
    "hablar",
    "hacer",
    "hacha",
    "hada",
    "hallar",
    "hamaca",
    "harina",
    "haz",
    "hazaña",
    "hebilla",
    "hebra",
    "hecho",
    "helado",
    "helio",
    "hembra",
    "herir",
    "hermano",
    "héroe",
    "hervir",
    "hielo",
    "hierro",
    "hígado",
    "higiene",
    "hijo",
    "himno",
    "historia",
    "hocico",
    "hogar",
    "hoguera",
    "hoja",
    "hombre",
    "hongo",
    "honor",
    "honra",
    "hora",
    "hormiga",
    "horno",
    "hostil",
    "hoyo",
    "hueco",
    "huelga",
    "huerta",
    "hueso",
    "huevo",
    "huida",
    "huir",
    "humano",
    "húmedo",
    "humilde",
    "humo",
    "hundir",
    "huracán",
    "hurto",
    "icono",
    "ideal",
    "idioma",
    "ídolo",
    "iglesia",
    "iglú",
    "igual",
    "ilegal",
    "ilusión",
    "imagen",
    "imán",
    "imitar",
    "impar",
    "imperio",
    "imponer",
    "impulso",
    "incapaz",
    "índice",
    "inerte",
    "infiel",
    "informe",
    "ingenio",
    "inicio",
    "inmenso",
    "inmune",
    "innato",
    "insecto",
    "instante",
    "interés",
    "íntimo",
    "intuir",
    "inútil",
    "invierno",
    "ira",
    "iris",
    "ironía",
    "isla",
    "islote",
    "jabalí",
    "jabón",
    "jamón",
    "jarabe",
    "jardín",
    "jarra",
    "jaula",
    "jazmín",
    "jefe",
    "jeringa",
    "jinete",
    "jornada",
    "joroba",
    "joven",
    "joya",
    "juerga",
    "jueves",
    "juez",
    "jugador",
    "jugo",
    "juguete",
    "juicio",
    "junco",
    "jungla",
    "junio",
    "juntar",
    "júpiter",
    "jurar",
    "justo",
    "juvenil",
    "juzgar",
    "kilo",
    "koala",
    "labio",
    "lacio",
    "lacra",
    "lado",
    "ladrón",
    "lagarto",
    "lágrima",
    "laguna",
    "laico",
    "lamer",
    "lámina",
    "lámpara",
    "lana",
    "lancha",
    "langosta",
    "lanza",
    "lápiz",
    "largo",
    "larva",
    "lástima",
    "lata",
    "látex",
    "latir",
    "laurel",
    "lavar",
    "lazo",
    "leal",
    "lección",
    "leche",
    "lector",
    "leer",
    "legión",
    "legumbre",
    "lejano",
    "lengua",
    "lento",
    "leña",
    "león",
    "leopardo",
    "lesión",
    "letal",
    "letra",
    "leve",
    "leyenda",
    "libertad",
    "libro",
    "licor",
    "líder",
    "lidiar",
    "lienzo",
    "liga",
    "ligero",
    "lima",
    "límite",
    "limón",
    "limpio",
    "lince",
    "lindo",
    "línea",
    "lingote",
    "lino",
    "linterna",
    "líquido",
    "liso",
    "lista",
    "litera",
    "litio",
    "litro",
    "llaga",
    "llama",
    "llanto",
    "llave",
    "llegar",
    "llenar",
    "llevar",
    "llorar",
    "llover",
    "lluvia",
    "lobo",
    "loción",
    "loco",
    "locura",
    "lógica",
    "logro",
    "lombriz",
    "lomo",
    "lonja",
    "lote",
    "lucha",
    "lucir",
    "lugar",
    "lujo",
    "luna",
    "lunes",
    "lupa",
    "lustro",
    "luto",
    "luz",
    "maceta",
    "macho",
    "madera",
    "madre",
    "maduro",
    "maestro",
    "mafia",
    "magia",
    "mago",
    "maíz",
    "maldad",
    "maleta",
    "malla",
    "malo",
    "mamá",
    "mambo",
    "mamut",
    "manco",
    "mando",
    "manejar",
    "manga",
    "maniquí",
    "manjar",
    "mano",
    "manso",
    "manta",
    "mañana",
    "mapa",
    "máquina",
    "mar",
    "marco",
    "marea",
    "marfil",
    "margen",
    "marido",
    "mármol",
    "marrón",
    "martes",
    "marzo",
    "masa",
    "máscara",
    "masivo",
    "matar",
    "materia",
    "matiz",
    "matriz",
    "máximo",
    "mayor",
    "mazorca",
    "mecha",
    "medalla",
    "medio",
    "médula",
    "mejilla",
    "mejor",
    "melena",
    "melón",
    "memoria",
    "menor",
    "mensaje",
    "mente",
    "menú",
    "mercado",
    "merengue",
    "mérito",
    "mes",
    "mesón",
    "meta",
    "meter",
    "método",
    "metro",
    "mezcla",
    "miedo",
    "miel",
    "miembro",
    "miga",
    "mil",
    "milagro",
    "militar",
    "millón",
    "mimo",
    "mina",
    "minero",
    "mínimo",
    "minuto",
    "miope",
    "mirar",
    "misa",
    "miseria",
    "misil",
    "mismo",
    "mitad",
    "mito",
    "mochila",
    "moción",
    "moda",
    "modelo",
    "moho",
    "mojar",
    "molde",
    "moler",
    "molino",
    "momento",
    "momia",
    "monarca",
    "moneda",
    "monja",
    "monto",
    "moño",
    "morada",
    "morder",
    "moreno",
    "morir",
    "morro",
    "morsa",
    "mortal",
    "mosca",
    "mostrar",
    "motivo",
    "mover",
    "móvil",
    "mozo",
    "mucho",
    "mudar",
    "mueble",
    "muela",
    "muerte",
    "muestra",
    "mugre",
    "mujer",
    "mula",
    "muleta",
    "multa",
    "mundo",
    "muñeca",
    "mural",
    "muro",
    "músculo",
    "museo",
    "musgo",
    "música",
    "muslo",
    "nácar",
    "nación",
    "nadar",
    "naipe",
    "naranja",
    "nariz",
    "narrar",
    "nasal",
    "natal",
    "nativo",
    "natural",
    "náusea",
    "naval",
    "nave",
    "navidad",
    "necio",
    "néctar",
    "negar",
    "negocio",
    "negro",
    "neón",
    "nervio",
    "neto",
    "neutro",
    "nevar",
    "nevera",
    "nicho",
    "nido",
    "niebla",
    "nieto",
    "niñez",
    "niño",
    "nítido",
    "nivel",
    "nobleza",
    "noche",
    "nómina",
    "noria",
    "norma",
    "norte",
    "nota",
    "noticia",
    "novato",
    "novela",
    "novio",
    "nube",
    "nuca",
    "núcleo",
    "nudillo",
    "nudo",
    "nuera",
    "nueve",
    "nuez",
    "nulo",
    "número",
    "nutria",
    "oasis",
    "obeso",
    "obispo",
    "objeto",
    "obra",
    "obrero",
    "observar",
    "obtener",
    "obvio",
    "oca",
    "ocaso",
    "océano",
    "ochenta",
    "ocho",
    "ocio",
    "ocre",
    "octavo",
    "octubre",
    "oculto",
    "ocupar",
    "ocurrir",
    "odiar",
    "odio",
    "odisea",
    "oeste",
    "ofensa",
    "oferta",
    "oficio",
    "ofrecer",
    "ogro",
    "oído",
    "oír",
    "ojo",
    "ola",
    "oleada",
    "olfato",
    "olivo",
    "olla",
    "olmo",
    "olor",
    "olvido",
    "ombligo",
    "onda",
    "onza",
    "opaco",
    "opción",
    "ópera",
    "opinar",
    "oponer",
    "optar",
    "óptica",
    "opuesto",
    "oración",
    "orador",
    "oral",
    "órbita",
    "orca",
    "orden",
    "oreja",
    "órgano",
    "orgía",
    "orgullo",
    "oriente",
    "origen",
    "orilla",
    "oro",
    "orquesta",
    "oruga",
    "osadía",
    "oscuro",
    "osezno",
    "oso",
    "ostra",
    "otoño",
    "otro",
    "oveja",
    "óvulo",
    "óxido",
    "oxígeno",
    "oyente",
    "ozono",
    "pacto",
    "padre",
    "paella",
    "página",
    "pago",
    "país",
    "pájaro",
    "palabra",
    "palco",
    "paleta",
    "pálido",
    "palma",
    "paloma",
    "palpar",
    "pan",
    "panal",
    "pánico",
    "pantera",
    "pañuelo",
    "papá",
    "papel",
    "papilla",
    "paquete",
    "parar",
    "parcela",
    "pared",
    "parir",
    "paro",
    "párpado",
    "parque",
    "párrafo",
    "parte",
    "pasar",
    "paseo",
    "pasión",
    "paso",
    "pasta",
    "pata",
    "patio",
    "patria",
    "pausa",
    "pauta",
    "pavo",
    "payaso",
    "peatón",
    "pecado",
    "pecera",
    "pecho",
    "pedal",
    "pedir",
    "pegar",
    "peine",
    "pelar",
    "peldaño",
    "pelea",
    "peligro",
    "pellejo",
    "pelo",
    "peluca",
    "pena",
    "pensar",
    "peñón",
    "peón",
    "peor",
    "pepino",
    "pequeño",
    "pera",
    "percha",
    "perder",
    "pereza",
    "perfil",
    "perico",
    "perla",
    "permiso",
    "perro",
    "persona",
    "pesa",
    "pesca",
    "pésimo",
    "pestaña",
    "pétalo",
    "petróleo",
    "pez",
    "pezuña",
    "picar",
    "pichón",
    "pie",
    "piedra",
    "pierna",
    "pieza",
    "pijama",
    "pilar",
    "piloto",
    "pimienta",
    "pino",
    "pintor",
    "pinza",
    "piña",
    "piojo",
    "pipa",
    "pirata",
    "pisar",
    "piscina",
    "piso",
    "pista",
    "pitón",
    "pizca",
    "placa",
    "plan",
    "plata",
    "playa",
    "plaza",
    "pleito",
    "pleno",
    "plomo",
    "pluma",
    "plural",
    "pobre",
    "poco",
    "poder",
    "podio",
    "poema",
    "poesía",
    "poeta",
    "polen",
    "policía",
    "pollo",
    "polvo",
    "pomada",
    "pomelo",
    "pomo",
    "pompa",
    "poner",
    "porción",
    "portal",
    "posada",
    "poseer",
    "posible",
    "poste",
    "potencia",
    "potro",
    "pozo",
    "prado",
    "precoz",
    "pregunta",
    "premio",
    "prensa",
    "preso",
    "previo",
    "primo",
    "príncipe",
    "prisión",
    "privar",
    "proa",
    "probar",
    "proceso",
    "producto",
    "proeza",
    "profesor",
    "programa",
    "prole",
    "promesa",
    "pronto",
    "propio",
    "próximo",
    "prueba",
    "público",
    "puchero",
    "pudor",
    "pueblo",
    "puerta",
    "puesto",
    "pulga",
    "pulir",
    "pulmón",
    "pulpo",
    "pulso",
    "puma",
    "punto",
    "puñal",
    "puño",
    "pupa",
    "pupila",
    "puré",
    "quedar",
    "queja",
    "quemar",
    "querer",
    "queso",
    "quieto",
    "química",
    "quince",
    "quitar",
    "rábano",
    "rabia",
    "rabo",
    "ración",
    "radical",
    "raíz",
    "rama",
    "rampa",
    "rancho",
    "rango",
    "rapaz",
    "rápido",
    "rapto",
    "rasgo",
    "raspa",
    "rato",
    "rayo",
    "raza",
    "razón",
    "reacción",
    "realidad",
    "rebaño",
    "rebote",
    "recaer",
    "receta",
    "rechazo",
    "recoger",
    "recreo",
    "recto",
    "recurso",
    "red",
    "redondo",
    "reducir",
    "reflejo",
    "reforma",
    "refrán",
    "refugio",
    "regalo",
    "regir",
    "regla",
    "regreso",
    "rehén",
    "reino",
    "reír",
    "reja",
    "relato",
    "relevo",
    "relieve",
    "relleno",
    "reloj",
    "remar",
    "remedio",
    "remo",
    "rencor",
    "rendir",
    "renta",
    "reparto",
    "repetir",
    "reposo",
    "reptil",
    "res",
    "rescate",
    "resina",
    "respeto",
    "resto",
    "resumen",
    "retiro",
    "retorno",
    "retrato",
    "reunir",
    "revés",
    "revista",
    "rey",
    "rezar",
    "rico",
    "riego",
    "rienda",
    "riesgo",
    "rifa",
    "rígido",
    "rigor",
    "rincón",
    "riñón",
    "río",
    "riqueza",
    "risa",
    "ritmo",
    "rito",
    "rizo",
    "roble",
    "roce",
    "rociar",
    "rodar",
    "rodeo",
    "rodilla",
    "roer",
    "rojizo",
    "rojo",
    "romero",
    "romper",
    "ron",
    "ronco",
    "ronda",
    "ropa",
    "ropero",
    "rosa",
    "rosca",
    "rostro",
    "rotar",
    "rubí",
    "rubor",
    "rudo",
    "rueda",
    "rugir",
    "ruido",
    "ruina",
    "ruleta",
    "rulo",
    "rumbo",
    "rumor",
    "ruptura",
    "ruta",
    "rutina",
    "sábado",
    "saber",
    "sabio",
    "sable",
    "sacar",
    "sagaz",
    "sagrado",
    "sala",
    "saldo",
    "salero",
    "salir",
    "salmón",
    "salón",
    "salsa",
    "salto",
    "salud",
    "salvar",
    "samba",
    "sanción",
    "sandía",
    "sanear",
    "sangre",
    "sanidad",
    "sano",
    "santo",
    "sapo",
    "saque",
    "sardina",
    "sartén",
    "sastre",
    "satán",
    "sauna",
    "saxofón",
    "sección",
    "seco",
    "secreto",
    "secta",
    "sed",
    "seguir",
    "seis",
    "sello",
    "selva",
    "semana",
    "semilla",
    "senda",
    "sensor",
    "señal",
    "señor",
    "separar",
    "sepia",
    "sequía",
    "ser",
    "serie",
    "sermón",
    "servir",
    "sesenta",
    "sesión",
    "seta",
    "setenta",
    "severo",
    "sexo",
    "sexto",
    "sidra",
    "siesta",
    "siete",
    "siglo",
    "signo",
    "sílaba",
    "silbar",
    "silencio",
    "silla",
    "símbolo",
    "simio",
    "sirena",
    "sistema",
    "sitio",
    "situar",
    "sobre",
    "socio",
    "sodio",
    "sol",
    "solapa",
    "soldado",
    "soledad",
    "sólido",
    "soltar",
    "solución",
    "sombra",
    "sondeo",
    "sonido",
    "sonoro",
    "sonrisa",
    "sopa",
    "soplar",
    "soporte",
    "sordo",
    "sorpresa",
    "sorteo",
    "sostén",
    "sótano",
    "suave",
    "subir",
    "suceso",
    "sudor",
    "suegra",
    "suelo",
    "sueño",
    "suerte",
    "sufrir",
    "sujeto",
    "sultán",
    "sumar",
    "superar",
    "suplir",
    "suponer",
    "supremo",
    "sur",
    "surco",
    "sureño",
    "surgir",
    "susto",
    "sutil",
    "tabaco",
    "tabique",
    "tabla",
    "tabú",
    "taco",
    "tacto",
    "tajo",
    "talar",
    "talco",
    "talento",
    "talla",
    "talón",
    "tamaño",
    "tambor",
    "tango",
    "tanque",
    "tapa",
    "tapete",
    "tapia",
    "tapón",
    "taquilla",
    "tarde",
    "tarea",
    "tarifa",
    "tarjeta",
    "tarot",
    "tarro",
    "tarta",
    "tatuaje",
    "tauro",
    "taza",
    "tazón",
    "teatro",
    "techo",
    "tecla",
    "técnica",
    "tejado",
    "tejer",
    "tejido",
    "tela",
    "teléfono",
    "tema",
    "temor",
    "templo",
    "tenaz",
    "tender",
    "tener",
    "tenis",
    "tenso",
    "teoría",
    "terapia",
    "terco",
    "término",
    "ternura",
    "terror",
    "tesis",
    "tesoro",
    "testigo",
    "tetera",
    "texto",
    "tez",
    "tibio",
    "tiburón",
    "tiempo",
    "tienda",
    "tierra",
    "tieso",
    "tigre",
    "tijera",
    "tilde",
    "timbre",
    "tímido",
    "timo",
    "tinta",
    "tío",
    "típico",
    "tipo",
    "tira",
    "tirón",
    "titán",
    "títere",
    "título",
    "tiza",
    "toalla",
    "tobillo",
    "tocar",
    "tocino",
    "todo",
    "toga",
    "toldo",
    "tomar",
    "tono",
    "tonto",
    "topar",
    "tope",
    "toque",
    "tórax",
    "torero",
    "tormenta",
    "torneo",
    "toro",
    "torpedo",
    "torre",
    "torso",
    "tortuga",
    "tos",
    "tosco",
    "toser",
    "tóxico",
    "trabajo",
    "tractor",
    "traer",
    "tráfico",
    "trago",
    "traje",
    "tramo",
    "trance",
    "trato",
    "trauma",
    "trazar",
    "trébol",
    "tregua",
    "treinta",
    "tren",
    "trepar",
    "tres",
    "tribu",
    "trigo",
    "tripa",
    "triste",
    "triunfo",
    "trofeo",
    "trompa",
    "tronco",
    "tropa",
    "trote",
    "trozo",
    "truco",
    "trueno",
    "trufa",
    "tubería",
    "tubo",
    "tuerto",
    "tumba",
    "tumor",
    "túnel",
    "túnica",
    "turbina",
    "turismo",
    "turno",
    "tutor",
    "ubicar",
    "úlcera",
    "umbral",
    "unidad",
    "unir",
    "universo",
    "uno",
    "untar",
    "uña",
    "urbano",
    "urbe",
    "urgente",
    "urna",
    "usar",
    "usuario",
    "útil",
    "utopía",
    "uva",
    "vaca",
    "vacío",
    "vacuna",
    "vagar",
    "vago",
    "vaina",
    "vajilla",
    "vale",
    "válido",
    "valle",
    "valor",
    "válvula",
    "vampiro",
    "vara",
    "variar",
    "varón",
    "vaso",
    "vecino",
    "vector",
    "vehículo",
    "veinte",
    "vejez",
    "vela",
    "velero",
    "veloz",
    "vena",
    "vencer",
    "venda",
    "veneno",
    "vengar",
    "venir",
    "venta",
    "venus",
    "ver",
    "verano",
    "verbo",
    "verde",
    "vereda",
    "verja",
    "verso",
    "verter",
    "vía",
    "viaje",
    "vibrar",
    "vicio",
    "víctima",
    "vida",
    "vídeo",
    "vidrio",
    "viejo",
    "viernes",
    "vigor",
    "vil",
    "villa",
    "vinagre",
    "vino",
    "viñedo",
    "violín",
    "viral",
    "virgo",
    "virtud",
    "visor",
    "víspera",
    "vista",
    "vitamina",
    "viudo",
    "vivaz",
    "vivero",
    "vivir",
    "vivo",
    "volcán",
    "volumen",
    "volver",
    "voraz",
    "votar",
    "voto",
    "voz",
    "vuelo",
    "vulgar",
    "yacer",
    "yate",
    "yegua",
    "yema",
    "yerno",
    "yeso",
    "yodo",
    "yoga",
    "yogur",
    "zafiro",
    "zanja",
    "zapato",
    "zarza",
    "zona",
    "zorro",
    "zumo",
    "zurdo"
]

},
"ffAsZA0UzzXnpBCz6JHYLNbJUHO6CIF2K44IDyjJN+o=":
function (require, module, exports, __dirname, __filename) {
module.exports = {
  net: 8008,
  ws: 8989
}

},
"flo5MMVYKgCxO3FuYOvvWdbilzNArrLpIOYYD97C4hg=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2020-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const fs = require("fs");
const path = require("path");
const mkdirp = require('mkdirp');
const FILENAME = 'manyverse-settings.json';
const DETAILED_LOGS = 'DETAILED_LOGS';
function writeSync(data) {
    if (!process.env.SSB_DIR) {
        throw new Error('writeSync needs the SSB_DIR env var');
    }
    if (!fs.existsSync(process.env.SSB_DIR))
        mkdirp.sync(process.env.SSB_DIR);
    const filePath = path.join(process.env.SSB_DIR, FILENAME);
    try {
        const content = JSON.stringify(data);
        fs.writeFileSync(filePath, content, { encoding: 'ascii' });
    }
    catch (err) {
        console.error(err);
    }
}
function readSync() {
    if (!process.env.SSB_DIR) {
        throw new Error('readSync needs the SSB_DIR env var');
    }
    if (!fs.existsSync(process.env.SSB_DIR))
        mkdirp.sync(process.env.SSB_DIR);
    const filePath = path.join(process.env.SSB_DIR, FILENAME);
    let settings;
    try {
        const content = fs.readFileSync(filePath, { encoding: 'ascii' });
        settings = JSON.parse(content);
    }
    catch (err) {
        if (err.code !== 'ENOENT')
            console.error(err);
        settings = {};
    }
    if (fs.existsSync(path.join(process.env.SSB_DIR, DETAILED_LOGS))) {
        settings.detailedLogs = true;
    }
    else {
        settings.detailedLogs = false;
    }
    return settings;
}
function writeDetailedLogs(detailedLogs) {
    if (!process.env.SSB_DIR) {
        throw new Error('writeSync needs the SSB_DIR env var');
    }
    if (!fs.existsSync(process.env.SSB_DIR))
        mkdirp.sync(process.env.SSB_DIR);
    const filePath = path.join(process.env.SSB_DIR, DETAILED_LOGS);
    try {
        if (detailedLogs) {
            fs.writeFileSync(filePath, '1', { encoding: 'ascii' });
        }
        else {
            fs.unlinkSync(filePath);
        }
    }
    catch (err) {
        if (err.code !== 'ENOENT')
            console.error(err);
    }
}
function updateField(key, value) {
    const prev = readSync();
    const next = Object.assign(Object.assign({}, prev), { [key]: value });
    writeSync(next);
}
module.exports = {
    name: 'settingsUtils',
    version: '1.0.0',
    manifest: {
        read: 'sync',
        updateHops: 'sync',
        updateBlobsPurge: 'sync',
        updateShowFollows: 'sync',
        updateDetailedLogs: 'sync',
    },
    permissions: {
        master: {
            allow: [
                'read',
                'updateHops',
                'updateBlobsPurge',
                'updateShowFollows',
                'updateDetailedLogs',
            ],
        },
    },
    readSync,
    init: function init(ssb, _config) {
        var _a, _b, _c;
        if (!((_a = ssb.blobsPurge) === null || _a === void 0 ? void 0 : _a.start)) {
            throw new Error('"settingsUtils" is missing required plugin "ssb-blobs-purge"');
        }
        // TODO: this logic could be moved to the frontend, and the storage of
        // the settings could be put in React Native's async-storage, as long as
        // we have a "global component" in cycle-native-navigation
        const current = readSync();
        let initialTimeout;
        const storageLimit = (_b = current.blobsStorageLimit) !== null && _b !== void 0 ? _b : 500e6;
        if (storageLimit >= 0) {
            initialTimeout = setTimeout(() => {
                ssb.blobsPurge.start({ storageLimit });
            }, 30e3);
            (_c = initialTimeout === null || initialTimeout === void 0 ? void 0 : initialTimeout.unref) === null || _c === void 0 ? void 0 : _c.call(initialTimeout);
        }
        return {
            updateHops(hops) {
                updateField('hops', hops);
            },
            updateShowFollows(showFollows) {
                // TODO: like above, this could also be moved to the frontend
                updateField('showFollows', showFollows);
            },
            updateBlobsPurge(storageLimit) {
                // TODO: like above, this could also be moved to the frontend
                if (initialTimeout) {
                    clearTimeout(initialTimeout);
                    initialTimeout = void 0;
                }
                if (storageLimit >= 0) {
                    ssb.blobsPurge.start({ storageLimit });
                    updateField('blobsStorageLimit', storageLimit);
                }
                else {
                    ssb.blobsPurge.stop();
                    updateField('blobsStorageLimit', void 0);
                }
            },
            updateDetailedLogs(detailedLogs) {
                writeDetailedLogs(detailedLogs);
            },
            read() {
                return readSync();
            },
        };
    },
};
//# sourceMappingURL=settingsUtils.js.map
},
"fm7agC5Aeb8jRfA/2BQwWV/IDEgg6Zg9esWkI3eBZkg=":
function (require, module, exports, __dirname, __filename) {
/**
 * lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright jQuery Foundation and other contributors <https://jquery.org/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the `TypeError` message for "Functions" methods. */
var FUNC_ERROR_TEXT = 'Expected a function';

/** Used to stand-in for `undefined` hash values. */
var HASH_UNDEFINED = '__lodash_hash_undefined__';

/** Used as references for various `Number` constants. */
var INFINITY = 1 / 0;

/** `Object#toString` result references. */
var funcTag = '[object Function]',
    genTag = '[object GeneratorFunction]',
    symbolTag = '[object Symbol]';

/** Used to match property names within property paths. */
var reIsDeepProp = /\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,
    reIsPlainProp = /^\w*$/,
    reLeadingDot = /^\./,
    rePropName = /[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g;

/**
 * Used to match `RegExp`
 * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).
 */
var reRegExpChar = /[\\^$.*+?()[\]{}|]/g;

/** Used to match backslashes in property paths. */
var reEscapeChar = /\\(\\)?/g;

/** Used to detect host constructors (Safari). */
var reIsHostCtor = /^\[object .+?Constructor\]$/;

/** Detect free variable `global` from Node.js. */
var freeGlobal = typeof global == 'object' && global && global.Object === Object && global;

/** Detect free variable `self`. */
var freeSelf = typeof self == 'object' && self && self.Object === Object && self;

/** Used as a reference to the global object. */
var root = freeGlobal || freeSelf || Function('return this')();

/**
 * Gets the value at `key` of `object`.
 *
 * @private
 * @param {Object} [object] The object to query.
 * @param {string} key The key of the property to get.
 * @returns {*} Returns the property value.
 */
function getValue(object, key) {
  return object == null ? undefined : object[key];
}

/**
 * Checks if `value` is a host object in IE < 9.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a host object, else `false`.
 */
function isHostObject(value) {
  // Many host objects are `Object` objects that can coerce to strings
  // despite having improperly defined `toString` methods.
  var result = false;
  if (value != null && typeof value.toString != 'function') {
    try {
      result = !!(value + '');
    } catch (e) {}
  }
  return result;
}

/** Used for built-in method references. */
var arrayProto = Array.prototype,
    funcProto = Function.prototype,
    objectProto = Object.prototype;

/** Used to detect overreaching core-js shims. */
var coreJsData = root['__core-js_shared__'];

/** Used to detect methods masquerading as native. */
var maskSrcKey = (function() {
  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');
  return uid ? ('Symbol(src)_1.' + uid) : '';
}());

/** Used to resolve the decompiled source of functions. */
var funcToString = funcProto.toString;

/** Used to check objects for own properties. */
var hasOwnProperty = objectProto.hasOwnProperty;

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var objectToString = objectProto.toString;

/** Used to detect if a method is native. */
var reIsNative = RegExp('^' +
  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\$&')
  .replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g, '$1.*?') + '$'
);

/** Built-in value references. */
var Symbol = root.Symbol,
    splice = arrayProto.splice;

/* Built-in method references that are verified to be native. */
var Map = getNative(root, 'Map'),
    nativeCreate = getNative(Object, 'create');

/** Used to convert symbols to primitives and strings. */
var symbolProto = Symbol ? Symbol.prototype : undefined,
    symbolToString = symbolProto ? symbolProto.toString : undefined;

/**
 * Creates a hash object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Hash(entries) {
  var index = -1,
      length = entries ? entries.length : 0;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the hash.
 *
 * @private
 * @name clear
 * @memberOf Hash
 */
function hashClear() {
  this.__data__ = nativeCreate ? nativeCreate(null) : {};
}

/**
 * Removes `key` and its value from the hash.
 *
 * @private
 * @name delete
 * @memberOf Hash
 * @param {Object} hash The hash to modify.
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function hashDelete(key) {
  return this.has(key) && delete this.__data__[key];
}

/**
 * Gets the hash value for `key`.
 *
 * @private
 * @name get
 * @memberOf Hash
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function hashGet(key) {
  var data = this.__data__;
  if (nativeCreate) {
    var result = data[key];
    return result === HASH_UNDEFINED ? undefined : result;
  }
  return hasOwnProperty.call(data, key) ? data[key] : undefined;
}

/**
 * Checks if a hash value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Hash
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function hashHas(key) {
  var data = this.__data__;
  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);
}

/**
 * Sets the hash `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Hash
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the hash instance.
 */
function hashSet(key, value) {
  var data = this.__data__;
  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;
  return this;
}

// Add methods to `Hash`.
Hash.prototype.clear = hashClear;
Hash.prototype['delete'] = hashDelete;
Hash.prototype.get = hashGet;
Hash.prototype.has = hashHas;
Hash.prototype.set = hashSet;

/**
 * Creates an list cache object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function ListCache(entries) {
  var index = -1,
      length = entries ? entries.length : 0;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the list cache.
 *
 * @private
 * @name clear
 * @memberOf ListCache
 */
function listCacheClear() {
  this.__data__ = [];
}

/**
 * Removes `key` and its value from the list cache.
 *
 * @private
 * @name delete
 * @memberOf ListCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function listCacheDelete(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    return false;
  }
  var lastIndex = data.length - 1;
  if (index == lastIndex) {
    data.pop();
  } else {
    splice.call(data, index, 1);
  }
  return true;
}

/**
 * Gets the list cache value for `key`.
 *
 * @private
 * @name get
 * @memberOf ListCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function listCacheGet(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  return index < 0 ? undefined : data[index][1];
}

/**
 * Checks if a list cache value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf ListCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function listCacheHas(key) {
  return assocIndexOf(this.__data__, key) > -1;
}

/**
 * Sets the list cache `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf ListCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the list cache instance.
 */
function listCacheSet(key, value) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    data.push([key, value]);
  } else {
    data[index][1] = value;
  }
  return this;
}

// Add methods to `ListCache`.
ListCache.prototype.clear = listCacheClear;
ListCache.prototype['delete'] = listCacheDelete;
ListCache.prototype.get = listCacheGet;
ListCache.prototype.has = listCacheHas;
ListCache.prototype.set = listCacheSet;

/**
 * Creates a map cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function MapCache(entries) {
  var index = -1,
      length = entries ? entries.length : 0;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the map.
 *
 * @private
 * @name clear
 * @memberOf MapCache
 */
function mapCacheClear() {
  this.__data__ = {
    'hash': new Hash,
    'map': new (Map || ListCache),
    'string': new Hash
  };
}

/**
 * Removes `key` and its value from the map.
 *
 * @private
 * @name delete
 * @memberOf MapCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function mapCacheDelete(key) {
  return getMapData(this, key)['delete'](key);
}

/**
 * Gets the map value for `key`.
 *
 * @private
 * @name get
 * @memberOf MapCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function mapCacheGet(key) {
  return getMapData(this, key).get(key);
}

/**
 * Checks if a map value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf MapCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function mapCacheHas(key) {
  return getMapData(this, key).has(key);
}

/**
 * Sets the map `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf MapCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the map cache instance.
 */
function mapCacheSet(key, value) {
  getMapData(this, key).set(key, value);
  return this;
}

// Add methods to `MapCache`.
MapCache.prototype.clear = mapCacheClear;
MapCache.prototype['delete'] = mapCacheDelete;
MapCache.prototype.get = mapCacheGet;
MapCache.prototype.has = mapCacheHas;
MapCache.prototype.set = mapCacheSet;

/**
 * Gets the index at which the `key` is found in `array` of key-value pairs.
 *
 * @private
 * @param {Array} array The array to inspect.
 * @param {*} key The key to search for.
 * @returns {number} Returns the index of the matched value, else `-1`.
 */
function assocIndexOf(array, key) {
  var length = array.length;
  while (length--) {
    if (eq(array[length][0], key)) {
      return length;
    }
  }
  return -1;
}

/**
 * The base implementation of `_.get` without support for default values.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {Array|string} path The path of the property to get.
 * @returns {*} Returns the resolved value.
 */
function baseGet(object, path) {
  path = isKey(path, object) ? [path] : castPath(path);

  var index = 0,
      length = path.length;

  while (object != null && index < length) {
    object = object[toKey(path[index++])];
  }
  return (index && index == length) ? object : undefined;
}

/**
 * The base implementation of `_.isNative` without bad shim checks.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a native function,
 *  else `false`.
 */
function baseIsNative(value) {
  if (!isObject(value) || isMasked(value)) {
    return false;
  }
  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;
  return pattern.test(toSource(value));
}

/**
 * The base implementation of `_.toString` which doesn't convert nullish
 * values to empty strings.
 *
 * @private
 * @param {*} value The value to process.
 * @returns {string} Returns the string.
 */
function baseToString(value) {
  // Exit early for strings to avoid a performance hit in some environments.
  if (typeof value == 'string') {
    return value;
  }
  if (isSymbol(value)) {
    return symbolToString ? symbolToString.call(value) : '';
  }
  var result = (value + '');
  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;
}

/**
 * Casts `value` to a path array if it's not one.
 *
 * @private
 * @param {*} value The value to inspect.
 * @returns {Array} Returns the cast property path array.
 */
function castPath(value) {
  return isArray(value) ? value : stringToPath(value);
}

/**
 * Gets the data for `map`.
 *
 * @private
 * @param {Object} map The map to query.
 * @param {string} key The reference key.
 * @returns {*} Returns the map data.
 */
function getMapData(map, key) {
  var data = map.__data__;
  return isKeyable(key)
    ? data[typeof key == 'string' ? 'string' : 'hash']
    : data.map;
}

/**
 * Gets the native function at `key` of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {string} key The key of the method to get.
 * @returns {*} Returns the function if it's native, else `undefined`.
 */
function getNative(object, key) {
  var value = getValue(object, key);
  return baseIsNative(value) ? value : undefined;
}

/**
 * Checks if `value` is a property name and not a property path.
 *
 * @private
 * @param {*} value The value to check.
 * @param {Object} [object] The object to query keys on.
 * @returns {boolean} Returns `true` if `value` is a property name, else `false`.
 */
function isKey(value, object) {
  if (isArray(value)) {
    return false;
  }
  var type = typeof value;
  if (type == 'number' || type == 'symbol' || type == 'boolean' ||
      value == null || isSymbol(value)) {
    return true;
  }
  return reIsPlainProp.test(value) || !reIsDeepProp.test(value) ||
    (object != null && value in Object(object));
}

/**
 * Checks if `value` is suitable for use as unique object key.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is suitable, else `false`.
 */
function isKeyable(value) {
  var type = typeof value;
  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')
    ? (value !== '__proto__')
    : (value === null);
}

/**
 * Checks if `func` has its source masked.
 *
 * @private
 * @param {Function} func The function to check.
 * @returns {boolean} Returns `true` if `func` is masked, else `false`.
 */
function isMasked(func) {
  return !!maskSrcKey && (maskSrcKey in func);
}

/**
 * Converts `string` to a property path array.
 *
 * @private
 * @param {string} string The string to convert.
 * @returns {Array} Returns the property path array.
 */
var stringToPath = memoize(function(string) {
  string = toString(string);

  var result = [];
  if (reLeadingDot.test(string)) {
    result.push('');
  }
  string.replace(rePropName, function(match, number, quote, string) {
    result.push(quote ? string.replace(reEscapeChar, '$1') : (number || match));
  });
  return result;
});

/**
 * Converts `value` to a string key if it's not a string or symbol.
 *
 * @private
 * @param {*} value The value to inspect.
 * @returns {string|symbol} Returns the key.
 */
function toKey(value) {
  if (typeof value == 'string' || isSymbol(value)) {
    return value;
  }
  var result = (value + '');
  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;
}

/**
 * Converts `func` to its source code.
 *
 * @private
 * @param {Function} func The function to process.
 * @returns {string} Returns the source code.
 */
function toSource(func) {
  if (func != null) {
    try {
      return funcToString.call(func);
    } catch (e) {}
    try {
      return (func + '');
    } catch (e) {}
  }
  return '';
}

/**
 * Creates a function that memoizes the result of `func`. If `resolver` is
 * provided, it determines the cache key for storing the result based on the
 * arguments provided to the memoized function. By default, the first argument
 * provided to the memoized function is used as the map cache key. The `func`
 * is invoked with the `this` binding of the memoized function.
 *
 * **Note:** The cache is exposed as the `cache` property on the memoized
 * function. Its creation may be customized by replacing the `_.memoize.Cache`
 * constructor with one whose instances implement the
 * [`Map`](http://ecma-international.org/ecma-262/7.0/#sec-properties-of-the-map-prototype-object)
 * method interface of `delete`, `get`, `has`, and `set`.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Function
 * @param {Function} func The function to have its output memoized.
 * @param {Function} [resolver] The function to resolve the cache key.
 * @returns {Function} Returns the new memoized function.
 * @example
 *
 * var object = { 'a': 1, 'b': 2 };
 * var other = { 'c': 3, 'd': 4 };
 *
 * var values = _.memoize(_.values);
 * values(object);
 * // => [1, 2]
 *
 * values(other);
 * // => [3, 4]
 *
 * object.a = 2;
 * values(object);
 * // => [1, 2]
 *
 * // Modify the result cache.
 * values.cache.set(object, ['a', 'b']);
 * values(object);
 * // => ['a', 'b']
 *
 * // Replace `_.memoize.Cache`.
 * _.memoize.Cache = WeakMap;
 */
function memoize(func, resolver) {
  if (typeof func != 'function' || (resolver && typeof resolver != 'function')) {
    throw new TypeError(FUNC_ERROR_TEXT);
  }
  var memoized = function() {
    var args = arguments,
        key = resolver ? resolver.apply(this, args) : args[0],
        cache = memoized.cache;

    if (cache.has(key)) {
      return cache.get(key);
    }
    var result = func.apply(this, args);
    memoized.cache = cache.set(key, result);
    return result;
  };
  memoized.cache = new (memoize.Cache || MapCache);
  return memoized;
}

// Assign cache to `_.memoize`.
memoize.Cache = MapCache;

/**
 * Performs a
 * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * comparison between two values to determine if they are equivalent.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.eq(object, object);
 * // => true
 *
 * _.eq(object, other);
 * // => false
 *
 * _.eq('a', 'a');
 * // => true
 *
 * _.eq('a', Object('a'));
 * // => false
 *
 * _.eq(NaN, NaN);
 * // => true
 */
function eq(value, other) {
  return value === other || (value !== value && other !== other);
}

/**
 * Checks if `value` is classified as an `Array` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array, else `false`.
 * @example
 *
 * _.isArray([1, 2, 3]);
 * // => true
 *
 * _.isArray(document.body.children);
 * // => false
 *
 * _.isArray('abc');
 * // => false
 *
 * _.isArray(_.noop);
 * // => false
 */
var isArray = Array.isArray;

/**
 * Checks if `value` is classified as a `Function` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a function, else `false`.
 * @example
 *
 * _.isFunction(_);
 * // => true
 *
 * _.isFunction(/abc/);
 * // => false
 */
function isFunction(value) {
  // The use of `Object#toString` avoids issues with the `typeof` operator
  // in Safari 8-9 which returns 'object' for typed array and other constructors.
  var tag = isObject(value) ? objectToString.call(value) : '';
  return tag == funcTag || tag == genTag;
}

/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */
function isObject(value) {
  var type = typeof value;
  return !!value && (type == 'object' || type == 'function');
}

/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */
function isObjectLike(value) {
  return !!value && typeof value == 'object';
}

/**
 * Checks if `value` is classified as a `Symbol` primitive or object.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.
 * @example
 *
 * _.isSymbol(Symbol.iterator);
 * // => true
 *
 * _.isSymbol('abc');
 * // => false
 */
function isSymbol(value) {
  return typeof value == 'symbol' ||
    (isObjectLike(value) && objectToString.call(value) == symbolTag);
}

/**
 * Converts `value` to a string. An empty string is returned for `null`
 * and `undefined` values. The sign of `-0` is preserved.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to process.
 * @returns {string} Returns the string.
 * @example
 *
 * _.toString(null);
 * // => ''
 *
 * _.toString(-0);
 * // => '-0'
 *
 * _.toString([1, 2, 3]);
 * // => '1,2,3'
 */
function toString(value) {
  return value == null ? '' : baseToString(value);
}

/**
 * Gets the value at `path` of `object`. If the resolved value is
 * `undefined`, the `defaultValue` is returned in its place.
 *
 * @static
 * @memberOf _
 * @since 3.7.0
 * @category Object
 * @param {Object} object The object to query.
 * @param {Array|string} path The path of the property to get.
 * @param {*} [defaultValue] The value returned for `undefined` resolved values.
 * @returns {*} Returns the resolved value.
 * @example
 *
 * var object = { 'a': [{ 'b': { 'c': 3 } }] };
 *
 * _.get(object, 'a[0].b.c');
 * // => 3
 *
 * _.get(object, ['a', '0', 'b', 'c']);
 * // => 3
 *
 * _.get(object, 'a.b.c', 'default');
 * // => 'default'
 */
function get(object, path, defaultValue) {
  var result = object == null ? undefined : baseGet(object, path);
  return result === undefined ? defaultValue : result;
}

module.exports = get;

},
"fqL4U2M6/E/gay4qfbjlINV7hpWvEWytY+di/LoO5PE=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bipf = require('bipf')
const Plugin = require('./plugin')
const { reEncrypt } = require('./private')

const B_VALUE = Buffer.from('value')
const B_AUTHOR = Buffer.from('author')
const B_SEQUENCE = Buffer.from('sequence')

// [author, sequence] => offset
module.exports = class EBT extends Plugin {
  constructor(log, dir) {
    super(log, dir, 'ebt', 1, 'json')
  }

  processRecord(record, seq) {
    const buf = record.value
    const pValue = bipf.seekKey(buf, 0, B_VALUE)
    if (pValue < 0) return
    const author = bipf.decode(buf, bipf.seekKey(buf, pValue, B_AUTHOR))
    const sequence = bipf.decode(buf, bipf.seekKey(buf, pValue, B_SEQUENCE))
    this.batch.push({
      type: 'put',
      key: [author, sequence],
      value: record.offset,
    })
  }

  indexesContent() {
    return false
  }

  levelKeyToMessage(key, cb) {
    this.level.get(key, (err, offset) => {
      if (err) return cb(err)
      else
        this.log.get(parseInt(offset, 10), (err, record) => {
          if (err) return cb(err)
          cb(null, bipf.decode(record, 0))
        })
    })
  }

  // this is for EBT so must be careful to not leak private messages
  getMessageFromAuthorSequence(key, cb) {
    this.levelKeyToMessage(JSON.stringify(key), (err, msg) => {
      if (err) cb(err)
      else cb(null, reEncrypt(msg))
    })
  }
}

},
"fqrJBQcVRwgEz7qsHCeTnM1dneca74nTAK2jFJDFN4g=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
const secret_stack_decorators_1 = require("secret-stack-decorators");
const run = require("promisify-tuple");
const pull = require('pull-stream');
const { onceWhen } = require('ssb-db2/utils');
const Deferred = require("p-defer");
function normalize(str) {
    return str
        .toLocaleLowerCase()
        .normalize('NFD')
        .replace(/[\u0300-\u036f]/g, '')
        .replace(/ +/g, '')
        .trim();
}
let suggest = class suggest {
    constructor(ssb, config) {
        var _a, _b, _c, _d, _e, _f;
        this.drainer = null;
        this.start = () => {
            var _a;
            if (this.drainer) {
                this.drainer.abort();
                this.drainer = null;
            }
            pull(this.ssb.friends.hopStream({ live: true, old: true }), pull.filter((x) => !x.sync), pull.asyncMap(async (hops, cb) => {
                this.checkAboutSelfPlugin();
                await run(this.ssb.db.onDrain)('base');
                await run(this.ssb.db.onDrain)('aboutSelf');
                const latestKVTs = this.ssb.db.getState();
                const aboutSelfIndex = this.ssb.db.getIndex('aboutSelf');
                onceWhen(this.ssb.db.stateFeedsReady, (ready) => ready === true, () => {
                    var _a, _b, _c;
                    const feedIds = Object.keys(hops).filter((feedId) => hops[feedId] >= 0 && hops[feedId] <= this.maxHops);
                    for (const feedId of feedIds) {
                        const profile = aboutSelfIndex.getProfile(feedId);
                        if (profile.name) {
                            const latestKVT = latestKVTs[feedId];
                            this.cache.set(feedId, {
                                id: feedId,
                                name: profile.name,
                                image: profile.image,
                                latest: Math.min((_a = latestKVT === null || latestKVT === void 0 ? void 0 : latestKVT.timestamp) !== null && _a !== void 0 ? _a : 0, (_c = (_b = latestKVT === null || latestKVT === void 0 ? void 0 : latestKVT.value) === null || _b === void 0 ? void 0 : _b.timestamp) !== null && _c !== void 0 ? _c : 0),
                            });
                        }
                    }
                    if (feedIds.length > 1 || feedIds[0] !== this.ssb.id) {
                        this.started.resolve();
                    }
                    cb(null, null);
                });
            }), (this.drainer = pull.drain(() => { })));
            const that = this;
            this.ssb.close.hook(function (fn, args) {
                if (that.drainer) {
                    that.drainer.abort();
                    that.drainer = null;
                }
                fn.apply(this, args);
            });
            const interval = setInterval(this.start, 60 * 60 * 1000);
            (_a = interval === null || interval === void 0 ? void 0 : interval.unref) === null || _a === void 0 ? void 0 : _a.call(interval);
        };
        this.profile = async (opts, cb) => {
            await this.started.promise;
            if (opts.text) {
                let results = [...this.cache.values()]
                    .map((profile) => {
                    const name = normalize(profile.name);
                    const query = normalize(opts.text);
                    const score = name === query
                        ? 3
                        : name.startsWith(query)
                            ? 2
                            : name.includes(query)
                                ? 1
                                : 0;
                    return { ...profile, score };
                })
                    .filter((profile) => profile.score > 0)
                    .sort((a, b) => b.latest + b.score * 3e9 - (a.latest + a.score * 3e9));
                if (typeof opts.limit === 'number') {
                    results = results.slice(0, opts.limit);
                }
                cb(null, results);
            }
            else if (opts.defaultIds) {
                await run(this.ssb.db.onDrain)('aboutSelf');
                const aboutSelf = this.ssb.db.getIndex('aboutSelf');
                const results = opts
                    .defaultIds.map((id) => {
                    const profile = aboutSelf.getProfile(id);
                    if (!profile)
                        return null;
                    profile.id = id;
                    return profile;
                })
                    .filter((profile) => !!profile);
                cb(null, results);
            }
            else {
                cb(null, []);
            }
        };
        if (!((_a = ssb.db) === null || _a === void 0 ? void 0 : _a.query)) {
            throw new Error('"ssb-suggest-lite" is missing required "ssb-db2"');
        }
        if (!((_b = ssb.friends) === null || _b === void 0 ? void 0 : _b.hopStream)) {
            throw new Error('"ssb-suggest-lite" is missing required "ssb-friends"');
        }
        this.ssb = ssb;
        this.cache = new Map();
        this.started = Deferred();
        this.maxHops = (_d = (_c = config.friends) === null || _c === void 0 ? void 0 : _c.hops) !== null && _d !== void 0 ? _d : 1;
        if ((_f = (_e = config.suggest) === null || _e === void 0 ? void 0 : _e.autostart) !== null && _f !== void 0 ? _f : true)
            this.start();
    }
    checkAboutSelfPlugin() {
        if (!this.ssb.db.getIndex('aboutSelf')) {
            throw new Error('"ssb-suggest-lite" is missing required "ssb-db2/about-self" plugin');
        }
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], suggest.prototype, "start", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('async')
], suggest.prototype, "profile", void 0);
suggest = __decorate([
    secret_stack_decorators_1.plugin('1.0.0')
], suggest);
module.exports = suggest;

},
"fsejwzyU5jrjbqFHK+d/77RRRc4UHfP3BFH1DLMLkM8=":
function (require, module, exports, __dirname, __filename) {
module.exports = read

var MSB = 0x80
  , REST = 0x7F

function read(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length

  do {
    if (counter >= l) {
      read.bytes = 0
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++]
    res += shift < 28
      ? (b & REST) << shift
      : (b & REST) * Math.pow(2, shift)
    shift += 7
  } while (b >= MSB)

  read.bytes = counter - offset

  return res
}

},
"fu5736jRclYQ5bBIMvHbeZrVIn9Ge1vsNaC3nOHuE6g=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = {
  drain: require('./drain'),
  onEnd: require('./on-end'),
  log: require('./log'),
  find: require('./find'),
  reduce: require('./reduce'),
  collect: require('./collect'),
  concat: require('./concat')
}


},
"fvBu1HImzrrY++SCWSsqYqf7grsD4+VmOTogJBTBdu8=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.migrateMany = exports.migrateOne = void 0;
const Ref = require('ssb-ref');
function migrateOne(old) {
    if (!old)
        throw new Error('Cannot migrate undefined entry');
    if (!old.address) {
        try {
            old.address = Ref.toMultiServerAddress(old);
        }
        catch (err) {
            throw new Error('Cannot migrate entry without field "address" ' +
                'or legacy {host,port,key}');
        }
    }
    let copy;
    try {
        copy = JSON.parse(JSON.stringify(old));
    }
    catch (err) {
        throw new Error('Cannot migrate entry that is not serializable');
    }
    const address = copy.address;
    delete copy.address;
    return [address, copy];
}
exports.migrateOne = migrateOne;
function migrateMany(olds) {
    if (!Array.isArray(olds))
        return {};
    return olds.reduce((obj, old) => {
        try {
            const [address, data] = migrateOne(old);
            obj[address] = data;
        }
        catch (err) {
            console.warn(err.message || err);
        }
        return obj;
    }, {});
}
exports.migrateMany = migrateMany;

},
"g/0pKxcFvD17UgSo6pY44/FmIQhzdkaV2qxj16I0psQ=":
function (require, module, exports, __dirname, __filename) {
'use strict';
const Token = require('token-types');
const strtok3 = require('strtok3/lib/core');
const {
	stringToBytes,
	tarHeaderChecksumMatches,
	uint32SyncSafeToken
} = require('./util');
const supported = require('./supported');

const minimumBytes = 4100; // A fair amount of file-types are detectable within this range

async function fromStream(stream) {
	const tokenizer = await strtok3.fromStream(stream);
	try {
		return await fromTokenizer(tokenizer);
	} finally {
		await tokenizer.close();
	}
}

async function fromBuffer(input) {
	if (!(input instanceof Uint8Array || input instanceof ArrayBuffer || Buffer.isBuffer(input))) {
		throw new TypeError(`Expected the \`input\` argument to be of type \`Uint8Array\` or \`Buffer\` or \`ArrayBuffer\`, got \`${typeof input}\``);
	}

	const buffer = input instanceof Buffer ? input : Buffer.from(input);

	if (!(buffer && buffer.length > 1)) {
		return;
	}

	const tokenizer = strtok3.fromBuffer(buffer);
	return fromTokenizer(tokenizer);
}

function _check(buffer, headers, options) {
	options = {
		offset: 0,
		...options
	};

	for (const [index, header] of headers.entries()) {
		// If a bitmask is set
		if (options.mask) {
			// If header doesn't equal `buf` with bits masked off
			if (header !== (options.mask[index] & buffer[index + options.offset])) {
				return false;
			}
		} else if (header !== buffer[index + options.offset]) {
			return false;
		}
	}

	return true;
}

async function fromTokenizer(tokenizer) {
	try {
		return _fromTokenizer(tokenizer);
	} catch (error) {
		if (!(error instanceof strtok3.EndOfStreamError)) {
			throw error;
		}
	}
}

async function _fromTokenizer(tokenizer) {
	let buffer = Buffer.alloc(minimumBytes);
	const bytesRead = 12;
	const check = (header, options) => _check(buffer, header, options);
	const checkString = (header, options) => check(stringToBytes(header), options);

	// Keep reading until EOF if the file size is unknown.
	if (!tokenizer.fileInfo.size) {
		tokenizer.fileInfo.size = Number.MAX_SAFE_INTEGER;
	}

	await tokenizer.peekBuffer(buffer, {length: bytesRead, mayBeLess: true});

	// -- 2-byte signatures --

	if (check([0x42, 0x4D])) {
		return {
			ext: 'bmp',
			mime: 'image/bmp'
		};
	}

	if (check([0x0B, 0x77])) {
		return {
			ext: 'ac3',
			mime: 'audio/vnd.dolby.dd-raw'
		};
	}

	if (check([0x78, 0x01])) {
		return {
			ext: 'dmg',
			mime: 'application/x-apple-diskimage'
		};
	}

	if (check([0x4D, 0x5A])) {
		return {
			ext: 'exe',
			mime: 'application/x-msdownload'
		};
	}

	if (check([0x25, 0x21])) {
		await tokenizer.peekBuffer(buffer, {length: 24, mayBeLess: true});

		if (checkString('PS-Adobe-', {offset: 2}) &&
			checkString(' EPSF-', {offset: 14})) {
			return {
				ext: 'eps',
				mime: 'application/eps'
			};
		}

		return {
			ext: 'ps',
			mime: 'application/postscript'
		};
	}

	if (
		check([0x1F, 0xA0]) ||
		check([0x1F, 0x9D])
	) {
		return {
			ext: 'Z',
			mime: 'application/x-compress'
		};
	}

	// -- 3-byte signatures --

	if (check([0xFF, 0xD8, 0xFF])) {
		return {
			ext: 'jpg',
			mime: 'image/jpeg'
		};
	}

	if (check([0x49, 0x49, 0xBC])) {
		return {
			ext: 'jxr',
			mime: 'image/vnd.ms-photo'
		};
	}

	if (check([0x1F, 0x8B, 0x8])) {
		return {
			ext: 'gz',
			mime: 'application/gzip'
		};
	}

	if (check([0x42, 0x5A, 0x68])) {
		return {
			ext: 'bz2',
			mime: 'application/x-bzip2'
		};
	}

	if (checkString('ID3')) {
		await tokenizer.ignore(6); // Skip ID3 header until the header size
		const id3HeaderLen = await tokenizer.readToken(uint32SyncSafeToken);
		if (tokenizer.position + id3HeaderLen > tokenizer.fileInfo.size) {
			// Guess file type based on ID3 header for backward compatibility
			return {
				ext: 'mp3',
				mime: 'audio/mpeg'
			};
		}

		await tokenizer.ignore(id3HeaderLen);
		return fromTokenizer(tokenizer); // Skip ID3 header, recursion
	}

	// Musepack, SV7
	if (checkString('MP+')) {
		return {
			ext: 'mpc',
			mime: 'audio/x-musepack'
		};
	}

	if (
		(buffer[0] === 0x43 || buffer[0] === 0x46) &&
		check([0x57, 0x53], {offset: 1})
	) {
		return {
			ext: 'swf',
			mime: 'application/x-shockwave-flash'
		};
	}

	// -- 4-byte signatures --

	if (check([0x47, 0x49, 0x46])) {
		return {
			ext: 'gif',
			mime: 'image/gif'
		};
	}

	if (checkString('FLIF')) {
		return {
			ext: 'flif',
			mime: 'image/flif'
		};
	}

	if (checkString('8BPS')) {
		return {
			ext: 'psd',
			mime: 'image/vnd.adobe.photoshop'
		};
	}

	if (checkString('WEBP', {offset: 8})) {
		return {
			ext: 'webp',
			mime: 'image/webp'
		};
	}

	// Musepack, SV8
	if (checkString('MPCK')) {
		return {
			ext: 'mpc',
			mime: 'audio/x-musepack'
		};
	}

	if (checkString('FORM')) {
		return {
			ext: 'aif',
			mime: 'audio/aiff'
		};
	}

	if (checkString('icns', {offset: 0})) {
		return {
			ext: 'icns',
			mime: 'image/icns'
		};
	}

	// Zip-based file formats
	// Need to be before the `zip` check
	if (check([0x50, 0x4B, 0x3, 0x4])) { // Local file header signature
		try {
			while (tokenizer.position + 30 < tokenizer.fileInfo.size) {
				await tokenizer.readBuffer(buffer, {length: 30});

				// https://en.wikipedia.org/wiki/Zip_(file_format)#File_headers
				const zipHeader = {
					compressedSize: buffer.readUInt32LE(18),
					uncompressedSize: buffer.readUInt32LE(22),
					filenameLength: buffer.readUInt16LE(26),
					extraFieldLength: buffer.readUInt16LE(28)
				};

				zipHeader.filename = await tokenizer.readToken(new Token.StringType(zipHeader.filenameLength, 'utf-8'));
				await tokenizer.ignore(zipHeader.extraFieldLength);

				// Assumes signed `.xpi` from addons.mozilla.org
				if (zipHeader.filename === 'META-INF/mozilla.rsa') {
					return {
						ext: 'xpi',
						mime: 'application/x-xpinstall'
					};
				}

				if (zipHeader.filename.endsWith('.rels') || zipHeader.filename.endsWith('.xml')) {
					const type = zipHeader.filename.split('/')[0];
					switch (type) {
						case '_rels':
							break;
						case 'word':
							return {
								ext: 'docx',
								mime: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
							};
						case 'ppt':
							return {
								ext: 'pptx',
								mime: 'application/vnd.openxmlformats-officedocument.presentationml.presentation'
							};
						case 'xl':
							return {
								ext: 'xlsx',
								mime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
							};
						default:
							break;
					}
				}

				if (zipHeader.filename.startsWith('xl/')) {
					return {
						ext: 'xlsx',
						mime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
					};
				}

				if (zipHeader.filename.startsWith('3D/') && zipHeader.filename.endsWith('.model')) {
					return {
						ext: '3mf',
						mime: 'model/3mf'
					};
				}

				// The docx, xlsx and pptx file types extend the Office Open XML file format:
				// https://en.wikipedia.org/wiki/Office_Open_XML_file_formats
				// We look for:
				// - one entry named '[Content_Types].xml' or '_rels/.rels',
				// - one entry indicating specific type of file.
				// MS Office, OpenOffice and LibreOffice may put the parts in different order, so the check should not rely on it.
				if (zipHeader.filename === 'mimetype' && zipHeader.compressedSize === zipHeader.uncompressedSize) {
					const mimeType = await tokenizer.readToken(new Token.StringType(zipHeader.compressedSize, 'utf-8'));

					switch (mimeType) {
						case 'application/epub+zip':
							return {
								ext: 'epub',
								mime: 'application/epub+zip'
							};
						case 'application/vnd.oasis.opendocument.text':
							return {
								ext: 'odt',
								mime: 'application/vnd.oasis.opendocument.text'
							};
						case 'application/vnd.oasis.opendocument.spreadsheet':
							return {
								ext: 'ods',
								mime: 'application/vnd.oasis.opendocument.spreadsheet'
							};
						case 'application/vnd.oasis.opendocument.presentation':
							return {
								ext: 'odp',
								mime: 'application/vnd.oasis.opendocument.presentation'
							};
						default:
					}
				}

				// Try to find next header manually when current one is corrupted
				if (zipHeader.compressedSize === 0) {
					let nextHeaderIndex = -1;

					while (nextHeaderIndex < 0 && (tokenizer.position < tokenizer.fileInfo.size)) {
						await tokenizer.peekBuffer(buffer, {mayBeLess: true});

						nextHeaderIndex = buffer.indexOf('504B0304', 0, 'hex');
						// Move position to the next header if found, skip the whole buffer otherwise
						await tokenizer.ignore(nextHeaderIndex >= 0 ? nextHeaderIndex : buffer.length);
					}
				} else {
					await tokenizer.ignore(zipHeader.compressedSize);
				}
			}
		} catch (error) {
			if (!(error instanceof strtok3.EndOfStreamError)) {
				throw error;
			}
		}

		return {
			ext: 'zip',
			mime: 'application/zip'
		};
	}

	if (checkString('OggS')) {
		// This is an OGG container
		await tokenizer.ignore(28);
		const type = Buffer.alloc(8);
		await tokenizer.readBuffer(type);

		// Needs to be before `ogg` check
		if (_check(type, [0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64])) {
			return {
				ext: 'opus',
				mime: 'audio/opus'
			};
		}

		// If ' theora' in header.
		if (_check(type, [0x80, 0x74, 0x68, 0x65, 0x6F, 0x72, 0x61])) {
			return {
				ext: 'ogv',
				mime: 'video/ogg'
			};
		}

		// If '\x01video' in header.
		if (_check(type, [0x01, 0x76, 0x69, 0x64, 0x65, 0x6F, 0x00])) {
			return {
				ext: 'ogm',
				mime: 'video/ogg'
			};
		}

		// If ' FLAC' in header  https://xiph.org/flac/faq.html
		if (_check(type, [0x7F, 0x46, 0x4C, 0x41, 0x43])) {
			return {
				ext: 'oga',
				mime: 'audio/ogg'
			};
		}

		// 'Speex  ' in header https://en.wikipedia.org/wiki/Speex
		if (_check(type, [0x53, 0x70, 0x65, 0x65, 0x78, 0x20, 0x20])) {
			return {
				ext: 'spx',
				mime: 'audio/ogg'
			};
		}

		// If '\x01vorbis' in header
		if (_check(type, [0x01, 0x76, 0x6F, 0x72, 0x62, 0x69, 0x73])) {
			return {
				ext: 'ogg',
				mime: 'audio/ogg'
			};
		}

		// Default OGG container https://www.iana.org/assignments/media-types/application/ogg
		return {
			ext: 'ogx',
			mime: 'application/ogg'
		};
	}

	if (
		check([0x50, 0x4B]) &&
		(buffer[2] === 0x3 || buffer[2] === 0x5 || buffer[2] === 0x7) &&
		(buffer[3] === 0x4 || buffer[3] === 0x6 || buffer[3] === 0x8)
	) {
		return {
			ext: 'zip',
			mime: 'application/zip'
		};
	}

	//

	// File Type Box (https://en.wikipedia.org/wiki/ISO_base_media_file_format)
	// It's not required to be first, but it's recommended to be. Almost all ISO base media files start with `ftyp` box.
	// `ftyp` box must contain a brand major identifier, which must consist of ISO 8859-1 printable characters.
	// Here we check for 8859-1 printable characters (for simplicity, it's a mask which also catches one non-printable character).
	if (
		checkString('ftyp', {offset: 4}) &&
		(buffer[8] & 0x60) !== 0x00 // Brand major, first character ASCII?
	) {
		// They all can have MIME `video/mp4` except `application/mp4` special-case which is hard to detect.
		// For some cases, we're specific, everything else falls to `video/mp4` with `mp4` extension.
		const brandMajor = buffer.toString('binary', 8, 12).replace('\0', ' ').trim();
		switch (brandMajor) {
			case 'avif':
				return {ext: 'avif', mime: 'image/avif'};
			case 'mif1':
				return {ext: 'heic', mime: 'image/heif'};
			case 'msf1':
				return {ext: 'heic', mime: 'image/heif-sequence'};
			case 'heic':
			case 'heix':
				return {ext: 'heic', mime: 'image/heic'};
			case 'hevc':
			case 'hevx':
				return {ext: 'heic', mime: 'image/heic-sequence'};
			case 'qt':
				return {ext: 'mov', mime: 'video/quicktime'};
			case 'M4V':
			case 'M4VH':
			case 'M4VP':
				return {ext: 'm4v', mime: 'video/x-m4v'};
			case 'M4P':
				return {ext: 'm4p', mime: 'video/mp4'};
			case 'M4B':
				return {ext: 'm4b', mime: 'audio/mp4'};
			case 'M4A':
				return {ext: 'm4a', mime: 'audio/x-m4a'};
			case 'F4V':
				return {ext: 'f4v', mime: 'video/mp4'};
			case 'F4P':
				return {ext: 'f4p', mime: 'video/mp4'};
			case 'F4A':
				return {ext: 'f4a', mime: 'audio/mp4'};
			case 'F4B':
				return {ext: 'f4b', mime: 'audio/mp4'};
			case 'crx':
				return {ext: 'cr3', mime: 'image/x-canon-cr3'};
			default:
				if (brandMajor.startsWith('3g')) {
					if (brandMajor.startsWith('3g2')) {
						return {ext: '3g2', mime: 'video/3gpp2'};
					}

					return {ext: '3gp', mime: 'video/3gpp'};
				}

				return {ext: 'mp4', mime: 'video/mp4'};
		}
	}

	if (checkString('MThd')) {
		return {
			ext: 'mid',
			mime: 'audio/midi'
		};
	}

	if (
		checkString('wOFF') &&
		(
			check([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||
			checkString('OTTO', {offset: 4})
		)
	) {
		return {
			ext: 'woff',
			mime: 'font/woff'
		};
	}

	if (
		checkString('wOF2') &&
		(
			check([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||
			checkString('OTTO', {offset: 4})
		)
	) {
		return {
			ext: 'woff2',
			mime: 'font/woff2'
		};
	}

	if (check([0xD4, 0xC3, 0xB2, 0xA1]) || check([0xA1, 0xB2, 0xC3, 0xD4])) {
		return {
			ext: 'pcap',
			mime: 'application/vnd.tcpdump.pcap'
		};
	}

	// Sony DSD Stream File (DSF)
	if (checkString('DSD ')) {
		return {
			ext: 'dsf',
			mime: 'audio/x-dsf' // Non-standard
		};
	}

	if (checkString('LZIP')) {
		return {
			ext: 'lz',
			mime: 'application/x-lzip'
		};
	}

	if (checkString('fLaC')) {
		return {
			ext: 'flac',
			mime: 'audio/x-flac'
		};
	}

	if (check([0x42, 0x50, 0x47, 0xFB])) {
		return {
			ext: 'bpg',
			mime: 'image/bpg'
		};
	}

	if (checkString('wvpk')) {
		return {
			ext: 'wv',
			mime: 'audio/wavpack'
		};
	}

	if (checkString('%PDF')) {
		await tokenizer.ignore(1350);
		const maxBufferSize = 10 * 1024 * 1024;
		const buffer = Buffer.alloc(Math.min(maxBufferSize, tokenizer.fileInfo.size));
		await tokenizer.readBuffer(buffer, {mayBeLess: true});

		// Check if this is an Adobe Illustrator file
		if (buffer.includes(Buffer.from('AIPrivateData'))) {
			return {
				ext: 'ai',
				mime: 'application/postscript'
			};
		}

		// Assume this is just a normal PDF
		return {
			ext: 'pdf',
			mime: 'application/pdf'
		};
	}

	if (check([0x00, 0x61, 0x73, 0x6D])) {
		return {
			ext: 'wasm',
			mime: 'application/wasm'
		};
	}

	// TIFF, little-endian type
	if (check([0x49, 0x49, 0x2A, 0x0])) {
		if (checkString('CR', {offset: 8})) {
			return {
				ext: 'cr2',
				mime: 'image/x-canon-cr2'
			};
		}

		if (check([0x1C, 0x00, 0xFE, 0x00], {offset: 8}) || check([0x1F, 0x00, 0x0B, 0x00], {offset: 8})) {
			return {
				ext: 'nef',
				mime: 'image/x-nikon-nef'
			};
		}

		if (
			check([0x08, 0x00, 0x00, 0x00], {offset: 4}) &&
			(check([0x2D, 0x00, 0xFE, 0x00], {offset: 8}) ||
				check([0x27, 0x00, 0xFE, 0x00], {offset: 8}))
		) {
			return {
				ext: 'dng',
				mime: 'image/x-adobe-dng'
			};
		}

		buffer = Buffer.alloc(24);
		await tokenizer.peekBuffer(buffer);
		if (
			(check([0x10, 0xFB, 0x86, 0x01], {offset: 4}) || check([0x08, 0x00, 0x00, 0x00], {offset: 4})) &&
			// This pattern differentiates ARW from other TIFF-ish file types:
			check([0x00, 0xFE, 0x00, 0x04, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x03, 0x01], {offset: 9})
		) {
			return {
				ext: 'arw',
				mime: 'image/x-sony-arw'
			};
		}

		return {
			ext: 'tif',
			mime: 'image/tiff'
		};
	}

	// TIFF, big-endian type
	if (check([0x4D, 0x4D, 0x0, 0x2A])) {
		return {
			ext: 'tif',
			mime: 'image/tiff'
		};
	}

	if (checkString('MAC ')) {
		return {
			ext: 'ape',
			mime: 'audio/ape'
		};
	}

	// https://github.com/threatstack/libmagic/blob/master/magic/Magdir/matroska
	if (check([0x1A, 0x45, 0xDF, 0xA3])) { // Root element: EBML
		async function readField() {
			const msb = await tokenizer.peekNumber(Token.UINT8);
			let mask = 0x80;
			let ic = 0; // 0 = A, 1 = B, 2 = C, 3 = D

			while ((msb & mask) === 0) {
				++ic;
				mask >>= 1;
			}

			const id = Buffer.alloc(ic + 1);
			await tokenizer.readBuffer(id);
			return id;
		}

		async function readElement() {
			const id = await readField();
			const lenField = await readField();
			lenField[0] ^= 0x80 >> (lenField.length - 1);
			const nrLen = Math.min(6, lenField.length); // JavaScript can max read 6 bytes integer
			return {
				id: id.readUIntBE(0, id.length),
				len: lenField.readUIntBE(lenField.length - nrLen, nrLen)
			};
		}

		async function readChildren(level, children) {
			while (children > 0) {
				const e = await readElement();
				if (e.id === 0x4282) {
					return tokenizer.readToken(new Token.StringType(e.len, 'utf-8')); // Return DocType
				}

				await tokenizer.ignore(e.len); // ignore payload
				--children;
			}
		}

		const re = await readElement();
		const docType = await readChildren(1, re.len);

		switch (docType) {
			case 'webm':
				return {
					ext: 'webm',
					mime: 'video/webm'
				};

			case 'matroska':
				return {
					ext: 'mkv',
					mime: 'video/x-matroska'
				};

			default:
				return;
		}
	}

	// RIFF file format which might be AVI, WAV, QCP, etc
	if (check([0x52, 0x49, 0x46, 0x46])) {
		if (check([0x41, 0x56, 0x49], {offset: 8})) {
			return {
				ext: 'avi',
				mime: 'video/vnd.avi'
			};
		}

		if (check([0x57, 0x41, 0x56, 0x45], {offset: 8})) {
			return {
				ext: 'wav',
				mime: 'audio/vnd.wave'
			};
		}

		// QLCM, QCP file
		if (check([0x51, 0x4C, 0x43, 0x4D], {offset: 8})) {
			return {
				ext: 'qcp',
				mime: 'audio/qcelp'
			};
		}
	}

	if (checkString('SQLi')) {
		return {
			ext: 'sqlite',
			mime: 'application/x-sqlite3'
		};
	}

	if (check([0x4E, 0x45, 0x53, 0x1A])) {
		return {
			ext: 'nes',
			mime: 'application/x-nintendo-nes-rom'
		};
	}

	if (checkString('Cr24')) {
		return {
			ext: 'crx',
			mime: 'application/x-google-chrome-extension'
		};
	}

	if (
		checkString('MSCF') ||
		checkString('ISc(')
	) {
		return {
			ext: 'cab',
			mime: 'application/vnd.ms-cab-compressed'
		};
	}

	if (check([0xED, 0xAB, 0xEE, 0xDB])) {
		return {
			ext: 'rpm',
			mime: 'application/x-rpm'
		};
	}

	if (check([0xC5, 0xD0, 0xD3, 0xC6])) {
		return {
			ext: 'eps',
			mime: 'application/eps'
		};
	}

	if (check([0x28, 0xB5, 0x2F, 0xFD])) {
		return {
			ext: 'zst',
			mime: 'application/zstd'
		};
	}

	// -- 5-byte signatures --

	if (check([0x4F, 0x54, 0x54, 0x4F, 0x00])) {
		return {
			ext: 'otf',
			mime: 'font/otf'
		};
	}

	if (checkString('#!AMR')) {
		return {
			ext: 'amr',
			mime: 'audio/amr'
		};
	}

	if (checkString('{\\rtf')) {
		return {
			ext: 'rtf',
			mime: 'application/rtf'
		};
	}

	if (check([0x46, 0x4C, 0x56, 0x01])) {
		return {
			ext: 'flv',
			mime: 'video/x-flv'
		};
	}

	if (checkString('IMPM')) {
		return {
			ext: 'it',
			mime: 'audio/x-it'
		};
	}

	if (
		checkString('-lh0-', {offset: 2}) ||
		checkString('-lh1-', {offset: 2}) ||
		checkString('-lh2-', {offset: 2}) ||
		checkString('-lh3-', {offset: 2}) ||
		checkString('-lh4-', {offset: 2}) ||
		checkString('-lh5-', {offset: 2}) ||
		checkString('-lh6-', {offset: 2}) ||
		checkString('-lh7-', {offset: 2}) ||
		checkString('-lzs-', {offset: 2}) ||
		checkString('-lz4-', {offset: 2}) ||
		checkString('-lz5-', {offset: 2}) ||
		checkString('-lhd-', {offset: 2})
	) {
		return {
			ext: 'lzh',
			mime: 'application/x-lzh-compressed'
		};
	}

	// MPEG program stream (PS or MPEG-PS)
	if (check([0x00, 0x00, 0x01, 0xBA])) {
		//  MPEG-PS, MPEG-1 Part 1
		if (check([0x21], {offset: 4, mask: [0xF1]})) {
			return {
				ext: 'mpg', // May also be .ps, .mpeg
				mime: 'video/MP1S'
			};
		}

		// MPEG-PS, MPEG-2 Part 1
		if (check([0x44], {offset: 4, mask: [0xC4]})) {
			return {
				ext: 'mpg', // May also be .mpg, .m2p, .vob or .sub
				mime: 'video/MP2P'
			};
		}
	}

	if (checkString('ITSF')) {
		return {
			ext: 'chm',
			mime: 'application/vnd.ms-htmlhelp'
		};
	}

	// -- 6-byte signatures --

	if (check([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])) {
		return {
			ext: 'xz',
			mime: 'application/x-xz'
		};
	}

	if (checkString('<?xml ')) {
		return {
			ext: 'xml',
			mime: 'application/xml'
		};
	}

	if (check([0x37, 0x7A, 0xBC, 0xAF, 0x27, 0x1C])) {
		return {
			ext: '7z',
			mime: 'application/x-7z-compressed'
		};
	}

	if (
		check([0x52, 0x61, 0x72, 0x21, 0x1A, 0x7]) &&
		(buffer[6] === 0x0 || buffer[6] === 0x1)
	) {
		return {
			ext: 'rar',
			mime: 'application/x-rar-compressed'
		};
	}

	if (checkString('solid ')) {
		return {
			ext: 'stl',
			mime: 'model/stl'
		};
	}

	// -- 7-byte signatures --

	if (checkString('BLENDER')) {
		return {
			ext: 'blend',
			mime: 'application/x-blender'
		};
	}

	if (checkString('!<arch>')) {
		await tokenizer.ignore(8);
		const str = await tokenizer.readToken(new Token.StringType(13, 'ascii'));
		if (str === 'debian-binary') {
			return {
				ext: 'deb',
				mime: 'application/x-deb'
			};
		}

		return {
			ext: 'ar',
			mime: 'application/x-unix-archive'
		};
	}

	// -- 8-byte signatures --

	if (check([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A])) {
		// APNG format (https://wiki.mozilla.org/APNG_Specification)
		// 1. Find the first IDAT (image data) chunk (49 44 41 54)
		// 2. Check if there is an "acTL" chunk before the IDAT one (61 63 54 4C)

		// Offset calculated as follows:
		// - 8 bytes: PNG signature
		// - 4 (length) + 4 (chunk type) + 13 (chunk data) + 4 (CRC): IHDR chunk

		await tokenizer.ignore(8); // ignore PNG signature

		async function readChunkHeader() {
			return {
				length: await tokenizer.readToken(Token.INT32_BE),
				type: await tokenizer.readToken(new Token.StringType(4, 'binary'))
			};
		}

		do {
			const chunk = await readChunkHeader();
			if (chunk.length < 0) {
				return; // Invalid chunk length
			}

			switch (chunk.type) {
				case 'IDAT':
					return {
						ext: 'png',
						mime: 'image/png'
					};
				case 'acTL':
					return {
						ext: 'apng',
						mime: 'image/apng'
					};
				default:
					await tokenizer.ignore(chunk.length + 4); // Ignore chunk-data + CRC
			}
		} while (tokenizer.position + 8 < tokenizer.fileInfo.size);

		return {
			ext: 'png',
			mime: 'image/png'
		};
	}

	if (check([0x41, 0x52, 0x52, 0x4F, 0x57, 0x31, 0x00, 0x00])) {
		return {
			ext: 'arrow',
			mime: 'application/x-apache-arrow'
		};
	}

	if (check([0x67, 0x6C, 0x54, 0x46, 0x02, 0x00, 0x00, 0x00])) {
		return {
			ext: 'glb',
			mime: 'model/gltf-binary'
		};
	}

	// `mov` format variants
	if (
		check([0x66, 0x72, 0x65, 0x65], {offset: 4}) || // `free`
		check([0x6D, 0x64, 0x61, 0x74], {offset: 4}) || // `mdat` MJPEG
		check([0x6D, 0x6F, 0x6F, 0x76], {offset: 4}) || // `moov`
		check([0x77, 0x69, 0x64, 0x65], {offset: 4}) // `wide`
	) {
		return {
			ext: 'mov',
			mime: 'video/quicktime'
		};
	}

	// -- 9-byte signatures --

	if (check([0x49, 0x49, 0x52, 0x4F, 0x08, 0x00, 0x00, 0x00, 0x18])) {
		return {
			ext: 'orf',
			mime: 'image/x-olympus-orf'
		};
	}

	if (checkString('gimp xcf ')) {
		return {
			ext: 'xcf',
			mime: 'image/x-xcf'
		};
	}

	// -- 12-byte signatures --

	if (check([0x49, 0x49, 0x55, 0x00, 0x18, 0x00, 0x00, 0x00, 0x88, 0xE7, 0x74, 0xD8])) {
		return {
			ext: 'rw2',
			mime: 'image/x-panasonic-rw2'
		};
	}

	// ASF_Header_Object first 80 bytes
	if (check([0x30, 0x26, 0xB2, 0x75, 0x8E, 0x66, 0xCF, 0x11, 0xA6, 0xD9])) {
		async function readHeader() {
			const guid = Buffer.alloc(16);
			await tokenizer.readBuffer(guid);
			return {
				id: guid,
				size: await tokenizer.readToken(Token.UINT64_LE)
			};
		}

		await tokenizer.ignore(30);
		// Search for header should be in first 1KB of file.
		while (tokenizer.position + 24 < tokenizer.fileInfo.size) {
			const header = await readHeader();
			let payload = header.size - 24;
			if (_check(header.id, [0x91, 0x07, 0xDC, 0xB7, 0xB7, 0xA9, 0xCF, 0x11, 0x8E, 0xE6, 0x00, 0xC0, 0x0C, 0x20, 0x53, 0x65])) {
				// Sync on Stream-Properties-Object (B7DC0791-A9B7-11CF-8EE6-00C00C205365)
				const typeId = Buffer.alloc(16);
				payload -= await tokenizer.readBuffer(typeId);

				if (_check(typeId, [0x40, 0x9E, 0x69, 0xF8, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {
					// Found audio:
					return {
						ext: 'asf',
						mime: 'audio/x-ms-asf'
					};
				}

				if (_check(typeId, [0xC0, 0xEF, 0x19, 0xBC, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {
					// Found video:
					return {
						ext: 'asf',
						mime: 'video/x-ms-asf'
					};
				}

				break;
			}

			await tokenizer.ignore(payload);
		}

		// Default to ASF generic extension
		return {
			ext: 'asf',
			mime: 'application/vnd.ms-asf'
		};
	}

	if (check([0xAB, 0x4B, 0x54, 0x58, 0x20, 0x31, 0x31, 0xBB, 0x0D, 0x0A, 0x1A, 0x0A])) {
		return {
			ext: 'ktx',
			mime: 'image/ktx'
		};
	}

	if ((check([0x7E, 0x10, 0x04]) || check([0x7E, 0x18, 0x04])) && check([0x30, 0x4D, 0x49, 0x45], {offset: 4})) {
		return {
			ext: 'mie',
			mime: 'application/x-mie'
		};
	}

	if (check([0x27, 0x0A, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00], {offset: 2})) {
		return {
			ext: 'shp',
			mime: 'application/x-esri-shape'
		};
	}

	if (check([0x00, 0x00, 0x00, 0x0C, 0x6A, 0x50, 0x20, 0x20, 0x0D, 0x0A, 0x87, 0x0A])) {
		// JPEG-2000 family

		await tokenizer.ignore(20);
		const type = await tokenizer.readToken(new Token.StringType(4, 'ascii'));
		switch (type) {
			case 'jp2 ':
				return {
					ext: 'jp2',
					mime: 'image/jp2'
				};
			case 'jpx ':
				return {
					ext: 'jpx',
					mime: 'image/jpx'
				};
			case 'jpm ':
				return {
					ext: 'jpm',
					mime: 'image/jpm'
				};
			case 'mjp2':
				return {
					ext: 'mj2',
					mime: 'image/mj2'
				};
			default:
				return;
		}
	}

	if (
		check([0xFF, 0x0A]) ||
		check([0x00, 0x00, 0x00, 0x0C, 0x4A, 0x58, 0x4C, 0x20, 0x0D, 0x0A, 0x87, 0x0A])
	) {
		return {
			ext: 'jxl',
			mime: 'image/jxl'
		};
	}

	// -- Unsafe signatures --

	if (
		check([0x0, 0x0, 0x1, 0xBA]) ||
		check([0x0, 0x0, 0x1, 0xB3])
	) {
		return {
			ext: 'mpg',
			mime: 'video/mpeg'
		};
	}

	if (check([0x00, 0x01, 0x00, 0x00, 0x00])) {
		return {
			ext: 'ttf',
			mime: 'font/ttf'
		};
	}

	if (check([0x00, 0x00, 0x01, 0x00])) {
		return {
			ext: 'ico',
			mime: 'image/x-icon'
		};
	}

	if (check([0x00, 0x00, 0x02, 0x00])) {
		return {
			ext: 'cur',
			mime: 'image/x-icon'
		};
	}

	if (check([0xD0, 0xCF, 0x11, 0xE0, 0xA1, 0xB1, 0x1A, 0xE1])) {
		// Detected Microsoft Compound File Binary File (MS-CFB) Format.
		return {
			ext: 'cfb',
			mime: 'application/x-cfb'
		};
	}

	// Increase sample size from 12 to 256.
	await tokenizer.peekBuffer(buffer, {length: Math.min(256, tokenizer.fileInfo.size), mayBeLess: true});

	// -- 15-byte signatures --

	if (checkString('BEGIN:')) {
		if (checkString('VCARD', {offset: 6})) {
			return {
				ext: 'vcf',
				mime: 'text/vcard'
			};
		}

		if (checkString('VCALENDAR', {offset: 6})) {
			return {
				ext: 'ics',
				mime: 'text/calendar'
			};
		}
	}

	// `raf` is here just to keep all the raw image detectors together.
	if (checkString('FUJIFILMCCD-RAW')) {
		return {
			ext: 'raf',
			mime: 'image/x-fujifilm-raf'
		};
	}

	if (checkString('Extended Module:')) {
		return {
			ext: 'xm',
			mime: 'audio/x-xm'
		};
	}

	if (checkString('Creative Voice File')) {
		return {
			ext: 'voc',
			mime: 'audio/x-voc'
		};
	}

	if (check([0x04, 0x00, 0x00, 0x00]) && buffer.length >= 16) { // Rough & quick check Pickle/ASAR
		const jsonSize = buffer.readUInt32LE(12);
		if (jsonSize > 12 && buffer.length >= jsonSize + 16) {
			try {
				const header = buffer.slice(16, jsonSize + 16).toString();
				const json = JSON.parse(header);
				// Check if Pickle is ASAR
				if (json.files) { // Final check, assuring Pickle/ASAR format
					return {
						ext: 'asar',
						mime: 'application/x-asar'
					};
				}
			} catch (_) {
			}
		}
	}

	if (check([0x06, 0x0E, 0x2B, 0x34, 0x02, 0x05, 0x01, 0x01, 0x0D, 0x01, 0x02, 0x01, 0x01, 0x02])) {
		return {
			ext: 'mxf',
			mime: 'application/mxf'
		};
	}

	if (checkString('SCRM', {offset: 44})) {
		return {
			ext: 's3m',
			mime: 'audio/x-s3m'
		};
	}

	if (check([0x47], {offset: 4}) && (check([0x47], {offset: 192}) || check([0x47], {offset: 196}))) {
		return {
			ext: 'mts',
			mime: 'video/mp2t'
		};
	}

	if (check([0x42, 0x4F, 0x4F, 0x4B, 0x4D, 0x4F, 0x42, 0x49], {offset: 60})) {
		return {
			ext: 'mobi',
			mime: 'application/x-mobipocket-ebook'
		};
	}

	if (check([0x44, 0x49, 0x43, 0x4D], {offset: 128})) {
		return {
			ext: 'dcm',
			mime: 'application/dicom'
		};
	}

	if (check([0x4C, 0x00, 0x00, 0x00, 0x01, 0x14, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0xC0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x46])) {
		return {
			ext: 'lnk',
			mime: 'application/x.ms.shortcut' // Invented by us
		};
	}

	if (check([0x62, 0x6F, 0x6F, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x6D, 0x61, 0x72, 0x6B, 0x00, 0x00, 0x00, 0x00])) {
		return {
			ext: 'alias',
			mime: 'application/x.apple.alias' // Invented by us
		};
	}

	if (
		check([0x4C, 0x50], {offset: 34}) &&
		(
			check([0x00, 0x00, 0x01], {offset: 8}) ||
			check([0x01, 0x00, 0x02], {offset: 8}) ||
			check([0x02, 0x00, 0x02], {offset: 8})
		)
	) {
		return {
			ext: 'eot',
			mime: 'application/vnd.ms-fontobject'
		};
	}

	if (check([0x06, 0x06, 0xED, 0xF5, 0xD8, 0x1D, 0x46, 0xE5, 0xBD, 0x31, 0xEF, 0xE7, 0xFE, 0x74, 0xB7, 0x1D])) {
		return {
			ext: 'indd',
			mime: 'application/x-indesign'
		};
	}

	// Increase sample size from 256 to 512
	await tokenizer.peekBuffer(buffer, {length: Math.min(512, tokenizer.fileInfo.size), mayBeLess: true});

	// Requires a buffer size of 512 bytes
	if (tarHeaderChecksumMatches(buffer)) {
		return {
			ext: 'tar',
			mime: 'application/x-tar'
		};
	}

	if (check([0xFF, 0xFE, 0xFF, 0x0E, 0x53, 0x00, 0x6B, 0x00, 0x65, 0x00, 0x74, 0x00, 0x63, 0x00, 0x68, 0x00, 0x55, 0x00, 0x70, 0x00, 0x20, 0x00, 0x4D, 0x00, 0x6F, 0x00, 0x64, 0x00, 0x65, 0x00, 0x6C, 0x00])) {
		return {
			ext: 'skp',
			mime: 'application/vnd.sketchup.skp'
		};
	}

	if (checkString('-----BEGIN PGP MESSAGE-----')) {
		return {
			ext: 'pgp',
			mime: 'application/pgp-encrypted'
		};
	}

	// Check MPEG 1 or 2 Layer 3 header, or 'layer 0' for ADTS (MPEG sync-word 0xFFE)
	if (buffer.length >= 2 && check([0xFF, 0xE0], {offset: 0, mask: [0xFF, 0xE0]})) {
		if (check([0x10], {offset: 1, mask: [0x16]})) {
			// Check for (ADTS) MPEG-2
			if (check([0x08], {offset: 1, mask: [0x08]})) {
				return {
					ext: 'aac',
					mime: 'audio/aac'
				};
			}

			// Must be (ADTS) MPEG-4
			return {
				ext: 'aac',
				mime: 'audio/aac'
			};
		}

		// MPEG 1 or 2 Layer 3 header
		// Check for MPEG layer 3
		if (check([0x02], {offset: 1, mask: [0x06]})) {
			return {
				ext: 'mp3',
				mime: 'audio/mpeg'
			};
		}

		// Check for MPEG layer 2
		if (check([0x04], {offset: 1, mask: [0x06]})) {
			return {
				ext: 'mp2',
				mime: 'audio/mpeg'
			};
		}

		// Check for MPEG layer 1
		if (check([0x06], {offset: 1, mask: [0x06]})) {
			return {
				ext: 'mp1',
				mime: 'audio/mpeg'
			};
		}
	}
}

const stream = readableStream => new Promise((resolve, reject) => {
	// Using `eval` to work around issues when bundling with Webpack
	const stream = eval('require')('stream'); // eslint-disable-line no-eval

	readableStream.on('error', reject);
	readableStream.once('readable', async () => {
		// Set up output stream
		const pass = new stream.PassThrough();
		let outputStream;
		if (stream.pipeline) {
			outputStream = stream.pipeline(readableStream, pass, () => {
			});
		} else {
			outputStream = readableStream.pipe(pass);
		}

		// Read the input stream and detect the filetype
		const chunk = readableStream.read(minimumBytes) || readableStream.read() || Buffer.alloc(0);
		try {
			const fileType = await fromBuffer(chunk);
			pass.fileType = fileType;
		} catch (error) {
			reject(error);
		}

		resolve(outputStream);
	});
});

const fileType = {
	fromStream,
	fromTokenizer,
	fromBuffer,
	stream
};

Object.defineProperty(fileType, 'extensions', {
	get() {
		return new Set(supported.extensions);
	}
});

Object.defineProperty(fileType, 'mimeTypes', {
	get() {
		return new Set(supported.mimeTypes);
	}
});

module.exports = fileType;

},
"g3Vx1n8DasPpnlH2ssn6Bk/hvwTrnt6KVea8psN2VRc=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var fs = require("fs");
var mkdirp = require("mkdirp");
var path = require("path");
var u = require("./util");

function isObject(o) {
  return "object" === typeof o;
}

function isFunction(f) {
  return "function" === typeof f;
}

function empty(v) {
  return !!v;
}

function toFile(filename) {
  if (isObject(filename)) return path.join(filename.path, "secret");
  return filename;
}

module.exports = function (generate) {
  if (!fs || !fs.readFile) return require("./local-storage")(generate);

  var exports = {};

  //(DE)SERIALIZE KEYS

  function constructKeys(keys, legacy) {
    if (!keys) throw new Error("*must* pass in keys");

    return `# WARNING: Never show this to anyone.
# WARNING: Never edit it or use it on multiple devices at once.
#
# This is your SECRET, it gives you magical powers. With your secret you can
# sign your messages so that your friends can verify that the messages came
# from you. If anyone learns your secret, they can use it to impersonate you.
#
# If you use this secret on more than one device you will create a fork and
# your friends will stop replicating your content.
#
${legacy ? keys.private : JSON.stringify(keys, null, 2)}
#
# The only part of this file that's safe to share is your public name:
#
#   ${keys.id}`;
  }

  function reconstructKeys(keyfile) {
    var privateKey = keyfile
      .replace(/\s*#[^\n]*/g, "")
      .split("\n")
      .filter(empty)
      .join("");

    //if the key is in JSON format, we are good.
    try {
      var keys = JSON.parse(privateKey);
      if (!u.hasSigil(keys.id)) keys.id = "@" + keys.public;
      return keys;
    } catch (_) {
      console.error(_.stack);
    }
  }

  exports.load = function (filename, cb) {
    filename = toFile(filename);
    fs.readFile(filename, "ascii", function (err, privateKeyStr) {
      if (err) return cb(err);
      var keys;
      try {
        keys = reconstructKeys(privateKeyStr);
      } catch (err) {
        return cb(err);
      }
      cb(null, keys);
    });
  };

  exports.loadSync = function (filename) {
    filename = toFile(filename);
    return reconstructKeys(fs.readFileSync(filename, "ascii"));
  };

  exports.create = function (filename, curve, legacy, cb) {
    if (isFunction(legacy)) (cb = legacy), (legacy = null);
    if (isFunction(curve)) (cb = curve), (curve = null);

    filename = toFile(filename);
    var keys = generate(curve);
    var keyfile = constructKeys(keys, legacy);
    mkdirp(path.dirname(filename), function (err) {
      if (err) return cb(err);
      fs.writeFile(filename, keyfile, { mode: 0x100, flag: "wx" }, function (
        err
      ) {
        if (err) return cb(err);
        cb(null, keys);
      });
    });
  };

  exports.createSync = function (filename, curve, legacy) {
    filename = toFile(filename);
    var keys = generate(curve);
    var keyfile = constructKeys(keys, legacy);
    mkdirp.sync(path.dirname(filename));
    fs.writeFileSync(filename, keyfile, { mode: 0x100, flag: "wx" });
    return keys;
  };

  return exports;
};

},
"g4zOVThIoKpKDOd5LclaDVQBHLrludnmLrPmtq5xUl0=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var values = require('../sources/values')
var once = require('../sources/once')

//convert a stream of arrays or streams into just a stream.
module.exports = function flatten () {
  return function (read) {
    var _read
    return function (abort, cb) {
      if (abort) { //abort the current stream, and then stream of streams.
        _read ? _read(abort, function(err) {
          read(err || abort, cb)
        }) : read(abort, cb)
      }
      else if(_read) nextChunk()
      else nextStream()

      function nextChunk () {
        _read(null, function (err, data) {
          if (err === true) nextStream()
          else if (err) {
            read(true, function(abortErr) {
              // TODO: what do we do with the abortErr?
              cb(err)
            })
          }
          else cb(null, data)
        })
      }
      function nextStream () {
        _read = null
        read(null, function (end, stream) {
          if(end)
            return cb(end)
          if(Array.isArray(stream) || stream && 'object' === typeof stream)
            stream = values(stream)
          else if('function' != typeof stream)
            stream = once(stream)
          _read = stream
          nextChunk()
        })
      }
    }
  }
}


},
"gCvs4gFsotcr+uMgZq2qK8X5EJQv6JI8otkGnZW7VLc=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.decompose = exports.compose = exports.isSSBURI = exports.isExperimentalSSBURIWithAction = exports.isExperimentalSSBURI = exports.isIdentityPOBoxSSBURI = exports.isEncryptionKeyBox2DMDiffieHellmanSSBURI = exports.isAddressSSBURI = exports.isBlobSSBURI = exports.isGabbyGroveV1MessageSSBURI = exports.isBendyButtV1MessageSSBURI = exports.isMessageSSBURI = exports.isGabbyGroveV1FeedSSBURI = exports.isBendyButtV1FeedSSBURI = exports.isFeedSSBURI = exports.toMultiserverAddress = exports.toBlobSigil = exports.toMessageSigil = exports.toFeedSigil = exports.fromMultiserverAddress = exports.fromBlobSigil = exports.fromMessageSigil = exports.fromFeedSigil = void 0;
const urlParse = require('url-parse');
const Base64 = {
    unsafeToSafe(input) {
        return input.replace(/\+/g, '-').replace(/\//g, '_');
    },
    safeToUnsafe(input) {
        return input.replace(/-/g, '+').replace(/_/g, '/');
    },
};
function extractBase64Data(pathname) {
    var _a;
    if (!pathname)
        return null;
    const lastPortion = (_a = /(:|\/)([\w_\-=]+)$/.exec(pathname)) === null || _a === void 0 ? void 0 : _a[2];
    if (!lastPortion)
        return null;
    return Base64.safeToUnsafe(lastPortion);
}
function fromFeedSigil(sigil) {
    const data = Base64.unsafeToSafe(sigil.slice(1, -8));
    return `ssb:feed/ed25519/${data}`;
}
exports.fromFeedSigil = fromFeedSigil;
function fromMessageSigil(sigil) {
    const data = Base64.unsafeToSafe(sigil.slice(1, -7));
    return `ssb:message/sha256/${data}`;
}
exports.fromMessageSigil = fromMessageSigil;
function fromBlobSigil(sigil) {
    const data = Base64.unsafeToSafe(sigil.slice(1, -7));
    return `ssb:blob/sha256/${data}`;
}
exports.fromBlobSigil = fromBlobSigil;
function fromMultiserverAddress(msaddr) {
    const encoded = encodeURIComponent(msaddr);
    return `ssb:address/multiserver?multiserverAddress=${encoded}`;
}
exports.fromMultiserverAddress = fromMultiserverAddress;
function toFeedSigil(uri) {
    if (!isFeedSSBURI(uri))
        return null;
    const base64Data = extractBase64Data(urlParse(uri, true).pathname);
    if (!base64Data)
        return null;
    return `@${base64Data}.ed25519`;
}
exports.toFeedSigil = toFeedSigil;
function toMessageSigil(uri) {
    if (!isMessageSSBURI(uri))
        return null;
    const base64Data = extractBase64Data(urlParse(uri, true).pathname);
    if (!base64Data)
        return null;
    return `%${base64Data}.sha256`;
}
exports.toMessageSigil = toMessageSigil;
function toBlobSigil(uri) {
    const base64Data = extractBase64Data(urlParse(uri, true).pathname);
    if (!base64Data)
        return null;
    return `&${base64Data}.sha256`;
}
exports.toBlobSigil = toBlobSigil;
function toMultiserverAddress(uri) {
    return urlParse(uri, true).query.multiserverAddress;
}
exports.toMultiserverAddress = toMultiserverAddress;
function checkTypeFormat(uri, ...args) {
    if (!uri)
        return false;
    const [type, format] = args;
    return ((uri.startsWith(`ssb:${type}:${format}:`) ||
        uri.startsWith(`ssb:${type}/${format}/`) ||
        uri.startsWith(`ssb://${type}/${format}/`)) &&
        !!extractBase64Data(urlParse(uri, true).pathname));
}
function isFeedSSBURI(uri) {
    return checkTypeFormat(uri, 'feed', 'ed25519');
}
exports.isFeedSSBURI = isFeedSSBURI;
function isBendyButtV1FeedSSBURI(uri) {
    return checkTypeFormat(uri, 'feed', 'bendybutt-v1');
}
exports.isBendyButtV1FeedSSBURI = isBendyButtV1FeedSSBURI;
function isGabbyGroveV1FeedSSBURI(uri) {
    return checkTypeFormat(uri, 'feed', 'gabbygrove-v1');
}
exports.isGabbyGroveV1FeedSSBURI = isGabbyGroveV1FeedSSBURI;
function isMessageSSBURI(uri) {
    return checkTypeFormat(uri, 'message', 'sha256');
}
exports.isMessageSSBURI = isMessageSSBURI;
function isBendyButtV1MessageSSBURI(uri) {
    return checkTypeFormat(uri, 'message', 'bendybutt-v1');
}
exports.isBendyButtV1MessageSSBURI = isBendyButtV1MessageSSBURI;
function isGabbyGroveV1MessageSSBURI(uri) {
    return checkTypeFormat(uri, 'message', 'gabbygrove-v1');
}
exports.isGabbyGroveV1MessageSSBURI = isGabbyGroveV1MessageSSBURI;
function isBlobSSBURI(uri) {
    return checkTypeFormat(uri, 'blob', 'sha256');
}
exports.isBlobSSBURI = isBlobSSBURI;
function isAddressSSBURI(uri) {
    var _a;
    if (!uri)
        return false;
    return ((uri.startsWith('ssb:address:multiserver') ||
        uri.startsWith('ssb:address/multiserver') ||
        uri.startsWith('ssb://address/multiserver')) &&
        !!((_a = urlParse(uri, true).query) === null || _a === void 0 ? void 0 : _a.multiserverAddress));
}
exports.isAddressSSBURI = isAddressSSBURI;
function isEncryptionKeyBox2DMDiffieHellmanSSBURI(uri) {
    return checkTypeFormat(uri, 'encryption-key', 'box2-dm-dh');
}
exports.isEncryptionKeyBox2DMDiffieHellmanSSBURI = isEncryptionKeyBox2DMDiffieHellmanSSBURI;
function isIdentityPOBoxSSBURI(uri) {
    return checkTypeFormat(uri, 'identity', 'po-box');
}
exports.isIdentityPOBoxSSBURI = isIdentityPOBoxSSBURI;
function isExperimentalSSBURI(uri) {
    if (!uri)
        return false;
    return (uri.startsWith('ssb:experimental') || uri.startsWith('ssb://experimental'));
}
exports.isExperimentalSSBURI = isExperimentalSSBURI;
function isExperimentalSSBURIWithAction(action) {
    return (uri) => {
        var _a;
        return (isExperimentalSSBURI(uri) && ((_a = urlParse(uri, true).query) === null || _a === void 0 ? void 0 : _a.action) === action);
    };
}
exports.isExperimentalSSBURIWithAction = isExperimentalSSBURIWithAction;
function isSSBURI(uri) {
    return (isFeedSSBURI(uri) ||
        isBendyButtV1FeedSSBURI(uri) ||
        isGabbyGroveV1FeedSSBURI(uri) ||
        isMessageSSBURI(uri) ||
        isBendyButtV1MessageSSBURI(uri) ||
        isGabbyGroveV1MessageSSBURI(uri) ||
        isBlobSSBURI(uri) ||
        isAddressSSBURI(uri) ||
        isEncryptionKeyBox2DMDiffieHellmanSSBURI(uri) ||
        isIdentityPOBoxSSBURI(uri) ||
        isExperimentalSSBURI(uri));
}
exports.isSSBURI = isSSBURI;
function validateParts(parts) {
    if (!parts.type)
        throw new Error('Missing required "type" property');
    if (!parts.format)
        throw new Error('Missing required "format" property');
    if (!parts.data)
        throw new Error('Missing required "data" property');
    if (parts.type === 'feed') {
        if (parts.format !== 'ed25519' && parts.format !== 'bendybutt-v1' && parts.format !== 'gabbygrove-v1') {
            throw new Error('Unknown format for type "feed": ' + parts.format);
        }
        else
            return;
    }
    if (parts.type === 'message') {
        if (parts.format !== 'sha256' && parts.format !== 'bendybutt-v1' && parts.format !== 'gabbygrove-v1') {
            throw new Error('Unknown format for type "message": ' + parts.format);
        }
        else
            return;
    }
    if (parts.type === 'blob') {
        if (parts.format !== 'sha256') {
            throw new Error('Unknown format for type "blob": ' + parts.format);
        }
        else
            return;
    }
    if (parts.type === 'address') {
        if (parts.format !== 'multiserver') {
            throw new Error('Unknown format for type "address": ' + parts.format);
        }
        else
            return;
    }
    if (parts.type === 'encryption-key') {
        if (parts.format !== 'box2-dm-dh') {
            throw new Error('Unknown format for type "encryption-key": ' + parts.format);
        }
        else
            return;
    }
    if (parts.type === 'identity') {
        if (parts.format !== 'po-box') {
            throw new Error('Unknown format for type "identity": ' + parts.format);
        }
        else
            return;
    }
}
function compose(parts) {
    validateParts(parts);
    const { type, format, data } = parts;
    return `ssb:${type}/${format}/${Base64.unsafeToSafe(data)}`;
}
exports.compose = compose;
function decompose(uri) {
    const pathname = urlParse(uri, true).pathname;
    if (!pathname) {
        throw new Error('Invalid SSB URI: ' + uri);
    }
    let [type, format, data] = pathname.split('/');
    data = Base64.safeToUnsafe(data);
    const parts = { type, format, data };
    validateParts(parts);
    return parts;
}
exports.decompose = decompose;

},
"gMHYP8b6vKRO61YoCyxW+3f1wgj+w4hadEXqdTRhitI=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var reduce = require('./reduce')

module.exports = function collect (cb) {
  return reduce(function (arr, item) {
    arr.push(item)
    return arr
  }, [], cb)
}

},
"gNsXfsz+6ZOyf5FxpV8CoAbfvuRi8WdIThz7T0zJYUs=":
function (require, module, exports, __dirname, __filename) {
var Notify = require('pull-notify')
var Dijkstra = require('dynamic-dijkstra')
var simple = require('dynamic-dijkstra/simple')
var Once = require('pull-stream/sources/once')
var pCont = require('pull-cont')

function isObject (o) {
  return o && 'object' === typeof o
}

function isEmpty (o) {
  for(var k in o) return false
  return true
}

function isString (s) {
  return 'string' === typeof s
}

module.exports = function (options) {
  var d = Dijkstra(simple)
  var byName = {}, layers = [], notify = Notify(), listeners = []
  var graph = {}, _graph = {}, hops = {}, ready = 0, readyListeners = []
  var layered
  hops[options.start] = simple.initial()
  if(isNaN(options.max))
    throw new Error('options.max must be provided')
  if(!isString(options.start))
    throw new Error('options.start must be provided')
  var isReady = {}

  return layered = {
    createLayer: function (name) {
      var index = layers.push({}) - 1
      name = name || 'unnamed_'+index
      byName[name] = index
      ready ++
      return function update (from, to, value) {
        if(isObject(from)) {
          var g = from
          layers[index] = g
          layers.forEach(function (g) {
            for(var j in g)
              for(var k in g[j]) {
                graph[j] = graph[j] || {}
                graph[j][k] = g[j][k]
              }
          })
          _graph = d.reverse(graph)
          hops = d.traverse(graph, _graph, options.max, options.start)
          notify(hops)
          if(!isReady[name]) {
            isReady[name] = true
            ready --
            if(ready === 0) {
              while(readyListeners.length) readyListeners.shift()()
            }
          }
        }
        else {
          layers[index][from] = layers[index][from] || {}
          layers[index][from][to] = value

          if(listeners.length)
            for(var i = 0; i < listeners.length; i++)
              listeners[i](from, to, value)

          for(var i = index + 1; i < layers.length; i++)
            if(layers[i][from] && layers[i][from][to] != null)
              return

          //update the main graph, if a higher layer doesn't override this.
          var diff = d.update(graph, _graph, hops, options.max, options.start, from, to, value)
          if(diff && !isEmpty(diff)) notify(diff)
        }
        return layers[index] //return graph from this layer
      }

    },
    onReady: function (fn) {
      if(ready == 0) fn()
      else
        readyListeners.push(fn)
    },
    onEdge: function (fn) {
      listeners.push(fn)
      return function () {
        listeners.splice(listeners.indexOf(fn), 1)
      }
    },
    //find everyone that follows you - reverse!
    getHops: function (opts) {
      opts = opts || {}
      var _start = opts && opts.start || options.start
      var _max = opts.max || options.max
      if(opts.reverse === true) {
        return d.traverse(_graph, graph, _max, _start)
      }
      else {
        if(_start === options.start) {
          if(_max === options.max)
            return hops
          else if(_max < options.max) {
            var hops2 = {}
            for(var k in hops)
              if(hops[k] <= _max)
                hops2[k] = hops[k]
            return hops2
          }
          else
            return d.traverse(graph, _graph, _max, _start)
        }
        else
          return d.traverse(graph, _graph, _max, _start)
      }
    },
    hopStream: function (opts) {
      opts = opts || {}
      var live = opts.live === true
      var old = opts.old !== false
      var source
      if(live) {
        return pCont(function (cb) {
          layered.onReady(function () {
            source = notify.listen()
            if(old && !isEmpty(hops))
              source.push(hops)
            cb(null, source)
          })
        })
      }
      else {
        return pCont(function (cb) {
          layered.onReady(function () {
            source = Once(hops)
            cb(null, source)
          })
        })
      }
    },
    getGraph: function (name) {
      if(name == null) return graph
      else return layers[byName[name]]
    }
  }
}


},
"gP3g9VLKEJyQWuiNQ78ib7+rKUW8f84N8Dcxp3qR3Yc=":
function (require, module, exports, __dirname, __filename) {
var Pushable = require('pull-pushable')
var stats = require('statistics/mutate')
var Drain = require('pull-stream/sinks/drain')

module.exports = function (opts) {
  var timeout = opts && opts.timeout || 5*60*1000 //default: 5 minutes
  var serve = false, timer
  var source = Pushable()
  var rtt = stats.initial(), skew = stats.initial()

  function ping () {
    //serve the ping pong, opponent
    //will volley it back to us, keeping connection alive
    //and revealing clock skew.
    serve = true
    source.push(ts = Date.now())
  }

  //we send the first ping
  if(opts && opts.serve) ping()

  var self
  return self = {
    source: source,
    sink: Drain(function (remote_ts) {
      if(serve) {
        var ts2 = Date.now()
        self.rtt = stats(self.rtt, ts2 - ts)
        //if their time is behind half a round trip behing ts2
        //consider that to be negative skew.
        self.skew = stats(self.skew, remote_ts - ((ts2 + ts)/2))
        serve = false
      }
      else {
        //volley timestamp back to opponent.
        source.push(ts = Date.now())
        //we'll serve next time.
        timer = setTimeout(ping, timeout)
      }
    }, function (err) {
      clearTimeout(timer)
    }),
    rtt: rtt, skew: skew
  }

}


},
"gz7IBtF0K9SDfQ8PyZ4H2+0CRzgct5aeaIavv4u7430=":
function (require, module, exports, __dirname, __filename) {
const { digitCount, getType } = require('./util.js')

function listLength (list) {
  let length = 1 + 1 // type marker + end-of-type marker

  for (const value of list) {
    length += encodingLength(value)
  }

  return length
}

function mapLength (map) {
  let length = 1 + 1 // type marker + end-of-type marker

  for (const [key, value] of map) {
    const keyLength = Buffer.byteLength(key)
    length += digitCount(keyLength) + 1 + keyLength
    length += encodingLength(value)
  }

  return length
}

function objectLength (value) {
  let length = 1 + 1 // type marker + end-of-type marker
  const keys = Object.keys(value)

  for (let i = 0; i < keys.length; i++) {
    const keyLength = Buffer.byteLength(keys[i])
    length += digitCount(keyLength) + 1 + keyLength
    length += encodingLength(value[keys[i]])
  }

  return length
}

function stringLength (value) {
  const length = Buffer.byteLength(value)
  return digitCount(length) + 1 + length
}

function arrayBufferLength (value) {
  const length = value.byteLength - value.byteOffset
  return digitCount(length) + 1 + length
}

function encodingLength (value) {
  const length = 0

  if (value == null) return length

  const type = getType(value)

  switch (type) {
    case 'buffer': return digitCount(value.length) + 1 + value.length
    case 'arraybufferview': return arrayBufferLength(value)
    case 'string': return stringLength(value)
    case 'array': case 'set': return listLength(value)
    case 'number': return 1 + digitCount(Math.floor(value)) + 1
    case 'bigint': return 1 + value.toString().length + 1
    case 'object': return objectLength(value)
    case 'map': return mapLength(value)
    default:
      throw new TypeError(`Unsupported value of type "${type}"`)
  }
}

module.exports = encodingLength

},
"h1KlfwWETsACybYDUptls1BwFpRIraumgRUPfJf3aJ0=":
function (require, module, exports, __dirname, __filename) {
'use strict';

/* eslint no-invalid-this: 1 */

var ERROR_MESSAGE = 'Function.prototype.bind called on incompatible ';
var slice = Array.prototype.slice;
var toStr = Object.prototype.toString;
var funcType = '[object Function]';

module.exports = function bind(that) {
    var target = this;
    if (typeof target !== 'function' || toStr.call(target) !== funcType) {
        throw new TypeError(ERROR_MESSAGE + target);
    }
    var args = slice.call(arguments, 1);

    var bound;
    var binder = function () {
        if (this instanceof bound) {
            var result = target.apply(
                this,
                args.concat(slice.call(arguments))
            );
            if (Object(result) === result) {
                return result;
            }
            return this;
        } else {
            return target.apply(
                that,
                args.concat(slice.call(arguments))
            );
        }
    };

    var boundLength = Math.max(0, target.length - args.length);
    var boundArgs = [];
    for (var i = 0; i < boundLength; i++) {
        boundArgs.push('$' + i);
    }

    bound = Function('binder', 'return function (' + boundArgs.join(',') + '){ return binder.apply(this,arguments); }')(binder);

    if (target.prototype) {
        var Empty = function Empty() {};
        Empty.prototype = target.prototype;
        bound.prototype = new Empty();
        Empty.prototype = null;
    }

    return bound;
};

},
"h1jrjtl3Kl6vXLm4kjf4kzLRRNPkpgIukEUI+VqJagE=":
function (require, module, exports, __dirname, __filename) {

var looper = module.exports = function (fun) {
  return function next (a, b, c) {
    var loop = true, returned = false, sync = false
    do {
      sync = true; loop = false
      fun.call(function (x, y, z) {
        if(sync) {
          a = x; b = y; c = z
          loop = true
        }
        else
          next(x, y, z)
      }, a, b, c)
      sync = false
    } while(loop)
  }
}

},
"h6raxbPMgIG1cKJDwXxXXBlcSuZC6Yg0SVKR+mJu2dY=":
function (require, module, exports, __dirname, __filename) {
/*!
 * @description Recursive object extending
 * @author Viacheslav Lotsmanov <lotsmanov89@gmail.com>
 * @license MIT
 *
 * The MIT License (MIT)
 *
 * Copyright (c) 2013-2018 Viacheslav Lotsmanov
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of
 * this software and associated documentation files (the "Software"), to deal in
 * the Software without restriction, including without limitation the rights to
 * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
 * the Software, and to permit persons to whom the Software is furnished to do so,
 * subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
 * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
 * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
 * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */

'use strict';

function isSpecificValue(val) {
	return (
		val instanceof Buffer
		|| val instanceof Date
		|| val instanceof RegExp
	) ? true : false;
}

function cloneSpecificValue(val) {
	if (val instanceof Buffer) {
		var x = Buffer.alloc
			? Buffer.alloc(val.length)
			: new Buffer(val.length);
		val.copy(x);
		return x;
	} else if (val instanceof Date) {
		return new Date(val.getTime());
	} else if (val instanceof RegExp) {
		return new RegExp(val);
	} else {
		throw new Error('Unexpected situation');
	}
}

/**
 * Recursive cloning array.
 */
function deepCloneArray(arr) {
	var clone = [];
	arr.forEach(function (item, index) {
		if (typeof item === 'object' && item !== null) {
			if (Array.isArray(item)) {
				clone[index] = deepCloneArray(item);
			} else if (isSpecificValue(item)) {
				clone[index] = cloneSpecificValue(item);
			} else {
				clone[index] = deepExtend({}, item);
			}
		} else {
			clone[index] = item;
		}
	});
	return clone;
}

function safeGetProperty(object, property) {
	return property === '__proto__' ? undefined : object[property];
}

/**
 * Extening object that entered in first argument.
 *
 * Returns extended object or false if have no target object or incorrect type.
 *
 * If you wish to clone source object (without modify it), just use empty new
 * object as first argument, like this:
 *   deepExtend({}, yourObj_1, [yourObj_N]);
 */
var deepExtend = module.exports = function (/*obj_1, [obj_2], [obj_N]*/) {
	if (arguments.length < 1 || typeof arguments[0] !== 'object') {
		return false;
	}

	if (arguments.length < 2) {
		return arguments[0];
	}

	var target = arguments[0];

	// convert arguments to array and cut off target object
	var args = Array.prototype.slice.call(arguments, 1);

	var val, src, clone;

	args.forEach(function (obj) {
		// skip argument if isn't an object, is null, or is an array
		if (typeof obj !== 'object' || obj === null || Array.isArray(obj)) {
			return;
		}

		Object.keys(obj).forEach(function (key) {
			src = safeGetProperty(target, key); // source value
			val = safeGetProperty(obj, key); // new value

			// recursion prevention
			if (val === target) {
				return;

			/**
			 * if new value isn't object then just overwrite by new value
			 * instead of extending.
			 */
			} else if (typeof val !== 'object' || val === null) {
				target[key] = val;
				return;

			// just clone arrays (and recursive clone objects inside)
			} else if (Array.isArray(val)) {
				target[key] = deepCloneArray(val);
				return;

			// custom cloning and overwrite for specific objects
			} else if (isSpecificValue(val)) {
				target[key] = cloneSpecificValue(val);
				return;

			// overwrite by new value if source isn't object or array
			} else if (typeof src !== 'object' || src === null || Array.isArray(src)) {
				target[key] = deepExtend({}, val);
				return;

			// source value and new value is objects both, extending...
			} else {
				target[key] = deepExtend(src, val);
				return;
			}
		});
	});

	return target;
};

},
"h9jG45dN8gAQewtq7QjyOncdP2vLaROZh0+NvviciZ0=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
'use strict';

module.exports = Readable;
/*<replacement>*/

var Duplex;
/*</replacement>*/

Readable.ReadableState = ReadableState;
/*<replacement>*/

var EE = require('events').EventEmitter;

var EElistenerCount = function EElistenerCount(emitter, type) {
  return emitter.listeners(type).length;
};
/*</replacement>*/

/*<replacement>*/


var Stream = require('./internal/streams/stream');
/*</replacement>*/


var Buffer = require('buffer').Buffer;

var OurUint8Array = global.Uint8Array || function () {};

function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}

function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}
/*<replacement>*/


var debugUtil = require('util');

var debug;

if (debugUtil && debugUtil.debuglog) {
  debug = debugUtil.debuglog('stream');
} else {
  debug = function debug() {};
}
/*</replacement>*/


var BufferList = require('./internal/streams/buffer_list');

var destroyImpl = require('./internal/streams/destroy');

var _require = require('./internal/streams/state'),
    getHighWaterMark = _require.getHighWaterMark;

var _require$codes = require('../errors').codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT;

var _require2 = require('../experimentalWarning'),
    emitExperimentalWarning = _require2.emitExperimentalWarning; // Lazy loaded to improve the startup performance.


var StringDecoder;
var createReadableStreamAsyncIterator;

require('inherits')(Readable, Stream);

var kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];

function prependListener(emitter, event, fn) {
  // Sadly this is not cacheable as some libraries bundle their own
  // event emitter implementation with them.
  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any
  // userland ones.  NEVER DO THIS. This is here only because this code needs
  // to continue to work with older versions of Node.js that do not include
  // the prependListener() method. The goal is to eventually remove this hack.

  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];
}

function ReadableState(options, stream, isDuplex) {
  Duplex = Duplex || require('./_stream_duplex');
  options = options || {}; // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream.
  // These options can be provided separately as readableXXX and writableXXX.

  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to
  // make all the buffer merging and length checks go away

  this.objectMode = !!options.objectMode;
  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer
  // Note: 0 is a valid value, means "don't call _read preemptively ever"

  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the
  // linked list can remove elements from the beginning faster than
  // array.shift()

  this.buffer = new BufferList();
  this.length = 0;
  this.pipes = null;
  this.pipesCount = 0;
  this.flowing = null;
  this.ended = false;
  this.endEmitted = false;
  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted
  // immediately, or on a later tick.  We set this to true at first, because
  // any actions that shouldn't happen until "later" should generally also
  // not happen before the first read call.

  this.sync = true; // whenever we return null, then we set a flag to say
  // that we're awaiting a 'readable' event emission.

  this.needReadable = false;
  this.emittedReadable = false;
  this.readableListening = false;
  this.resumeScheduled = false;
  this.paused = true; // Should close be emitted on destroy. Defaults to true.

  this.emitClose = options.emitClose !== false; // has it been destroyed

  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.

  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s

  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled

  this.readingMore = false;
  this.decoder = null;
  this.encoding = null;

  if (options.encoding) {
    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;
    this.decoder = new StringDecoder(options.encoding);
    this.encoding = options.encoding;
  }
}

function Readable(options) {
  Duplex = Duplex || require('./_stream_duplex');
  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside
  // the ReadableState constructor, at least with V8 6.5

  var isDuplex = this instanceof Duplex;
  this._readableState = new ReadableState(options, this, isDuplex); // legacy

  this.readable = true;

  if (options) {
    if (typeof options.read === 'function') this._read = options.read;
    if (typeof options.destroy === 'function') this._destroy = options.destroy;
  }

  Stream.call(this);
}

Object.defineProperty(Readable.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._readableState === undefined) {
      return false;
    }

    return this._readableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._readableState) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._readableState.destroyed = value;
  }
});
Readable.prototype.destroy = destroyImpl.destroy;
Readable.prototype._undestroy = destroyImpl.undestroy;

Readable.prototype._destroy = function (err, cb) {
  cb(err);
}; // Manually shove something into the read() buffer.
// This returns true if the highWaterMark has not been hit yet,
// similar to how Writable.write() returns true if you should
// write() some more.


Readable.prototype.push = function (chunk, encoding) {
  var state = this._readableState;
  var skipChunkCheck;

  if (!state.objectMode) {
    if (typeof chunk === 'string') {
      encoding = encoding || state.defaultEncoding;

      if (encoding !== state.encoding) {
        chunk = Buffer.from(chunk, encoding);
        encoding = '';
      }

      skipChunkCheck = true;
    }
  } else {
    skipChunkCheck = true;
  }

  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);
}; // Unshift should *always* be something directly out of read()


Readable.prototype.unshift = function (chunk) {
  return readableAddChunk(this, chunk, null, true, false);
};

function readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {
  debug('readableAddChunk', chunk);
  var state = stream._readableState;

  if (chunk === null) {
    state.reading = false;
    onEofChunk(stream, state);
  } else {
    var er;
    if (!skipChunkCheck) er = chunkInvalid(state, chunk);

    if (er) {
      stream.emit('error', er);
    } else if (state.objectMode || chunk && chunk.length > 0) {
      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {
        chunk = _uint8ArrayToBuffer(chunk);
      }

      if (addToFront) {
        if (state.endEmitted) stream.emit('error', new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);
      } else if (state.ended) {
        stream.emit('error', new ERR_STREAM_PUSH_AFTER_EOF());
      } else if (state.destroyed) {
        return false;
      } else {
        state.reading = false;

        if (state.decoder && !encoding) {
          chunk = state.decoder.write(chunk);
          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);
        } else {
          addChunk(stream, state, chunk, false);
        }
      }
    } else if (!addToFront) {
      state.reading = false;
      maybeReadMore(stream, state);
    }
  } // We can push more data if we are below the highWaterMark.
  // Also, if we have no data yet, we can stand some more bytes.
  // This is to work around cases where hwm=0, such as the repl.


  return !state.ended && (state.length < state.highWaterMark || state.length === 0);
}

function addChunk(stream, state, chunk, addToFront) {
  if (state.flowing && state.length === 0 && !state.sync) {
    state.awaitDrain = 0;
    stream.emit('data', chunk);
  } else {
    // update the buffer info.
    state.length += state.objectMode ? 1 : chunk.length;
    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);
    if (state.needReadable) emitReadable(stream);
  }

  maybeReadMore(stream, state);
}

function chunkInvalid(state, chunk) {
  var er;

  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {
    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);
  }

  return er;
}

Readable.prototype.isPaused = function () {
  return this._readableState.flowing === false;
}; // backwards compatibility.


Readable.prototype.setEncoding = function (enc) {
  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;
  this._readableState.decoder = new StringDecoder(enc); // if setEncoding(null), decoder.encoding equals utf8

  this._readableState.encoding = this._readableState.decoder.encoding;
  return this;
}; // Don't raise the hwm > 8MB


var MAX_HWM = 0x800000;

function computeNewHighWaterMark(n) {
  if (n >= MAX_HWM) {
    n = MAX_HWM;
  } else {
    // Get the next highest power of 2 to prevent increasing hwm excessively in
    // tiny amounts
    n--;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    n++;
  }

  return n;
} // This function is designed to be inlinable, so please take care when making
// changes to the function body.


function howMuchToRead(n, state) {
  if (n <= 0 || state.length === 0 && state.ended) return 0;
  if (state.objectMode) return 1;

  if (n !== n) {
    // Only flow one buffer at a time
    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;
  } // If we're asking for more than the current hwm, then raise the hwm.


  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);
  if (n <= state.length) return n; // Don't have enough

  if (!state.ended) {
    state.needReadable = true;
    return 0;
  }

  return state.length;
} // you can override either this method, or the async _read(n) below.


Readable.prototype.read = function (n) {
  debug('read', n);
  n = parseInt(n, 10);
  var state = this._readableState;
  var nOrig = n;
  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we
  // already have a bunch of data in the buffer, then just trigger
  // the 'readable' event and move on.

  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {
    debug('read: emitReadable', state.length, state.ended);
    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);
    return null;
  }

  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.

  if (n === 0 && state.ended) {
    if (state.length === 0) endReadable(this);
    return null;
  } // All the actual chunk generation logic needs to be
  // *below* the call to _read.  The reason is that in certain
  // synthetic stream cases, such as passthrough streams, _read
  // may be a completely synchronous operation which may change
  // the state of the read buffer, providing enough data when
  // before there was *not* enough.
  //
  // So, the steps are:
  // 1. Figure out what the state of things will be after we do
  // a read from the buffer.
  //
  // 2. If that resulting state will trigger a _read, then call _read.
  // Note that this may be asynchronous, or synchronous.  Yes, it is
  // deeply ugly to write APIs this way, but that still doesn't mean
  // that the Readable class should behave improperly, as streams are
  // designed to be sync/async agnostic.
  // Take note if the _read call is sync or async (ie, if the read call
  // has returned yet), so that we know whether or not it's safe to emit
  // 'readable' etc.
  //
  // 3. Actually pull the requested chunks out of the buffer and return.
  // if we need a readable event, then we need to do some reading.


  var doRead = state.needReadable;
  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some

  if (state.length === 0 || state.length - n < state.highWaterMark) {
    doRead = true;
    debug('length less than watermark', doRead);
  } // however, if we've ended, then there's no point, and if we're already
  // reading, then it's unnecessary.


  if (state.ended || state.reading) {
    doRead = false;
    debug('reading or ended', doRead);
  } else if (doRead) {
    debug('do read');
    state.reading = true;
    state.sync = true; // if the length is currently zero, then we *need* a readable event.

    if (state.length === 0) state.needReadable = true; // call internal read method

    this._read(state.highWaterMark);

    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,
    // and we need to re-evaluate how much data we can return to the user.

    if (!state.reading) n = howMuchToRead(nOrig, state);
  }

  var ret;
  if (n > 0) ret = fromList(n, state);else ret = null;

  if (ret === null) {
    state.needReadable = true;
    n = 0;
  } else {
    state.length -= n;
    state.awaitDrain = 0;
  }

  if (state.length === 0) {
    // If we have nothing in the buffer, then we want to know
    // as soon as we *do* get something into the buffer.
    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.

    if (nOrig !== n && state.ended) endReadable(this);
  }

  if (ret !== null) this.emit('data', ret);
  return ret;
};

function onEofChunk(stream, state) {
  if (state.ended) return;

  if (state.decoder) {
    var chunk = state.decoder.end();

    if (chunk && chunk.length) {
      state.buffer.push(chunk);
      state.length += state.objectMode ? 1 : chunk.length;
    }
  }

  state.ended = true;

  if (state.sync) {
    // if we are sync, wait until next tick to emit the data.
    // Otherwise we risk emitting data in the flow()
    // the readable code triggers during a read() call
    emitReadable(stream);
  } else {
    // emit 'readable' now to make sure it gets picked up.
    state.needReadable = false;

    if (!state.emittedReadable) {
      state.emittedReadable = true;
      emitReadable_(stream);
    }
  }
} // Don't emit readable right away in sync mode, because this can trigger
// another read() call => stack overflow.  This way, it might trigger
// a nextTick recursion warning, but that's not so bad.


function emitReadable(stream) {
  var state = stream._readableState;
  state.needReadable = false;

  if (!state.emittedReadable) {
    debug('emitReadable', state.flowing);
    state.emittedReadable = true;
    process.nextTick(emitReadable_, stream);
  }
}

function emitReadable_(stream) {
  var state = stream._readableState;
  debug('emitReadable_', state.destroyed, state.length, state.ended);

  if (!state.destroyed && (state.length || state.ended)) {
    stream.emit('readable');
  } // The stream needs another readable event if
  // 1. It is not flowing, as the flow mechanism will take
  //    care of it.
  // 2. It is not ended.
  // 3. It is below the highWaterMark, so we can schedule
  //    another readable later.


  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;
  flow(stream);
} // at this point, the user has presumably seen the 'readable' event,
// and called read() to consume some data.  that may have triggered
// in turn another _read(n) call, in which case reading = true if
// it's in progress.
// However, if we're not ended, or reading, and the length < hwm,
// then go ahead and try to read some more preemptively.


function maybeReadMore(stream, state) {
  if (!state.readingMore) {
    state.readingMore = true;
    process.nextTick(maybeReadMore_, stream, state);
  }
}

function maybeReadMore_(stream, state) {
  // Attempt to read more data if we should.
  //
  // The conditions for reading more data are (one of):
  // - Not enough data buffered (state.length < state.highWaterMark). The loop
  //   is responsible for filling the buffer with enough data if such data
  //   is available. If highWaterMark is 0 and we are not in the flowing mode
  //   we should _not_ attempt to buffer any extra data. We'll get more data
  //   when the stream consumer calls read() instead.
  // - No data in the buffer, and the stream is in flowing mode. In this mode
  //   the loop below is responsible for ensuring read() is called. Failing to
  //   call read here would abort the flow and there's no other mechanism for
  //   continuing the flow if the stream consumer has just subscribed to the
  //   'data' event.
  //
  // In addition to the above conditions to keep reading data, the following
  // conditions prevent the data from being read:
  // - The stream has ended (state.ended).
  // - There is already a pending 'read' operation (state.reading). This is a
  //   case where the the stream has called the implementation defined _read()
  //   method, but they are processing the call asynchronously and have _not_
  //   called push() with new data. In this case we skip performing more
  //   read()s. The execution ends in this method again after the _read() ends
  //   up calling push() with more data.
  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {
    var len = state.length;
    debug('maybeReadMore read 0');
    stream.read(0);
    if (len === state.length) // didn't get any data, stop spinning.
      break;
  }

  state.readingMore = false;
} // abstract method.  to be overridden in specific implementation classes.
// call cb(er, data) where data is <= n in length.
// for virtual (non-string, non-buffer) streams, "length" is somewhat
// arbitrary, and perhaps not very meaningful.


Readable.prototype._read = function (n) {
  this.emit('error', new ERR_METHOD_NOT_IMPLEMENTED('_read()'));
};

Readable.prototype.pipe = function (dest, pipeOpts) {
  var src = this;
  var state = this._readableState;

  switch (state.pipesCount) {
    case 0:
      state.pipes = dest;
      break;

    case 1:
      state.pipes = [state.pipes, dest];
      break;

    default:
      state.pipes.push(dest);
      break;
  }

  state.pipesCount += 1;
  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);
  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;
  var endFn = doEnd ? onend : unpipe;
  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);
  dest.on('unpipe', onunpipe);

  function onunpipe(readable, unpipeInfo) {
    debug('onunpipe');

    if (readable === src) {
      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
        unpipeInfo.hasUnpiped = true;
        cleanup();
      }
    }
  }

  function onend() {
    debug('onend');
    dest.end();
  } // when the dest drains, it reduces the awaitDrain counter
  // on the source.  This would be more elegant with a .once()
  // handler in flow(), but adding and removing repeatedly is
  // too slow.


  var ondrain = pipeOnDrain(src);
  dest.on('drain', ondrain);
  var cleanedUp = false;

  function cleanup() {
    debug('cleanup'); // cleanup event handlers once the pipe is broken

    dest.removeListener('close', onclose);
    dest.removeListener('finish', onfinish);
    dest.removeListener('drain', ondrain);
    dest.removeListener('error', onerror);
    dest.removeListener('unpipe', onunpipe);
    src.removeListener('end', onend);
    src.removeListener('end', unpipe);
    src.removeListener('data', ondata);
    cleanedUp = true; // if the reader is waiting for a drain event from this
    // specific writer, then it would cause it to never start
    // flowing again.
    // So, if this is awaiting a drain, then we just call it now.
    // If we don't know, then assume that we are waiting for one.

    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();
  }

  src.on('data', ondata);

  function ondata(chunk) {
    debug('ondata');
    var ret = dest.write(chunk);
    debug('dest.write', ret);

    if (ret === false) {
      // If the user unpiped during `dest.write()`, it is possible
      // to get stuck in a permanently paused state if that write
      // also returned false.
      // => Check whether `dest` is still a piping destination.
      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {
        debug('false write response, pause', state.awaitDrain);
        state.awaitDrain++;
      }

      src.pause();
    }
  } // if the dest has an error, then stop piping into it.
  // however, don't suppress the throwing behavior for this.


  function onerror(er) {
    debug('onerror', er);
    unpipe();
    dest.removeListener('error', onerror);
    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);
  } // Make sure our error handler is attached before userland ones.


  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.

  function onclose() {
    dest.removeListener('finish', onfinish);
    unpipe();
  }

  dest.once('close', onclose);

  function onfinish() {
    debug('onfinish');
    dest.removeListener('close', onclose);
    unpipe();
  }

  dest.once('finish', onfinish);

  function unpipe() {
    debug('unpipe');
    src.unpipe(dest);
  } // tell the dest that it's being piped to


  dest.emit('pipe', src); // start the flow if it hasn't been started already.

  if (!state.flowing) {
    debug('pipe resume');
    src.resume();
  }

  return dest;
};

function pipeOnDrain(src) {
  return function pipeOnDrainFunctionResult() {
    var state = src._readableState;
    debug('pipeOnDrain', state.awaitDrain);
    if (state.awaitDrain) state.awaitDrain--;

    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {
      state.flowing = true;
      flow(src);
    }
  };
}

Readable.prototype.unpipe = function (dest) {
  var state = this._readableState;
  var unpipeInfo = {
    hasUnpiped: false
  }; // if we're not piping anywhere, then do nothing.

  if (state.pipesCount === 0) return this; // just one destination.  most common case.

  if (state.pipesCount === 1) {
    // passed in one, but it's not the right one.
    if (dest && dest !== state.pipes) return this;
    if (!dest) dest = state.pipes; // got a match.

    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;
    if (dest) dest.emit('unpipe', this, unpipeInfo);
    return this;
  } // slow case. multiple pipe destinations.


  if (!dest) {
    // remove all.
    var dests = state.pipes;
    var len = state.pipesCount;
    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;

    for (var i = 0; i < len; i++) {
      dests[i].emit('unpipe', this, {
        hasUnpiped: false
      });
    }

    return this;
  } // try to find the right one.


  var index = indexOf(state.pipes, dest);
  if (index === -1) return this;
  state.pipes.splice(index, 1);
  state.pipesCount -= 1;
  if (state.pipesCount === 1) state.pipes = state.pipes[0];
  dest.emit('unpipe', this, unpipeInfo);
  return this;
}; // set up data events if they are asked for
// Ensure readable listeners eventually get something


Readable.prototype.on = function (ev, fn) {
  var res = Stream.prototype.on.call(this, ev, fn);
  var state = this._readableState;

  if (ev === 'data') {
    // update readableListening so that resume() may be a no-op
    // a few lines down. This is needed to support once('readable').
    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused

    if (state.flowing !== false) this.resume();
  } else if (ev === 'readable') {
    if (!state.endEmitted && !state.readableListening) {
      state.readableListening = state.needReadable = true;
      state.flowing = false;
      state.emittedReadable = false;
      debug('on readable', state.length, state.reading);

      if (state.length) {
        emitReadable(this);
      } else if (!state.reading) {
        process.nextTick(nReadingNextTick, this);
      }
    }
  }

  return res;
};

Readable.prototype.addListener = Readable.prototype.on;

Readable.prototype.removeListener = function (ev, fn) {
  var res = Stream.prototype.removeListener.call(this, ev, fn);

  if (ev === 'readable') {
    // We need to check if there is someone still listening to
    // readable and reset the state. However this needs to happen
    // after readable has been emitted but before I/O (nextTick) to
    // support once('readable', fn) cycles. This means that calling
    // resume within the same tick will have no
    // effect.
    process.nextTick(updateReadableListening, this);
  }

  return res;
};

Readable.prototype.removeAllListeners = function (ev) {
  var res = Stream.prototype.removeAllListeners.apply(this, arguments);

  if (ev === 'readable' || ev === undefined) {
    // We need to check if there is someone still listening to
    // readable and reset the state. However this needs to happen
    // after readable has been emitted but before I/O (nextTick) to
    // support once('readable', fn) cycles. This means that calling
    // resume within the same tick will have no
    // effect.
    process.nextTick(updateReadableListening, this);
  }

  return res;
};

function updateReadableListening(self) {
  var state = self._readableState;
  state.readableListening = self.listenerCount('readable') > 0;

  if (state.resumeScheduled && !state.paused) {
    // flowing needs to be set to true now, otherwise
    // the upcoming resume will not flow.
    state.flowing = true; // crude way to check if we should resume
  } else if (self.listenerCount('data') > 0) {
    self.resume();
  }
}

function nReadingNextTick(self) {
  debug('readable nexttick read 0');
  self.read(0);
} // pause() and resume() are remnants of the legacy readable stream API
// If the user uses them, then switch into old mode.


Readable.prototype.resume = function () {
  var state = this._readableState;

  if (!state.flowing) {
    debug('resume'); // we flow only if there is no one listening
    // for readable, but we still have to call
    // resume()

    state.flowing = !state.readableListening;
    resume(this, state);
  }

  state.paused = false;
  return this;
};

function resume(stream, state) {
  if (!state.resumeScheduled) {
    state.resumeScheduled = true;
    process.nextTick(resume_, stream, state);
  }
}

function resume_(stream, state) {
  debug('resume', state.reading);

  if (!state.reading) {
    stream.read(0);
  }

  state.resumeScheduled = false;
  stream.emit('resume');
  flow(stream);
  if (state.flowing && !state.reading) stream.read(0);
}

Readable.prototype.pause = function () {
  debug('call pause flowing=%j', this._readableState.flowing);

  if (this._readableState.flowing !== false) {
    debug('pause');
    this._readableState.flowing = false;
    this.emit('pause');
  }

  this._readableState.paused = true;
  return this;
};

function flow(stream) {
  var state = stream._readableState;
  debug('flow', state.flowing);

  while (state.flowing && stream.read() !== null) {
    ;
  }
} // wrap an old-style stream as the async data source.
// This is *not* part of the readable stream interface.
// It is an ugly unfortunate mess of history.


Readable.prototype.wrap = function (stream) {
  var _this = this;

  var state = this._readableState;
  var paused = false;
  stream.on('end', function () {
    debug('wrapped end');

    if (state.decoder && !state.ended) {
      var chunk = state.decoder.end();
      if (chunk && chunk.length) _this.push(chunk);
    }

    _this.push(null);
  });
  stream.on('data', function (chunk) {
    debug('wrapped data');
    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode

    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;

    var ret = _this.push(chunk);

    if (!ret) {
      paused = true;
      stream.pause();
    }
  }); // proxy all the other methods.
  // important when wrapping filters and duplexes.

  for (var i in stream) {
    if (this[i] === undefined && typeof stream[i] === 'function') {
      this[i] = function methodWrap(method) {
        return function methodWrapReturnFunction() {
          return stream[method].apply(stream, arguments);
        };
      }(i);
    }
  } // proxy certain important events.


  for (var n = 0; n < kProxyEvents.length; n++) {
    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));
  } // when we try to consume some more bytes, simply unpause the
  // underlying stream.


  this._read = function (n) {
    debug('wrapped _read', n);

    if (paused) {
      paused = false;
      stream.resume();
    }
  };

  return this;
};

if (typeof Symbol === 'function') {
  Readable.prototype[Symbol.asyncIterator] = function () {
    emitExperimentalWarning('Readable[Symbol.asyncIterator]');

    if (createReadableStreamAsyncIterator === undefined) {
      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');
    }

    return createReadableStreamAsyncIterator(this);
  };
}

Object.defineProperty(Readable.prototype, 'readableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.highWaterMark;
  }
});
Object.defineProperty(Readable.prototype, 'readableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState && this._readableState.buffer;
  }
});
Object.defineProperty(Readable.prototype, 'readableFlowing', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.flowing;
  },
  set: function set(state) {
    if (this._readableState) {
      this._readableState.flowing = state;
    }
  }
}); // exposed for testing purposes only.

Readable._fromList = fromList;
Object.defineProperty(Readable.prototype, 'readableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.length;
  }
}); // Pluck off n bytes from an array of buffers.
// Length is the combined lengths of all the buffers in the list.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.

function fromList(n, state) {
  // nothing buffered
  if (state.length === 0) return null;
  var ret;
  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {
    // read it all, truncate the list
    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);
    state.buffer.clear();
  } else {
    // read part of list
    ret = state.buffer.consume(n, state.decoder);
  }
  return ret;
}

function endReadable(stream) {
  var state = stream._readableState;
  debug('endReadable', state.endEmitted);

  if (!state.endEmitted) {
    state.ended = true;
    process.nextTick(endReadableNT, state, stream);
  }
}

function endReadableNT(state, stream) {
  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.

  if (!state.endEmitted && state.length === 0) {
    state.endEmitted = true;
    stream.readable = false;
    stream.emit('end');
  }
}

function indexOf(xs, x) {
  for (var i = 0, l = xs.length; i < l; i++) {
    if (xs[i] === x) return i;
  }

  return -1;
}
},
"hBy4BpDLhfBjslamYaN7SKNU00r5tz2pFNrSVFl+q5o=":
function (require, module, exports, __dirname, __filename) {

var Through = require('pull-through')
var Reader = require('pull-reader')

var BUFFER = 0, STRING = 1, OBJECT = 2

var GOODBYE = 'GOODBYE'
var isBuffer = Buffer.isBuffer

function isString (s) {
  return 'string' === typeof s
}

function encodePair (msg) {

  var head = Buffer.alloc(9)
  var flags = 0
  var value = msg.value !== undefined ? msg.value : msg.end

  //final packet
  if(isString(msg) && msg === GOODBYE) {
    head.fill(0)
    return [head, null]
  }

  if(isString(value)) {
    flags = STRING
    value = Buffer.from(value, 'utf-8')
  }
  else if(isBuffer(value)) {
    flags = BUFFER
  }
  else {
    flags = OBJECT
    value = Buffer.from(JSON.stringify(value), 'utf-8')
  }

  // does this frame represent a msg, a req, or a stream?

  //end, stream

  flags = msg.stream << 3 | msg.end << 2 | flags

  head[0] = flags

  head.writeUInt32BE(value.length, 1)
  head.writeInt32BE(msg.req || 0, 5)

  return [head, value]
}

function decodeHead (bytes) {
  if(bytes.length != 9)
    throw new Error('expected header to be 9 bytes long')
  var flags = bytes[0]
  var length = bytes.readUInt32BE(1)
  var req = bytes.readInt32BE(5)

  return {
    req    : req,
    stream : !!(flags & 8),
    end    : !!(flags & 4),
    value  : null,
    length : length,
    type   : flags & 3
  }
}

function decodeBody (bytes, msg) {
  if(bytes.length !== msg.length)
    throw new Error('incorrect length, expected:'+msg.length+' found:'+bytes.length)
  if(BUFFER === msg.type) msg.value = bytes
  else if(STRING === msg.type) msg.value = bytes.toString()
  else if(OBJECT === msg.type) msg.value = JSON.parse(bytes.toString())
  else throw new Error('unknown message type')
  return msg
}

function encode () {
  return Through(function (d) {
    var c = encodePair(d)
    this.queue(c[0])
    if(c[1] !== null)
      this.queue(c[1])
  })
}

function decode () {
  var reader = Reader(), ended = false

  return function (read) {
    reader(read)

    return function (abort, cb) {
      if(ended) return cb(true)
      if(abort) return reader.abort(abort, cb)
      reader.read(9, function (err, head) {
        if(err) return cb(err)
        var msg = decodeHead(head)
        if(msg.length === 0) { //final packet
          ended = true
          return cb(null, GOODBYE)
        }
        reader.read(msg.length, function (err, body) {
          if(err) return cb(err)
          try {
            decodeBody(body, msg)
          } catch(e) {
            return cb(e)
          }
          cb(null, msg)
        })
      })
    }
  }
}

exports = module.exports = function (stream) {
  return {
    source: encode()(stream.source),
    sink: function (read) { return stream.sink(decode()(read)) }
  }
}

exports.encodePair = encodePair
exports.decodeHead = decodeHead
exports.decodeBody = decodeBody

exports.encode = encode
exports.decode = decode


},
"hFQKenIZaVQyuP6Hd5SjFa4atiqjB4h7WNbq/6qL8cM=":
function (require, module, exports, __dirname, __filename) {
(function(root, factory) {
    if (typeof module === 'object' && module.exports) {
        module.exports = factory();
    } else {
        root.nearley = factory();
    }
}(this, function() {

    function Rule(name, symbols, postprocess) {
        this.id = ++Rule.highestId;
        this.name = name;
        this.symbols = symbols;        // a list of literal | regex class | nonterminal
        this.postprocess = postprocess;
        return this;
    }
    Rule.highestId = 0;

    Rule.prototype.toString = function(withCursorAt) {
        function stringifySymbolSequence (e) {
            return e.literal ? JSON.stringify(e.literal) :
                   e.type ? '%' + e.type : e.toString();
        }
        var symbolSequence = (typeof withCursorAt === "undefined")
                             ? this.symbols.map(stringifySymbolSequence).join(' ')
                             : (   this.symbols.slice(0, withCursorAt).map(stringifySymbolSequence).join(' ')
                                 + " ● "
                                 + this.symbols.slice(withCursorAt).map(stringifySymbolSequence).join(' ')     );
        return this.name + " → " + symbolSequence;
    }


    // a State is a rule at a position from a given starting point in the input stream (reference)
    function State(rule, dot, reference, wantedBy) {
        this.rule = rule;
        this.dot = dot;
        this.reference = reference;
        this.data = [];
        this.wantedBy = wantedBy;
        this.isComplete = this.dot === rule.symbols.length;
    }

    State.prototype.toString = function() {
        return "{" + this.rule.toString(this.dot) + "}, from: " + (this.reference || 0);
    };

    State.prototype.nextState = function(child) {
        var state = new State(this.rule, this.dot + 1, this.reference, this.wantedBy);
        state.left = this;
        state.right = child;
        if (state.isComplete) {
            state.data = state.build();
        }
        return state;
    };

    State.prototype.build = function() {
        var children = [];
        var node = this;
        do {
            children.push(node.right.data);
            node = node.left;
        } while (node.left);
        children.reverse();
        return children;
    };

    State.prototype.finish = function() {
        if (this.rule.postprocess) {
            this.data = this.rule.postprocess(this.data, this.reference, Parser.fail);
        }
    };


    function Column(grammar, index) {
        this.grammar = grammar;
        this.index = index;
        this.states = [];
        this.wants = {}; // states indexed by the non-terminal they expect
        this.scannable = []; // list of states that expect a token
        this.completed = {}; // states that are nullable
    }


    Column.prototype.process = function(nextColumn) {
        var states = this.states;
        var wants = this.wants;
        var completed = this.completed;

        for (var w = 0; w < states.length; w++) { // nb. we push() during iteration
            var state = states[w];

            if (state.isComplete) {
                state.finish();
                if (state.data !== Parser.fail) {
                    // complete
                    var wantedBy = state.wantedBy;
                    for (var i = wantedBy.length; i--; ) { // this line is hot
                        var left = wantedBy[i];
                        this.complete(left, state);
                    }

                    // special-case nullables
                    if (state.reference === this.index) {
                        // make sure future predictors of this rule get completed.
                        var exp = state.rule.name;
                        (this.completed[exp] = this.completed[exp] || []).push(state);
                    }
                }

            } else {
                // queue scannable states
                var exp = state.rule.symbols[state.dot];
                if (typeof exp !== 'string') {
                    this.scannable.push(state);
                    continue;
                }

                // predict
                if (wants[exp]) {
                    wants[exp].push(state);

                    if (completed.hasOwnProperty(exp)) {
                        var nulls = completed[exp];
                        for (var i = 0; i < nulls.length; i++) {
                            var right = nulls[i];
                            this.complete(state, right);
                        }
                    }
                } else {
                    wants[exp] = [state];
                    this.predict(exp);
                }
            }
        }
    }

    Column.prototype.predict = function(exp) {
        var rules = this.grammar.byName[exp] || [];

        for (var i = 0; i < rules.length; i++) {
            var r = rules[i];
            var wantedBy = this.wants[exp];
            var s = new State(r, 0, this.index, wantedBy);
            this.states.push(s);
        }
    }

    Column.prototype.complete = function(left, right) {
        var copy = left.nextState(right);
        this.states.push(copy);
    }


    function Grammar(rules, start) {
        this.rules = rules;
        this.start = start || this.rules[0].name;
        var byName = this.byName = {};
        this.rules.forEach(function(rule) {
            if (!byName.hasOwnProperty(rule.name)) {
                byName[rule.name] = [];
            }
            byName[rule.name].push(rule);
        });
    }

    // So we can allow passing (rules, start) directly to Parser for backwards compatibility
    Grammar.fromCompiled = function(rules, start) {
        var lexer = rules.Lexer;
        if (rules.ParserStart) {
          start = rules.ParserStart;
          rules = rules.ParserRules;
        }
        var rules = rules.map(function (r) { return (new Rule(r.name, r.symbols, r.postprocess)); });
        var g = new Grammar(rules, start);
        g.lexer = lexer; // nb. storing lexer on Grammar is iffy, but unavoidable
        return g;
    }


    function StreamLexer() {
      this.reset("");
    }

    StreamLexer.prototype.reset = function(data, state) {
        this.buffer = data;
        this.index = 0;
        this.line = state ? state.line : 1;
        this.lastLineBreak = state ? -state.col : 0;
    }

    StreamLexer.prototype.next = function() {
        if (this.index < this.buffer.length) {
            var ch = this.buffer[this.index++];
            if (ch === '\n') {
              this.line += 1;
              this.lastLineBreak = this.index;
            }
            return {value: ch};
        }
    }

    StreamLexer.prototype.save = function() {
      return {
        line: this.line,
        col: this.index - this.lastLineBreak,
      }
    }

    StreamLexer.prototype.formatError = function(token, message) {
        // nb. this gets called after consuming the offending token,
        // so the culprit is index-1
        var buffer = this.buffer;
        if (typeof buffer === 'string') {
            var nextLineBreak = buffer.indexOf('\n', this.index);
            if (nextLineBreak === -1) nextLineBreak = buffer.length;
            var line = buffer.substring(this.lastLineBreak, nextLineBreak)
            var col = this.index - this.lastLineBreak;
            message += " at line " + this.line + " col " + col + ":\n\n";
            message += "  " + line + "\n"
            message += "  " + Array(col).join(" ") + "^"
            return message;
        } else {
            return message + " at index " + (this.index - 1);
        }
    }


    function Parser(rules, start, options) {
        if (rules instanceof Grammar) {
            var grammar = rules;
            var options = start;
        } else {
            var grammar = Grammar.fromCompiled(rules, start);
        }
        this.grammar = grammar;

        // Read options
        this.options = {
            keepHistory: false,
            lexer: grammar.lexer || new StreamLexer,
        };
        for (var key in (options || {})) {
            this.options[key] = options[key];
        }

        // Setup lexer
        this.lexer = this.options.lexer;
        this.lexerState = undefined;

        // Setup a table
        var column = new Column(grammar, 0);
        var table = this.table = [column];

        // I could be expecting anything.
        column.wants[grammar.start] = [];
        column.predict(grammar.start);
        // TODO what if start rule is nullable?
        column.process();
        this.current = 0; // token index
    }

    // create a reserved token for indicating a parse fail
    Parser.fail = {};

    Parser.prototype.feed = function(chunk) {
        var lexer = this.lexer;
        lexer.reset(chunk, this.lexerState);

        var token;
        while (token = lexer.next()) {
            // We add new states to table[current+1]
            var column = this.table[this.current];

            // GC unused states
            if (!this.options.keepHistory) {
                delete this.table[this.current - 1];
            }

            var n = this.current + 1;
            var nextColumn = new Column(this.grammar, n);
            this.table.push(nextColumn);

            // Advance all tokens that expect the symbol
            var literal = token.text !== undefined ? token.text : token.value;
            var value = lexer.constructor === StreamLexer ? token.value : token;
            var scannable = column.scannable;
            for (var w = scannable.length; w--; ) {
                var state = scannable[w];
                var expect = state.rule.symbols[state.dot];
                // Try to consume the token
                // either regex or literal
                if (expect.test ? expect.test(value) :
                    expect.type ? expect.type === token.type
                                : expect.literal === literal) {
                    // Add it
                    var next = state.nextState({data: value, token: token, isToken: true, reference: n - 1});
                    nextColumn.states.push(next);
                }
            }

            // Next, for each of the rules, we either
            // (a) complete it, and try to see if the reference row expected that
            //     rule
            // (b) predict the next nonterminal it expects by adding that
            //     nonterminal's start state
            // To prevent duplication, we also keep track of rules we have already
            // added

            nextColumn.process();

            // If needed, throw an error:
            if (nextColumn.states.length === 0) {
                // No states at all! This is not good.
                var message = this.lexer.formatError(token, "invalid syntax") + "\n";
                message += "Unexpected " + (token.type ? token.type + " token: " : "");
                message += JSON.stringify(token.value !== undefined ? token.value : token) + "\n";
                var err = new Error(message);
                err.offset = this.current;
                err.token = token;
                throw err;
            }

            // maybe save lexer state
            if (this.options.keepHistory) {
              column.lexerState = lexer.save()
            }

            this.current++;
        }
        if (column) {
          this.lexerState = lexer.save()
        }

        // Incrementally keep track of results
        this.results = this.finish();

        // Allow chaining, for whatever it's worth
        return this;
    };

    Parser.prototype.save = function() {
        var column = this.table[this.current];
        column.lexerState = this.lexerState;
        return column;
    };

    Parser.prototype.restore = function(column) {
        var index = column.index;
        this.current = index;
        this.table[index] = column;
        this.table.splice(index + 1);
        this.lexerState = column.lexerState;

        // Incrementally keep track of results
        this.results = this.finish();
    };

    // nb. deprecated: use save/restore instead!
    Parser.prototype.rewind = function(index) {
        if (!this.options.keepHistory) {
            throw new Error('set option `keepHistory` to enable rewinding')
        }
        // nb. recall column (table) indicies fall between token indicies.
        //        col 0   --   token 0   --   col 1
        this.restore(this.table[index]);
    };

    Parser.prototype.finish = function() {
        // Return the possible parsings
        var considerations = [];
        var start = this.grammar.start;
        var column = this.table[this.table.length - 1]
        column.states.forEach(function (t) {
            if (t.rule.name === start
                    && t.dot === t.rule.symbols.length
                    && t.reference === 0
                    && t.data !== Parser.fail) {
                considerations.push(t);
            }
        });
        return considerations.map(function(c) {return c.data; });
    };

    return {
        Parser: Parser,
        Grammar: Grammar,
        Rule: Rule,
    };

}));

},
"hLfHheaBCA/u6FTNJvtvLUBUzn0KmM8b/BoYWPmXzkY=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const explain = require('explain-error')
const u = require('./util')

/**
 * Recursively traverse the `obj` according to the `manifest` shape,
 * replacing all leafs with `remoteCall`. Returns the mutated `obj`.
 */
function recurse (obj, manifest, path, remoteCall) {
  for (const name in manifest) {
    const val = manifest[name]
    const nestedPath = path ? path.concat(name) : [name]
    if (val && typeof val === 'object') {
      const nestedManifest = val
      obj[name] = recurse({}, nestedManifest, nestedPath, remoteCall)
    } else {
      const type = val
      obj[name] = (...args) => remoteCall(type, nestedPath, args)
    }
  }
  return obj
}

function noop (err) {
  if (err) throw explain(err, 'callback not provided')
}

function createRemoteApi (obj, manifest, actualRemoteCall, bootstrapCB) {
  obj = obj || {}

  function remoteCall (type, name, args) {
    const cb = typeof args[args.length - 1] === 'function'
      ? args.pop()
      : type === 'sync' || type === 'async' // promise types
        ? null
        : noop

    if (typeof cb === 'function') {
      let value
      // Callback style
      try {
        value = actualRemoteCall(type, name, args, cb)
      } catch (err) {
        return u.errorAsStreamOrCb(type, err, cb)
      }
      return value
    } else {
      // Promise style
      return new Promise((resolve, reject) => {
        actualRemoteCall(type, name, args, (err, val) => {
          if (err) reject(err)
          else resolve(val)
        })
      })
    }
  }

  if (bootstrapCB) {
    remoteCall('async', 'manifest', [function (err, manifest) {
      if (err) return bootstrapCB(err)
      recurse(obj, manifest, null, remoteCall)
      bootstrapCB(null, manifest, obj)
    }])
  } else {
    recurse(obj, manifest, null, remoteCall)
  }

  return obj
}

module.exports = createRemoteApi

},
"hRDMkQ2i0TTb2zJwx88UQkQmM7bedmkKApHibXXsH5Q=":
function (require, module, exports, __dirname, __filename) {

/*
A push stream pipeline is a doublely linked list.
data (write/end) travels one way, and signals (pause/resume/abort) travels the other way.

when you pipe to a stream, if it already has a source, find the first
source and pipe to that. this makes a.pipe(b.pipe(c) work, or a.pipe(b)

also, duplex streams (which, like in pull streams, are a pair {source, sink} streams)

*/

module.exports = function pipe (sink) {
  if(!sink) throw new Error('sink must be provided')
  var _sink = sink
  while(sink.source) sink = sink.source
  this.sink = sink
  sink.source = this
  if(!sink.paused) this.resume()
  return _sink
}

},
"hcDFJjsYaT2bXTd+DVrmrGpO6LJFYxkNxzD8/5cKXZs=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.toCamelCase = exports.hookOptionalCB = exports.merge = exports.toId = exports.clone = void 0;
var mapMerge = require('map-merge');
var camelize = require('to-camel-case');
function isObject(o) {
    return o && typeof o === 'object';
}
function clone(obj, mapper) {
    function map(v, k) {
        return isObject(v) ? clone(v, mapper) : mapper(v, k);
    }
    if (Array.isArray(obj)) {
        return obj.map(map);
    }
    else if (isObject(obj)) {
        var o = {};
        for (var k in obj) {
            o[k] = map(obj[k], k);
        }
        return o;
    }
    else {
        return map(obj);
    }
}
exports.clone = clone;
function toId(pub) {
    return Buffer.isBuffer(pub) ? pub.toString('base64') + '.ed25519' : pub;
}
exports.toId = toId;
exports.merge = {
    permissions: function (perms, _perms, name) {
        return mapMerge(perms, clone(_perms, function (v) { return name ? name + '.' + v : v; }));
    },
    manifest: function (manf, _manf, name) {
        if (name) {
            var o = {};
            o[name] = _manf;
            _manf = o;
        }
        return mapMerge(manf, _manf);
    }
};
function hookOptionalCB(syncFn) {
    syncFn.hook(function (fn, args) {
        var cb = args[args.length - 1];
        if (typeof cb === 'function') {
            var res = void 0;
            args.pop();
            try {
                res = fn.apply(this, args);
            }
            catch (e) {
                return cb(e);
            }
            cb(null, res);
        }
        else {
            return fn.apply(this, args);
        }
    });
}
exports.hookOptionalCB = hookOptionalCB;
function toCamelCase(n) {
    return n ? camelize(n) : n;
}
exports.toCamelCase = toCamelCase;

},
"hzCxsz+nDf0dyJJDPun/vULTAdbOd9PJq0maneo+4vc=":
function (require, module, exports, __dirname, __filename) {
'use strict';

exports.stringToBytes = string => [...string].map(character => character.charCodeAt(0));

/**
Checks whether the TAR checksum is valid.

@param {Buffer} buffer - The TAR header `[offset ... offset + 512]`.
@param {number} offset - TAR header offset.
@returns {boolean} `true` if the TAR checksum is valid, otherwise `false`.
*/
exports.tarHeaderChecksumMatches = (buffer, offset = 0) => {
	const readSum = parseInt(buffer.toString('utf8', 148, 154).replace(/\0.*$/, '').trim(), 8); // Read sum in header
	if (isNaN(readSum)) {
		return false;
	}

	let sum = 8 * 0x20; // Initialize signed bit sum

	for (let i = offset; i < offset + 148; i++) {
		sum += buffer[i];
	}

	for (let i = offset + 156; i < offset + 512; i++) {
		sum += buffer[i];
	}

	return readSum === sum;
};

/**
ID3 UINT32 sync-safe tokenizer token.
28 bits (representing up to 256MB) integer, the msb is 0 to avoid "false syncsignals".
*/
exports.uint32SyncSafeToken = {
	get: (buffer, offset) => {
		return (buffer[offset + 3] & 0x7F) | ((buffer[offset + 2]) << 7) | ((buffer[offset + 1]) << 14) | ((buffer[offset]) << 21);
	},
	len: 4
};

},
"i3ZecsskmJPA4FlkZFhpDz9h4J/vS4YwfHM48haowDU=":
function (require, module, exports, __dirname, __filename) {
var isCanonicalBase64 = require('is-canonical-base64')
var isDomain = require('is-valid-domain')
var Querystring = require('querystring')
var ip = require('ip')
var MultiServerAddress = require('multiserver-address')

var parseLinkRegex = /^((@|%|&)[A-Za-z0-9/+]{43}=\.[\w\d]+)(\?(.+))?$/
var feedIdRegex = exports.feedIdRegex = isCanonicalBase64('@', '.(?:sha256|ed25519)', 32)
var blobIdRegex = exports.blobIdRegex = isCanonicalBase64('&', '.sha256', 32)
var msgIdRegex = exports.msgIdRegex = isCanonicalBase64('%', '.sha256', 32)
var cloakedMsgIdRegex = exports.cloakedMsgIdRegex = isCanonicalBase64('%', '.cloaked', 32)

var extractRegex = /([@%&][A-Za-z0-9/+]{43}=\.[\w\d]+)/

function isMultiServerAddress (str) {
  // a http url fits into the multiserver scheme,
  // but all ssb address must have a transport and a transform
  // so check there is at least one unescaped ~ in the address
  return MultiServerAddress.check(str) && /[^!][~]/.test(str)
}

function isIP (s) {
  return ip.isV4Format(s) || ip.isV6Format(s)
}

var isInteger = Number.isInteger
var DEFAULT_PORT = 8008

function isString (s) {
  return typeof s === 'string'
}

var isHost = function (addr) {
  if (!isString(addr)) return
  addr = addr.replace(/^wss?:\/\//, '')
  return (isIP(addr)) || isDomain(addr) || addr === 'localhost'
}

var isPort = function (p) {
  return isInteger(p) && p <= 65536
}

function isObject (o) {
  return o && typeof o === 'object' && !Array.isArray(o)
}

var isFeedId = exports.isFeed = exports.isFeedId =
  function (data) {
    return isString(data) && feedIdRegex.test(data)
  }

var isMsgId = exports.isMsg = exports.isMsgId =
  function (data) {
    return isString(data) && msgIdRegex.test(data)
  }

exports.isCloakedMsg = exports.isCloakedMsgId =
  function (data) {
    return isString(data) && cloakedMsgIdRegex.test(data)
  }

var isBlobId = exports.isBlob = exports.isBlobId =
  function (data) {
    return isString(data) && blobIdRegex.test(data)
  }

var isLink = exports.isLink =
  function (data) {
    if (!isString(data)) return false
    var index = data.indexOf('?')
    data = ~index ? data.substring(0, index) : data
    return isString(data) && (isFeedId(data) || isMsgId(data) || isBlobId(data))
  }

exports.isBlobLink = function (s) {
  return s[0] === '&' && isLink(s)
}

exports.isMsgLink = function (s) {
  return s[0] === '%' && isLink(s)
}

exports.normalizeChannel =
  function (data) {
    if (typeof data === 'string') {
      data = data.toLowerCase().replace(/\s|,|\.|\?|!|<|>|\(|\)|\[|\]|"|#/g, '')
      if (data.length > 0) {
        return data.slice(0, 30)
      }
    }
    return null
  }

function deprecate (name, fn) {
  var logged = false
  return function () {
    var args = [].slice.call(arguments)
    if (!logged) {
      console.trace('deprecated api used: ' + name)
      logged = true
    }
    return fn.apply(this, args)
  }
}

var parseMultiServerAddress = function (data) {
  if (!isString(data)) return false
  if (!MultiServerAddress.check(data)) return false

  var addr = MultiServerAddress.decode(data)
  addr = addr.find(function (address) {
    if (!address[0]) return false
    if (!address[1]) return false
    return /^(net|wss?|onion)$/.test(address[0].name) && /^shs/.test(address[1].name)
  })
  if (!Array.isArray(addr)) {
    return false
  }
  var port = +addr[0].data.pop() // last item always port, to handle ipv6

  // preserve protocol type on websocket addresses
  var host = (/^wss?$/.test(addr[0].name) ? addr[0].name + ':' : '') + addr[0].data.join(':')
  var key = '@' + addr[1].data[0] + '.ed25519'
  var seed = addr[1].data[2]
  // allow multiserver addresses that are not currently understood!
  if (!(isHost(host) && isPort(+port) && isFeedId(key))) return false
  var address = {
    host: host,
    port: port,
    key: key
  }
  if (seed) { address.seed = seed }

  return address
}

var toLegacyAddress = parseMultiServerAddress
exports.toLegacyAddress = deprecate('ssb-ref.toLegacyAddress', toLegacyAddress)

exports.isLegacyAddress = function (addr) {
  return isObject(addr) && isHost(addr.host) && isPort(addr.port) && isFeedId(addr.key)
}

var toMultiServerAddress = exports.toMultiServerAddress = function (addr) {
  if (MultiServerAddress.check(addr)) return addr
  if (!isPort(addr.port)) throw new Error('ssb-ref.toMultiServerAddress - invalid port:' + addr.port)
  if (!isHost(addr.host)) throw new Error('ssb-ref.toMultiServerAddress - invalid host:' + addr.host)
  if (!isFeedId(addr.key)) throw new Error('ssb-ref.toMultiServerAddress - invalid key:' + addr.key)

  return (
    /^wss?:/.test(addr.host) ? addr.host
      : /\.onion$/.test(addr.host) ? 'onion:' + addr.host
        : 'net:' + addr.host
  ) + ':' + addr.port + '~shs:' + addr.key.substring(1, addr.key.indexOf('.'))
}

var isAddress = exports.isAddress = function (data) {
  var host, port, id
  if (isObject(data)) {
    id = data.key; host = data.host; port = data.port
  } else if (!isString(data)) return false
  else if (isMultiServerAddress(data)) return true
  else {
    var parts = data.split(':')
    id = parts.pop(); port = parts.pop(); host = parts.join(':')
  }
  return (
    isFeedId(id) && isPort(+port) &&
    isHost(host)
  )
}

// This is somewhat fragile, because maybe non-shs protocols get added...
// it would be better to treat all addresses as opaque or have multiserver handle
// extraction of a signing key from the address.
exports.getKeyFromAddress = function (addr) {
  if (addr.key) return addr.key
  try {
    var data = MultiServerAddress.decode(addr)
  } catch (err) {
    console.error(new Error('Attempted connection with malformed multiserver-address ' + addr))
  }
  if (!data) return undefined
  for (var k in data) {
    var address = data[k]
    for (var j in address) {
      var protocol = address[j]
      if (/^shs/.test(protocol.name)) {
        // forwards compatible with future shs versions...
        return '@' + protocol.data[0] + '.ed25519'
      }
    }
  }
}

var parseAddress = function (e) {
  if (isString(e)) {
    if (~e.indexOf('~')) { return parseMultiServerAddress(e) }
    var parts = e.split(':')
    var id = parts.pop(); var port = parts.pop(); var host = parts.join(':')
    e = {
      host: host,
      port: +(port || DEFAULT_PORT),
      key: id
    }
    return e
  }
  return e
}
exports.parseAddress = deprecate('ssb-ref.parseAddress', parseAddress)

var toAddress = exports.toAddress = function (e) {
  e = parseAddress(e)
  e.port = e.port || DEFAULT_PORT
  e.host = e.host || 'localhost'
  return e
}

var legacyInviteRegex = /^[A-Za-z0-9/+]{43}=$/
var legacyInviteFixerRegex = /#.*$/
var isLegacyInvite = exports.isLegacyInvite =
  function (data) {
    if (!isString(data)) return false
    data = data.replace(legacyInviteFixerRegex, '')
    var parts = data.split('~')
    return parts.length === 2 && isAddress(parts[0]) && legacyInviteRegex.test(parts[1])
  }

var isMultiServerInvite = exports.isMultiServerInvite =
  function (data) {
    if (!isString(data)) return false
    return !!parseMultiServerInvite(data)
  }

var isInvite = exports.isInvite =
  function (data) {
    if (!isString(data)) return false
    return isLegacyInvite(data) || isMultiServerInvite(data)
  }

exports.parseLink = function parseBlob (ref) {
  var match = parseLinkRegex.exec(ref)
  if (match && match[1]) {
    if (match[3]) {
      var query = Querystring.parse(match[4])
      // unbox keys have a '+' in them that is parsed into a ' ', this changes it back
      if (isString(query.unbox)) query.unbox = query.unbox.replace(/ /g, '+')
      return { link: match[1], query }
    } else {
      return { link: match[1] }
    }
  }
}

function parseLegacyInvite (invite) {
  var redirect = invite.split('#')
  invite = redirect.shift()
  var parts = invite.split('~')
  var addr = toAddress(parts[0])// .split(':')
  // convert legacy code to multiserver invite code.
  var remote = toMultiServerAddress(addr)
  invite = remote + ':' + parts[1]
  return {
    invite: remote + ':' + parts[1],
    key: addr.key,
    remote: remote,
    redirect: redirect.length ? '#' + redirect.join('#') : null
  }
}

function parseMultiServerInvite (invite) {
  var redirect = invite.split('#')
  if (!redirect.length) return null

  invite = redirect.shift()
  var addr = toLegacyAddress(invite)
  if (!addr) return null
  delete addr.seed
  return {
    invite: invite,
    remote: toMultiServerAddress(addr),
    key: addr.key,
    redirect: redirect.length ? '#' + redirect.join('#') : null
  }
}

exports.parseLegacyInvite = deprecate('ssb-ref.parseLegacyInvite', parseLegacyInvite)
exports.parseMultiServerInvite = deprecate('ssb-ref.parseMultiServerInvite', parseMultiServerInvite)

exports.parseInvite = deprecate('ssb-ref.parseInvite', function (invite) {
  return (
    isLegacyInvite(invite)
      ? parseLegacyInvite(invite)
      : isMultiServerInvite(invite)
        ? parseMultiServerInvite(invite)
        : null
  )
})

exports.type =
  function (id) {
    if (!isString(id)) return false
    var c = id.charAt(0)
    if (c === '@' && isFeedId(id)) { return 'feed' } else if (c === '%' && isMsgId(id)) { return 'msg' } else if (c === '&' && isBlobId(id)) { return 'blob' } else if (isAddress(id)) return 'address'
    else if (isInvite(id)) return 'invite'
    else { return false }
  }

exports.extract =
  function (data) {
    if (!isString(data)) { return false }

    var _data = data

    var res = extractRegex.exec(_data)
    if (res) {
      return res && res[0]
    } else {
      try {
        _data = decodeURIComponent(data)
      } catch (e) {
        // this may fail if it's not encoded, so don't worry if it does
      }
      _data = _data.replace(/&amp;/g, '&')

      res = extractRegex.exec(_data)
      return res && res[0]
    }
  }

},
"i7hs1ROQ5c8UpROCVPsG/HxeXhdrV8iusVB8W5UPuvk=":
function (require, module, exports, __dirname, __filename) {
var pull = require('pull-stream')

function rate (s) {
  var recent = []
  var stream = pull.through(function (d) {
    stream.ts = Date.now()
    recent.push({size: d.length, ts: stream.ts})
    if(recent.length > 5)
      recent.shift()

  })

  stream.ts = Date.now()

  stream.rate = function () {
    var ts = Date.now()
    if(recent.length > 1) {
      var rate = (recent.reduce(function (size, item) {
        return size + item.size
      }, 0)/1000000) / ((ts - recent[0].ts)/1000)

      return rate
    }
  }

  return stream
}

module.exports = rate

},
"iEHVV2tV4tL4wu+KJx29RNWO9GblFOmSYf9anyFqp8c=":
function (require, module, exports, __dirname, __filename) {
module.exports = {
  "_args": [
    [
      "ssb-blobs@1.2.2",
      "/Users/lonmee/Projects/meta_life/nodejs-assets/nodejs-project"
    ]
  ],
  "_from": "ssb-blobs@1.2.2",
  "_id": "ssb-blobs@1.2.2",
  "_inBundle": false,
  "_integrity": "sha512-N+X46lE/KaIH9y1w3LQ9pPnt2tQr5VCSj1dAo/pJGYnSwnHz8GhIiboq7UGzrCZwCWgVUs22/2YiytCXSC9ASg==",
  "_location": "/ssb-blobs",
  "_phantomChildren": {},
  "_requested": {
    "type": "version",
    "registry": true,
    "raw": "ssb-blobs@1.2.2",
    "name": "ssb-blobs",
    "escapedName": "ssb-blobs",
    "rawSpec": "1.2.2",
    "saveSpec": null,
    "fetchSpec": "1.2.2"
  },
  "_requiredBy": [
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/ssb-blobs/-/ssb-blobs-1.2.2.tgz",
  "_spec": "1.2.2",
  "_where": "/Users/lonmee/Projects/meta_life/nodejs-assets/nodejs-project",
  "author": {
    "name": "Dominic Tarr",
    "email": "dominic.tarr@gmail.com",
    "url": "http://dominictarr.com"
  },
  "bugs": {
    "url": "https://github.com/ssbc/ssb-blobs/issues"
  },
  "dependencies": {
    "cont": "^1.0.3",
    "debug": "^4.1.1",
    "level": "^5.0.1",
    "multiblob": "^1.12.0",
    "pull-level": "^2.0.4",
    "pull-notify": "^0.1.0",
    "pull-stream": "^3.3.0",
    "ssb-ref": "^2.3.0"
  },
  "description": "blobs and blob replication for ssb",
  "devDependencies": {
    "interleavings": "^1.0.0",
    "mkdirp": "^0.5.1",
    "osenv": "^0.1.3",
    "pull-bitflipper": "^0.1.0",
    "rimraf": "^2.5.2",
    "secret-stack": "^6.0.1",
    "tape": "^4.5.1"
  },
  "homepage": "https://github.com/ssbc/ssb-blobs",
  "license": "MIT",
  "name": "ssb-blobs",
  "repository": {
    "type": "git",
    "url": "git://github.com/ssbc/ssb-blobs.git"
  },
  "scripts": {
    "test": "set -e; for t in test/*.js; do node $t; done"
  },
  "version": "1.2.2"
}

},
"iH0TcLTxRBPQ09mNvsmD4iv9MaMkB8ZNmder3XPFVwo=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var tester = require('../util/tester')

module.exports = function filter (test) {
  //regexp
  test = tester(test)
  return function (read) {
    return function next (end, cb) {
      var sync, loop = true
      while(loop) {
        loop = false
        sync = true
        read(end, function (end, data) {
          if(!end && !test(data))
            return sync ? loop = true : next(end, cb)
          cb(end, data)
        })
        sync = false
      }
    }
  }
}


},
"iNFmWMaOW92q0y0KBbZ4lp23v+VKyzsbYGydLZaoAGI=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (stream) {
  var read, started = false

  function consume (_read) {
    if(!_read) throw new Error('must be passed a readable')
    read = _read
    if(started) stream(read)
  }

  consume.resolve =
  consume.ready =
  consume.start = function (_stream) {
    started = true; stream = _stream || stream
    if(read) stream(read)
    return consume
  }

  return consume
}

},
"iNs+m8tgrtDQ9g9ihUsrslFd5iDUv/Hx/brMXDbjo6U=":
function (require, module, exports, __dirname, __filename) {

exports.empty = require('./empty')
exports.values = require('./values')
exports.infinite = require('./infinite')

},
"icbkd+UFtlzcBH2FZL1S82H9g+EfjgiTDf75GwYy1gQ=":
function (require, module, exports, __dirname, __filename) {
'use strict'
//a stream that errors immediately.
module.exports = function error (err) {
  return function (abort, cb) {
    cb(err)
  }
}


},
"idd7qu25M925EN8jktnwp9Lp6QUaQ7d5lzrO+4WrzJ4=":
function (require, module, exports, __dirname, __filename) {
var noop = function () {}

function abortAll(ary, abort, cb) {
  var n = ary.length
  if(!n) return cb(abort)
  ary.forEach(function (f) {
    if(f) f(abort, next)
    else next()
  })

  function next() {
    if(--n) return
    cb(abort)
  }
  if(!n) next()
}

module.exports = function (streams) {
  return function (abort, cb) {
    ;(function next () {
      if(abort)
        abortAll(streams, abort, cb)
      else if(!streams.length)
        cb(true)
      else if(!streams[0])
        streams.shift(), next()
      else
        streams[0](null, function (err, data) {
          if(err) {
            streams.shift() //drop the first, has already ended.
            if(err === true) next()
            else             abortAll(streams, err, cb)
          }
          else
            cb(null, data)
        })
    })()
  }
}



},
"ig/61bj+prdFkzKhs5YFZsxSmf+2jvKFpUBfxY4g8A8=":
function (require, module, exports, __dirname, __filename) {
module.exports = {
  "shs": "1KHLiKZvAvjbY1ziZEHMXawbCEIM6qwjCDm3VYRan/s=",
  "sign": null,
  "invite": "HT0wIYuk3OWc2FtaCfHNnakV68jSGRrjRMP9Kos7IQc="
}

},
"ijDe77uaZDBR5WxVfPWIas5CDn1d9ga0e143aW4TUBs=":
function (require, module, exports, __dirname, __filename) {
/*
  better progress algorithm:

  count number of feeds we expect to send to each peer.
  sum of the difference between what they have asked, and what we have sent.

  same for receive, but have to remember what we asked for.
*/

module.exports = function (state) {
  var prog = { start: 0, current: 0, target: 0 }
  for (var peer_id in state.peers) {
    var peer = state.peers[peer_id]

    for (var feed_id in peer.replicating) {
      var rep = peer.replicating[feed_id]
      //progress for sending initial note
      prog.target++
      if (rep.sent != null) prog.current++

      prog.target++
      if (rep.requested != null) prog.current++

      var seq = peer.clock[feed_id]
      var lseq = state.clock[feed_id] || 0

      if (rep.rx && rep.requested != null && rep.requested > -1 && lseq < seq) {
        prog.current += lseq - rep.requested
        prog.target += seq - rep.requested
      }

      if (rep.tx && seq > -1 && seq < lseq) {
        prog.current += rep.sent - seq
        prog.target += lseq - seq
      }
    }
  }

  return prog
}

},
"ikAOguEfEN2DC6+EuZVI5oOYmN2HnlETDh8Rn/xQ4C8=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const debug = require('debug')('ssb:http-auth:client');
const constants_1 = require("./constants");
const solution_1 = require("./solution");
module.exports = {
    name: 'httpAuth',
    version: '1.0.0',
    manifest: {
        sendSolution: 'async',
        requestSolution: 'async',
        invalidateAllSolutions: 'async',
    },
    permissions: {
        anonymous: {
            allow: ['sendSolution', 'requestSolution', 'invalidateAllSolutions'],
        },
    },
    init(ssb, config) {
        return {
            sendSolution(_sc, _cc, _sol, cb) {
                cb(new Error('httpAuth.sendSolution not supported on the client side'));
            },
            requestSolution(sc, cc, cb) {
                if (sc.length < constants_1.NONCE_LENGTH_BASE64) {
                    cb(new Error(`Server nonce "sc" is not ${constants_1.NONCE_LENGTH} bits: ${sc}`));
                    return;
                }
                if (cc.length < constants_1.NONCE_LENGTH_BASE64) {
                    cb(new Error(`Client nonce "cc" is not ${constants_1.NONCE_LENGTH} bits: ${cc}`));
                    return;
                }
                if (!ssb.httpAuthClientTokens.has(cc)) {
                    cb(new Error('The client nonce "cc" is unknown or has expired'));
                    return;
                }
                const cid = ssb.id;
                const sid = this.id;
                debug(`requestSolution where sid=${sid}, cid=${cid}, sc=${sc}, cc=${cc}`);
                const sol = solution_1.solve(config.keys, sid, cid, sc, cc);
                cb(null, sol);
            },
            invalidateAllSolutions(cb) {
                cb(new Error('httpAuth.invalidateAllSolutions not supported on the client side'));
            },
        };
    },
};

},
"ipAeMUD7gTZ/UJ5ca9uKT2OR95ebbUzcr8EGj0N2eOY=":
function (require, module, exports, __dirname, __filename) {
module.exports = 26830;

},
"jW4NYfy5IT7F/a/OMmCnVccFAro2P6EYPbke77c0xpo=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const stop_words_1 = require("./stop-words");
const Plugin = require('ssb-db2/indexes/plugin');
const { seqs } = require('ssb-db2/operators');
const bipf = require('bipf');
const pull = require('pull-stream');
const pl = require('pull-level');
const Ref = require('ssb-ref');
const unicode_word_regex_1 = require("./unicode-word-regex");
const B_0 = Buffer.alloc(0);
const B_VALUE = Buffer.from('value');
const B_CONTENT = Buffer.from('content');
const B_TEXT = Buffer.from('text');
const oneAsciiRegex = /^[a-zA-Z]{1}$/;
const twoLowerCaseAsciiRegex = /^[a-z]{2}$/;
const unicodeWordRegex = unicode_word_regex_1.getUnicodeWordRegex();
const msgIdRegex = new RegExp(Ref.msgIdRegex.source.slice(1, -1), 'g');
const blobIdRegex = new RegExp(Ref.blobIdRegex.source.slice(1, -1), 'g');
const feedIdRegex = new RegExp(Ref.feedIdRegex.source.slice(1, -1), 'g');
const localhostUrlRegex = /https?:\/\/(?:localhost|127\.0\.0\.1)(?::\d+)?(?:[/?#][^\s"]*)?/g;
const urlRegex = /https?:\/\/(?:[a-zA-Z]*[-.]*[a-zA-Z0-9]*\.)?([a-zA-Z0-9]+)\.[a-zA-Z]{2,}(?:[/?#][^\s"]*)?/g;
function findValueContentText(buf) {
    let p = 0;
    p = bipf.seekKey(buf, p, B_VALUE);
    if (p < 0)
        return;
    p = bipf.seekKey(buf, p, B_CONTENT);
    if (p < 0)
        return;
    p = bipf.seekKey(buf, p, B_TEXT);
    if (p < 0)
        return;
    const text = bipf.decode(buf, p);
    if (typeof text !== 'string')
        return;
    if (!text)
        return;
    return text;
}
class WordsIndex extends Plugin {
    constructor(log, dir) {
        super(log, dir, 'search2', 1, 'json', 'binary');
    }
    processRecord(record, seq) {
        let text = findValueContentText(record.value);
        if (!text)
            return;
        text = text.replace(feedIdRegex, '');
        text = text.replace(msgIdRegex, '');
        text = text.replace(blobIdRegex, '');
        text = text.replace(localhostUrlRegex, '');
        text = text.replace(urlRegex, '$1');
        const uniqueLowercaseWords = new Set();
        for (const [word] of text.matchAll(unicodeWordRegex)) {
            if (oneAsciiRegex.test(word))
                continue;
            if (twoLowerCaseAsciiRegex.test(word))
                continue;
            if (stop_words_1.default['en'].includes(word.toLocaleLowerCase()))
                continue;
            uniqueLowercaseWords.add(word.toLocaleLowerCase());
        }
        for (const word of uniqueLowercaseWords) {
            this.batch.push({
                type: 'put',
                key: [word, seq],
                value: B_0,
            });
        }
        uniqueLowercaseWords.clear();
    }
    query(text, cb, onAbort) {
        const terms = [...text.toLocaleLowerCase().matchAll(unicodeWordRegex)].map((result) => result[0]);
        let drainers;
        onAbort(() => {
            var _a;
            while (drainers && drainers.length)
                (_a = drainers.shift()) === null || _a === void 0 ? void 0 : _a.abort();
        });
        const HIT_ALL = 2 ** terms.length - 1;
        const hitsFor = new Map();
        const seqArr = [];
        let ended = 0;
        drainers = terms.map((term, i) => {
            let drainer;
            pull(pl.read(this.level, {
                gte: [term, ''],
                lte: [term + '~', undefined],
                keys: true,
                keyEncoding: this.keyEncoding,
                values: false,
            }), (drainer = pull.drain(([_word, seq]) => {
                if (hitsFor.get(seq) === HIT_ALL)
                    return;
                const hits = hitsFor.get(seq) | (1 << i);
                hitsFor.set(seq, hits);
                if (hits === HIT_ALL) {
                    seqArr.push(seq);
                }
            }, () => {
                if (++ended === terms.length) {
                    cb(null, seqs(seqArr));
                }
            })));
            return drainer;
        });
    }
}
module.exports = WordsIndex;

},
"jZcIkJxgPPvJUSn/GZwG+T7smUrcB25nczaGP1Fv/7Y=":
function (require, module, exports, __dirname, __filename) {
var Buffer = require('safe-buffer').Buffer

module.exports = function (thing, encoding, name) {
  if (Buffer.isBuffer(thing)) {
    return thing
  } else if (typeof thing === 'string') {
    return Buffer.from(thing, encoding)
  } else if (ArrayBuffer.isView(thing)) {
    return Buffer.from(thing.buffer)
  } else {
    throw new TypeError(name + ' must be a string, a Buffer, a typed array or a DataView')
  }
}

},
"je0s82rvO4qSmFDi+lj3VDr97Ad+B249AVdxkBptbag=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.getUnicodeWordRegex = void 0;
function getUnicodeWordRegex() {
    try {
        /\p{Letter}/u.test('a');
        return /\p{Letter}+/giu;
    }
    catch (err) {
        return /([A-Za-z\xAA\xB5\xBA\xC0-\xD6\xD8-\xF6\xF8-\u02C1\u02C6-\u02D1\u02E0-\u02E4\u02EC\u02EE\u0370-\u0374\u0376\u0377\u037A-\u037D\u037F\u0386\u0388-\u038A\u038C\u038E-\u03A1\u03A3-\u03F5\u03F7-\u0481\u048A-\u052F\u0531-\u0556\u0559\u0560-\u0588\u05D0-\u05EA\u05EF-\u05F2\u0620-\u064A\u066E\u066F\u0671-\u06D3\u06D5\u06E5\u06E6\u06EE\u06EF\u06FA-\u06FC\u06FF\u0710\u0712-\u072F\u074D-\u07A5\u07B1\u07CA-\u07EA\u07F4\u07F5\u07FA\u0800-\u0815\u081A\u0824\u0828\u0840-\u0858\u0860-\u086A\u08A0-\u08B4\u08B6-\u08C7\u0904-\u0939\u093D\u0950\u0958-\u0961\u0971-\u0980\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BD\u09CE\u09DC\u09DD\u09DF-\u09E1\u09F0\u09F1\u09FC\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A59-\u0A5C\u0A5E\u0A72-\u0A74\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABD\u0AD0\u0AE0\u0AE1\u0AF9\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3D\u0B5C\u0B5D\u0B5F-\u0B61\u0B71\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BD0\u0C05-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3D\u0C58-\u0C5A\u0C60\u0C61\u0C80\u0C85-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBD\u0CDE\u0CE0\u0CE1\u0CF1\u0CF2\u0D04-\u0D0C\u0D0E-\u0D10\u0D12-\u0D3A\u0D3D\u0D4E\u0D54-\u0D56\u0D5F-\u0D61\u0D7A-\u0D7F\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0E01-\u0E30\u0E32\u0E33\u0E40-\u0E46\u0E81\u0E82\u0E84\u0E86-\u0E8A\u0E8C-\u0EA3\u0EA5\u0EA7-\u0EB0\u0EB2\u0EB3\u0EBD\u0EC0-\u0EC4\u0EC6\u0EDC-\u0EDF\u0F00\u0F40-\u0F47\u0F49-\u0F6C\u0F88-\u0F8C\u1000-\u102A\u103F\u1050-\u1055\u105A-\u105D\u1061\u1065\u1066\u106E-\u1070\u1075-\u1081\u108E\u10A0-\u10C5\u10C7\u10CD\u10D0-\u10FA\u10FC-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u1380-\u138F\u13A0-\u13F5\u13F8-\u13FD\u1401-\u166C\u166F-\u167F\u1681-\u169A\u16A0-\u16EA\u16F1-\u16F8\u1700-\u170C\u170E-\u1711\u1720-\u1731\u1740-\u1751\u1760-\u176C\u176E-\u1770\u1780-\u17B3\u17D7\u17DC\u1820-\u1878\u1880-\u1884\u1887-\u18A8\u18AA\u18B0-\u18F5\u1900-\u191E\u1950-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u1A00-\u1A16\u1A20-\u1A54\u1AA7\u1B05-\u1B33\u1B45-\u1B4B\u1B83-\u1BA0\u1BAE\u1BAF\u1BBA-\u1BE5\u1C00-\u1C23\u1C4D-\u1C4F\u1C5A-\u1C7D\u1C80-\u1C88\u1C90-\u1CBA\u1CBD-\u1CBF\u1CE9-\u1CEC\u1CEE-\u1CF3\u1CF5\u1CF6\u1CFA\u1D00-\u1DBF\u1E00-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FBC\u1FBE\u1FC2-\u1FC4\u1FC6-\u1FCC\u1FD0-\u1FD3\u1FD6-\u1FDB\u1FE0-\u1FEC\u1FF2-\u1FF4\u1FF6-\u1FFC\u2071\u207F\u2090-\u209C\u2102\u2107\u210A-\u2113\u2115\u2119-\u211D\u2124\u2126\u2128\u212A-\u212D\u212F-\u2139\u213C-\u213F\u2145-\u2149\u214E\u2183\u2184\u2C00-\u2C2E\u2C30-\u2C5E\u2C60-\u2CE4\u2CEB-\u2CEE\u2CF2\u2CF3\u2D00-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D80-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u2E2F\u3005\u3006\u3031-\u3035\u303B\u303C\u3041-\u3096\u309D-\u309F\u30A1-\u30FA\u30FC-\u30FF\u3105-\u312F\u3131-\u318E\u31A0-\u31BF\u31F0-\u31FF\u3400-\u4DBF\u4E00-\u9FFC\uA000-\uA48C\uA4D0-\uA4FD\uA500-\uA60C\uA610-\uA61F\uA62A\uA62B\uA640-\uA66E\uA67F-\uA69D\uA6A0-\uA6E5\uA717-\uA71F\uA722-\uA788\uA78B-\uA7BF\uA7C2-\uA7CA\uA7F5-\uA801\uA803-\uA805\uA807-\uA80A\uA80C-\uA822\uA840-\uA873\uA882-\uA8B3\uA8F2-\uA8F7\uA8FB\uA8FD\uA8FE\uA90A-\uA925\uA930-\uA946\uA960-\uA97C\uA984-\uA9B2\uA9CF\uA9E0-\uA9E4\uA9E6-\uA9EF\uA9FA-\uA9FE\uAA00-\uAA28\uAA40-\uAA42\uAA44-\uAA4B\uAA60-\uAA76\uAA7A\uAA7E-\uAAAF\uAAB1\uAAB5\uAAB6\uAAB9-\uAABD\uAAC0\uAAC2\uAADB-\uAADD\uAAE0-\uAAEA\uAAF2-\uAAF4\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB5A\uAB5C-\uAB69\uAB70-\uABE2\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uF900-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFB1D\uFB1F-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBB1\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFB\uFE70-\uFE74\uFE76-\uFEFC\uFF21-\uFF3A\uFF41-\uFF5A\uFF66-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC]|\uD800[\uDC00-\uDC0B\uDC0D-\uDC26\uDC28-\uDC3A\uDC3C\uDC3D\uDC3F-\uDC4D\uDC50-\uDC5D\uDC80-\uDCFA\uDE80-\uDE9C\uDEA0-\uDED0\uDF00-\uDF1F\uDF2D-\uDF40\uDF42-\uDF49\uDF50-\uDF75\uDF80-\uDF9D\uDFA0-\uDFC3\uDFC8-\uDFCF]|\uD801[\uDC00-\uDC9D\uDCB0-\uDCD3\uDCD8-\uDCFB\uDD00-\uDD27\uDD30-\uDD63\uDE00-\uDF36\uDF40-\uDF55\uDF60-\uDF67]|\uD802[\uDC00-\uDC05\uDC08\uDC0A-\uDC35\uDC37\uDC38\uDC3C\uDC3F-\uDC55\uDC60-\uDC76\uDC80-\uDC9E\uDCE0-\uDCF2\uDCF4\uDCF5\uDD00-\uDD15\uDD20-\uDD39\uDD80-\uDDB7\uDDBE\uDDBF\uDE00\uDE10-\uDE13\uDE15-\uDE17\uDE19-\uDE35\uDE60-\uDE7C\uDE80-\uDE9C\uDEC0-\uDEC7\uDEC9-\uDEE4\uDF00-\uDF35\uDF40-\uDF55\uDF60-\uDF72\uDF80-\uDF91]|\uD803[\uDC00-\uDC48\uDC80-\uDCB2\uDCC0-\uDCF2\uDD00-\uDD23\uDE80-\uDEA9\uDEB0\uDEB1\uDF00-\uDF1C\uDF27\uDF30-\uDF45\uDFB0-\uDFC4\uDFE0-\uDFF6]|\uD804[\uDC03-\uDC37\uDC83-\uDCAF\uDCD0-\uDCE8\uDD03-\uDD26\uDD44\uDD47\uDD50-\uDD72\uDD76\uDD83-\uDDB2\uDDC1-\uDDC4\uDDDA\uDDDC\uDE00-\uDE11\uDE13-\uDE2B\uDE80-\uDE86\uDE88\uDE8A-\uDE8D\uDE8F-\uDE9D\uDE9F-\uDEA8\uDEB0-\uDEDE\uDF05-\uDF0C\uDF0F\uDF10\uDF13-\uDF28\uDF2A-\uDF30\uDF32\uDF33\uDF35-\uDF39\uDF3D\uDF50\uDF5D-\uDF61]|\uD805[\uDC00-\uDC34\uDC47-\uDC4A\uDC5F-\uDC61\uDC80-\uDCAF\uDCC4\uDCC5\uDCC7\uDD80-\uDDAE\uDDD8-\uDDDB\uDE00-\uDE2F\uDE44\uDE80-\uDEAA\uDEB8\uDF00-\uDF1A]|\uD806[\uDC00-\uDC2B\uDCA0-\uDCDF\uDCFF-\uDD06\uDD09\uDD0C-\uDD13\uDD15\uDD16\uDD18-\uDD2F\uDD3F\uDD41\uDDA0-\uDDA7\uDDAA-\uDDD0\uDDE1\uDDE3\uDE00\uDE0B-\uDE32\uDE3A\uDE50\uDE5C-\uDE89\uDE9D\uDEC0-\uDEF8]|\uD807[\uDC00-\uDC08\uDC0A-\uDC2E\uDC40\uDC72-\uDC8F\uDD00-\uDD06\uDD08\uDD09\uDD0B-\uDD30\uDD46\uDD60-\uDD65\uDD67\uDD68\uDD6A-\uDD89\uDD98\uDEE0-\uDEF2\uDFB0]|\uD808[\uDC00-\uDF99]|\uD809[\uDC80-\uDD43]|[\uD80C\uD81C-\uD820\uD822\uD840-\uD868\uD86A-\uD86C\uD86F-\uD872\uD874-\uD879\uD880-\uD883][\uDC00-\uDFFF]|\uD80D[\uDC00-\uDC2E]|\uD811[\uDC00-\uDE46]|\uD81A[\uDC00-\uDE38\uDE40-\uDE5E\uDED0-\uDEED\uDF00-\uDF2F\uDF40-\uDF43\uDF63-\uDF77\uDF7D-\uDF8F]|\uD81B[\uDE40-\uDE7F\uDF00-\uDF4A\uDF50\uDF93-\uDF9F\uDFE0\uDFE1\uDFE3]|\uD821[\uDC00-\uDFF7]|\uD823[\uDC00-\uDCD5\uDD00-\uDD08]|\uD82C[\uDC00-\uDD1E\uDD50-\uDD52\uDD64-\uDD67\uDD70-\uDEFB]|\uD82F[\uDC00-\uDC6A\uDC70-\uDC7C\uDC80-\uDC88\uDC90-\uDC99]|\uD835[\uDC00-\uDC54\uDC56-\uDC9C\uDC9E\uDC9F\uDCA2\uDCA5\uDCA6\uDCA9-\uDCAC\uDCAE-\uDCB9\uDCBB\uDCBD-\uDCC3\uDCC5-\uDD05\uDD07-\uDD0A\uDD0D-\uDD14\uDD16-\uDD1C\uDD1E-\uDD39\uDD3B-\uDD3E\uDD40-\uDD44\uDD46\uDD4A-\uDD50\uDD52-\uDEA5\uDEA8-\uDEC0\uDEC2-\uDEDA\uDEDC-\uDEFA\uDEFC-\uDF14\uDF16-\uDF34\uDF36-\uDF4E\uDF50-\uDF6E\uDF70-\uDF88\uDF8A-\uDFA8\uDFAA-\uDFC2\uDFC4-\uDFCB]|\uD838[\uDD00-\uDD2C\uDD37-\uDD3D\uDD4E\uDEC0-\uDEEB]|\uD83A[\uDC00-\uDCC4\uDD00-\uDD43\uDD4B]|\uD83B[\uDE00-\uDE03\uDE05-\uDE1F\uDE21\uDE22\uDE24\uDE27\uDE29-\uDE32\uDE34-\uDE37\uDE39\uDE3B\uDE42\uDE47\uDE49\uDE4B\uDE4D-\uDE4F\uDE51\uDE52\uDE54\uDE57\uDE59\uDE5B\uDE5D\uDE5F\uDE61\uDE62\uDE64\uDE67-\uDE6A\uDE6C-\uDE72\uDE74-\uDE77\uDE79-\uDE7C\uDE7E\uDE80-\uDE89\uDE8B-\uDE9B\uDEA1-\uDEA3\uDEA5-\uDEA9\uDEAB-\uDEBB]|\uD869[\uDC00-\uDEDD\uDF00-\uDFFF]|\uD86D[\uDC00-\uDF34\uDF40-\uDFFF]|\uD86E[\uDC00-\uDC1D\uDC20-\uDFFF]|\uD873[\uDC00-\uDEA1\uDEB0-\uDFFF]|\uD87A[\uDC00-\uDFE0]|\uD87E[\uDC00-\uDE1D]|\uD884[\uDC00-\uDF4A])+/gi;
    }
}
exports.getUnicodeWordRegex = getUnicodeWordRegex;

},
"jhlhpZ0VEFx8CzyctLwC6i43SWm7KHJoRPbVJPefQi8=":
function (require, module, exports, __dirname, __filename) {


module.exports = require('./inject')(require('./store'))

},
"jlYk3dkZh74NvvWycIVRL655poF0Tuy+mQdFjJCZbNI=":
function (require, module, exports, __dirname, __filename) {

//normalize a ws url.
var URL = require('url')
module.exports = function (url, location, protocolMap, defaultProtocol) {
  protocolMap = protocolMap ||{}
  /*

  https://nodejs.org/dist/latest-v6.x/docs/api/url.html#url_url_parse_urlstr_parsequerystring_slashesdenotehost

  I didn't know this, but url.parse takes a 3rd
  argument which interprets "//foo.com" as the hostname,
  but without the protocol. by default, // is interpreted
  as the path.

  that lets us do what the wsurl module does.
  https://www.npmjs.com/package/wsurl

  but most of the time, I want to write js
  that will work on localhost, and will work
  on a server...

  so I want to just do createWebSocket('/')
  and get "ws://mydomain.com/"

  */

  var url = URL.parse(url, false, true)

  var proto
  if(url.protocol) proto = url.protocol
  else {
    proto = location.protocol ? location.protocol.replace(/:$/,'') : 'http'
    proto = ((protocolMap)[proto] || defaultProtocol || proto) + ':'
  }

  //handle quirk in url package
  if(url.host && url.host[0] === ':')
    url.host = null

  //useful for websockets
  if(url.hostname) {
    return URL.format({
      protocol: proto,
      slashes: true,
      hostname: url.hostname,
      port: url.port,
      pathname: url.pathname,
      search: url.search
    })
  }
  else url.host = location.host

  //included for completeness. would you want to do this?
  if(url.port) {
    return URL.format({
      protocol: proto,
      slashes: true,
      host: location.hostname + ':' + url.port,
      port: url.port,
      pathname: url.pathname,
      search: url.search
    })
  }

  //definately useful for websockets
  if(url.pathname) {
    return URL.format({
      protocol: proto,
      slashes: true,
      host: url.host,
      pathname: url.pathname,
      search: url.search
    })
  }
  else
    url.pathname = location.pathname

  //included for completeness. would you want to do this?
  if(url.search) {
    return URL.format({
      protocol: proto,
      slashes: true,
      host: url.host,
      pathname: url.pathname,
      search: url.search
    })
  }
  else url.search = location.search

  return url.format(url)
}






},
"jp9lOh+ob7kYCzYhOaWELxf1731oXTuDJctH/xjwJmE=":
function (require, module, exports, __dirname, __filename) {

var drain = require('./drain')

module.exports = function (reduce, acc, cb) {
  if(!cb) cb = acc, acc = null
  return drain(function (item) {
    acc = reduce(acc, item)
  }, function () {
    cb(null, acc)
  })
}

},
"jyKM70FLOQpwcr/asR5ObYxwOtitTeL1RpczLyYXco8=":
function (require, module, exports, __dirname, __filename) {
if (typeof localStorage === "undefined" || localStorage === null)
  module.exports = require("./fs")
else
  module.exports = require("./browser")

},
"k6uvt6ifD+AMZizY9BAPSu731bCgaLipr4GzjwPSEyU=":
function (require, module, exports, __dirname, __filename) {
const platform = process.env.__TESTING_MKDIRP_PLATFORM__ || process.platform
const { resolve, parse } = require('path')
const pathArg = path => {
  if (/\0/.test(path)) {
    // simulate same failure that node raises
    throw Object.assign(
      new TypeError('path must be a string without null bytes'),
      {
        path,
        code: 'ERR_INVALID_ARG_VALUE',
      }
    )
  }

  path = resolve(path)
  if (platform === 'win32') {
    const badWinChars = /[*|"<>?:]/
    const {root} = parse(path)
    if (badWinChars.test(path.substr(root.length))) {
      throw Object.assign(new Error('Illegal characters in path.'), {
        path,
        code: 'EINVAL',
      })
    }
  }

  return path
}
module.exports = pathArg

},
"kLNE+2h2M6nSj5bQygkmpHV8JjSUIbzQgYr/aXCsmm0=":
function (require, module, exports, __dirname, __filename) {
var quicktask = require('quicktask').default;
var schedule = quicktask();
module.exports = function thenable(readable, prev) {
  return {
    cont: {},
    then: function then(resolve, reject) {
      var cont = this.cont;
      function run() {
        readable(null, function(errOrEnd, data) {
          if (errOrEnd === true) reject(true);
          else if (errOrEnd) reject(errOrEnd);
          else {
            resolve(data);
            if (cont.run) cont.run();
          }
        });
      }
      if (prev) prev.run = run;
      else schedule(run);
      return thenable(readable, cont);
    },
  };
};

},
"kOY7mCKQFTpUGdM5qk1XnVaUR7u8E7uwENICOAnjVu8=":
function (require, module, exports, __dirname, __filename) {
//what happens when you block a same-as

function min (a, b) {
    if(a == null) return b
    if(b == null) return a
    if(Math.abs(a) == Math.abs(b)) {
      return a > b ? a : b
    }
    return Math.abs(a) < Math.abs(b) ? a : b
  }
module.exports =  {
  lt: function (a, b) {
    if(a < 0) return false
    if(a < b) return true
  },
  min: function (a, b) {
    if(min(a,b) != min(b, a)) throw new Error('min not associative:'+a+','+b)
    return min(a, b)
  },
  add: function (a, v) {
    if(a < 0 || v == null) return null
    v = v === 0 ? 0.1 : v
    if(isNaN(v)) throw new Error('edge distance must be a number, was:'+v)
    if(isNaN(v + a)) throw new Error('NaN detected:'+a+', '+v)
    if(v >= 0) return a >= 0 ? a + v : a - v
    else       return a >= 0 ? a*-1 + v : a
  },
  initial: function () {
    return 0
  },
  expand: function (v, max) {
    return v != null && v >= 0 && v < max
  },
  isAdd: function (v) {
    return v >= 0
  },
  isRemove: function (v) {
    return v < 0
  }
}


},
"kUBbIgYLAvRSup7tX8ogxgGnWC85fZEvFlBsZLHOl8Y=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const crypto = require("crypto");
const constants_1 = require("./constants");
const PERIOD = 20e3;
const EXPIRY = 2 * 60e3;
module.exports = {
    name: 'httpAuthClientTokens',
    version: '1.0.0',
    manifest: {
        create: 'sync',
        has: 'sync',
    },
    permissions: {
        anonymous: {},
    },
    init(ssb, _config) {
        var _a;
        const tokens = new Map();
        let interval = null;
        function startInterval() {
            var _a;
            if (interval)
                return;
            interval = setInterval(() => {
                const expired = [];
                const now = Date.now();
                tokens.forEach((birth, cc) => {
                    if (now > birth + EXPIRY)
                        expired.push(cc);
                });
                for (const cc of expired)
                    tokens.delete(cc);
                if (tokens.size === 0)
                    stopInterval();
            }, PERIOD);
            (_a = interval.unref) === null || _a === void 0 ? void 0 : _a.call(interval);
        }
        function stopInterval() {
            if (!interval)
                return;
            clearInterval(interval);
        }
        (_a = ssb.close) === null || _a === void 0 ? void 0 : _a.hook(function (fn, args) {
            stopInterval();
            fn.apply(this, args);
        });
        return {
            create() {
                const nonce = crypto.randomBytes(constants_1.NONCE_LENGTH_BYTE);
                const cc = nonce.toString('base64');
                tokens.set(cc, Date.now());
                startInterval();
                return cc;
            },
            has(cc) {
                return tokens.has(cc);
            },
        };
    },
};

},
"kX3/dabPNkkX8aoya4k75CrGE9M4nWwp35tb9KdglsA=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.ConnScheduler = void 0;
const z = require("ziii");
const secret_stack_decorators_1 = require("secret-stack-decorators");
const ConnQuery = require("ssb-conn-query");
const { hasNoAttempts, hasOnlyFailedAttempts } = ConnQuery;
const pull = require('pull-stream');
const Pausable = require('pull-pause');
const ip = require('ip');
const onWakeup = require('on-wakeup');
const onNetwork = require('on-change-network-strict');
const hasNetworkRightNow = require('has-network2');
const Ref = require('ssb-ref');
const debug = require('debug')('ssb:conn:scheduler');
const SECONDS = 1e3;
const MINUTES = 60e3;
const HOUR = 60 * 60e3;
const RANDOM_MULTIPLIER = 0.8 + Math.random() * 0.4;
let lastCheck = 0;
let lastValue = null;
function hasNetwork() {
    if (lastCheck + 1e3 < Date.now()) {
        lastCheck = Date.now();
        lastValue = hasNetworkRightNow();
    }
    return lastValue;
}
function take(n) {
    return (arr) => arr.slice(0, Math.max(n, 0));
}
function filter(condition) {
    return (arr) => arr.filter(condition);
}
function detectType(peer) {
    const [addr, data] = peer;
    if (data.type === 'bt')
        return 'bt';
    if (data.type === 'lan')
        return 'lan';
    if (data.type === 'internet')
        return 'internet';
    if (data.type === 'dht')
        return 'dht';
    if (data.type === 'pub')
        return 'pub';
    if (data.type === 'room')
        return 'room';
    if (data.type === 'room-endpoint' || data.type === 'room-attendant') {
        if (data.alias)
            return 'room-attendant-alias';
        else
            return 'room-attendant';
    }
    if (data.source === 'local')
        return 'lan';
    if (data.source === 'pub')
        return 'pub';
    if (data.source === 'internet')
        return 'internet';
    if (data.source === 'dht')
        return 'dht';
    if (data.inferredType === 'bt')
        return 'bt';
    if (data.inferredType === 'lan')
        return 'lan';
    if (data.inferredType === 'dht')
        return 'dht';
    if (data.inferredType === 'internet')
        return 'internet';
    if (addr.startsWith('bt:'))
        return 'bt';
    if (addr.startsWith('dht:'))
        return 'dht';
    return '?';
}
const isNotLocalhost = (p) => !ip.isLoopback(p[1].host) && p[1].host !== 'localhost';
function isNotRoom(peer) {
    return peer[1].type !== 'room';
}
function isRoom(peer) {
    return peer[1].type === 'room';
}
function isDefunct(peer) {
    return peer[1].defunct === true;
}
function filterOldExcess(excess) {
    return (peers) => {
        const WAIT_TIME = 2 * MINUTES * RANDOM_MULTIPLIER;
        return peers.filter((p) => Date.now() > p[1].hubUpdated + WAIT_TIME / excess);
    };
}
function sortByOldestConnection(peers) {
    return peers.sort((a, b) => {
        return a[1].hubUpdated - b[1].hubUpdated;
    });
}
function calculateCooldown(fullPercent, hops) {
    return (peers) => {
        return peers.map((peer) => {
            const [, data] = peer;
            const peerType = detectType(peer);
            const normalizedFullPercent = Math.max(0.1, fullPercent);
            const hop = hops[data.key];
            const hopsCooldown = peerType === 'room'
                ? 1 * SECONDS
                : hop === null || hop === void 0 || hop < 0
                    ? Infinity
                    : hop * SECONDS;
            const retryCooldown = 4 * SECONDS + Math.min(64, data.failure || 0) ** 3 * 10 * SECONDS;
            let cooldown = (hopsCooldown + retryCooldown) * normalizedFullPercent;
            if (hasNoAttempts(peer))
                cooldown *= 0.5;
            if (Math.random() < 0.3)
                cooldown *= 0.5;
            if (peerType === 'lan')
                cooldown *= 0.7;
            if (peerType === 'room-attendant')
                cooldown *= 0.8;
            if (hasOnlyFailedAttempts(peer))
                cooldown *= 3;
            data.cooldown = cooldown;
            return peer;
        });
    };
}
function cooledDownEnough(peer) {
    var _a, _b;
    const [, data] = peer;
    const lastAttempt = (_b = (_a = data.stateChange) !== null && _a !== void 0 ? _a : data.hubUpdated) !== null && _b !== void 0 ? _b : 0;
    if (data.cooldown === undefined)
        return true;
    return Date.now() > lastAttempt + data.cooldown;
}
function sortByCooldownAscending(peers) {
    return peers.sort((a, b) => {
        const [, aData] = a;
        const [, bData] = b;
        if (aData.cooldown === undefined)
            return 1;
        if (bData.cooldown === undefined)
            return -1;
        return aData.cooldown - bData.cooldown;
    });
}
let ConnScheduler = class ConnScheduler {
    constructor(ssb, config) {
        this.isBlocked = (peer) => {
            const [, data] = peer;
            if (!(data === null || data === void 0 ? void 0 : data.key))
                return false;
            return this.hops[data.key] === -1;
        };
        this.isNotBlocked = (peer) => {
            return !this.isBlocked(peer);
        };
        this.isNotConnected = (address) => {
            return !this.ssb.conn.hub().getState(address);
        };
        this.start = () => {
            var _a, _b, _c;
            if (!this.closed)
                return;
            this.closed = false;
            this.cleanUpDB();
            this.ssbDB2Subscription = (_a = this.ssb.db) === null || _a === void 0 ? void 0 : _a.post((msg) => {
                if (msg.value.author !== this.ssb.id) {
                    this.lastMessageAt = Date.now();
                }
            });
            this.loadSocialGraph();
            this.setupBluetoothDiscovery();
            this.setupLanDiscovery();
            this.setupRoomAttendantDiscovery();
            this.setupPubDiscovery();
            this.intervalForUpdate = setInterval(() => this.updateSoon(), 2e3);
            (_c = (_b = this.intervalForUpdate) === null || _b === void 0 ? void 0 : _b.unref) === null || _c === void 0 ? void 0 : _c.call(_b);
            onWakeup(() => {
                if (!this.closed)
                    this.ssb.conn.hub().reset();
            });
            onNetwork(() => {
                if (!this.closed)
                    this.ssb.conn.hub().reset();
            });
            pull(this.ssb.conn.hub().listen(), pull.filter((ev) => ev.type === 'disconnected'), pull.drain(() => this.updateSoon(200)));
            this.updateNow();
        };
        this.stop = () => {
            var _a, _b, _c;
            (_a = this.pubDiscoveryPausable) === null || _a === void 0 ? void 0 : _a.pause();
            (_b = this.ssb.lan) === null || _b === void 0 ? void 0 : _b.stop();
            (_c = this.ssbDB2Subscription) === null || _c === void 0 ? void 0 : _c.call(this);
            if (this.intervalForUpdate) {
                clearInterval(this.intervalForUpdate);
                this.intervalForUpdate = void 0;
            }
            this.ssb.conn.hub().reset();
            this.closed = true;
        };
        this.ssb = ssb;
        this.config = config;
        this.closed = true;
        this.lastMessageAt = 0;
        this.lastRotationAt = 0;
        this.hasScheduledAnUpdate = false;
        this.loadedHops = false;
        this.hops = {};
    }
    loadSocialGraph() {
        var _a, _b;
        if (!((_a = this.ssb.friends) === null || _a === void 0 ? void 0 : _a.hopStream)) {
            debug('Warning: ssb-friends@5 is missing, scheduling is degraded');
            this.loadedHops = true;
            return;
        }
        pull((_b = this.ssb.friends) === null || _b === void 0 ? void 0 : _b.hopStream({ live: true, old: true }), pull.drain((h) => {
            this.hops = { ...this.hops, ...h };
            this.loadedHops = true;
        }));
    }
    isCurrentlyDownloading() {
        return this.lastMessageAt && this.lastMessageAt > Date.now() - 500;
    }
    maxWaitToConnect(peer) {
        const type = detectType(peer);
        switch (type) {
            case 'lan':
                return 30e3;
            case 'room-attendant-alias':
                return 30e3;
            case 'bt':
                return 60e3;
            case 'dht':
                return 300e3;
            default:
                return 10e3;
        }
    }
    maintainConnections(quota, isDesiredPeer, pool, isPeerRotatable, rotationPeriod) {
        const query = this.ssb.conn.query();
        const peersUp = query.peersConnected().filter(isDesiredPeer);
        const peersDown = query
            .peersConnectable(pool)
            .filter(isDesiredPeer)
            .filter(this.isNotBlocked)
            .filter(isNotLocalhost)
            .filter(([, data]) => data.autoconnect !== false);
        const excess = peersUp.length > quota * 2 ? peersUp.length - quota : 0;
        const freeSlots = Math.max(quota - peersUp.length, 0);
        const fullPercent = 1 - freeSlots / quota;
        z(peersUp)
            .z(filterOldExcess(excess))
            .z(sortByOldestConnection)
            .z(take(excess))
            .forEach(([addr]) => this.ssb.conn.disconnect(addr));
        const ROTATION_PERIOD = (rotationPeriod * RANDOM_MULTIPLIER) / Math.sqrt(peersDown.length);
        if (freeSlots === 0 &&
            peersDown.length > 0 &&
            this.lastRotationAt + ROTATION_PERIOD < Date.now()) {
            z(peersUp)
                .z(filter(isPeerRotatable !== null && isPeerRotatable !== void 0 ? isPeerRotatable : (() => true)))
                .z(filter(([, data]) => {
                var _a, _b;
                const lastAttempt = (_b = (_a = data.stateChange) !== null && _a !== void 0 ? _a : data.hubUpdated) !== null && _b !== void 0 ? _b : 0;
                return lastAttempt + ROTATION_PERIOD < Date.now();
            }))
                .z(sortByOldestConnection)
                .z(take(1))
                .forEach(([addr]) => {
                this.lastRotationAt = Date.now();
                this.ssb.conn.disconnect(addr);
            });
        }
        z(peersDown)
            .z(calculateCooldown(fullPercent, this.hops))
            .z(filter(cooledDownEnough))
            .z(sortByCooldownAscending)
            .z(take(freeSlots))
            .forEach(([addr, data]) => this.ssb.conn.connect(addr, data));
    }
    updateStagingNow() {
        this.ssb.conn
            .query()
            .peersConnectable('db')
            .filter(this.isNotBlocked)
            .filter(([, data]) => data.autoconnect === false)
            .forEach(([addr, data]) => this.ssb.conn.stage(addr, data));
        this.ssb.conn
            .query()
            .peersConnectable('staging')
            .filter(this.isBlocked)
            .forEach(([addr]) => this.ssb.conn.unstage(addr));
        this.ssb.conn
            .query()
            .peersConnectable('staging')
            .filter(([, data]) => data.type === 'lan')
            .filter(([, data]) => data.stagingUpdated + 10e3 < Date.now())
            .forEach(([addr]) => this.ssb.conn.unstage(addr));
        this.ssb.conn
            .query()
            .peersConnectable('staging')
            .filter(([, data]) => data.type === 'bt')
            .filter(([, data]) => data.stagingUpdated + 30e3 < Date.now())
            .forEach(([addr]) => this.ssb.conn.unstage(addr));
    }
    updateHubNow() {
        this.maintainConnections(5, isRoom, 'db', (p) => p[1].onlineCount === 0, 2 * MINUTES);
        this.maintainConnections(4, isNotRoom, 'dbAndStaging', null, 2 * HOUR);
        this.ssb.conn
            .query()
            .peersInConnection()
            .filter(this.isBlocked)
            .forEach(([addr]) => this.ssb.conn.disconnect(addr));
        this.ssb.conn
            .query()
            .peersInConnection()
            .filter((p) => this.ssb.conn.hub().getState(p[0]) === 'connecting')
            .filter((p) => p[1].stateChange + this.maxWaitToConnect(p) < Date.now())
            .forEach(([addr]) => this.ssb.conn.disconnect(addr));
    }
    updateNow() {
        if (this.closed)
            return;
        if (this.isCurrentlyDownloading())
            return;
        if (!this.loadedHops)
            return;
        if (!hasNetwork())
            return;
        this.updateStagingNow();
        this.updateHubNow();
    }
    updateSoon(period = 1000) {
        if (this.closed)
            return;
        if (this.hasScheduledAnUpdate)
            return;
        const fuzzyPeriod = period * 0.5 + period * Math.random();
        this.hasScheduledAnUpdate = true;
        const timer = setTimeout(() => {
            this.updateNow();
            this.hasScheduledAnUpdate = false;
        }, fuzzyPeriod);
        if (timer.unref)
            timer.unref();
    }
    removeDefunct(addr) {
        this.ssb.conn.db().update(addr, { defunct: void 0, autoconnect: void 0 });
    }
    setupBluetoothDiscovery() {
        var _a;
        if (!((_a = this.ssb.bluetooth) === null || _a === void 0 ? void 0 : _a.nearbyScuttlebuttDevices)) {
            debug('Warning: ssb-bluetooth is missing, scheduling is degraded');
            return;
        }
        pull(this.ssb.bluetooth.nearbyScuttlebuttDevices(1000), pull.drain(({ discovered }) => {
            if (this.closed)
                return;
            for (const btPeer of discovered) {
                const addr = `bt:${btPeer.remoteAddress.split(':').join('')}` +
                    '~' +
                    `shs:${btPeer.id.replace(/^\@/, '').replace(/\.ed25519$/, '')}`;
                const data = {
                    type: 'bt',
                    note: btPeer.displayName,
                    key: btPeer.id,
                };
                if (this.isNotBlocked([addr, data]) && this.isNotConnected(addr)) {
                    this.ssb.conn.stage(addr, data);
                    this.updateSoon(100);
                }
            }
        }));
    }
    setupLanDiscovery() {
        var _a, _b;
        if (!((_a = this.ssb.lan) === null || _a === void 0 ? void 0 : _a.start) || !((_b = this.ssb.lan) === null || _b === void 0 ? void 0 : _b.discoveredPeers)) {
            debug('Warning: ssb-lan is missing, scheduling is degraded');
            return;
        }
        pull(this.ssb.lan.discoveredPeers(), pull.drain(({ address, verified }) => {
            const key = Ref.getKeyFromAddress(address);
            if (!key)
                return;
            const data = {
                type: 'lan',
                key,
                verified,
            };
            if (this.isNotBlocked([address, data]) &&
                this.isNotConnected(address)) {
                this.ssb.conn.stage(address, data);
                this.updateSoon(100);
            }
        }));
        this.ssb.lan.start();
    }
    setupRoomAttendantDiscovery() {
        var _a;
        const timer = setTimeout(() => {
            var _a;
            if (!((_a = this.ssb.roomClient) === null || _a === void 0 ? void 0 : _a.discoveredAttendants)) {
                debug('Warning: ssb-room-client@2 is missing, scheduling is degraded');
                return;
            }
            pull(this.ssb.roomClient.discoveredAttendants(), pull.drain((attendant) => {
                const addr = attendant.address;
                const data = {
                    type: 'room-attendant',
                    key: attendant.key,
                    room: attendant.room,
                    roomName: attendant.roomName,
                };
                if (this.isNotBlocked([addr, data]) && this.isNotConnected(addr)) {
                    this.ssb.conn.stage(addr, data);
                    this.updateSoon(100);
                }
            }));
        }, 100);
        (_a = timer === null || timer === void 0 ? void 0 : timer.unref) === null || _a === void 0 ? void 0 : _a.call(timer);
    }
    setupPubDiscovery() {
        var _a, _b, _c;
        if (((_a = this.config.conn) === null || _a === void 0 ? void 0 : _a.populatePubs) === false)
            return;
        if (!((_b = this.ssb.db) === null || _b === void 0 ? void 0 : _b.operators)) {
            debug('Warning: ssb-db2 is missing, scheduling is degraded');
            return;
        }
        const timer = setTimeout(() => {
            var _a, _b;
            if (this.closed)
                return;
            if (!((_a = this.ssb.db) === null || _a === void 0 ? void 0 : _a.operators))
                return;
            const MAX_STAGED_PUBS = 3;
            const { where, type, live, toPullStream } = this.ssb.db.operators;
            this.pubDiscoveryPausable = (_b = this.pubDiscoveryPausable) !== null && _b !== void 0 ? _b : Pausable();
            pull(this.ssb.db.query(where(type('pub')), live({ old: true }), toPullStream()), pull.filter((msg) => { var _a; return Ref.isAddress((_a = msg.value.content) === null || _a === void 0 ? void 0 : _a.address); }), pull.asyncMap((x, cb) => setTimeout(() => cb(null, x), 250)), this.pubDiscoveryPausable, pull.drain((msg) => {
                try {
                    const address = Ref.toMultiServerAddress(msg.value.content.address);
                    const key = Ref.getKeyFromAddress(address);
                    if (this.isBlocked([address, { key }])) {
                        this.ssb.conn.forget(address);
                    }
                    else if (!this.ssb.conn.db().has(address)) {
                        this.ssb.conn.stage(address, { key, type: 'pub' });
                        this.ssb.conn.remember(address, {
                            key,
                            type: 'pub',
                            autoconnect: false,
                        });
                    }
                }
                catch (err) {
                    debug('cannot process discovered pub because: %s', err);
                }
            }));
            pull(this.ssb.conn.staging().liveEntries(), pull.drain((staged) => {
                var _a, _b;
                if (this.closed)
                    return;
                const stagedPubs = staged.filter(([, data]) => data.type === 'pub');
                if (stagedPubs.length >= MAX_STAGED_PUBS) {
                    (_a = this.pubDiscoveryPausable) === null || _a === void 0 ? void 0 : _a.pause();
                }
                else {
                    (_b = this.pubDiscoveryPausable) === null || _b === void 0 ? void 0 : _b.resume();
                }
            }));
        }, 1000);
        (_c = timer === null || timer === void 0 ? void 0 : timer.unref) === null || _c === void 0 ? void 0 : _c.call(timer);
    }
    cleanUpDB() {
        const roomsWithMembership = new Set();
        for (let peer of this.ssb.conn.dbPeers()) {
            const [address, { source, type, membership }] = peer;
            if (source === 'local' ||
                source === 'bt' ||
                type === 'lan' ||
                type === 'bt') {
                this.ssb.conn.forget(address);
            }
            if (isDefunct(peer)) {
                this.removeDefunct(address);
            }
            if (type === 'room' && membership) {
                roomsWithMembership.add(address);
            }
        }
        for (let [address, data] of this.ssb.conn.dbPeers()) {
            if (data.type === 'room-endpoint' || data.type === 'room-attendant') {
                if (data.alias &&
                    data.roomAddress &&
                    roomsWithMembership.has(data.roomAddress)) {
                    this.ssb.conn.forget(address);
                }
            }
        }
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], ConnScheduler.prototype, "start", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], ConnScheduler.prototype, "stop", void 0);
ConnScheduler = __decorate([
    secret_stack_decorators_1.plugin('1.0.0')
], ConnScheduler);
exports.ConnScheduler = ConnScheduler;

},
"kjarMDG4fOFPkE0j1ksTmuUxzv+ss31VwYKWWR4IU2g=":
function (require, module, exports, __dirname, __filename) {
var get = require('lodash.get')

module.exports = function getNet (config) {
  const conns = get(config, 'connections.incoming.ws', [])

  return (
    conns.find(isPublic) ||
    conns.find(isLocal) ||
    conns.find(isDevice)
  )
}

function isPublic (transport) {
  const scope = 'public' // internet

  return (
    transport.scope === scope ||
    transport.scope.includes(scope)
  )
}

function isLocal (transport) {
  const scopes = [
    'local', // local wifi
    'private' // (alias of local)
  ]

  return scopes.some(s => {
    return transport.scope === s || transport.scope.includes(s)
  })
}

function isDevice (transport) {
  const scope = 'device' // local device only

  return (
    transport.scope === scope ||
    transport.scope.includes(scope)
  )
}

},
"kqkTySq5HILtVHAgmi6fmLuKEBmoX7tVEoz9t26YJ38=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bipf = require('bipf')
const pull = require('pull-stream')
const pl = require('pull-level')
const Plugin = require('./plugin')

const B_VALUE = Buffer.from('value')
const B_AUTHOR = Buffer.from('author')
const B_CONTENT = Buffer.from('content')
const B_TYPE = Buffer.from('type')
const B_ABOUT = Buffer.from('about')

// feedId => hydratedAboutObj
module.exports = class AboutSelf extends Plugin {
  constructor(log, dir) {
    super(log, dir, 'aboutSelf', 3, 'json', 'json')
    this.profiles = {}
  }

  onLoaded(cb) {
    pull(
      pl.read(this.level, {
        gte: '',
        lte: undefined,
        keyEncoding: this.keyEncoding,
        valueEncoding: this.valueEncoding,
        keys: true,
      }),
      pull.drain((data) => (this.profiles[data.key] = data.value), cb)
    )
  }

  processRecord(record, seq) {
    const buf = record.value

    let p = 0 // note you pass in p!
    p = bipf.seekKey(buf, p, B_VALUE)
    if (p < 0) return
    const pAuthor = bipf.seekKey(buf, p, B_AUTHOR)
    const pContent = bipf.seekKey(buf, p, B_CONTENT)
    if (pContent < 0) return
    const pType = bipf.seekKey(buf, pContent, B_TYPE)
    if (pType < 0) return

    if (bipf.compareString(buf, pType, B_ABOUT) === 0) {
      const author = bipf.decode(buf, pAuthor)
      const content = bipf.decode(buf, pContent)
      if (content.about !== author) return

      this.updateProfileData(author, content)

      this.batch.push({
        type: 'put',
        key: author,
        value: this.profiles[author],
      })
    }
  }

  indexesContent() {
    return true
  }

  updateProfileData(author, content) {
    let profile = this.profiles[author] || {}

    if (content.name) profile.name = content.name

    if (content.description) profile.description = content.description

    if (content.image && typeof content.image.link === 'string')
      profile.image = content.image.link
    else if (typeof content.image === 'string') profile.image = content.image

    this.profiles[author] = profile
  }

  getProfile(feedId) {
    return this.profiles[feedId] || {}
  }

  getLiveProfile(feedId) {
    return pl.read(this.level, {
      gte: feedId,
      lte: feedId,
      keyEncoding: this.keyEncoding,
      valueEncoding: this.valueEncoding,
      keys: false,
      live: true,
      old: false,
    })
  }

  getProfiles() {
    return this.profiles
  }
}

},
"kukEw2ejQrFQSyLoq/mQZIyVXu5nX3HQgP+iQbU8T8E=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.default = {
    en: [
        'about',
        'above',
        'actually',
        'after',
        'again',
        'all',
        'almost',
        'along',
        'already',
        'also',
        'although',
        'always',
        'among',
        'an',
        'and',
        'another',
        'any',
        'anybody',
        'anyone',
        'anything',
        'anywhere',
        'are',
        'around',
        'as',
        'ask',
        'asked',
        'asking',
        'asks',
        'at',
        'be',
        'became',
        'because',
        'become',
        'becomes',
        'becoming',
        'been',
        'before',
        'behind',
        'being',
        'better',
        'between',
        'both',
        'but',
        'by',
        'came',
        'can',
        'certain',
        'certainly',
        'clearly',
        'come',
        'consider',
        'considering',
        'could',
        'did',
        'do',
        'does',
        'doing',
        'done',
        'down',
        'downwards',
        'during',
        'each',
        'eg',
        'eight',
        'either',
        'enough',
        'even',
        'ever',
        'every',
        'everybody',
        'everyone',
        'everything',
        'everywhere',
        'ex',
        'exactly',
        'except',
        'far',
        'few',
        'first',
        'five',
        'for',
        'four',
        'from',
        'further',
        'get',
        'gets',
        'given',
        'gives',
        'go',
        'going',
        'got',
        'had',
        'has',
        'have',
        'having',
        'he',
        'her',
        'here',
        'herself',
        'him',
        'himself',
        'his',
        'how',
        'however',
        'ie',
        'if',
        'in',
        'into',
        'is',
        'it',
        'its',
        'itself',
        'just',
        'keep',
        'keeps',
        'knew',
        'know',
        'known',
        'knows',
        'last',
        'later',
        'least',
        'less',
        'let',
        'like',
        'likely',
        'many',
        'may',
        'me',
        'might',
        'more',
        'most',
        'mostly',
        'much',
        'must',
        'my',
        'myself',
        'need',
        'needs',
        'never',
        'new',
        'next',
        'nine',
        'no',
        'nobody',
        'non',
        'not',
        'nothing',
        'now',
        'nowhere',
        'of',
        'off',
        'often',
        'old',
        'on',
        'once',
        'one',
        'only',
        'or',
        'other',
        'others',
        'our',
        'out',
        'over',
        'per',
        'perhaps',
        'please',
        'possible',
        'put',
        'quite',
        'rather',
        'really',
        'right',
        'said',
        'same',
        'saw',
        'say',
        'says',
        'second',
        'see',
        'seem',
        'seemed',
        'seems',
        'seven',
        'several',
        'shall',
        'she',
        'should',
        'since',
        'six',
        'so',
        'some',
        'something',
        'somewhere',
        'still',
        'such',
        'sure',
        'take',
        'taken',
        'ten',
        'than',
        'that',
        'the',
        'their',
        'them',
        'then',
        'there',
        'therefore',
        'therein',
        'thereupon',
        'these',
        'they',
        'third',
        'this',
        'those',
        'though',
        'three',
        'through',
        'thus',
        'to',
        'together',
        'too',
        'took',
        'toward',
        'two',
        'under',
        'until',
        'up',
        'upon',
        'us',
        'use',
        'used',
        'uses',
        'very',
        'want',
        'wanted',
        'wants',
        'was',
        'way',
        'we',
        'well',
        'went',
        'were',
        'what',
        'when',
        'where',
        'whether',
        'which',
        'while',
        'who',
        'whole',
        'whose',
        'why',
        'will',
        'with',
        'within',
        'without',
        'would',
        'yet',
        'you',
        'your',
        'yours',
    ],
};

},
"kyY0pema5Lmak0gYmGaTDoLGVKnsVW712hHlvXK9Ev0=":
function (require, module, exports, __dirname, __filename) {

module.exports = 'undefined' === typeof WebSocket ? require('ws') : WebSocket

},
"l2IwU6xsFEXan/x2xPS/h8CMhbIgsTxAXNU6urAAsCQ=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var drain = require('./drain')

module.exports = function reduce (reducer, acc, cb ) {
  if(!cb) cb = acc, acc = null
  var sink = drain(function (data) {
    acc = reducer(acc, data)
  }, function (err) {
    cb(err, acc)
  })
  if (arguments.length === 2)
    return function (source) {
      source(null, function (end, data) {
        //if ended immediately, and no initial...
        if(end) return cb(end === true ? null : end)
        acc = data; sink(source)
      })
    }
  else
    return sink
}

},
"lOD7p1oqL5sG3n2M87o/mW8Hfeb1TltKtfoBBhT0eWU=":
function (require, module, exports, __dirname, __filename) {
var Pausable = require('pull-pause');
var usage = require('cpu-percentage');

// We need our own drain, should not import from pull-stream
function drain(op, done) {
  var read, abort;
  function sink(_read) {
    read = _read;
    if (abort) return sink.abort();
    (function next() {
      var loop = true;
      var cbed = false;
      while (loop) {
        cbed = false;
        read(null, (end, data) => {
          cbed = true;
          if ((end = end || abort)) {
            loop = false;
            if (done) done(end === true ? null : end);
            else if (end && end !== true) throw end;
          } else if ((op && false === op(data)) || abort) {
            loop = false;
            read(abort || true, done || (() => {}));
          } else if (!loop) {
            next();
          }
        });
        if (!cbed) {
          loop = false;
          return;
        }
      }
    })();
  }
  sink.abort = (err, cb) => {
    if (typeof err === 'function') (cb = err), (err = true);
    abort = err || true;
    if (read) return read(abort, cb || (() => {}));
  };
  return sink;
}

module.exports = function drainGently(a, b, c) {
  var opFirst = !a || typeof a === 'function';
  var opts = opFirst ? {ceiling: 88, wait: 144, maxPause: Infinity} : a;
  var op = opFirst ? a : b;
  var opDone = opFirst ? b : c;
  var ceiling = opts.ceiling;
  var wait = opts.wait;
  var maxPause = opts.maxPause;
  var pausable = Pausable();
  var start = (stats = usage());
  var lastResume = Date.now()
  var step = 2,
    i = 0;

  function checkpoint() {
    stats = usage(start);
    if (
      stats.percent < ceiling || // "CPU is cold enough"
      stats.time < 20 || // "we just now began draining"
      Date.now() - lastResume > maxPause // "remained paused for too long"
    ) {
      step = step << 1 || 1;
      lastResume = Date.now()
      pausable.resume();
    } else {
      step = step >> 1 || 1;
      pausable.pause();
      setTimeout(checkpoint, wait);
    }
  }

  function opWrapper(x) {
    var res;
    if (op) res = op(x);
    if (++i >= step) {
      i = 0;
      checkpoint();
    }
    return res;
  }

  // The below does `return pull(pausable, drain(opWrapper, opDone))`:
  var _sink = drain(opWrapper, opDone);
  function sink(read) {
    _sink(pausable(read));
  }
  sink.abort = _sink.abort;
  return sink;
};

},
"lOsxLWvDh9oFvVCijNGrR2iC+dtdL8ipsbKaPsjzyvw=":
function (require, module, exports, __dirname, __filename) {

const abortCb = require('pull-stream/util/abort-cb')

module.exports = source

function source (promise, onAbort) {
  var read = false

  return function (abort, cb) {
    if (abort) return abortCb(cb, abort, onAbort)

    promise.then(function (v) {
      if (read === false) {
        cb(null, v)
        read = true
      } else {
        cb(true)
      }
    }).catch(cb)
  }
}

},
"lqba57wshQ1ewL/FaQpvlzUvhJgj8qnhTopraWplcQw=":
function (require, module, exports, __dirname, __filename) {
var varint = require('varint')

var STRING = 0 // 000
var BUFFER = 1 // 001

var INT = 2 // 010 // 32bit int
var DOUBLE = 3 // 011 // use next 8 bytes to encode 64bit float

var ARRAY = 4 // 100
var OBJECT = 5 // 101

var BOOLNULL = 6 // 110 // and use the rest of the byte as true/false/null
var RESERVED = 7 // 111

var TAG_SIZE = 3
var TAG_MASK = 7

//sets buffer, and returns length
var encoders = [
  function String(string, buffer, start) {
    return buffer.write(string, start)
  },
  function Buffer(b, buffer, start) {
    b.copy(buffer, start, 0, b.length)
    return b.length
  },
  function Integer(i, buffer, start) {
    buffer.writeInt32LE(i, start)
    return 4
  },
  function Double(d, buffer, start) {
    buffer.writeDoubleLE(d, start)
    return 8
  },
  function Array(a, buffer, start) {
    var p = start
    for (var i = 0; i < a.length; i++) {
      p += encode(a[i], buffer, p)
    }
    return p - start
  },
  function Object(o, buffer, start) {
    var p = start
    for (var k in o) {
      //TODO filter non json types
      p += encode(k, buffer, p)
      p += encode(o[k], buffer, p)
    }
    return p - start
  },
  function Boolean(b, buffer, start) {
    if (b !== null) buffer[start] = b === false ? 0 : b === true ? 1 : 2 // undefined
    return b === null ? 0 : 1
  },
]

var encodingLengthers = [
  function String(string) {
    return Buffer.byteLength(string)
  },
  function Buffer(b) {
    return b.length
  },
  function Integer(i) {
    return 4
  },
  function Double(d) {
    return 8
  },
  function Array(a) {
    var bytes = 0
    for (var i = 0; i < a.length; i++) bytes += encodingLength(a[i])
    return bytes
  },
  function Object(o) {
    var bytes = 0
    for (var k in o) bytes += encodingLength(k) + encodingLength(o[k])
    return bytes
  },
  function boolnull(b, buffer, start) {
    return b === null ? 0 : 1 // encode null as zero length!
  },
]

function decode_string(buffer, start, length) {
  return buffer.toString('utf8', start, start + length)
}

function decode_buffer(buffer, start, length) {
  return buffer.slice(start, start + length)
}

function decode_integer(buffer, start, length) {
  return buffer.readInt32LE(start) //TODO: encode in minimum bytes
}

function decode_double(buffer, start, length) {
  return buffer.readDoubleLE(start) //TODO: encode in minimum bytes
}

function decode_array(buffer, start, length) {
  var a = []
  for (var c = 0; c < length; ) {
    var tag = varint.decode(buffer, start + c)
    var type = tag & TAG_MASK
    if (type === 7) throw new Error('reserved type')
    var len = tag >> TAG_SIZE
    c += varint.decode.bytes
    var value = decode_type(type, buffer, start + c, len)
    a.push(value)
    c += len
  }
  return a
}

function decode_object(buffer, start, length) {
  var o = {}
  for (var c = 0; c < length; ) {
    var tag = varint.decode(buffer, start + c)
    // JavaScript only allows string-valued and Symbol keys for objects
    if (tag & TAG_MASK) throw new Error('required type:string')
    var len = tag >> TAG_SIZE
    c += varint.decode.bytes
    var key = decode_string(buffer, start + c, len)
    c += len

    var tag2 = varint.decode(buffer, start + c)
    var type2 = tag2 & TAG_MASK
    if (type2 === 7) throw new Error('reserved type:value')
    var len2 = tag2 >> TAG_SIZE
    c += varint.decode.bytes
    var value = decode_type(type2, buffer, start + c, len2)
    c += len2
    o[key] = value
  }
  return o
}

function decode_boolnull(buffer, start, length) {
  if (length === 0) return null
  if (buffer[start] > 2) throw new Error('invalid boolnull')
  if (length > 1) throw new Error('invalid boolnull, length must = 1')
  return buffer[start] === 0 ? false : buffer[start] === 1 ? true : undefined
}

function getType(value) {
  if ('string' === typeof value || value instanceof Date) return STRING
  else if (Buffer.isBuffer(value)) return BUFFER
  else if (Number.isInteger(value) && Math.abs(value) <= 4294967296) return INT
  else if ('number' === typeof value && Number.isFinite(value))
    //do not support Infinity or NaN (because JSON)
    return DOUBLE
  else if (Array.isArray(value)) return ARRAY
  else if (value && 'object' === typeof value) return OBJECT
  else if ('boolean' === typeof value || null == value) return BOOLNULL //boolean, null, undefined
}

function encodingLength(value) {
  var type = getType(value)
  if ('function' !== typeof encodingLengthers[type])
    throw new Error('unknown type:' + type + ', ' + JSON.stringify(value))
  var len = encodingLengthers[type](value)
  return varint.encodingLength(len << TAG_SIZE) + len
}

function slice(buffer, start) {
  var tag_value = varint.decode(buffer, start)
  var length = tag_value >> TAG_SIZE
  return buffer.slice(
    start + varint.decode.bytes,
    start + varint.decode.bytes + length
  )
}

function getEncodedLength(buffer, start) {
  return varint.decode(buffer, start) >> TAG_SIZE
}

function getEncodedType(buffer, start) {
  return varint.decode(buffer, start) & TAG_MASK
}

function encode(value, buffer, start, _len) {
  start = start | 0
  var type = getType(value)
  if ('function' !== typeof encodingLengthers[type])
    throw new Error('unknown type:' + type + ', ' + JSON.stringify(value))
  var len = _len === undefined ? encodingLengthers[type](value) : _len
  //  if(!buffer)
  //    buffer = Buffer.allocUnsafe(len)
  //throw new Error('buffer must be provided')
  varint.encode((len << TAG_SIZE) | type, buffer, start)
  var bytes = varint.encode.bytes
  return encoders[type](value, buffer, start + bytes) + bytes
}

function allocAndEncode(value) {
  var len = encodingLength(value)
  var buffer = Buffer.allocUnsafe(len)
  encode(value, buffer, 0)
  return buffer
}

function decode_type(type, buffer, start, len) {
  switch (type) {
    case STRING:
      return decode_string(buffer, start, len)
    case BUFFER:
      return decode_buffer(buffer, start, len)
    case INT:
      return decode_integer(buffer, start, len)
    case DOUBLE:
      return decode_double(buffer, start, len)
    case ARRAY:
      return decode_array(buffer, start, len)
    case OBJECT:
      return decode_object(buffer, start, len)
    case BOOLNULL:
      return decode_boolnull(buffer, start, len)
    default:
      throw new Error('unable to decode type=' + type + ' ' + buffer)
  }
}

function decode(buffer, start) {
  start = start | 0
  var tag = varint.decode(buffer, start)
  var type = tag & TAG_MASK
  var len = tag >> TAG_SIZE
  var bytes = varint.decode.bytes
  start += bytes
  var value = decode_type(type, buffer, start, len)
  decode.bytes = len + bytes
  return value
}

function seekKey(buffer, start, target) {
  if (start === -1) return -1
  var tag = varint.decode(buffer, start)
  var type = tag & TAG_MASK
  if (type !== OBJECT) return -1
  target = Buffer.isBuffer(target) ? target : Buffer.from(target)
  var targetLength = target.length
  var len = tag >> TAG_SIZE
  for (var c = varint.decode.bytes; c < len; ) {
    var key_tag = varint.decode(buffer, start + c)
    c += varint.decode.bytes
    var key_len = key_tag >> TAG_SIZE
    var key_type = key_tag & TAG_MASK
    if (key_type === STRING && targetLength === key_len)
      if (
        buffer.compare(
          target,
          0,
          targetLength,
          start + c,
          start + c + targetLength
        ) === 0
      )
        return start + c + key_len

    c += key_len
    var value_tag = varint.decode(buffer, start + c)
    c += varint.decode.bytes
    var value_len = value_tag >> TAG_SIZE
    c += value_len
  }
  return -1
}

function seekKey2(buffer, start, target, t_start) {
  var tag = varint.decode(buffer, start)
  var type = tag & TAG_MASK
  if (type !== OBJECT) return -1
  var c = varint.decode.bytes
  var len = tag >> TAG_SIZE
  var t_tag = varint.decode(target, t_start)
  var t_length = (t_tag >> TAG_SIZE) + varint.decode.bytes
  for (; c + t_length < len; ) {
    var b_tag = varint.decode(buffer, start + c)
    if (
      b_tag === t_tag &&
      buffer.compare(
        target,
        t_start,
        t_length,
        start + c,
        start + c + t_length
      ) === 0
    )
      return start + c + (b_tag >> TAG_SIZE) + varint.decode.bytes
    else {
      c += (b_tag >> TAG_SIZE) + varint.decode.bytes //key
      c += (varint.decode(buffer, start + c) >> TAG_SIZE) + varint.decode.bytes //value
    }
  }
  return -1
}

// TODO rewrite the seek methods so that there is minimal copies.

function seekPath(buffer, start, target, target_start) {
  target_start = target_start || 0
  var ary = decode(target, target_start)
  if (!Array.isArray(ary)) throw new Error('path must be encoded array')
  for (var i = 0; i < ary.length; i++) {
    var string = ary[i]
    start = seekKey(buffer, start, string)
    if (start === -1) return -1
  }
  return start
}

//for some reason, seek path
function createSeekPathSrc(target) {
  return (
    '"use strict";\n' + //go fast sauce!
    target
      .map(function (e, i) {
        return '  var k' + i + ' = Buffer.from(' + JSON.stringify(e) + ');' //strings only!
      })
      .join('\n') +
    '\n' +
    '  return function (buffer, start) {\n' +
    target
      .map(function (_, i) {
        return '  start = seekKey(buffer, start, k' + i + ')'
      })
      .join('\n') +
    '\n' +
    '  return start;\n' +
    '}\n'
  )
}

function createSeekPath(target) {
  return new Function('seekKey', createSeekPathSrc(target))(seekKey)
}

function compareString(buffer, start, target) {
  if (start === -1) return null
  target = Buffer.isBuffer(target) ? target : Buffer.from(target)
  var tag = varint.decode(buffer, start)
  if ((tag & TAG_MASK) !== STRING) return null
  var len = tag >> TAG_SIZE
  var _len = Math.min(target.length, len)
  return (
    buffer.compare(
      target,
      0,
      _len,
      start + varint.decode.bytes,
      start + varint.decode.bytes + _len
    ) || target.length - len
  )
}

function isNull(tag) {
  return tag === 6
}
function isUndefined(tag, firstByte) {
  // prettier-ignore
  return tag === 0xE && firstByte === 2
}

function compare(buffer1, start1, buffer2, start2) {
  //handle null pointers...
  //  console.log(start1, start2)
  if (start1 === -1 || start2 === -1) return start1 - start2

  var tag1 = varint.decode(buffer1, start1)
  var len1 = varint.decode.bytes
  var tag2 = varint.decode(buffer2, start2)
  var len2 = varint.decode.bytes
  var type1 = tag1 & TAG_MASK
  var type2 = tag2 & TAG_MASK

  //null, lowest value
  if (isNull(tag1)) return isNull(tag2) ? 0 : -1
  else if (isNull(tag2)) return 1

  //undefined, highest value
  if (isUndefined(tag1, buffer1[start1 + 1]))
    return isUndefined(tag2, buffer2[start2 + 1]) ? 0 : 1
  else if (isUndefined(tag2, buffer2[start2 + 1])) return -1

  //allow comparison of number types. **javascriptism**
  //maybe it's better to just have one number type? how can I make a varint double?
  if (type1 === INT && type2 === DOUBLE)
    return (
      buffer1.readInt32LE(start1 + len1) - buffer2.readDoubleLE(start2 + len2)
    )

  if (type1 === DOUBLE && type2 === INT)
    return (
      buffer1.readDoubleLE(start1 + len1) - buffer2.readInt32LE(start2 + len2)
    )

  if (type1 !== type2) return type1 - type2
  //if they are the same type, compare encoded value.
  //TODO: compare by type semantics...
  if (type1 === DOUBLE)
    return (
      buffer1.readDoubleLE(start1 + len1) - buffer2.readDoubleLE(start2 + len2)
    )
  if (type1 === INT)
    return (
      buffer1.readInt32LE(start1 + len1) - buffer2.readInt32LE(start2 + len2)
    )

  return buffer1.compare(
    buffer2,
    start2 + len2,
    start2 + len2 + (tag2 >> TAG_SIZE),
    start1 + len1,
    start1 + len1 + (tag1 >> TAG_SIZE)
  )
}

function iterate(buffer, start, iter) {
  var tag = varint.decode(buffer, start)
  var len = tag >> TAG_SIZE
  var type = tag & TAG_MASK
  if (type === OBJECT) {
    for (var c = varint.decode.bytes; c < len; ) {
      var key_start = start + c
      var key_tag = varint.decode(buffer, key_start)
      c += varint.decode.bytes
      c += key_tag >> TAG_SIZE
      var value_start = start + c
      var value_tag = varint.decode(buffer, value_start)
      var next_start = varint.decode.bytes + (value_tag >> TAG_SIZE)
      if (iter(buffer, value_start, key_start)) return start
      c += next_start
    }
    return start
  } else if (type === ARRAY) {
    var i = 0
    for (var c = varint.decode.bytes; c < len; ) {
      if (iter(buffer, start + c, i++)) return start
      var value_tag = varint.decode(buffer, start + c)
      c += varint.decode.bytes + (value_tag >> TAG_SIZE)
    }
    return start
  } else return -1
}

function createCompareAt(paths) {
  var getPaths = paths.map(createSeekPath)
  return function (a, b) {
    for (var i = 0; i < getPaths.length; i++) {
      var _a = getPaths[i](a, 0)
      var _b = getPaths[i](b, 0)
      var r = compare(a, _a, b, _b)
      if (r) return r
    }
    return 0
  }
}

module.exports = {
  encode: encode,
  decode: decode,
  allocAndEncode: allocAndEncode,
  encodingLength: encodingLength,
  buffer: true,
  slice: slice,
  getValueType: getType,
  getEncodedLength: getEncodedLength,
  getEncodedType: getEncodedType,
  seekKey: seekKey,
  seekKey2: seekKey2,
  createSeekPath: createSeekPath,
  seekPath: seekPath,
  compareString: compareString,
  compare: compare,
  createCompareAt: createCompareAt,
  iterate: iterate,
  types: {
    string: STRING,
    buffer: BUFFER,
    int: INT,
    double: DOUBLE,
    array: ARRAY,
    object: OBJECT,
    boolnull: BOOLNULL,
    reserved: RESERVED,
  },
}

},
"m6a2DG/HlwoJKhEG4Gt3lmhodGzghRbD2liCnEWLyOQ=":
function (require, module, exports, __dirname, __filename) {
var getNet = require('./get-net')
var getWS = require('./get-ws')
var defaultPorts = require('../default-ports')

// *** BACKSTORY ***
// there has been an evolution of how connection host:port and ws are set
// historically you have been able to set host, port net connections,
// and we want to keep this behaviour to support legacy code, and easy CLI setting
//
// we also want to support the new connections.incoming style
// this code:
//   - checks that a user is not declaring conflicting settings
//      (so new/ old parts of the stack don't run divergent config!)
//   - writes host,port,ws settings based on the connections.incoming setting

module.exports = function fixConnections (config) {
  const net = getNet(config) || {}
  const ws = getWS(config) || {}

  // Add default ports
  if (net.host && !net.port) net.port = config.port || defaultPorts.net
  if (ws.host && !ws.port) ws.port = config.port || defaultPorts.ws

  // [LEGACY] ensure host:port + ws are set
  var errors = []
  if (config.host && net.host) {
    if (config.host !== net.host) errors.push('net host')
  }
  if (config.port && net.port) {
    if (config.port !== net.port) errors.push('net port')
  }
  if (config.ws && config.ws.port && ws.port) {
    if (config.ws.port !== ws.port) errors.push('ws port')
  }

  if (errors.length) {
    const message = 'ssb-config: conflicting connection settings for: ' + errors.join(', ')
    throw new Error(message)
  }

  // LEGACY - ensure host and port are set
  // (but based on new connections config style)
  config.host = net.host || ws.host
  config.port = net.port
  config.ws = ws

  return config
}

},
"mJ1Mb97wyF/JYKHtacPJzv4XFtJkBvQS68qNva21Y08=":
function (require, module, exports, __dirname, __filename) {
var sleepCheckInterval
var lastSleepCheck = false
var SLEEP_CHECK_INTERVAL = 10e3
var NUM_MISSABLE_INTERVALS = 3
var EE = require('events')
var emitter = new EE()

module.exports = function (cb) {
  emitter.on('wakeup', cb)

  if (!sleepCheckInterval) {
    // setup interval
    sleepCheckInterval = setInterval(function () {
      var t = Date.now()
      if (lastSleepCheck && (t - lastSleepCheck) > SLEEP_CHECK_INTERVAL*NUM_MISSABLE_INTERVALS)
        emitter.emit('wakeup') // missed NUM_MISSABLE_INTERVALS checks, let's run the callbacks 
      lastSleepCheck = t
    }, SLEEP_CHECK_INTERVAL)
  }
  
  // unreference the timer so that the program can close
  if (sleepCheckInterval.unref)
    sleepCheckInterval.unref()

  return sleepCheckInterval
}

},
"moain6NKmbhh5wc0X7HR4uVabCPtuPmSvtV8xgf0LY4=":
function (require, module, exports, __dirname, __filename) {

/**
 * For Node.js, simply re-export the core `util.deprecate` function.
 */

module.exports = require('util').deprecate;

},
"mv08HRBnnsICLk0zCcodkRt8u9Hmsh2jmrS0b2QVvvg=":
function (require, module, exports, __dirname, __filename) {
const SourceDest = {
  source: {
    type: 'FeedId',
    description: 'the feed which posted the contact message'
  },
  dest: {
    type: 'FeedId',
    description: 'the feed the contact message pointed at'
  }
}

const HopsOpts = {
  start: {
    type: 'FeedId',
    description: 'feed at which to start traversing graph from, default to your own feed id'
  },
  max: {
    type: 'number',
    description: 'include feeds less than or equal to this number of hops'
  }
}

const StreamOpts = Object.assign(
  HopsOpts, {
    live: {
      type: 'boolean',
      description: 'include real time results, defaults to false'
    },
    old: {
      type: 'boolean',
      description: 'include old results, defaults to true'
    }
  }
)

module.exports = {
  description: 'track what feeds are following or blocking each other',
  commands: {
    isFollowing: {
      type: 'async',
      description: 'check if a feed is following another',
      args: SourceDest
    },
    isBlocking: {
      type: 'async',
      description: 'check if a feed is blocking another',
      args: SourceDest
    },
    hops: {
      type: 'async',
      description: 'dump the map of hops, show all feeds, and how far away they are from start',
      args: HopsOpts
    },
    hopStream: {
      type: 'source',
      description: 'stream real time changes to hops. output is series of `{<FeedId>: <hops>,...}` merging these together will give the output of hops',
      args: StreamOpts
    },

    get: {
      type: 'async',
      description: 'dump internal state of friends plugin, the stored follow graph',
      args: {}
    },
    stream: {
      type: 'source',
      description: 'stream real time changes to graph. of hops, output of `get`, followed by {from: <FeedId>, to: <FeedId>: value: true|null|false, where true represents follow, null represents unfollow, and false represents block.',
      args: StreamOpts
    },
    createFriendStream: {
      type: 'source',
      description: 'same as `stream`, but output is series of `{id: <FeedId>, hops: <hops>}`',
      args: StreamOpts
    }
  }
}

},
"my3Mtk8msQFkFs5faZG4tS0EjwmtODFORzhSxcgleDM=":
function (require, module, exports, __dirname, __filename) {
var cont = require('continuable')

exports = module.exports = function (fun) {
  return cont.to(fun)
}

for(var k in cont)
  exports[k] = cont[k]

exports.para = require('continuable-para')
exports.series = require('continuable-series')

},
"n4CGggNJyMn+JKT8JsASRAWx0CF5ZzurUGes9wLMyTM=":
function (require, module, exports, __dirname, __filename) {
var AbstractIterator = require('abstract-leveldown').AbstractIterator
var inherits = require('inherits')

function DeferredIterator (db, options) {
  AbstractIterator.call(this, db)

  this._options = options
  this._iterator = null
  this._operations = []
}

inherits(DeferredIterator, AbstractIterator)

DeferredIterator.prototype.setDb = function (db) {
  var it = this._iterator = db.iterator(this._options)
  this._operations.forEach(function (op) {
    it[op.method].apply(it, op.args)
  })
}

DeferredIterator.prototype._operation = function (method, args) {
  if (this._iterator) return this._iterator[method].apply(this._iterator, args)
  this._operations.push({ method: method, args: args })
}

'next end'.split(' ').forEach(function (m) {
  DeferredIterator.prototype['_' + m] = function () {
    this._operation(m, arguments)
  }
})

// Must defer seek() rather than _seek() because it requires db._serializeKey to be available
DeferredIterator.prototype.seek = function () {
  this._operation('seek', arguments)
}

module.exports = DeferredIterator

},
"nE3FfVy09zeoqtOb2QPPhqMDmYweZPnssE1SJZU42xk=":
function (require, module, exports, __dirname, __filename) {
var looper = require('looper')

module.exports = function (writer, ender) {
  return function (read) {
    var queue = [], ended, error

    function enqueue (data) {
      queue.push(data)
    }

    writer = writer || function (data) {
      this.queue(data)
    }

    ender = ender || function () {
      this.queue(null)
    }

    var emitter = {
      emit: function (event, data) {
        if(event == 'data') enqueue(data)
        if(event == 'end')  ended = true, enqueue(null)
        if(event == 'error') error = data
      },
      queue: enqueue
    }
    var _cb
    return function (end, cb) {
      ended = ended || end
      if(end)
        return read(end, function () {
          if(_cb) {
            var t = _cb; _cb = null; t(end)
          }
          cb(end)
        })

      _cb = cb
      looper(function pull (next) {
        //if it's an error
        if(!_cb) return
        cb = _cb
        if(error) _cb = null, cb(error)
        else if(queue.length) {
          var data = queue.shift()
          _cb = null,cb(data === null, data)
        }
        else {
          read(ended, function (end, data) {
             //null has no special meaning for pull-stream
            if(end && end !== true) {
              error = end; return next()
            }
            if(ended = ended || end)  ender.call(emitter)
            else if(data !== null) {
              writer.call(emitter, data)
              if(error || ended)
                return read(error || ended, function () {
                  _cb = null; cb(error || ended)
                })
            }
            next(pull)
          })
        }
      })
    }
  }
}


},
"nJL/dqbqreskZ1hfmziKpRGw7JzGShFX7hpYB0bica8=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var $Object = Object;
var $TypeError = TypeError;

module.exports = function flags() {
	if (this != null && this !== $Object(this)) {
		throw new $TypeError('RegExp.prototype.flags getter called on non-object');
	}
	var result = '';
	if (this.global) {
		result += 'g';
	}
	if (this.ignoreCase) {
		result += 'i';
	}
	if (this.multiline) {
		result += 'm';
	}
	if (this.dotAll) {
		result += 's';
	}
	if (this.unicode) {
		result += 'u';
	}
	if (this.sticky) {
		result += 'y';
	}
	return result;
};

},
"nP40HJesq/zYmYY9CtXsQPha934F3omdk4vyEHx/6DY=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var u = require("../util");
var Shs = require('multiserver/plugins/shs');
function toBuffer(base64) {
    if (Buffer.isBuffer(base64))
        return base64;
    var i = base64.indexOf('.');
    return Buffer.from(~i ? base64.substring(0, i) : base64, 'base64');
}
function toSodiumKeys(keys) {
    if (typeof keys.public !== 'string' || typeof keys.private !== 'string') {
        return keys;
    }
    return {
        publicKey: toBuffer(keys.public),
        secretKey: toBuffer(keys.private)
    };
}
module.exports = {
    name: 'multiserver-shs',
    version: '1.0.0',
    init: function (api, config) {
        var _a, _b, _c;
        var timeoutHandshake;
        if (!isNaN((_a = config.timers) === null || _a === void 0 ? void 0 : _a.handshake)) {
            timeoutHandshake = (_b = config.timers) === null || _b === void 0 ? void 0 : _b.handshake;
        }
        if (!timeoutHandshake) {
            timeoutHandshake = (config.timers ? 15e3 : 5e3);
        }
        if (config.timeout) {
            timeoutHandshake = config.timeout;
        }
        var shsCap = (_c = (config.caps && config.caps.shs)) !== null && _c !== void 0 ? _c : config.appKey;
        if (!shsCap) {
            throw new Error('secret-stack/plugins/shs must have caps.shs configured');
        }
        var shs = Shs({
            keys: config.keys && toSodiumKeys(config.keys),
            seed: config.seed,
            appKey: toBuffer(shsCap),
            timeout: timeoutHandshake,
            authenticate: function (pub, cb) {
                var id = '@' + u.toId(pub);
                api.auth(id, function (err, auth) {
                    if (err)
                        cb(err);
                    else
                        cb(null, auth || true);
                });
            }
        });
        var id = '@' + u.toId(shs.publicKey);
        api.id = id;
        api.publicKey = id;
        api.multiserver.transform({
            name: 'shs',
            create: function () { return shs; }
        });
    }
};

},
"nVJ+N1U99iiq9YmyakUHVN/k7LAk2VQPq2nEmud3gGE=":
function (require, module, exports, __dirname, __filename) {
var BlobId = {
  type: 'BlobId',
  description: 'the hash of the blob, in ssb blob id format: &{hash-as-base64}.{hash-algorithum}',
  optional: false
}

var BlobOpts = {
  id: BlobId
}

module.exports = {
  description: 'retrive, store, and share blobs',
  commands: {
    add: {
      type: 'sink',
      description: 'add a blob',
      args: {
        id: Object.assign(BlobId, {optional: true})
      }
    },
    get: {
      type: 'source',
      description: 'get a blob',
      args: BlobOpts
    },
    getSlice: {
      type: 'source'
,     description: 'get part of a blob',
      args: {
        id: BlobId,
        size: {
          type: 'number',
          description: 'reject if not exactly this size',
          optional: true
        },
        max: {
          type: 'number',
          description: 'reject if more than this size',
          optional: true
        },
        start: {
          type: 'number',
          description: 'start stream from this byte',
          optional: true
        },
        end: {
          type: 'number',
          description: 'stream until this byte',
          optional: true
        }
      }
    },
    has: {
      type: 'async',
      description: 'check if a blob is in the local store',
      args: BlobOpts
    },
    size: {
      type: 'async',
      description: 'get the size for a blob in the local store',
      args: BlobOpts
    },
    want: {
      type: 'async',
      description: 'request a blob from the network, wait until found or timeout',
      args: BlobOpts
    },
    push: {
      type: 'async',
      description: 'ask the network to take the blob, wait until at least 3 peers have it',
      args: BlobOpts
    },
    rm: {
      type: 'async',
      description: 'remove a blob from the local store',
      args: BlobOpts
    },
    ls: {
      type: 'source',
      description: 'list all blobs',
      args: {
        meta: {
          type: 'boolean',
          description: 'include all metadata, id, size, receive timestamp',
          optional: true
        },
        long: {
          type: 'boolean',
          description: 'long format, like in `ls -l synonym for --meta. `',
          optional: true
        },
        old: {
          type: 'boolean',
          description: 'include old data, default: true',
          optional: true
        },
        live: {
          type: 'boolean',
          description: 'stream real time changes, default: false',
          optional: true
        }
      }
    }
  }

}

















},
"niN9ewvht3fE9moc8XWMebNBifnM/0WKOAdoePiTIk4=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var sodium = require("chloride");

module.exports = {
  curves: ["ed25519"],

  generate: function (seed) {
    if (!seed) sodium.randombytes((seed = Buffer.alloc(32)));

    var keys = seed
      ? sodium.crypto_sign_seed_keypair(seed)
      : sodium.crypto_sign_keypair();
    return {
      curve: "ed25519",
      public: keys.publicKey,

      //so that this works with either sodium
      //or libsodium-wrappers (in browser)
      private: keys.privateKey || keys.secretKey,
    };
  },

  sign: function (privateKey, message) {
    return sodium.crypto_sign_detached(message, privateKey);
  },

  verify: function (publicKey, sig, message) {
    return sodium.crypto_sign_verify_detached(sig, message, publicKey);
  },
};

},
"oKxecXS+ExfxPnCAlaCsLAYOIJ3m/bKnF0qZ6fDcXok=":
function (require, module, exports, __dirname, __filename) {
var compose = require('./compose')
var isArray = Array.isArray
var multicb = require('multicb')

function split(str) {
  return isArray(str) ? str : str.split(';')
}

module.exports = function (plugs, wrap) {

  plugs = plugs.map(function (e) {
    return isArray(e) ? compose(e, wrap) : e
  })

  var _self = {
    name: plugs.map(function (e) { return e.name }).join(';'),
    client: function (addr, cb) {
      let plug
      const _addr = split(addr).find(function (addr) {
        //connect with the first plug that understands this string.
        plug = plugs.find(function (plug) {
          return plug.parse(addr) ? plug : null
        })
        if(plug) return addr
      })
      if(plug) plug.client(_addr, cb)
      else cb(new Error('could not connect to:'+addr+', only know:'+_self.name))
    },
    server: function (onConnect, onError, startedCb) {
      //start all servers

      if (!startedCb) {
        // If a callback is not registered to be called back when the servers are
        // fully started, our default behaviour is just to print any errors starting
        // the servers to the log
        startedCb = (err, result) => {
          if (err) {
            console.error("Error starting multiserver server: " + err)
          }
        }
      }

      var started = multicb()

      var closes = plugs.map(function (plug) {
        return plug.server(onConnect, onError, started())
      }).filter(Boolean)

      started(startedCb);

      return function (cb) {
        var done
        if (cb) done = multicb()
        closes.forEach(function (close) {
          if (done && close.length) close(done())
          else close()
        })
        if (done) done(cb)
      }
    },
    stringify: function (scope) {
      if (!scope) scope = 'device'
      return plugs
        .filter(function (plug) {
          var _scope = plug.scope()
          return Array.isArray(_scope) ? ~_scope.indexOf(scope) : _scope === scope
        })
        .map(function (plug) { return plug.stringify(scope) })
        .filter(Boolean)
        .join(';')
    },
    //parse doesn't really make sense here...
    //like, what if you only have a partial match?
    //maybe just parse the ones you understand?
    parse: function (str) {
      return str.split(';').map(function (e, i) {
        return plugs[i].parse(e)
      })
    }
  }
  return _self
}



},
"oSONbch8b+vRQVX4roPYOvFuj3bSvkH7oL4ImqhBafM=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var cl = require("chloride");

exports.hash = function (data, enc) {
  data =
    "string" === typeof data && enc == null
      ? Buffer.from(data, "binary")
      : Buffer.from(data, enc);
  return cl.crypto_hash_sha256(data).toString("base64") + ".sha256";
};

exports.hasSigil = function hasSigil(s) {
  return /^(@|%|&)/.test(s);
};

function tag(key, tag) {
  if (!tag) throw new Error("no tag for:" + key.toString("base64"));
  return key.toString("base64") + "." + tag.replace(/^\./, "");
}

exports.keysToJSON = function keysToJSON(keys, curve) {
  curve = keys.curve || curve;

  var pub = tag(keys.public, curve);
  return {
    curve: curve,
    public: pub,
    private: keys.private ? tag(keys.private, curve) : undefined,
    id: "@" + pub,
  };
};

exports.getTag = function getTag(string) {
  var i = string.indexOf(".");
  return string.substring(i + 1);
};

exports.toBuffer = function (buf) {
  if (buf == null) return buf;
  if (Buffer.isBuffer(buf)) return buf;
  var i = buf.indexOf(".");
  var start = exports.hasSigil(buf) ? 1 : 0;
  return Buffer.from(buf.substring(start, ~i ? i : buf.length), "base64");
};

},
"omS13tMv0GjwKuOachD8YKC7sSFZdM+7IFEqxHBCIeo=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const createHash = require("create-hash");
const pbkdf2_1 = require("pbkdf2");
const randomBytes = require("randombytes");
const _wordlists_1 = require("./_wordlists");
let DEFAULT_WORDLIST = _wordlists_1._default;
const INVALID_MNEMONIC = 'Invalid mnemonic';
const INVALID_ENTROPY = 'Invalid entropy';
const INVALID_CHECKSUM = 'Invalid mnemonic checksum';
const WORDLIST_REQUIRED = 'A wordlist is required but a default could not be found.\n' +
    'Please explicitly pass a 2048 word array explicitly.';
function pbkdf2Promise(password, saltMixin, iterations, keylen, digest) {
    return Promise.resolve().then(() => new Promise((resolve, reject) => {
        const callback = (err, derivedKey) => {
            if (err) {
                return reject(err);
            }
            else {
                return resolve(derivedKey);
            }
        };
        pbkdf2_1.pbkdf2(password, saltMixin, iterations, keylen, digest, callback);
    }));
}
function normalize(str) {
    return (str || '').normalize('NFKD');
}
function lpad(str, padString, length) {
    while (str.length < length) {
        str = padString + str;
    }
    return str;
}
function binaryToByte(bin) {
    return parseInt(bin, 2);
}
function bytesToBinary(bytes) {
    return bytes.map((x) => lpad(x.toString(2), '0', 8)).join('');
}
function deriveChecksumBits(entropyBuffer) {
    const ENT = entropyBuffer.length * 8;
    const CS = ENT / 32;
    const hash = createHash('sha256')
        .update(entropyBuffer)
        .digest();
    return bytesToBinary(Array.from(hash)).slice(0, CS);
}
function salt(password) {
    return 'mnemonic' + (password || '');
}
function mnemonicToSeedSync(mnemonic, password) {
    const mnemonicBuffer = Buffer.from(normalize(mnemonic), 'utf8');
    const saltBuffer = Buffer.from(salt(normalize(password)), 'utf8');
    return pbkdf2_1.pbkdf2Sync(mnemonicBuffer, saltBuffer, 2048, 64, 'sha512');
}
exports.mnemonicToSeedSync = mnemonicToSeedSync;
function mnemonicToSeed(mnemonic, password) {
    return Promise.resolve().then(() => {
        const mnemonicBuffer = Buffer.from(normalize(mnemonic), 'utf8');
        const saltBuffer = Buffer.from(salt(normalize(password)), 'utf8');
        return pbkdf2Promise(mnemonicBuffer, saltBuffer, 2048, 64, 'sha512');
    });
}
exports.mnemonicToSeed = mnemonicToSeed;
function mnemonicToEntropy(mnemonic, wordlist) {
    wordlist = wordlist || DEFAULT_WORDLIST;
    if (!wordlist) {
        throw new Error(WORDLIST_REQUIRED);
    }
    const words = normalize(mnemonic).split(' ');
    if (words.length % 3 !== 0) {
        throw new Error(INVALID_MNEMONIC);
    }
    // convert word indices to 11 bit binary strings
    const bits = words
        .map((word) => {
        const index = wordlist.indexOf(word);
        if (index === -1) {
            throw new Error(INVALID_MNEMONIC);
        }
        return lpad(index.toString(2), '0', 11);
    })
        .join('');
    // split the binary string into ENT/CS
    const dividerIndex = Math.floor(bits.length / 33) * 32;
    const entropyBits = bits.slice(0, dividerIndex);
    const checksumBits = bits.slice(dividerIndex);
    // calculate the checksum and compare
    const entropyBytes = entropyBits.match(/(.{1,8})/g).map(binaryToByte);
    if (entropyBytes.length < 16) {
        throw new Error(INVALID_ENTROPY);
    }
    if (entropyBytes.length > 32) {
        throw new Error(INVALID_ENTROPY);
    }
    if (entropyBytes.length % 4 !== 0) {
        throw new Error(INVALID_ENTROPY);
    }
    const entropy = Buffer.from(entropyBytes);
    const newChecksum = deriveChecksumBits(entropy);
    if (newChecksum !== checksumBits) {
        throw new Error(INVALID_CHECKSUM);
    }
    return entropy.toString('hex');
}
exports.mnemonicToEntropy = mnemonicToEntropy;
function entropyToMnemonic(entropy, wordlist) {
    if (!Buffer.isBuffer(entropy)) {
        entropy = Buffer.from(entropy, 'hex');
    }
    wordlist = wordlist || DEFAULT_WORDLIST;
    if (!wordlist) {
        throw new Error(WORDLIST_REQUIRED);
    }
    // 128 <= ENT <= 256
    if (entropy.length < 16) {
        throw new TypeError(INVALID_ENTROPY);
    }
    if (entropy.length > 32) {
        throw new TypeError(INVALID_ENTROPY);
    }
    if (entropy.length % 4 !== 0) {
        throw new TypeError(INVALID_ENTROPY);
    }
    const entropyBits = bytesToBinary(Array.from(entropy));
    const checksumBits = deriveChecksumBits(entropy);
    const bits = entropyBits + checksumBits;
    const chunks = bits.match(/(.{1,11})/g);
    const words = chunks.map((binary) => {
        const index = binaryToByte(binary);
        return wordlist[index];
    });
    return wordlist[0] === '\u3042\u3044\u3053\u304f\u3057\u3093' // Japanese wordlist
        ? words.join('\u3000')
        : words.join(' ');
}
exports.entropyToMnemonic = entropyToMnemonic;
function generateMnemonic(strength, rng, wordlist) {
    strength = strength || 128;
    if (strength % 32 !== 0) {
        throw new TypeError(INVALID_ENTROPY);
    }
    rng = rng || randomBytes;
    return entropyToMnemonic(rng(strength / 8), wordlist);
}
exports.generateMnemonic = generateMnemonic;
function validateMnemonic(mnemonic, wordlist) {
    try {
        mnemonicToEntropy(mnemonic, wordlist);
    }
    catch (e) {
        return false;
    }
    return true;
}
exports.validateMnemonic = validateMnemonic;
function setDefaultWordlist(language) {
    const result = _wordlists_1.wordlists[language];
    if (result) {
        DEFAULT_WORDLIST = result;
    }
    else {
        throw new Error('Could not find wordlist for language "' + language + '"');
    }
}
exports.setDefaultWordlist = setDefaultWordlist;
function getDefaultWordlist() {
    if (!DEFAULT_WORDLIST) {
        throw new Error('No Default Wordlist set');
    }
    return Object.keys(_wordlists_1.wordlists).filter((lang) => {
        if (lang === 'JA' || lang === 'EN') {
            return false;
        }
        return _wordlists_1.wordlists[lang].every((word, index) => word === DEFAULT_WORDLIST[index]);
    })[0];
}
exports.getDefaultWordlist = getDefaultWordlist;
var _wordlists_2 = require("./_wordlists");
exports.wordlists = _wordlists_2.wordlists;

},
"oxwx+EUZbcigI6wvnehb6W7UwGyO5S3/coTk3OTTQJ8=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const PacketStreamCodec = require('packet-stream-codec')
const EventEmitter = require('events').EventEmitter
const initStream = require('./stream')
const createRemoteApi = require('./remote-api')
const createLocalApi = require('./local-api')

function createMuxrpc (remoteManifest, localManifest, localApi, id, perms, codec, legacy) {
  let bootstrapCB
  if (typeof remoteManifest === 'function') {
    bootstrapCB = remoteManifest
    remoteManifest = {}
  }

  localManifest = localManifest || {}
  remoteManifest = remoteManifest || {}
  const emitter = new EventEmitter()
  if (!codec) codec = PacketStreamCodec

  // pass the manifest to the permissions so that it can know
  // what something should be.
  let _cb
  const context = {
    _emit (event, value) {
      if (emitter) emitter._emit(event, value)
      return context
    },
    id
  }

  const ws = initStream(
    createLocalApi(localApi, localManifest, perms).bind(context),
    codec,
    (err) => {
      if (emitter.closed) return
      emitter.closed = true
      emitter.emit('closed')
      if (_cb) {
        const cb = _cb
        _cb = null
        cb(err)
      }
    }
  )

  createRemoteApi(
    emitter,
    remoteManifest,
    (type, name, args, cb) => {
      if (ws.closed) throw new Error('stream is closed')
      return ws.remoteCall(type, name, args, cb)
    },
    bootstrapCB
  )

  // legacy local emit, from when remote emit was supported.
  emitter._emit = emitter.emit

  if (legacy) {
    Object.__defineGetter__.call(emitter, 'id', () => context.id)
    Object.__defineSetter__.call(emitter, 'id', (value) => { context.id = value })

    let first = true
    emitter.createStream = (cb) => {
      _cb = cb
      if (first) {
        first = false
        return ws
      } else {
        throw new Error('one stream per rpc')
      }
    }
  } else {
    emitter.stream = ws
  }

  emitter.closed = false

  emitter.close = function (err, cb) {
    ws.close(err, cb)
    return this
  }

  return emitter
}

module.exports = function (remoteManifest, localManifest, codec) {
  if (arguments.length > 3) {
    return createMuxrpc.apply(this, arguments)
  }
  return function (local, perms, id) {
    return createMuxrpc(remoteManifest, localManifest, local, id, perms, codec, true)
  }
}

},
"ozyIVscu19VKjALanqYmscOQ6YeyyveCY+pQetRrmpw=":
function (require, module, exports, __dirname, __filename) {

var space = require('to-space-case')

/**
 * Export.
 */

module.exports = toCamelCase

/**
 * Convert a `string` to camel case.
 *
 * @param {String} string
 * @return {String}
 */

function toCamelCase(string) {
  return space(string).replace(/\s(\w)/g, function (matches, letter) {
    return letter.toUpperCase()
  })
}

},
"pHKD0YRdWAkLaR4mj/jjwLSo0oWPObv1rDQFtnBdbgQ=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var abortCb = require('../util/abort-cb')

module.exports = function once (value, onAbort) {
  return function (abort, cb) {
    if(abort)
      return abortCb(cb, abort, onAbort)
    if(value != null) {
      var _value = value; value = null
      cb(null, _value)
    } else
      cb(true)
  }
}



},
"pN128HmfxJd3AhJuZ6vuPPgWw3XLAKVTqj/gX8bFlno=":
function (require, module, exports, __dirname, __filename) {
var slice = Array.prototype.slice

/* Given a function that takes n arguments and returns a continuable
    return a function that takes n arguments and maybe a n+1th argument
    which is a callback or takes n arguments and returns a continuable

This basically means that you can do this:

```js
var readFile = maybeCallback(function (uri) {
    return function (cb) { fs.readFile(uri, cb) }
})

readFile("./foo")(cb)
readFile("./foo", cb)
```

Be warned this breaks if the last argument is a function

*/
module.exports = maybeCallback

//  maybeCallback := (fn: (Any, ...) => Continuable<T>) =>
//      (Any, ..., Callback<T>?) => Continuable<T>
function maybeCallback(fn) {
    return function maybeContinuable() {
        var args = slice.call(arguments)
        var callback = args[args.length - 1]

        if (typeof callback === "function") {
            args.pop()
        }

        var continuable = fn.apply(null, args)

        if (typeof callback === "function") {
            continuable(callback)
        } else {
            return continuable
        }
    }
}

},
"pOnCRFSzp+kJnH5MSNe9WnblM1oX8MZ9asmcDPKQb5o=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
module.exports = {
    name: 'resyncUtils',
    version: '1.0.0',
    manifest: {},
    permissions: {
        master: {
            allow: [],
        },
    },
    init(ssb, config) {
        // Disable conn firewall to allow "strangers" to connect and resync data
        ssb.getVectorClock((err, clock) => {
            if (err)
                return console.error('resyncUtils exception', err);
            if (!clock)
                return console.error('resyncUtils missing clock', clock);
            if (clock[ssb.id])
                return; // we are not resyncing, apparently
            // Our feed is empty, so temporarily disable firewall for strangers
            ssb.connFirewall.reconfigure({ rejectUnknown: false });
            // Re-enable firewall when our first msg is detected
            let unsubscribeDB = ssb.post((msg) => {
                var _a, _b, _c;
                if (msg.value.author === ssb.id) {
                    ssb.connFirewall.reconfigure({
                        rejectUnknown: (_c = (_b = (_a = config.conn) === null || _a === void 0 ? void 0 : _a.firewall) === null || _b === void 0 ? void 0 : _b.rejectUnknown) !== null && _c !== void 0 ? _c : true,
                    });
                    unsubscribeDB === null || unsubscribeDB === void 0 ? void 0 : unsubscribeDB();
                    unsubscribeDB = null;
                }
            }, false);
        });
    },
};
//# sourceMappingURL=resyncUtils.js.map
},
"phvOfVFFv8Xts/2HMFfcnDzhAJ/DebRZVKq2h/QyX9s=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('./lib/heap');

},
"pypnDHT31dfog1AFrqXz8xOQHgBglbiMO10JsdrAXi0=":
function (require, module, exports, __dirname, __filename) {


/*
all pull streams have these states:

{
  START: {
    read: READING,
    abort: ABORTING
  },
  READY: {
    read: READING,
    abort: ABORTING
  },
  READING: {
    cb: READY,
    err: ERROR,
    end: END
  },
  ABORTING: {
    cb: END
  },
  ERROR: {},
  END: {}
}

this module takes a collection of pull-streams,
and interleaves their states.
if all the streams have ended, it ends.
If it is in reading state, and one stream goes has READING->cb
it goes into READY

on read, trigger read on every stream in START or READY

on abort, trigger abort on all streams immediately***

if a stream is in READY, and big stream is in ABORT,
trigger abort

if every stream is in END or ERROR, trigger end or error

could you describe this declaritively or something?
*/

module.exports = function (ary) {

  var capped = !!ary
  var inputs = (ary || []).map(create), i = 0, abort, cb

  function create (stream) {
    return {ready: false, reading: false, ended: false, read: stream, data: null}
  }

  function check () {
    if(!cb) return
    clean()
    var l = inputs.length
    var _cb = cb
    if(l === 0 && (abort || capped)) {
      cb = null; _cb(abort ||  true)
      return
    }

    //scan the inputs to check whether there is one we can use.
    for(var j = 0; j < l; j++) {
      var current = inputs[(i + j) % l]
      if(current.ready && !current.ended) {
        var data = current.data
        current.ready = false
        current.data = null
        i ++; cb = null
        return _cb(null, data)
      }
    }
  }

  function clean () {
    var l = inputs.length
    //iterate backwards so that we can remove items.
    while(l--) {
      if(inputs[l].ended)
        inputs.splice(l, 1)
    }
  }

  function next () {
    var l = inputs.length
    while(l--)
      (function (current) {
        //read the next item if we aren't already
        if(l > inputs.length) throw new Error('this should never happen')
        if(current.reading || current.ended || current.ready) return
        current.reading = true
        var sync = true
        current.read(abort, function next (end, data) {
          current.data = data
          current.ready = true
          current.reading = false

          if(end === true || abort) current.ended = true
          else if(end) abort = current.ended = end
          //check whether we need to abort this stream.
          if(abort && !end) current.read(abort, next)
          if(!sync) check()
        })
        sync = false
      })(inputs[l])

    //scan the feed
    check()
  }

  function read (_abort, _cb) {
    abort = abort || _abort; cb = _cb; next()
  }

  read.add = function (stream) {
    if(!stream) {
      //the stream will now end when all the streams end.
      capped = true
      //we just changed state, so we may need to cb
      return next()
    }
    inputs.push(create(stream))
    next()
  }

  read.cap = function (err) {
    read.add(null)
  }

  return read
}


},
"q5bx/UTtkXlbC5JX0SxWtwzw/uUs9V7eftjsmve1IVE=":
function (require, module, exports, __dirname, __filename) {
const toDuplex = require('pull-rn-channel');

module.exports = function makePlugin(opts) {
  return {
    name: 'channel',

    scope: function() {
      return 'device';
    },

    server: function(onConnection, onError) {
      const channel = !!opts ? opts.channel || opts : null;
      if (!channel) {
        onError(
          new Error(
            'multiserver-rn-channel plugin requires the channel given in ' +
              'the opts argument when starting the server'
          )
        );
        return function() {};
      }
      onConnection(toDuplex(channel));
      return function() {};
    },

    client: function(_address, cb) {
      try {
        const channel = !!opts ? opts.channel || opts : null;
        if (!channel) {
          throw new Error(
            'multiserver-rn-channel plugin requires the channel given in ' +
              'the opts argument when starting the client'
          );
        }
        const stream = toDuplex(channel);
        stream.channel = channel;
        cb(null, stream);
      } catch (err) {
        cb(err);
      }
    },

    // MUST be 'channel' string
    parse: function(s) {
      if (s !== 'channel') return null;
      return {name: 'channel'};
    },

    stringify: function() {
      return 'channel';
    },
  };
};

},
"qFCsWoiBRAd3oPgvj8EWwVVhlnFzpzxOEnet7B/KAQ4=":
function (require, module, exports, __dirname, __filename) {
const makeMultiservPlugin = require('multiserver-bluetooth');

/**
 * A plugin for bluetooth functionality. Initialises a multiserve plugin
 * for managing connections, and exposes some mux-rpc functions for bluetooth
 * functionality (such as scanning for nearby devices, making your device discoverable)
 * 
 * @param {*} bluetoothManager an instance of a bluetooth manager that implements the platform
 *                             specific (e.g. android or PC) bluetooth functionality.
 *                             See ssb-mobile-bluetooth-manager for an example.
 */
module.exports = (bluetoothManager, opts) => {

    function initMultiservePlugin(stack) {
      const plugin = {
        name: 'bluetooth',
        create: () => {
          return makeMultiservPlugin({
            bluetoothManager: bluetoothManager,
            scope: opts ? opts.scope : null
          })
        }
      }
    
      stack.multiserver.transport(plugin);
    }

    return {
      name: "bluetooth",
      version: "1.0.0",
      init: (stack) => {
        initMultiservePlugin(stack);

        return {
          nearbyDevices: (refreshInterval) => {
            return bluetoothManager.nearbyDevices(refreshInterval);
          },
          nearbyScuttlebuttDevices: (refreshInterval) => {
            return bluetoothManager.nearbyScuttlebuttDevices(refreshInterval);
          },
          bluetoothScanState: () => {
            return bluetoothManager.bluetoothScanState();
          },
          makeDeviceDiscoverable: (forTime, cb) => {
            bluetoothManager.makeDeviceDiscoverable(forTime, cb);
          },
          isEnabled: (cb) => {
            bluetoothManager.isEnabled(cb);
          },
          getMetadataForDevice: (deviceAddress, cb) => {
            bluetoothManager.getMetadataForDevice(deviceAddress, cb);
          }

        }
      },
      manifest: {
        "nearbyDevices": "source",
        "nearbyScuttlebuttDevices": "source",
        "bluetoothScanState": "source",
        "makeDeviceDiscoverable": "async",
        "isEnabled": "async",
        "getMetadataForDevice": "async"
      }

    }
}
},
"qRbKwEJSKJyVjIDhbQ80030gZD5fwou1JipZ80ksCEk=":
function (require, module, exports, __dirname, __filename) {
'use strict'

//a pass through stream that doesn't change the value.
module.exports = function through (op, onEnd) {
  var a = false

  function once (abort) {
    if(a || !onEnd) return
    a = true
    onEnd(abort === true ? null : abort)
  }

  return function (read) {
    return function (end, cb) {
      if(end) once(end)
      return read(end, function (end, data) {
        if(!end) op && op(data)
        else once(end)
        cb(end, data)
      })
    }
  }
}

},
"qTPbn8TDQgcxQj5aib9JU8JN/XRJr217ks5Skf/uOUs=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const bipf = require('bipf');
const pl = require('pull-level');
const pull = require('pull-stream');
const DB2Plugin = require('ssb-db2/indexes/plugin');
const { seqs, deferred } = require('ssb-db2/operators');
const B_0 = Buffer.alloc(0);
const B_VALUE = Buffer.from('value');
const B_CONTENT = Buffer.from('content');
const B_CHANNEL = Buffer.from('channel');
const B_MENTIONS = Buffer.from('mentions');
function sanitize(hashtag) {
    return hashtag.startsWith('#') ? hashtag.slice(1) : hashtag;
}
const INDEX_NAME = 'hashtags';
const INDEX_VERSION = 1;
module.exports = class HashtagPlugin extends DB2Plugin {
    constructor(log, dir) {
        super(log, dir, INDEX_NAME, INDEX_VERSION, 'json', 'binary');
    }
    static operator(text) {
        return deferred((meta, cb, onAbort) => {
            meta.db.onDrain(INDEX_NAME, () => {
                const plugin = meta.db.getIndex(INDEX_NAME);
                plugin.getMessagesByHashtag(text, cb, onAbort);
            });
        });
    }
    processRecord(record, seq) {
        const buf = record.value;
        const pValue = bipf.seekKey(buf, 0, B_VALUE);
        if (pValue < 0)
            return;
        const pValueContent = bipf.seekKey(buf, pValue, B_CONTENT);
        if (pValueContent < 0)
            return;
        const pValueContentChannel = bipf.seekKey(buf, pValueContent, B_CHANNEL);
        const pValueContentMentions = bipf.seekKey(buf, pValueContent, B_MENTIONS);
        if (pValueContentChannel >= 0) {
            const channel = bipf.decode(buf, pValueContentChannel);
            // msg.value.content.channel typically does not have `#`
            if (channel && typeof channel === 'string') {
                const label = sanitize(channel);
                this.batch.push({
                    type: 'put',
                    key: [label, seq],
                    value: B_0,
                });
            }
        }
        if (pValueContentMentions >= 0) {
            const mentions = bipf.decode(buf, pValueContentMentions);
            if (Array.isArray(mentions)) {
                for (const { link } of mentions) {
                    // msg.value.content.mentions[].link SHOULD have `#`
                    if (link && typeof link === 'string' && link.startsWith('#')) {
                        const label = sanitize(link);
                        this.batch.push({
                            type: 'put',
                            key: [label, seq],
                            value: B_0,
                        });
                    }
                }
            }
        }
    }
    getMessagesByHashtag(hashtag, cb, onAbort) {
        if (!hashtag || typeof hashtag !== 'string')
            return cb(null, seqs([]));
        const label = sanitize(hashtag);
        let drainer;
        const seqArr = [];
        onAbort(() => {
            drainer === null || drainer === void 0 ? void 0 : drainer.abort();
        });
        pull(pl.read(this.level, {
            gte: [label, ''],
            lte: [label, undefined],
            keys: true,
            keyEncoding: this.keyEncoding,
            values: false,
        }), (drainer = pull.drain(([, seq]) => seqArr.push(seq), (err) => {
            if (err)
                return cb(err);
            else
                cb(null, seqs(seqArr));
        })));
    }
};
//# sourceMappingURL=hashtags.js.map
},
"qZ4HR5CmlpLbPLk1+d1LqqW1rFhXcWDxdD7g9IgIB+M=":
function (require, module, exports, __dirname, __filename) {
var isCanonicalBase64 = require('is-canonical-base64')
var isDomain = require('is-valid-domain')
var Querystring = require('querystring')
var ip = require('ip')

var parseLinkRegex = /^((@|%|&)[A-Za-z0-9\/+]{43}=\.[\w\d]+)(\?(.+))?$/
var linkRegex = exports.linkRegex = /^(@|%|&)[A-Za-z0-9\/+]{43}=\.[\w\d]+$/
var feedIdRegex = exports.feedIdRegex = isCanonicalBase64('@', '\.(?:sha256|ed25519)', 32)
var blobIdRegex = exports.blobIdRegex = isCanonicalBase64('&', '\.sha256', 32)
var msgIdRegex = exports.msgIdRegex = isCanonicalBase64('%', '\.sha256', 32)

var extractRegex = /([@%&][A-Za-z0-9\/+]{43}=\.[\w\d]+)/

var MultiServerAddress = require('multiserver-address')

function isMultiServerAddress (str) {
  //a http url fits into the multiserver scheme,
  //but all ssb address must have a transport and a transform
  //so check there is at least one unescaped ~ in the address
  return MultiServerAddress.check(str) && /[^!][~]/.test(str)
}

function isIP (s) {
  return ip.isV4Format(s) || ip.isV6Format(s)
}

var isInteger = Number.isInteger
var DEFAULT_PORT = 8008

function isString(s) {
  return 'string' === typeof s
}

var isHost = function (addr) {
  if(!isString(addr)) return
  addr = addr.replace(/^wss?:\/\//, '')
  return (isIP(addr)) || isDomain(addr) || addr === 'localhost'
}

var isPort = function (p) {
  return isInteger(p) && p <= 65536
}

function isObject (o) {
  return o && 'object' === typeof o && !Array.isArray(o)
}

var isFeedId = exports.isFeed = exports.isFeedId =
  function (data) {
    return isString(data) && feedIdRegex.test(data)
  }

var isMsgId = exports.isMsg = exports.isMsgId =
  function (data) {
    return isString(data) && msgIdRegex.test(data)
  }

var isBlobId = exports.isBlob = exports.isBlobId =
  function (data) {
    return isString(data) && blobIdRegex.test(data)
  }

var isLink = exports.isLink =
  function (data) {
    if(!isString(data)) return false
    var index = data.indexOf('?')
    data = ~index ? data.substring(0, index) : data
    return isString(data) && (isFeedId(data) || isMsgId(data) || isBlobId(data))
  }


exports.isBlobLink = function (s) {
  return s[0] === '&' && isLink(s)
}

exports.isMsgLink = function (s) {
  return s[0] === '%' && isLink(s)
}


var normalizeChannel = exports.normalizeChannel =
  function (data) {
    if (typeof data === 'string') {
      data = data.toLowerCase().replace(/\s|,|\.|\?|!|<|>|\(|\)|\[|\]|"|#/g, '')
      if (data.length > 0 && data.length < 30) {
        return data
      }
    }
  }

function deprecate (name, fn) {
  var logged = false
  return function () {
    var args = [].slice.call(arguments)
    if(!logged) {
      console.trace('deprecated api used: '+name)
      logged = true
    }
    return fn.apply(this, args)
  }
}

var parseMultiServerAddress = function (data) {
  if(!isString(data)) return false
  if(!MultiServerAddress.check(data)) return false

  var addr = MultiServerAddress.decode(data)
  addr = addr.find(function (address) {
    if (!address[0]) return false
    if (!address[1]) return false
    return /^(net|wss?|onion)$/.test(address[0].name) && /^shs/.test(address[1].name)
  })
  if (!Array.isArray(addr)) {
    return false
  }
  var port = +addr[0].data.pop() //last item always port, to handle ipv6

  //preserve protocol type on websocket addresses
  var host = (/^wss?$/.test(addr[0].name) ? addr[0].name+':' : '') + addr[0].data.join(':')
  var key = '@'+addr[1].data[0]+'.ed25519'
  var seed = addr[1].data[2]
  // allow multiserver addresses that are not currently understood!
  if(!(isHost(host) && isPort(+port) && isFeedId(key))) return false
  var address = {
    host: host,
    port: port,
    key: key,
  }
  if(seed)
    address.seed = seed

  return address
}

var toLegacyAddress = parseMultiServerAddress
exports.toLegacyAddress = deprecate('ssb-ref.toLegacyAddress', toLegacyAddress)

var isLegacyAddress = exports.isLegacyAddress = function (addr) {
  return isObject(addr) && isHost(addr.host) && isPort(addr.port) && isFeedId(addr.key)
}

var toMultiServerAddress = exports.toMultiServerAddress = function (addr) {
  if(MultiServerAddress.check(addr)) return addr
  if(!isPort(addr.port)) throw new Error('ssb-ref.toMultiServerAddress - invalid port:'+addr.port)
  if(!isHost(addr.host)) throw new Error('ssb-ref.toMultiServerAddress - invalid host:'+addr.host)
  if(!isFeedId(addr.key)) throw new Error('ssb-ref.toMultiServerAddress - invalid key:'+addr.key)

  return (
    /^wss?:/.test(addr.host)   ? addr.host
  : /\.onion$/.test(addr.host) ? 'onion:'+addr.host
  :                              'net:'+addr.host
  )+':'+addr.port+'~shs:'+addr.key.substring(1, addr.key.indexOf('.'))
}

var isAddress = exports.isAddress = function (data) {
  var host, port, id
  if(isObject(data)) {
    id = data.key; host = data.host; port = data.port
  }
  else if(!isString(data)) return false
  else if(isMultiServerAddress(data)) return true
  else {
    var parts = data.split(':')
    id = parts.pop(); port = parts.pop(); host = parts.join(':')
  }
  return (
    isFeedId(id) && isPort(+port)
    && isHost(host)
  )
}

//This is somewhat fragile, because maybe non-shs protocols get added...
//it would be better to treat all addresses as opaque or have multiserver handle
//extraction of a signing key from the address.
var getKeyFromAddress = exports.getKeyFromAddress = function (addr) {
  if(addr.key) return addr.key
  var data = MultiServerAddress.decode(addr)
  if(!data) return
  for(var k in data) {
    var address = data[k]
    for(var j in address) {
      var protocol = address[j]
      if(/^shs/.test(protocol.name)) //forwards compatible with future shs versions...
        return '@'+protocol.data[0]+'.ed25519'
    }
  }
}

var parseAddress = function (e) {
  if(isString(e)) {
    if(~e.indexOf('~'))
      return parseMultiServerAddress(e)
    var parts = e.split(':')
    var id = parts.pop(), port = parts.pop(), host = parts.join(':')
    var e = {
      host: host,
      port: +(port || DEFAULT_PORT),
      key: id
    }
    return e
  }
  return e
}
exports.parseAddress = deprecate('ssb-ref.parseAddress',parseAddress)

var toAddress = exports.toAddress = function (e) {
  e = parseAddress(e)
  e.port = e.port || DEFAULT_PORT
  e.host = e.host || 'localhost'
  return e
}


var legacyInviteRegex = /^[A-Za-z0-9\/+]{43}=$/
var legacyInviteFixerRegex = /#.*$/
var isLegacyInvite = exports.isLegacyInvite =
  function (data) {
    if(!isString(data)) return false
    data = data.replace(legacyInviteFixerRegex, '')
    var parts = data.split('~')
    return parts.length == 2 && isAddress(parts[0]) && legacyInviteRegex.test(parts[1])
  }

var isMultiServerInvite = exports.isMultiServerInvite =
  function (data) {
    if(!isString(data)) return false
    return !!parseMultiServerInvite(data)
  }

var isInvite = exports.isInvite =
  function (data) {
    if(!isString(data)) return false
    return isLegacyInvite(data) || isMultiServerInvite(data)
  }

exports.parseLink = function parseBlob (ref) {
  var match = parseLinkRegex.exec(ref)
  if (match && match[1]) {
    if (match[3]) {
      var query = Querystring.parse(match[4])
      // unbox keys have a '+' in them that is parsed into a ' ', this changes it back
      if (isString(query.unbox)) query.unbox = query.unbox.replace(/ /g, '+')
      return {link: match[1], query }
    } else {
      return {link: match[1]}
    }
  }
}

function parseLegacyInvite (invite) {
  var redirect = invite.split('#')
  invite = redirect.shift()
  var parts = invite.split('~')
  var addr = toAddress(parts[0])//.split(':')
  //convert legacy code to multiserver invite code.
  invite = remote+':'+parts[1]
  var remote = toMultiServerAddress(addr)
  return {
    invite: remote + ':' + parts[1],
    key: addr.key,
    redirect: null,
    remote: remote,
    redirect: redirect.length ? '#' + redirect.join('#') : null
  }
}

function parseMultiServerInvite (invite) {

  var redirect = invite.split('#')
  if(!redirect.length) return null

  invite = redirect.shift()
  var addr = toLegacyAddress(invite)
  if(!addr) return null
  delete addr.seed
  return {
    invite: invite,
    remote: toMultiServerAddress(addr),
    key: addr.key,
    redirect: redirect.length ? '#' + redirect.join('#') : null
  }
}

exports.parseLegacyInvite = deprecate('ssb-ref.parseLegacyInvite', parseLegacyInvite)
exports.parseMultiServerInvite = deprecate('ssb-ref.parseMultiServerInvite', parseMultiServerInvite)

exports.parseInvite = deprecate('ssb-ref.parseInvite', function (invite) {
  return (
    isLegacyInvite(invite)
  ? parseLegacyInvite(invite)
  : isMultiServerInvite(invite)
  ? parseMultiServerInvite(invite)
  : null
  )
})

exports.type =
  function (id) {
    if(!isString(id)) return false
    var c = id.charAt(0)
    if (c == '@' && isFeedId(id))
      return 'feed'
    else if (c == '%' && isMsgId(id))
      return 'msg'
    else if (c == '&' && isBlobId(id))
      return 'blob'
    else if(isAddress(id)) return 'address'
    else if(isInvite(id)) return 'invite'
    else
    return false
  }

exports.extract =
  function (data) {
    if (!isString(data))
      return false

    var _data = data

    var res = extractRegex.exec(_data)
    if (res) {
      return res && res[0]
    } else {
      try { _data = decodeURIComponent(data) }
      catch (e) {} // this may fail if it's not encoded, so don't worry if it does
      _data = _data.replace(/&amp;/g, '&')

      var res = extractRegex.exec(_data)
      return res && res[0]
    }
  }









},
"qaPk8XACAcHssdXrsz1tpp7PPbI1RsTQd8cwrkKgpqk=":
function (require, module, exports, __dirname, __filename) {
const { promisify } = require('util')
const fs = require('fs')
const optsArg = opts => {
  if (!opts)
    opts = { mode: 0o777, fs }
  else if (typeof opts === 'object')
    opts = { mode: 0o777, fs, ...opts }
  else if (typeof opts === 'number')
    opts = { mode: opts, fs }
  else if (typeof opts === 'string')
    opts = { mode: parseInt(opts, 8), fs }
  else
    throw new TypeError('invalid options argument')

  opts.mkdir = opts.mkdir || opts.fs.mkdir || fs.mkdir
  opts.mkdirAsync = promisify(opts.mkdir)
  opts.stat = opts.stat || opts.fs.stat || fs.stat
  opts.statAsync = promisify(opts.stat)
  opts.statSync = opts.statSync || opts.fs.statSync || fs.statSync
  opts.mkdirSync = opts.mkdirSync || opts.fs.mkdirSync || fs.mkdirSync
  return opts
}
module.exports = optsArg

},
"qhIwNTpyhDgj1BQ3p6RpDN7ODtzFIDCmou5BfVoQeNI=":
function (require, module, exports, __dirname, __filename) {

//module.exports = function (sep, esc) {
//  sep = sep || ','
//  esc = esc || '\\'
//
//  new RegExp('([^'+sep+']|'+esc+sep+')
//}

module.exports = function (sep, esc) {
  if(sep.length != 1) throw new Error('separator must be a single char')
  if(esc.length != 1) throw new Error('escape must be a single char')

  return {
    parse: function (str) {
      var ary = []
      var cur = ''
      for(var i = 0; i < str.length; i++) {
       if(str[i] == esc && i+1 < str.length) {
          cur += str[++i]
        }
        else if(str[i] === sep) {
          ary.push(cur)
          cur = ''
        }
        else
          cur += str[i]
      }
      ary.push(cur)
      return ary

    },
    stringify: function (ary) {
      //for each item in the array.
      return ary.map(function (str) {
        var s = ''
        for(var i = 0; i < str.length; i++) {
          if(str[i] === esc || str[i] === sep)
            s += esc + str[i]
          else
            s += str[i]
        }
        return s
      }).join(sep)
    }
  }
}



},
"qhJ/8XUrfZx0FcXHu2mU2apyK4G8vKtL1IMWsBPSO/M=":
function (require, module, exports, __dirname, __filename) {
/**
 * Detect Electron renderer / nwjs process, which is node, but we should
 * treat as a browser.
 */

if (typeof process === 'undefined' || process.type === 'renderer' || process.browser === true || process.__nwjs) {
	module.exports = require('./browser.js');
} else {
	module.exports = require('./node.js');
}

},
"r4M+MkdrPeknGkMqLH50etmG6hXXz6HrwbMI8zjG1Ok=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var cl = require('chloride')

module.exports = function (bytes) {
  var b = Buffer.alloc(bytes)
  cl.randombytes(b, bytes)
  return b
}

},
"r77I/UpUX6QrJvmkqR1wQOWxv7nv8h5DHVc+ncT2DVg=":
function (require, module, exports, __dirname, __filename) {
'use strict'
function isEmpty (o) {
  for(var k in o) return false
  return true
}

function isInteger (i) {
  return Number.isInteger(i)
}

var isArray = Array.isArray

var Notify = require('pull-notify')
var pull = require('pull-stream')
var isBlobId = require('ssb-ref').isBlob

var MB = 1024*1024
var MAX_SIZE = 5*MB

function clone (obj) {
  var o = {}
  for(var k in obj)
    o[k] = obj[k]
  return o
}

function count(obj) {
  var c = 0
  for(var k in obj) c++
  return c
}

function onAbort(abortCb) {
  return function (read) {
    return function (abort, cb) {
      if (abort) abortCb(abort, cb)
      else read(null, cb)
    }
  }
}

function toBlobId(id) {
  if(Array.isArray(id)) return id//.map(toBlobId)
  return isBlobId(id) ? id : isBlobId(id && id.id) ? id.id : null
}

function wrap (fn) {
  return function (id, cb) {
    if (!toBlobId(id)) {
      cb = id
      return fn.call(this, cb)
    }
    return fn.call(this, toBlobId(id), cb)
  }
}

module.exports = function inject (blobs, set, name, opts) {
  opts = opts || {}
  //sympathy controls whether you'll replicate
  var sympathy = opts.sympathy == null ? 3 : opts.sympathy | 0
  var stingy = opts.stingy === true
  var legacy = opts.legacy !== false
  var pushy = opts.pushy || 3
  var max = opts.max || 5*1024*1024

  var notify = Notify()
  var pushed = Notify()

  var peers = {}
  var want = {}, push = {}, waiting = {}, getting = {}
  var available = {}, streams = {}
  var send = {}, timer

  function queue (id, hops) {
    if(hops < 0)
      want[id] = hops
    else
      delete want[id]

    send[id] = hops
    var _send = send;
    send = {}
    notify(_send)
  }

  function isAvailable(id) {
    for(var peer in peers)
      if(available[peer] && available[peer][id] < max && peers[peer])
        return peer
  }

  function get (peer, id, name) {
    if(getting[id] || !peers[peer]) return

    getting[id] = peer
    var source = peers[peer].blobs.get({key: id, max: max})
    pull(source, blobs.add(id, function (err, _id) {
      delete getting[id]
      if(err) {
        if(available[peer]) delete available[peer][id]
        //check if another peer has this.
        //if so get it from them.
        if(peer = isAvailable(id)) get(peer, id, name)
      }
    }))
  }

  function wants (peer, id, hops) {
    if(Math.abs(hops) > sympathy) return //sorry!
    if(!want[id] || want[id] < hops) {
      want[id] = hops
      queue(id, hops)
      if(peer = isAvailable(id)) {
        get(peer, id)
      }
    }
  }

  pull(
    blobs.ls({old: false, meta: true}),
    pull.drain(function (data) {
      queue(data.id, data.size)
      delete want[data.id]
      if(waiting[data.id])
        while(waiting[data.id].length)
          waiting[data.id].shift()(null, true)
    })
  )

  function has(peer_id, id, size) {
    if('string' !== typeof peer_id) throw new Error('peer must be string id')
    available[peer_id] = available[peer_id] || {}
    available[peer_id][id] = size
    //if we are broadcasting this blob,
    //mark this peer has it.
    //if N peers have it, we can stop broadcasting.
    if(push[id]) {
      push[id][peer_id] = size
      if(count(push[id]) >= pushy) {
        var data = {key: id, peers: push[id]}
        set.remove(id)
        delete push[id]; pushed(data)
      }
    }
    if(want[id] && !getting[id] && size < max) get(peer_id, id)
  }

  function process (data, peer, cb) {
    var n = 0, res = {}
    for(var id in data) (function (id) {
      if(isBlobId(id) && isInteger(data[id])) {
        if(data[id] < 0 && (opts.stingy !== true || push[id])) { //interpret as "WANT"
          n++
          //check whether we already *HAVE* this file.
          //respond with it's size, if we do.
          blobs.size(id, function (err, size) { //XXX
            if(size) res[id] = size
            else wants(peer, id, data[id] - 1)
            next()
          })
        }
        else if(data[id] > 0) { //interpret as "HAS"
          has(peer, id, data[id])
        }
      }
    }(id))

    function next () {
      if(--n) return
      cb(null, res)
    }
  }

  function dead (peer_id) {
    delete peers[peer_id]
    delete available[peer_id]
    delete streams[peer_id]
  }

  //LEGACY LEGACY LEGACY
  function legacySync (peer) {
    if(!legacy) return

    var drain //we need to keep a reference to drain
              //so we can abort it when we get an error.
    function hasLegacy (hashes) {
      var ary = Object.keys(hashes).filter(function (k) {
        return hashes[k] < 0
      })
      if(ary.length)
        peer.blobs.has(ary, function (err, haves) {
          if(err) drain.abort(err) //ERROR: abort this stream.
          else haves.forEach(function (have, i) {
            if(have) has(peer.id, ary[i], have)
          })
        })
    }

    function notPeer (err) {
      if(err) dead(peer.id)
    }

    drain = pull.drain(function (hash) {
      has(peer.id, hash, true)
    }, notPeer)


    pull(peer.blobs.changes(), drain)

    hasLegacy(want)

    //a stream of hashes
    pull(notify.listen(), pull.drain(hasLegacy, notPeer))
  }
  //LEGACY LEGACY LEGACY

  function createWantStream (id) {
    if(!streams[id]) {
      streams[id] = notify.listen()

      //merge in ids we are pushing.
      var w = clone(want)
      for(var k in push) w[k] = -1
      streams[id].push(w)
    }
    return pull(streams[id], onAbort(function (err, cb) {
      streams[id] = false
      cb(err)
    }))
  }

  function wantSink (peer) {
    createWantStream(peer.id) //set streams[peer.id]

    var modern = false
    return pull.drain(function (data) {
        modern = true
        //respond with list of blobs you already have,
        process(data, peer.id, function (err, has_data) {
          //(if you have any)
          if(!isEmpty(has_data) && streams[peer.id]) streams[peer.id].push(has_data)
        })
      }, function (err) {
        if(err && !modern) {
          streams[peer.id] = false
          if(legacy) legacySync(peer)
        }
        //if can handle unpeer another way,
        //then can refactor legacy handling out of sight.

        //handle error and fallback to legacy mode, if enabled.
        else if(peers[peer.id] == peer) {
          delete peers[peer.id]
          delete available[peer.id]
          delete streams[peer.id]
        }
      })
  }

  var self
  return self = {
    //id: name,
    has: function (id, cb) {
      id = toBlobId(id)

      if(isArray(id)) {
        for(var i = 0; i < id.length; i++)
          if(!isBlobId(id[i]))
            return cb(new Error('invalid id:'+id[i]))
      }
      else if(!isBlobId(id))
        return cb(new Error('invalid id:'+id))

      if(!legacy) {
        blobs.has.call(this, id, cb)
      }
      else {
      //LEGACY LEGACY LEGACY
        if(this === self || !this || this === global) { // a local call
          return blobs.has.call(this, id, cb)
        }
        //ELSE, interpret remote calls to has as a WANT request.
        //handling this by calling process (which calls size())
        //avoids a race condition in the tests.
        //(and avoids doubling the number of calls)
        var a = Array.isArray(id) ? id : [id]
        var o = {}
        a.forEach(function (h) { o[h] = -1 })
        //since this is always "has" process will never use the second arg.
        process(o, null, function (err, res) {
          var a = []; for(var k in o) a.push(res[k] > 0)
          cb(null, Array.isArray(id) ? a : a[0])
        })
      //LEGACY LEGACY LEGACY
      }
    },
    size: wrap(blobs.size),
    get: blobs.get,
    getSlice: blobs.getSlice,
    add: wrap(blobs.add),
    rm: wrap(blobs.rm),
    ls: blobs.ls,
    changes: function () {
      //XXX for bandwidth sensitive peers, don't tell them about blobs we arn't trying to push.
      return pull(
        blobs.ls({old: false, meta: false}),
        pull.filter(function (id) {
          return !stingy || push[id]
        })
      )
    },
    want: function (id, cb) {
      id = toBlobId(id)
      if(!isBlobId(id))
        return cb(new Error('invalid id:'+id))
      //always broadcast wants immediately, because of race condition
      //between has and adding a blob (needed to pass test/async.js)
      if(blobs.isEmptyHash(id)) return cb(null, true)

      var peerId = isAvailable(id)

      if(waiting[id])
        waiting[id].push(cb)
      else {
        waiting[id] = [cb]
        blobs.size(id, function (err, size) {
          if(size != null) {
            while(waiting[id].length)
              waiting[id].shift()(null, true)
            delete waiting[id]
          }
        })
      }

      if(!peerId && waiting[id]) queue(id, -1)

      if(peerId) return get(peerId, id)
    },
    push: function (id, cb) {
      id = toBlobId(id)
      //also store the id to push.
      if(!isBlobId(id))
        return cb(new Error('invalid hash:'+id))

      push[id] = push[id] || {}
      queue(id, -1)
      set.add(id, cb)
    },
    pushed: function () {
      return pushed.listen()
    },
    createWants: function () {
      return createWantStream(this.id)
    },
    //private api. used for testing. not exposed over rpc.
    _wantSink: wantSink,
    _onConnect: function (other, name) {
      peers[other.id] = other
      //sending of your wants starts when you we know
      //that they are not legacy style.
      //process is called when wantSync
      //doesn't immediately get an error.
      pull(other.blobs.createWants(), wantSink(other))
    },
    help: function () {
      return require('./help')
    }
  }
}



},
"r7K2Ec87mTos7IN6ebWeulFVVA5l0tGjezcSIff0kEA=":
function (require, module, exports, __dirname, __filename) {

function getStack(err) {
  if(err.stack && err.name && err.message)
    return err.stack.substring(err.name.length + 3 + err.message.length)
      .split('\n')
  else if(err.stack)
    return err.stack.split('\n')
}

function removePrefix (a, b) {
  return a.filter(function (e) {
    return !~b.indexOf(e)
  })
}

var explain = module.exports = function (err, message) {
  if(!(err.stack && err.name && err.message)) {
    console.error(new Error('stackless error'))
    return err
  }

  var _err = new Error(message)
  var stack = removePrefix(getStack(_err).slice(1), getStack(err)).join('\n')

  _err.__proto__ = err

  _err.stack =
    _err.name + ': ' + _err.message + '\n' +
    stack + '\n  ' + err.stack

  return _err
}




},
"rTIqex3sYPPS69ogkYFkae+1W1Z9JBzzzw+kxaSv5QA=":
function (require, module, exports, __dirname, __filename) {
if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      ctor.prototype = Object.create(superCtor.prototype, {
        constructor: {
          value: ctor,
          enumerable: false,
          writable: true,
          configurable: true
        }
      })
    }
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      var TempCtor = function () {}
      TempCtor.prototype = superCtor.prototype
      ctor.prototype = new TempCtor()
      ctor.prototype.constructor = ctor
    }
  }
}

},
"ri2iJYfd1hM101FVpLsSCXGjhg5rx9jF3AKh+LwFcIk=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const pull = require('pull-stream');
const pullAsync = require('pull-async');
const cat = require('pull-cat');
module.exports = {
    name: 'aboutSelf',
    version: '1.0.0',
    manifest: {
        get: 'async',
        stream: 'source',
    },
    permissions: {
        master: {
            allow: ['get', 'stream'],
        },
    },
    init: function init(ssb) {
        function get(feedId, cb) {
            // TODO: this is a workaround for https://github.com/ssb-ngi-pointer/ssb-db2/issues/235
            // When that issue is resolved, we should remove this boolean
            let done = false;
            ssb.db.onDrain('aboutSelf', () => {
                if (!done) {
                    done = true;
                    cb(null, ssb.db.getIndex('aboutSelf').getProfile(feedId));
                }
            });
        }
        function stream(feedId) {
            return cat([
                // First deliver latest field value
                pull(pullAsync((cb) => {
                    get(feedId, cb);
                }), pull.filter((out) => out.name || out.image || out.description)),
                // Then deliver live field values
                ssb.db.getIndex('aboutSelf').getLiveProfile(feedId),
            ]);
        }
        return {
            get,
            stream,
        };
    },
};
//# sourceMappingURL=aboutSelf.js.map
},
"rmhV6fXvZoeqj3bmndGFTxuZmFFGQ02v8xAVAIPP3gI=":
function (require, module, exports, __dirname, __filename) {

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = require('ms');
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => enableOverride === null ? createDebug.enabled(namespace) : enableOverride,
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);

		createDebug.names = [];
		createDebug.skips = [];

		let i;
		const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
		const len = split.length;

		for (i = 0; i < len; i++) {
			if (!split[i]) {
				// ignore empty strings
				continue;
			}

			namespaces = split[i].replace(/\*/g, '.*?');

			if (namespaces[0] === '-') {
				createDebug.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));
			} else {
				createDebug.names.push(new RegExp('^' + namespaces + '$'));
			}
		}
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names.map(toNamespace),
			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		if (name[name.length - 1] === '*') {
			return true;
		}

		let i;
		let len;

		for (i = 0, len = createDebug.skips.length; i < len; i++) {
			if (createDebug.skips[i].test(name)) {
				return false;
			}
		}

		for (i = 0, len = createDebug.names.length; i < len; i++) {
			if (createDebug.names[i].test(name)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Convert regexp to namespace
	*
	* @param {RegExp} regxep
	* @return {String} namespace
	* @api private
	*/
	function toNamespace(regexp) {
		return regexp.toString()
			.substring(2, regexp.toString().length - 2)
			.replace(/\.\*\?$/, '*');
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

module.exports = setup;

},
"rqwIhOjK14ppHLMhv6r7JKQ86nk8skJVNtKQIdyb/gs=":
function (require, module, exports, __dirname, __filename) {
'use strict'
function isFunction (f) {
  return 'function' === typeof f
}
function isContinuable (c) {
  return isFunction(c) && c.length === 1
}
function isSource (s) {
  return isFunction(s) && s.length === 2
}

module.exports = function (continuable) {
  var read = null
  return function (abort, cb) {
    if(read) return read(abort, cb)
    if(abort) return cb(abort)

    continuable(function again (err, value) {
      if(err) return cb(err)
      if(isSource(value)) (read = value)(abort, cb) //if it's a source... then read from it
      else if(isContinuable(value)) value(again) //if it's another continuable... then continue
      else throw new Error('not a valid source stream or continuable')
    })
  }
}











},
"rw6wQdeShnSEjU8e/YNtOxUjBtvczz3KxnDJvn1GGAY=":
function (require, module, exports, __dirname, __filename) {
function wrap (fn, hook) {
  return function () {
    return hook.call(this, fn, [].slice.call(arguments))
  }
}

module.exports = function hookable(fn) {

  function hooked () {
    return fn.apply(this, [].slice.call(arguments))
  }

  hooked.hook = function (hook) {
    fn = wrap(fn, hook)
    return this
  }

  return hooked
}

},
"rwNYsCS+A6tOLsNoqukwlgE/+tgudzpFMF5kNadc528=":
function (require, module, exports, __dirname, __filename) {
var Live = require('pull-live')

var old = require('./old')
var live = require('./live')

module.exports = function (db, opts) {
  if(opts && opts.tail) {
    console.error('pull-level: .tail option is depreciated. use .live instead')
    opts.live = opts.tail
  }
  return Live(function (opts) {
    return old(db, opts)
  }, function (opts) {
    return live(db, opts)
  })(opts)
}

},
"s0VA/WSn9Snw5iF0galXnEPUhSoS2pTt11wFpXW+RZc=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var define = require('define-properties');
var callBind = require('call-bind');

var implementation = require('./implementation');
var getPolyfill = require('./polyfill');
var shim = require('./shim');

var polyfill = callBind(getPolyfill(), Object);

define(polyfill, {
	getPolyfill: getPolyfill,
	implementation: implementation,
	shim: shim
});

module.exports = polyfill;

},
"s2GmZ2ZSShDi54xGGLJaMSX93aDQhunBlMbiZOlPmvc=":
function (require, module, exports, __dirname, __filename) {
const ref = require('ssb-ref')

module.exports = {
  name: 'classic',
  prepareForIsFeed(sbot, feedId, cb) {
    cb()
  },
  // used in request, block, cleanClock, sbot.post, vectorClock
  isFeed (sbot, feedId) {
    return ref.isFeed(feedId)
  },
  getAtSequence (sbot, pair, cb) {
    sbot.getAtSequence([pair.id, pair.sequence], (err, msg) => {
      cb(err, msg ? msg.value : null)
    })
  },
  appendMsg (sbot, msgVal, cb) {
    sbot.add(msgVal, (err, msg) => {
      cb(err && err.fatal ? err : null, msg)
    })
  },
  // used in onAppend
  convertMsg (sbot, msgVal, cb) {
    cb(null, msgVal)
  },
  // used in vectorClock
  isReady (sbot) {
    return Promise.resolve(true)
  },

  // used in ebt:stream to distinguish between messages and notes
  isMsg (msgVal) {
    return Number.isInteger(msgVal.sequence) && msgVal.sequence > 0 &&
      ref.isFeed(msgVal.author) && msgVal.content
  },
  // used in ebt:events
  getMsgAuthor (msgVal) {
    return msgVal.author
  },
  // used in ebt:events
  getMsgSequence (msgVal) {
    return msgVal.sequence
  }
}

},
"sBIjpA5A4qWyBo1+qf1Idy87JZuRsOvpsp+1eY3taIA=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "あいこくしん",
    "あいさつ",
    "あいだ",
    "あおぞら",
    "あかちゃん",
    "あきる",
    "あけがた",
    "あける",
    "あこがれる",
    "あさい",
    "あさひ",
    "あしあと",
    "あじわう",
    "あずかる",
    "あずき",
    "あそぶ",
    "あたえる",
    "あたためる",
    "あたりまえ",
    "あたる",
    "あつい",
    "あつかう",
    "あっしゅく",
    "あつまり",
    "あつめる",
    "あてな",
    "あてはまる",
    "あひる",
    "あぶら",
    "あぶる",
    "あふれる",
    "あまい",
    "あまど",
    "あまやかす",
    "あまり",
    "あみもの",
    "あめりか",
    "あやまる",
    "あゆむ",
    "あらいぐま",
    "あらし",
    "あらすじ",
    "あらためる",
    "あらゆる",
    "あらわす",
    "ありがとう",
    "あわせる",
    "あわてる",
    "あんい",
    "あんがい",
    "あんこ",
    "あんぜん",
    "あんてい",
    "あんない",
    "あんまり",
    "いいだす",
    "いおん",
    "いがい",
    "いがく",
    "いきおい",
    "いきなり",
    "いきもの",
    "いきる",
    "いくじ",
    "いくぶん",
    "いけばな",
    "いけん",
    "いこう",
    "いこく",
    "いこつ",
    "いさましい",
    "いさん",
    "いしき",
    "いじゅう",
    "いじょう",
    "いじわる",
    "いずみ",
    "いずれ",
    "いせい",
    "いせえび",
    "いせかい",
    "いせき",
    "いぜん",
    "いそうろう",
    "いそがしい",
    "いだい",
    "いだく",
    "いたずら",
    "いたみ",
    "いたりあ",
    "いちおう",
    "いちじ",
    "いちど",
    "いちば",
    "いちぶ",
    "いちりゅう",
    "いつか",
    "いっしゅん",
    "いっせい",
    "いっそう",
    "いったん",
    "いっち",
    "いってい",
    "いっぽう",
    "いてざ",
    "いてん",
    "いどう",
    "いとこ",
    "いない",
    "いなか",
    "いねむり",
    "いのち",
    "いのる",
    "いはつ",
    "いばる",
    "いはん",
    "いびき",
    "いひん",
    "いふく",
    "いへん",
    "いほう",
    "いみん",
    "いもうと",
    "いもたれ",
    "いもり",
    "いやがる",
    "いやす",
    "いよかん",
    "いよく",
    "いらい",
    "いらすと",
    "いりぐち",
    "いりょう",
    "いれい",
    "いれもの",
    "いれる",
    "いろえんぴつ",
    "いわい",
    "いわう",
    "いわかん",
    "いわば",
    "いわゆる",
    "いんげんまめ",
    "いんさつ",
    "いんしょう",
    "いんよう",
    "うえき",
    "うえる",
    "うおざ",
    "うがい",
    "うかぶ",
    "うかべる",
    "うきわ",
    "うくらいな",
    "うくれれ",
    "うけたまわる",
    "うけつけ",
    "うけとる",
    "うけもつ",
    "うける",
    "うごかす",
    "うごく",
    "うこん",
    "うさぎ",
    "うしなう",
    "うしろがみ",
    "うすい",
    "うすぎ",
    "うすぐらい",
    "うすめる",
    "うせつ",
    "うちあわせ",
    "うちがわ",
    "うちき",
    "うちゅう",
    "うっかり",
    "うつくしい",
    "うったえる",
    "うつる",
    "うどん",
    "うなぎ",
    "うなじ",
    "うなずく",
    "うなる",
    "うねる",
    "うのう",
    "うぶげ",
    "うぶごえ",
    "うまれる",
    "うめる",
    "うもう",
    "うやまう",
    "うよく",
    "うらがえす",
    "うらぐち",
    "うらない",
    "うりあげ",
    "うりきれ",
    "うるさい",
    "うれしい",
    "うれゆき",
    "うれる",
    "うろこ",
    "うわき",
    "うわさ",
    "うんこう",
    "うんちん",
    "うんてん",
    "うんどう",
    "えいえん",
    "えいが",
    "えいきょう",
    "えいご",
    "えいせい",
    "えいぶん",
    "えいよう",
    "えいわ",
    "えおり",
    "えがお",
    "えがく",
    "えきたい",
    "えくせる",
    "えしゃく",
    "えすて",
    "えつらん",
    "えのぐ",
    "えほうまき",
    "えほん",
    "えまき",
    "えもじ",
    "えもの",
    "えらい",
    "えらぶ",
    "えりあ",
    "えんえん",
    "えんかい",
    "えんぎ",
    "えんげき",
    "えんしゅう",
    "えんぜつ",
    "えんそく",
    "えんちょう",
    "えんとつ",
    "おいかける",
    "おいこす",
    "おいしい",
    "おいつく",
    "おうえん",
    "おうさま",
    "おうじ",
    "おうせつ",
    "おうたい",
    "おうふく",
    "おうべい",
    "おうよう",
    "おえる",
    "おおい",
    "おおう",
    "おおどおり",
    "おおや",
    "おおよそ",
    "おかえり",
    "おかず",
    "おがむ",
    "おかわり",
    "おぎなう",
    "おきる",
    "おくさま",
    "おくじょう",
    "おくりがな",
    "おくる",
    "おくれる",
    "おこす",
    "おこなう",
    "おこる",
    "おさえる",
    "おさない",
    "おさめる",
    "おしいれ",
    "おしえる",
    "おじぎ",
    "おじさん",
    "おしゃれ",
    "おそらく",
    "おそわる",
    "おたがい",
    "おたく",
    "おだやか",
    "おちつく",
    "おっと",
    "おつり",
    "おでかけ",
    "おとしもの",
    "おとなしい",
    "おどり",
    "おどろかす",
    "おばさん",
    "おまいり",
    "おめでとう",
    "おもいで",
    "おもう",
    "おもたい",
    "おもちゃ",
    "おやつ",
    "おやゆび",
    "およぼす",
    "おらんだ",
    "おろす",
    "おんがく",
    "おんけい",
    "おんしゃ",
    "おんせん",
    "おんだん",
    "おんちゅう",
    "おんどけい",
    "かあつ",
    "かいが",
    "がいき",
    "がいけん",
    "がいこう",
    "かいさつ",
    "かいしゃ",
    "かいすいよく",
    "かいぜん",
    "かいぞうど",
    "かいつう",
    "かいてん",
    "かいとう",
    "かいふく",
    "がいへき",
    "かいほう",
    "かいよう",
    "がいらい",
    "かいわ",
    "かえる",
    "かおり",
    "かかえる",
    "かがく",
    "かがし",
    "かがみ",
    "かくご",
    "かくとく",
    "かざる",
    "がぞう",
    "かたい",
    "かたち",
    "がちょう",
    "がっきゅう",
    "がっこう",
    "がっさん",
    "がっしょう",
    "かなざわし",
    "かのう",
    "がはく",
    "かぶか",
    "かほう",
    "かほご",
    "かまう",
    "かまぼこ",
    "かめれおん",
    "かゆい",
    "かようび",
    "からい",
    "かるい",
    "かろう",
    "かわく",
    "かわら",
    "がんか",
    "かんけい",
    "かんこう",
    "かんしゃ",
    "かんそう",
    "かんたん",
    "かんち",
    "がんばる",
    "きあい",
    "きあつ",
    "きいろ",
    "ぎいん",
    "きうい",
    "きうん",
    "きえる",
    "きおう",
    "きおく",
    "きおち",
    "きおん",
    "きかい",
    "きかく",
    "きかんしゃ",
    "ききて",
    "きくばり",
    "きくらげ",
    "きけんせい",
    "きこう",
    "きこえる",
    "きこく",
    "きさい",
    "きさく",
    "きさま",
    "きさらぎ",
    "ぎじかがく",
    "ぎしき",
    "ぎじたいけん",
    "ぎじにってい",
    "ぎじゅつしゃ",
    "きすう",
    "きせい",
    "きせき",
    "きせつ",
    "きそう",
    "きぞく",
    "きぞん",
    "きたえる",
    "きちょう",
    "きつえん",
    "ぎっちり",
    "きつつき",
    "きつね",
    "きてい",
    "きどう",
    "きどく",
    "きない",
    "きなが",
    "きなこ",
    "きぬごし",
    "きねん",
    "きのう",
    "きのした",
    "きはく",
    "きびしい",
    "きひん",
    "きふく",
    "きぶん",
    "きぼう",
    "きほん",
    "きまる",
    "きみつ",
    "きむずかしい",
    "きめる",
    "きもだめし",
    "きもち",
    "きもの",
    "きゃく",
    "きやく",
    "ぎゅうにく",
    "きよう",
    "きょうりゅう",
    "きらい",
    "きらく",
    "きりん",
    "きれい",
    "きれつ",
    "きろく",
    "ぎろん",
    "きわめる",
    "ぎんいろ",
    "きんかくじ",
    "きんじょ",
    "きんようび",
    "ぐあい",
    "くいず",
    "くうかん",
    "くうき",
    "くうぐん",
    "くうこう",
    "ぐうせい",
    "くうそう",
    "ぐうたら",
    "くうふく",
    "くうぼ",
    "くかん",
    "くきょう",
    "くげん",
    "ぐこう",
    "くさい",
    "くさき",
    "くさばな",
    "くさる",
    "くしゃみ",
    "くしょう",
    "くすのき",
    "くすりゆび",
    "くせげ",
    "くせん",
    "ぐたいてき",
    "くださる",
    "くたびれる",
    "くちこみ",
    "くちさき",
    "くつした",
    "ぐっすり",
    "くつろぐ",
    "くとうてん",
    "くどく",
    "くなん",
    "くねくね",
    "くのう",
    "くふう",
    "くみあわせ",
    "くみたてる",
    "くめる",
    "くやくしょ",
    "くらす",
    "くらべる",
    "くるま",
    "くれる",
    "くろう",
    "くわしい",
    "ぐんかん",
    "ぐんしょく",
    "ぐんたい",
    "ぐんて",
    "けあな",
    "けいかく",
    "けいけん",
    "けいこ",
    "けいさつ",
    "げいじゅつ",
    "けいたい",
    "げいのうじん",
    "けいれき",
    "けいろ",
    "けおとす",
    "けおりもの",
    "げきか",
    "げきげん",
    "げきだん",
    "げきちん",
    "げきとつ",
    "げきは",
    "げきやく",
    "げこう",
    "げこくじょう",
    "げざい",
    "けさき",
    "げざん",
    "けしき",
    "けしごむ",
    "けしょう",
    "げすと",
    "けたば",
    "けちゃっぷ",
    "けちらす",
    "けつあつ",
    "けつい",
    "けつえき",
    "けっこん",
    "けつじょ",
    "けっせき",
    "けってい",
    "けつまつ",
    "げつようび",
    "げつれい",
    "けつろん",
    "げどく",
    "けとばす",
    "けとる",
    "けなげ",
    "けなす",
    "けなみ",
    "けぬき",
    "げねつ",
    "けねん",
    "けはい",
    "げひん",
    "けぶかい",
    "げぼく",
    "けまり",
    "けみかる",
    "けむし",
    "けむり",
    "けもの",
    "けらい",
    "けろけろ",
    "けわしい",
    "けんい",
    "けんえつ",
    "けんお",
    "けんか",
    "げんき",
    "けんげん",
    "けんこう",
    "けんさく",
    "けんしゅう",
    "けんすう",
    "げんそう",
    "けんちく",
    "けんてい",
    "けんとう",
    "けんない",
    "けんにん",
    "げんぶつ",
    "けんま",
    "けんみん",
    "けんめい",
    "けんらん",
    "けんり",
    "こあくま",
    "こいぬ",
    "こいびと",
    "ごうい",
    "こうえん",
    "こうおん",
    "こうかん",
    "ごうきゅう",
    "ごうけい",
    "こうこう",
    "こうさい",
    "こうじ",
    "こうすい",
    "ごうせい",
    "こうそく",
    "こうたい",
    "こうちゃ",
    "こうつう",
    "こうてい",
    "こうどう",
    "こうない",
    "こうはい",
    "ごうほう",
    "ごうまん",
    "こうもく",
    "こうりつ",
    "こえる",
    "こおり",
    "ごかい",
    "ごがつ",
    "ごかん",
    "こくご",
    "こくさい",
    "こくとう",
    "こくない",
    "こくはく",
    "こぐま",
    "こけい",
    "こける",
    "ここのか",
    "こころ",
    "こさめ",
    "こしつ",
    "こすう",
    "こせい",
    "こせき",
    "こぜん",
    "こそだて",
    "こたい",
    "こたえる",
    "こたつ",
    "こちょう",
    "こっか",
    "こつこつ",
    "こつばん",
    "こつぶ",
    "こてい",
    "こてん",
    "ことがら",
    "ことし",
    "ことば",
    "ことり",
    "こなごな",
    "こねこね",
    "このまま",
    "このみ",
    "このよ",
    "ごはん",
    "こひつじ",
    "こふう",
    "こふん",
    "こぼれる",
    "ごまあぶら",
    "こまかい",
    "ごますり",
    "こまつな",
    "こまる",
    "こむぎこ",
    "こもじ",
    "こもち",
    "こもの",
    "こもん",
    "こやく",
    "こやま",
    "こゆう",
    "こゆび",
    "こよい",
    "こよう",
    "こりる",
    "これくしょん",
    "ころっけ",
    "こわもて",
    "こわれる",
    "こんいん",
    "こんかい",
    "こんき",
    "こんしゅう",
    "こんすい",
    "こんだて",
    "こんとん",
    "こんなん",
    "こんびに",
    "こんぽん",
    "こんまけ",
    "こんや",
    "こんれい",
    "こんわく",
    "ざいえき",
    "さいかい",
    "さいきん",
    "ざいげん",
    "ざいこ",
    "さいしょ",
    "さいせい",
    "ざいたく",
    "ざいちゅう",
    "さいてき",
    "ざいりょう",
    "さうな",
    "さかいし",
    "さがす",
    "さかな",
    "さかみち",
    "さがる",
    "さぎょう",
    "さくし",
    "さくひん",
    "さくら",
    "さこく",
    "さこつ",
    "さずかる",
    "ざせき",
    "さたん",
    "さつえい",
    "ざつおん",
    "ざっか",
    "ざつがく",
    "さっきょく",
    "ざっし",
    "さつじん",
    "ざっそう",
    "さつたば",
    "さつまいも",
    "さてい",
    "さといも",
    "さとう",
    "さとおや",
    "さとし",
    "さとる",
    "さのう",
    "さばく",
    "さびしい",
    "さべつ",
    "さほう",
    "さほど",
    "さます",
    "さみしい",
    "さみだれ",
    "さむけ",
    "さめる",
    "さやえんどう",
    "さゆう",
    "さよう",
    "さよく",
    "さらだ",
    "ざるそば",
    "さわやか",
    "さわる",
    "さんいん",
    "さんか",
    "さんきゃく",
    "さんこう",
    "さんさい",
    "ざんしょ",
    "さんすう",
    "さんせい",
    "さんそ",
    "さんち",
    "さんま",
    "さんみ",
    "さんらん",
    "しあい",
    "しあげ",
    "しあさって",
    "しあわせ",
    "しいく",
    "しいん",
    "しうち",
    "しえい",
    "しおけ",
    "しかい",
    "しかく",
    "じかん",
    "しごと",
    "しすう",
    "じだい",
    "したうけ",
    "したぎ",
    "したて",
    "したみ",
    "しちょう",
    "しちりん",
    "しっかり",
    "しつじ",
    "しつもん",
    "してい",
    "してき",
    "してつ",
    "じてん",
    "じどう",
    "しなぎれ",
    "しなもの",
    "しなん",
    "しねま",
    "しねん",
    "しのぐ",
    "しのぶ",
    "しはい",
    "しばかり",
    "しはつ",
    "しはらい",
    "しはん",
    "しひょう",
    "しふく",
    "じぶん",
    "しへい",
    "しほう",
    "しほん",
    "しまう",
    "しまる",
    "しみん",
    "しむける",
    "じむしょ",
    "しめい",
    "しめる",
    "しもん",
    "しゃいん",
    "しゃうん",
    "しゃおん",
    "じゃがいも",
    "しやくしょ",
    "しゃくほう",
    "しゃけん",
    "しゃこ",
    "しゃざい",
    "しゃしん",
    "しゃせん",
    "しゃそう",
    "しゃたい",
    "しゃちょう",
    "しゃっきん",
    "じゃま",
    "しゃりん",
    "しゃれい",
    "じゆう",
    "じゅうしょ",
    "しゅくはく",
    "じゅしん",
    "しゅっせき",
    "しゅみ",
    "しゅらば",
    "じゅんばん",
    "しょうかい",
    "しょくたく",
    "しょっけん",
    "しょどう",
    "しょもつ",
    "しらせる",
    "しらべる",
    "しんか",
    "しんこう",
    "じんじゃ",
    "しんせいじ",
    "しんちく",
    "しんりん",
    "すあげ",
    "すあし",
    "すあな",
    "ずあん",
    "すいえい",
    "すいか",
    "すいとう",
    "ずいぶん",
    "すいようび",
    "すうがく",
    "すうじつ",
    "すうせん",
    "すおどり",
    "すきま",
    "すくう",
    "すくない",
    "すける",
    "すごい",
    "すこし",
    "ずさん",
    "すずしい",
    "すすむ",
    "すすめる",
    "すっかり",
    "ずっしり",
    "ずっと",
    "すてき",
    "すてる",
    "すねる",
    "すのこ",
    "すはだ",
    "すばらしい",
    "ずひょう",
    "ずぶぬれ",
    "すぶり",
    "すふれ",
    "すべて",
    "すべる",
    "ずほう",
    "すぼん",
    "すまい",
    "すめし",
    "すもう",
    "すやき",
    "すらすら",
    "するめ",
    "すれちがう",
    "すろっと",
    "すわる",
    "すんぜん",
    "すんぽう",
    "せあぶら",
    "せいかつ",
    "せいげん",
    "せいじ",
    "せいよう",
    "せおう",
    "せかいかん",
    "せきにん",
    "せきむ",
    "せきゆ",
    "せきらんうん",
    "せけん",
    "せこう",
    "せすじ",
    "せたい",
    "せたけ",
    "せっかく",
    "せっきゃく",
    "ぜっく",
    "せっけん",
    "せっこつ",
    "せっさたくま",
    "せつぞく",
    "せつだん",
    "せつでん",
    "せっぱん",
    "せつび",
    "せつぶん",
    "せつめい",
    "せつりつ",
    "せなか",
    "せのび",
    "せはば",
    "せびろ",
    "せぼね",
    "せまい",
    "せまる",
    "せめる",
    "せもたれ",
    "せりふ",
    "ぜんあく",
    "せんい",
    "せんえい",
    "せんか",
    "せんきょ",
    "せんく",
    "せんげん",
    "ぜんご",
    "せんさい",
    "せんしゅ",
    "せんすい",
    "せんせい",
    "せんぞ",
    "せんたく",
    "せんちょう",
    "せんてい",
    "せんとう",
    "せんぬき",
    "せんねん",
    "せんぱい",
    "ぜんぶ",
    "ぜんぽう",
    "せんむ",
    "せんめんじょ",
    "せんもん",
    "せんやく",
    "せんゆう",
    "せんよう",
    "ぜんら",
    "ぜんりゃく",
    "せんれい",
    "せんろ",
    "そあく",
    "そいとげる",
    "そいね",
    "そうがんきょう",
    "そうき",
    "そうご",
    "そうしん",
    "そうだん",
    "そうなん",
    "そうび",
    "そうめん",
    "そうり",
    "そえもの",
    "そえん",
    "そがい",
    "そげき",
    "そこう",
    "そこそこ",
    "そざい",
    "そしな",
    "そせい",
    "そせん",
    "そそぐ",
    "そだてる",
    "そつう",
    "そつえん",
    "そっかん",
    "そつぎょう",
    "そっけつ",
    "そっこう",
    "そっせん",
    "そっと",
    "そとがわ",
    "そとづら",
    "そなえる",
    "そなた",
    "そふぼ",
    "そぼく",
    "そぼろ",
    "そまつ",
    "そまる",
    "そむく",
    "そむりえ",
    "そめる",
    "そもそも",
    "そよかぜ",
    "そらまめ",
    "そろう",
    "そんかい",
    "そんけい",
    "そんざい",
    "そんしつ",
    "そんぞく",
    "そんちょう",
    "ぞんび",
    "ぞんぶん",
    "そんみん",
    "たあい",
    "たいいん",
    "たいうん",
    "たいえき",
    "たいおう",
    "だいがく",
    "たいき",
    "たいぐう",
    "たいけん",
    "たいこ",
    "たいざい",
    "だいじょうぶ",
    "だいすき",
    "たいせつ",
    "たいそう",
    "だいたい",
    "たいちょう",
    "たいてい",
    "だいどころ",
    "たいない",
    "たいねつ",
    "たいのう",
    "たいはん",
    "だいひょう",
    "たいふう",
    "たいへん",
    "たいほ",
    "たいまつばな",
    "たいみんぐ",
    "たいむ",
    "たいめん",
    "たいやき",
    "たいよう",
    "たいら",
    "たいりょく",
    "たいる",
    "たいわん",
    "たうえ",
    "たえる",
    "たおす",
    "たおる",
    "たおれる",
    "たかい",
    "たかね",
    "たきび",
    "たくさん",
    "たこく",
    "たこやき",
    "たさい",
    "たしざん",
    "だじゃれ",
    "たすける",
    "たずさわる",
    "たそがれ",
    "たたかう",
    "たたく",
    "ただしい",
    "たたみ",
    "たちばな",
    "だっかい",
    "だっきゃく",
    "だっこ",
    "だっしゅつ",
    "だったい",
    "たてる",
    "たとえる",
    "たなばた",
    "たにん",
    "たぬき",
    "たのしみ",
    "たはつ",
    "たぶん",
    "たべる",
    "たぼう",
    "たまご",
    "たまる",
    "だむる",
    "ためいき",
    "ためす",
    "ためる",
    "たもつ",
    "たやすい",
    "たよる",
    "たらす",
    "たりきほんがん",
    "たりょう",
    "たりる",
    "たると",
    "たれる",
    "たれんと",
    "たろっと",
    "たわむれる",
    "だんあつ",
    "たんい",
    "たんおん",
    "たんか",
    "たんき",
    "たんけん",
    "たんご",
    "たんさん",
    "たんじょうび",
    "だんせい",
    "たんそく",
    "たんたい",
    "だんち",
    "たんてい",
    "たんとう",
    "だんな",
    "たんにん",
    "だんねつ",
    "たんのう",
    "たんぴん",
    "だんぼう",
    "たんまつ",
    "たんめい",
    "だんれつ",
    "だんろ",
    "だんわ",
    "ちあい",
    "ちあん",
    "ちいき",
    "ちいさい",
    "ちえん",
    "ちかい",
    "ちから",
    "ちきゅう",
    "ちきん",
    "ちけいず",
    "ちけん",
    "ちこく",
    "ちさい",
    "ちしき",
    "ちしりょう",
    "ちせい",
    "ちそう",
    "ちたい",
    "ちたん",
    "ちちおや",
    "ちつじょ",
    "ちてき",
    "ちてん",
    "ちぬき",
    "ちぬり",
    "ちのう",
    "ちひょう",
    "ちへいせん",
    "ちほう",
    "ちまた",
    "ちみつ",
    "ちみどろ",
    "ちめいど",
    "ちゃんこなべ",
    "ちゅうい",
    "ちゆりょく",
    "ちょうし",
    "ちょさくけん",
    "ちらし",
    "ちらみ",
    "ちりがみ",
    "ちりょう",
    "ちるど",
    "ちわわ",
    "ちんたい",
    "ちんもく",
    "ついか",
    "ついたち",
    "つうか",
    "つうじょう",
    "つうはん",
    "つうわ",
    "つかう",
    "つかれる",
    "つくね",
    "つくる",
    "つけね",
    "つける",
    "つごう",
    "つたえる",
    "つづく",
    "つつじ",
    "つつむ",
    "つとめる",
    "つながる",
    "つなみ",
    "つねづね",
    "つのる",
    "つぶす",
    "つまらない",
    "つまる",
    "つみき",
    "つめたい",
    "つもり",
    "つもる",
    "つよい",
    "つるぼ",
    "つるみく",
    "つわもの",
    "つわり",
    "てあし",
    "てあて",
    "てあみ",
    "ていおん",
    "ていか",
    "ていき",
    "ていけい",
    "ていこく",
    "ていさつ",
    "ていし",
    "ていせい",
    "ていたい",
    "ていど",
    "ていねい",
    "ていひょう",
    "ていへん",
    "ていぼう",
    "てうち",
    "ておくれ",
    "てきとう",
    "てくび",
    "でこぼこ",
    "てさぎょう",
    "てさげ",
    "てすり",
    "てそう",
    "てちがい",
    "てちょう",
    "てつがく",
    "てつづき",
    "でっぱ",
    "てつぼう",
    "てつや",
    "でぬかえ",
    "てぬき",
    "てぬぐい",
    "てのひら",
    "てはい",
    "てぶくろ",
    "てふだ",
    "てほどき",
    "てほん",
    "てまえ",
    "てまきずし",
    "てみじか",
    "てみやげ",
    "てらす",
    "てれび",
    "てわけ",
    "てわたし",
    "でんあつ",
    "てんいん",
    "てんかい",
    "てんき",
    "てんぐ",
    "てんけん",
    "てんごく",
    "てんさい",
    "てんし",
    "てんすう",
    "でんち",
    "てんてき",
    "てんとう",
    "てんない",
    "てんぷら",
    "てんぼうだい",
    "てんめつ",
    "てんらんかい",
    "でんりょく",
    "でんわ",
    "どあい",
    "といれ",
    "どうかん",
    "とうきゅう",
    "どうぐ",
    "とうし",
    "とうむぎ",
    "とおい",
    "とおか",
    "とおく",
    "とおす",
    "とおる",
    "とかい",
    "とかす",
    "ときおり",
    "ときどき",
    "とくい",
    "とくしゅう",
    "とくてん",
    "とくに",
    "とくべつ",
    "とけい",
    "とける",
    "とこや",
    "とさか",
    "としょかん",
    "とそう",
    "とたん",
    "とちゅう",
    "とっきゅう",
    "とっくん",
    "とつぜん",
    "とつにゅう",
    "とどける",
    "ととのえる",
    "とない",
    "となえる",
    "となり",
    "とのさま",
    "とばす",
    "どぶがわ",
    "とほう",
    "とまる",
    "とめる",
    "ともだち",
    "ともる",
    "どようび",
    "とらえる",
    "とんかつ",
    "どんぶり",
    "ないかく",
    "ないこう",
    "ないしょ",
    "ないす",
    "ないせん",
    "ないそう",
    "なおす",
    "ながい",
    "なくす",
    "なげる",
    "なこうど",
    "なさけ",
    "なたでここ",
    "なっとう",
    "なつやすみ",
    "ななおし",
    "なにごと",
    "なにもの",
    "なにわ",
    "なのか",
    "なふだ",
    "なまいき",
    "なまえ",
    "なまみ",
    "なみだ",
    "なめらか",
    "なめる",
    "なやむ",
    "ならう",
    "ならび",
    "ならぶ",
    "なれる",
    "なわとび",
    "なわばり",
    "にあう",
    "にいがた",
    "にうけ",
    "におい",
    "にかい",
    "にがて",
    "にきび",
    "にくしみ",
    "にくまん",
    "にげる",
    "にさんかたんそ",
    "にしき",
    "にせもの",
    "にちじょう",
    "にちようび",
    "にっか",
    "にっき",
    "にっけい",
    "にっこう",
    "にっさん",
    "にっしょく",
    "にっすう",
    "にっせき",
    "にってい",
    "になう",
    "にほん",
    "にまめ",
    "にもつ",
    "にやり",
    "にゅういん",
    "にりんしゃ",
    "にわとり",
    "にんい",
    "にんか",
    "にんき",
    "にんげん",
    "にんしき",
    "にんずう",
    "にんそう",
    "にんたい",
    "にんち",
    "にんてい",
    "にんにく",
    "にんぷ",
    "にんまり",
    "にんむ",
    "にんめい",
    "にんよう",
    "ぬいくぎ",
    "ぬかす",
    "ぬぐいとる",
    "ぬぐう",
    "ぬくもり",
    "ぬすむ",
    "ぬまえび",
    "ぬめり",
    "ぬらす",
    "ぬんちゃく",
    "ねあげ",
    "ねいき",
    "ねいる",
    "ねいろ",
    "ねぐせ",
    "ねくたい",
    "ねくら",
    "ねこぜ",
    "ねこむ",
    "ねさげ",
    "ねすごす",
    "ねそべる",
    "ねだん",
    "ねつい",
    "ねっしん",
    "ねつぞう",
    "ねったいぎょ",
    "ねぶそく",
    "ねふだ",
    "ねぼう",
    "ねほりはほり",
    "ねまき",
    "ねまわし",
    "ねみみ",
    "ねむい",
    "ねむたい",
    "ねもと",
    "ねらう",
    "ねわざ",
    "ねんいり",
    "ねんおし",
    "ねんかん",
    "ねんきん",
    "ねんぐ",
    "ねんざ",
    "ねんし",
    "ねんちゃく",
    "ねんど",
    "ねんぴ",
    "ねんぶつ",
    "ねんまつ",
    "ねんりょう",
    "ねんれい",
    "のいず",
    "のおづま",
    "のがす",
    "のきなみ",
    "のこぎり",
    "のこす",
    "のこる",
    "のせる",
    "のぞく",
    "のぞむ",
    "のたまう",
    "のちほど",
    "のっく",
    "のばす",
    "のはら",
    "のべる",
    "のぼる",
    "のみもの",
    "のやま",
    "のらいぬ",
    "のらねこ",
    "のりもの",
    "のりゆき",
    "のれん",
    "のんき",
    "ばあい",
    "はあく",
    "ばあさん",
    "ばいか",
    "ばいく",
    "はいけん",
    "はいご",
    "はいしん",
    "はいすい",
    "はいせん",
    "はいそう",
    "はいち",
    "ばいばい",
    "はいれつ",
    "はえる",
    "はおる",
    "はかい",
    "ばかり",
    "はかる",
    "はくしゅ",
    "はけん",
    "はこぶ",
    "はさみ",
    "はさん",
    "はしご",
    "ばしょ",
    "はしる",
    "はせる",
    "ぱそこん",
    "はそん",
    "はたん",
    "はちみつ",
    "はつおん",
    "はっかく",
    "はづき",
    "はっきり",
    "はっくつ",
    "はっけん",
    "はっこう",
    "はっさん",
    "はっしん",
    "はったつ",
    "はっちゅう",
    "はってん",
    "はっぴょう",
    "はっぽう",
    "はなす",
    "はなび",
    "はにかむ",
    "はぶらし",
    "はみがき",
    "はむかう",
    "はめつ",
    "はやい",
    "はやし",
    "はらう",
    "はろうぃん",
    "はわい",
    "はんい",
    "はんえい",
    "はんおん",
    "はんかく",
    "はんきょう",
    "ばんぐみ",
    "はんこ",
    "はんしゃ",
    "はんすう",
    "はんだん",
    "ぱんち",
    "ぱんつ",
    "はんてい",
    "はんとし",
    "はんのう",
    "はんぱ",
    "はんぶん",
    "はんぺん",
    "はんぼうき",
    "はんめい",
    "はんらん",
    "はんろん",
    "ひいき",
    "ひうん",
    "ひえる",
    "ひかく",
    "ひかり",
    "ひかる",
    "ひかん",
    "ひくい",
    "ひけつ",
    "ひこうき",
    "ひこく",
    "ひさい",
    "ひさしぶり",
    "ひさん",
    "びじゅつかん",
    "ひしょ",
    "ひそか",
    "ひそむ",
    "ひたむき",
    "ひだり",
    "ひたる",
    "ひつぎ",
    "ひっこし",
    "ひっし",
    "ひつじゅひん",
    "ひっす",
    "ひつぜん",
    "ぴったり",
    "ぴっちり",
    "ひつよう",
    "ひてい",
    "ひとごみ",
    "ひなまつり",
    "ひなん",
    "ひねる",
    "ひはん",
    "ひびく",
    "ひひょう",
    "ひほう",
    "ひまわり",
    "ひまん",
    "ひみつ",
    "ひめい",
    "ひめじし",
    "ひやけ",
    "ひやす",
    "ひよう",
    "びょうき",
    "ひらがな",
    "ひらく",
    "ひりつ",
    "ひりょう",
    "ひるま",
    "ひるやすみ",
    "ひれい",
    "ひろい",
    "ひろう",
    "ひろき",
    "ひろゆき",
    "ひんかく",
    "ひんけつ",
    "ひんこん",
    "ひんしゅ",
    "ひんそう",
    "ぴんち",
    "ひんぱん",
    "びんぼう",
    "ふあん",
    "ふいうち",
    "ふうけい",
    "ふうせん",
    "ぷうたろう",
    "ふうとう",
    "ふうふ",
    "ふえる",
    "ふおん",
    "ふかい",
    "ふきん",
    "ふくざつ",
    "ふくぶくろ",
    "ふこう",
    "ふさい",
    "ふしぎ",
    "ふじみ",
    "ふすま",
    "ふせい",
    "ふせぐ",
    "ふそく",
    "ぶたにく",
    "ふたん",
    "ふちょう",
    "ふつう",
    "ふつか",
    "ふっかつ",
    "ふっき",
    "ふっこく",
    "ぶどう",
    "ふとる",
    "ふとん",
    "ふのう",
    "ふはい",
    "ふひょう",
    "ふへん",
    "ふまん",
    "ふみん",
    "ふめつ",
    "ふめん",
    "ふよう",
    "ふりこ",
    "ふりる",
    "ふるい",
    "ふんいき",
    "ぶんがく",
    "ぶんぐ",
    "ふんしつ",
    "ぶんせき",
    "ふんそう",
    "ぶんぽう",
    "へいあん",
    "へいおん",
    "へいがい",
    "へいき",
    "へいげん",
    "へいこう",
    "へいさ",
    "へいしゃ",
    "へいせつ",
    "へいそ",
    "へいたく",
    "へいてん",
    "へいねつ",
    "へいわ",
    "へきが",
    "へこむ",
    "べにいろ",
    "べにしょうが",
    "へらす",
    "へんかん",
    "べんきょう",
    "べんごし",
    "へんさい",
    "へんたい",
    "べんり",
    "ほあん",
    "ほいく",
    "ぼうぎょ",
    "ほうこく",
    "ほうそう",
    "ほうほう",
    "ほうもん",
    "ほうりつ",
    "ほえる",
    "ほおん",
    "ほかん",
    "ほきょう",
    "ぼきん",
    "ほくろ",
    "ほけつ",
    "ほけん",
    "ほこう",
    "ほこる",
    "ほしい",
    "ほしつ",
    "ほしゅ",
    "ほしょう",
    "ほせい",
    "ほそい",
    "ほそく",
    "ほたて",
    "ほたる",
    "ぽちぶくろ",
    "ほっきょく",
    "ほっさ",
    "ほったん",
    "ほとんど",
    "ほめる",
    "ほんい",
    "ほんき",
    "ほんけ",
    "ほんしつ",
    "ほんやく",
    "まいにち",
    "まかい",
    "まかせる",
    "まがる",
    "まける",
    "まこと",
    "まさつ",
    "まじめ",
    "ますく",
    "まぜる",
    "まつり",
    "まとめ",
    "まなぶ",
    "まぬけ",
    "まねく",
    "まほう",
    "まもる",
    "まゆげ",
    "まよう",
    "まろやか",
    "まわす",
    "まわり",
    "まわる",
    "まんが",
    "まんきつ",
    "まんぞく",
    "まんなか",
    "みいら",
    "みうち",
    "みえる",
    "みがく",
    "みかた",
    "みかん",
    "みけん",
    "みこん",
    "みじかい",
    "みすい",
    "みすえる",
    "みせる",
    "みっか",
    "みつかる",
    "みつける",
    "みてい",
    "みとめる",
    "みなと",
    "みなみかさい",
    "みねらる",
    "みのう",
    "みのがす",
    "みほん",
    "みもと",
    "みやげ",
    "みらい",
    "みりょく",
    "みわく",
    "みんか",
    "みんぞく",
    "むいか",
    "むえき",
    "むえん",
    "むかい",
    "むかう",
    "むかえ",
    "むかし",
    "むぎちゃ",
    "むける",
    "むげん",
    "むさぼる",
    "むしあつい",
    "むしば",
    "むじゅん",
    "むしろ",
    "むすう",
    "むすこ",
    "むすぶ",
    "むすめ",
    "むせる",
    "むせん",
    "むちゅう",
    "むなしい",
    "むのう",
    "むやみ",
    "むよう",
    "むらさき",
    "むりょう",
    "むろん",
    "めいあん",
    "めいうん",
    "めいえん",
    "めいかく",
    "めいきょく",
    "めいさい",
    "めいし",
    "めいそう",
    "めいぶつ",
    "めいれい",
    "めいわく",
    "めぐまれる",
    "めざす",
    "めした",
    "めずらしい",
    "めだつ",
    "めまい",
    "めやす",
    "めんきょ",
    "めんせき",
    "めんどう",
    "もうしあげる",
    "もうどうけん",
    "もえる",
    "もくし",
    "もくてき",
    "もくようび",
    "もちろん",
    "もどる",
    "もらう",
    "もんく",
    "もんだい",
    "やおや",
    "やける",
    "やさい",
    "やさしい",
    "やすい",
    "やすたろう",
    "やすみ",
    "やせる",
    "やそう",
    "やたい",
    "やちん",
    "やっと",
    "やっぱり",
    "やぶる",
    "やめる",
    "ややこしい",
    "やよい",
    "やわらかい",
    "ゆうき",
    "ゆうびんきょく",
    "ゆうべ",
    "ゆうめい",
    "ゆけつ",
    "ゆしゅつ",
    "ゆせん",
    "ゆそう",
    "ゆたか",
    "ゆちゃく",
    "ゆでる",
    "ゆにゅう",
    "ゆびわ",
    "ゆらい",
    "ゆれる",
    "ようい",
    "ようか",
    "ようきゅう",
    "ようじ",
    "ようす",
    "ようちえん",
    "よかぜ",
    "よかん",
    "よきん",
    "よくせい",
    "よくぼう",
    "よけい",
    "よごれる",
    "よさん",
    "よしゅう",
    "よそう",
    "よそく",
    "よっか",
    "よてい",
    "よどがわく",
    "よねつ",
    "よやく",
    "よゆう",
    "よろこぶ",
    "よろしい",
    "らいう",
    "らくがき",
    "らくご",
    "らくさつ",
    "らくだ",
    "らしんばん",
    "らせん",
    "らぞく",
    "らたい",
    "らっか",
    "られつ",
    "りえき",
    "りかい",
    "りきさく",
    "りきせつ",
    "りくぐん",
    "りくつ",
    "りけん",
    "りこう",
    "りせい",
    "りそう",
    "りそく",
    "りてん",
    "りねん",
    "りゆう",
    "りゅうがく",
    "りよう",
    "りょうり",
    "りょかん",
    "りょくちゃ",
    "りょこう",
    "りりく",
    "りれき",
    "りろん",
    "りんご",
    "るいけい",
    "るいさい",
    "るいじ",
    "るいせき",
    "るすばん",
    "るりがわら",
    "れいかん",
    "れいぎ",
    "れいせい",
    "れいぞうこ",
    "れいとう",
    "れいぼう",
    "れきし",
    "れきだい",
    "れんあい",
    "れんけい",
    "れんこん",
    "れんさい",
    "れんしゅう",
    "れんぞく",
    "れんらく",
    "ろうか",
    "ろうご",
    "ろうじん",
    "ろうそく",
    "ろくが",
    "ろこつ",
    "ろじうら",
    "ろしゅつ",
    "ろせん",
    "ろてん",
    "ろめん",
    "ろれつ",
    "ろんぎ",
    "ろんぱ",
    "ろんぶん",
    "ろんり",
    "わかす",
    "わかめ",
    "わかやま",
    "わかれる",
    "わしつ",
    "わじまし",
    "わすれもの",
    "わらう",
    "われる"
]

},
"sEVbgS2SVdiKblUzCYwGwg+DLmGgnGsI1AkpCzt+Ld4=":
function (require, module, exports, __dirname, __filename) {
/* eslint-env browser */

module.exports = IdbKvStore

var EventEmitter = require('events').EventEmitter
var inherits = require('inherits')
var promisize = require('promisize')

var global = typeof window === 'undefined' ? self : window
var IDB = global.indexedDB || global.mozIndexedDB || global.webkitIndexedDB || global.msIndexedDB

IdbKvStore.INDEXEDDB_SUPPORT = IDB != null
IdbKvStore.BROADCAST_SUPPORT = global.BroadcastChannel != null

inherits(IdbKvStore, EventEmitter)
function IdbKvStore (name, opts, cb) {
  var self = this
  if (typeof name !== 'string') throw new Error('A name must be supplied of type string')
  if (!IDB) throw new Error('IndexedDB not supported')
  if (typeof opts === 'function') return new IdbKvStore(name, null, opts)
  if (!(self instanceof IdbKvStore)) return new IdbKvStore(name, opts, cb)
  if (!opts) opts = {}

  EventEmitter.call(self)

  self._db = null
  self._closed = false
  self._channel = null
  self._waiters = []

  if (opts.disableBroadcast !== true) {
    var Channel = opts.channel || global.BroadcastChannel
    if (Channel) {
      self._channel = new Channel(name)
      self._channel.onmessage = onChange
    }
  }

  var request = IDB.open(name)
  request.onerror = onerror
  request.onsuccess = onsuccess
  request.onupgradeneeded = onupgradeneeded

  self.on('newListener', onNewListener)

  function onerror (event) {
    handleError(event)
    self._close(event.target.error)
    if (cb) cb(event.target.error)
  }

  function onDbError (event) {
    handleError(event)
    self._close(event.target.error)
  }

  function onsuccess (event) {
    if (self._closed) {
      event.target.result.close()
    } else {
      self._db = event.target.result
      self._db.onclose = onclose
      self._db.onerror = onDbError
      for (var i in self._waiters) self._waiters[i]._init(null)
      self._waiters = null
      if (cb) cb(null)
      self.emit('open')
    }
  }

  function onupgradeneeded (event) {
    var db = event.target.result
    db.createObjectStore('kv', {autoIncrement: true})
  }

  function onclose () {
    self._close()
  }

  function onNewListener (event) {
    if (event !== 'add' && event !== 'set' && event !== 'remove') return
    if (!self._channel) return self.emit('error', new Error('No BroadcastChannel support'))
  }

  function onChange (event) {
    if (event.data.method === 'add') self.emit('add', event.data)
    else if (event.data.method === 'set') self.emit('set', event.data)
    else if (event.data.method === 'remove') self.emit('remove', event.data)
  }
}

IdbKvStore.prototype.get = function (key, cb) {
  return this.transaction('readonly').get(key, cb)
}

IdbKvStore.prototype.getMultiple = function (keys, cb) {
  return this.transaction('readonly').getMultiple(keys, cb)
}

IdbKvStore.prototype.set = function (key, value, cb) {
  cb = promisize(cb)
  var error = null
  var t = this.transaction('readwrite', function (err) {
    error = error || err
    cb(error)
  })
  t.set(key, value, function (err) {
    error = err
  })
  return cb.promise
}

IdbKvStore.prototype.json = function (range, cb) {
  return this.transaction('readonly').json(range, cb)
}

IdbKvStore.prototype.keys = function (range, cb) {
  return this.transaction('readonly').keys(range, cb)
}

IdbKvStore.prototype.values = function (range, cb) {
  return this.transaction('readonly').values(range, cb)
}

IdbKvStore.prototype.remove = function (key, cb) {
  cb = promisize(cb)
  var error = null
  var t = this.transaction('readwrite', function (err) {
    error = error || err
    cb(error)
  })
  t.remove(key, function (err) {
    error = err
  })
  return cb.promise
}

IdbKvStore.prototype.clear = function (cb) {
  cb = promisize(cb)
  var error = null
  var t = this.transaction('readwrite', function (err) {
    error = error || err
    cb(error)
  })
  t.clear(function (err) {
    error = err
  })
  return cb.promise
}

IdbKvStore.prototype.count = function (range, cb) {
  return this.transaction('readonly').count(range, cb)
}

IdbKvStore.prototype.add = function (key, value, cb) {
  cb = promisize(cb)
  var error = null
  var t = this.transaction('readwrite', function (err) {
    error = error || err
    cb(error)
  })
  t.add(key, value, function (err) {
    error = err
  })
  return cb.promise
}

IdbKvStore.prototype.iterator = function (range, next) {
  return this.transaction('readonly').iterator(range, next)
}

IdbKvStore.prototype.transaction = function (mode, onfinish) {
  if (this._closed) throw new Error('Database is closed')

  var transaction = new Transaction(this, mode, onfinish)
  if (this._db) transaction._init(null)
  else this._waiters.push(transaction)
  return transaction
}

IdbKvStore.prototype.close = function () {
  this._close()
}

IdbKvStore.prototype._close = function (err) {
  if (this._closed) return
  this._closed = true

  if (this._db) this._db.close()
  if (this._channel) this._channel.close()

  this._db = null
  this._channel = null

  if (err) this.emit('error', err)

  this.emit('close')

  for (var i in this._waiters) this._waiters[i]._init(err || new Error('Database is closed'))
  this._waiters = null

  this.removeAllListeners()
}

function Transaction (kvStore, mode, cb) {
  if (typeof mode === 'function') return new Transaction(kvStore, null, mode)

  this._kvStore = kvStore
  this._mode = mode || 'readwrite'
  this._objectStore = null
  this._waiters = null

  this.finished = false
  this.onfinish = promisize(cb) // `onfinish` public variable for backwards compatibility with v4.3.1
  this.done = this.onfinish.promise

  if (this._mode !== 'readonly' && this._mode !== 'readwrite') {
    throw new Error('mode must be either "readonly" or "readwrite"')
  }
}

Transaction.prototype._init = function (err) {
  var self = this

  if (self.finished) return
  if (err) return self._close(err)

  var transaction = self._kvStore._db.transaction('kv', self._mode)
  transaction.oncomplete = oncomplete
  transaction.onerror = onerror
  transaction.onabort = onerror

  self._objectStore = transaction.objectStore('kv')

  for (var i in self._waiters) self._waiters[i](null, self._objectStore)
  self._waiters = null

  function oncomplete () {
    self._close(null)
  }

  function onerror (event) {
    handleError(event)
    self._close(event.target.error)
  }
}

Transaction.prototype._getObjectStore = function (cb) {
  if (this.finished) throw new Error('Transaction is finished')
  if (this._objectStore) return cb(null, this._objectStore)
  this._waiters = this._waiters || []
  this._waiters.push(cb)
}

Transaction.prototype.set = function (key, value, cb) {
  var self = this
  if (key == null || value == null) throw new Error('A key and value must be given')
  cb = promisize(cb)

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    try {
      var request = objectStore.put(value, key)
    } catch (e) {
      return cb(e)
    }

    request.onerror = handleError.bind(this, cb)
    request.onsuccess = function () {
      if (self._kvStore._channel) {
        self._kvStore._channel.postMessage({
          method: 'set',
          key: key,
          value: value
        })
      }
      cb(null)
    }
  })

  return cb.promise
}

Transaction.prototype.add = function (key, value, cb) {
  var self = this
  if (value == null && key != null) return self.add(undefined, key, cb)
  if (typeof value === 'function' || (value == null && cb == null)) return self.add(undefined, key, value)
  if (value == null) throw new Error('A value must be provided as an argument')
  cb = promisize(cb)

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    try {
      var request = key == null ? objectStore.add(value) : objectStore.add(value, key)
    } catch (e) {
      return cb(e)
    }

    request.onerror = handleError.bind(this, cb)
    request.onsuccess = function () {
      if (self._kvStore._channel) {
        self._kvStore._channel.postMessage({
          method: 'add',
          key: key,
          value: value
        })
      }
      cb(null)
    }
  })

  return cb.promise
}

Transaction.prototype.get = function (key, cb) {
  var self = this
  if (key == null) throw new Error('A key must be given as an argument')
  cb = promisize(cb)

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    try {
      var request = objectStore.get(key)
    } catch (e) {
      return cb(e)
    }

    request.onerror = handleError.bind(this, cb)
    request.onsuccess = function (event) {
      cb(null, event.target.result)
    }
  })

  return cb.promise
}

Transaction.prototype.getMultiple = function (keys, cb) {
  var self = this
  if (keys == null) throw new Error('An array of keys must be given as an argument')
  cb = promisize(cb)

  if (keys.length === 0) {
    cb(null, [])
    return cb.promise
  }

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    // Implementation mostly taken from https://www.codeproject.com/Articles/744986/How-to-do-some-magic-with-indexedDB
    var sortedKeys = keys.slice().sort()
    var i = 0
    var resultsMap = {}
    var getReturnValue = function () {
      return keys.map(function (key) {
        return resultsMap[key]
      })
    }
    var cursorReq = objectStore.openCursor()
    cursorReq.onerror = handleError.bind(this, cb)
    cursorReq.onsuccess = function (event) {
      var cursor = event.target.result
      if (!cursor) {
        cb(null, getReturnValue())
        return
      }
      var key = cursor.key
      while (key > sortedKeys[i]) {
        // The cursor has passed beyond this key. Check next.
        ++i
        if (i === sortedKeys.length) {
          // There is no next. Stop searching.
          cb(null, getReturnValue())
          return
        }
      }
      if (key === sortedKeys[i]) {
        resultsMap[key] = cursor.value
        // The current cursor value should be included and we should continue
        // a single step in case next item has the same key or possibly our
        // next key in sortedKeys.
        cursor.continue()
      } else {
        // cursor.key not yet at sortedKeys[i]. Forward cursor to the next key to hunt for.
        cursor.continue(sortedKeys[i])
      }
    }
  })

  return cb.promise
}

Transaction.prototype.json = function (range, cb) {
  var self = this
  if (typeof range === 'function') return self.json(null, range)
  cb = promisize(cb)

  var json = {}
  self.iterator(range, function (err, cursor) {
    if (err) return cb(err)
    if (cursor) {
      json[cursor.key] = cursor.value
      cursor.continue()
    } else {
      cb(null, json)
    }
  })

  return cb.promise
}

Transaction.prototype.keys = function (range, cb) {
  var self = this
  if (typeof range === 'function') return self.keys(null, range)
  cb = promisize(cb)

  var keys = []
  self.iterator(range, function (err, cursor) {
    if (err) return cb(err)
    if (cursor) {
      keys.push(cursor.key)
      cursor.continue()
    } else {
      cb(null, keys)
    }
  })

  return cb.promise
}

Transaction.prototype.values = function (range, cb) {
  var self = this
  if (typeof range === 'function') return self.values(null, range)
  cb = promisize(cb)

  var values = []
  self.iterator(range, function (err, cursor) {
    if (err) return cb(err)
    if (cursor) {
      values.push(cursor.value)
      cursor.continue()
    } else {
      cb(null, values)
    }
  })

  return cb.promise
}

Transaction.prototype.remove = function (key, cb) {
  var self = this
  if (key == null) throw new Error('A key must be given as an argument')
  cb = promisize(cb)

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    try {
      var request = objectStore.delete(key)
    } catch (e) {
      return cb(e)
    }

    request.onerror = handleError.bind(this, cb)
    request.onsuccess = function () {
      if (self._kvStore._channel) {
        self._kvStore._channel.postMessage({
          method: 'remove',
          key: key
        })
      }
      cb(null)
    }
  })

  return cb.promise
}

Transaction.prototype.clear = function (cb) {
  var self = this
  cb = promisize(cb)

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    try {
      var request = objectStore.clear()
    } catch (e) {
      return cb(e)
    }

    request.onerror = handleError.bind(this, cb)
    request.onsuccess = function () {
      cb(null)
    }
  })

  return cb.promise
}

Transaction.prototype.count = function (range, cb) {
  var self = this
  if (typeof range === 'function') return self.count(null, range)
  cb = promisize(cb)

  self._getObjectStore(function (err, objectStore) {
    if (err) return cb(err)

    try {
      var request = range == null ? objectStore.count() : objectStore.count(range)
    } catch (e) {
      return cb(e)
    }

    request.onerror = handleError.bind(this, cb)
    request.onsuccess = function (event) {
      cb(null, event.target.result)
    }
  })

  return cb.promise
}

Transaction.prototype.iterator = function (range, next) {
  var self = this
  if (typeof range === 'function') return self.iterator(null, range)
  if (typeof next !== 'function') throw new Error('A function must be given')
  self._getObjectStore(function (err, objectStore) {
    if (err) return next(err)

    try {
      var request = range == null ? objectStore.openCursor() : objectStore.openCursor(range)
    } catch (e) {
      return next(e)
    }

    request.onerror = handleError.bind(this, next)
    request.onsuccess = function (event) {
      var cursor = event.target.result
      next(null, cursor)
    }
  })
}

Transaction.prototype.abort = function () {
  if (this.finished) throw new Error('Transaction is finished')
  if (this._objectStore) this._objectStore.transaction.abort()
  this._close(new Error('Transaction aborted'))
}

Transaction.prototype._close = function (err) {
  if (this.finished) return
  this.finished = true

  this._kvStore = null
  this._objectStore = null

  for (var i in this._waiters) this._waiters[i](err || new Error('Transaction is finished'))
  this._waiters = null

  if (this.onfinish) this.onfinish(err)
  this.onfinish = null
}

function handleError (cb, event) {
  if (event == null) return handleError(null, cb)
  event.preventDefault()
  event.stopPropagation()
  if (cb) cb(event.target.error)
}

},
"sLmiPjL2jm6TJh7NT1zi9RFhougdthD/RilkssESTwY=":
function (require, module, exports, __dirname, __filename) {
var separator = '~', escape = '!'
var SE = require('separator-escape')(separator, escape)

var isArray = Array.isArray
function isString (s) {
  return 'string' === typeof s
}
function head (opts) {
  return isArray(opts) ? opts[0] : opts
}
function tail (opts) {
  return isArray(opts) ? opts.slice(1) : []
}

function compose (stream, transforms, cb) {
  if(!stream) throw new Error('multiserver.compose: *must* pass stream')
  ;(function next (err, stream, i, addr) {
    if(err) {
      err.address = addr + '~' + err.address
      return cb(err)
    }
    else if(i >= transforms.length) {
      stream.address = addr
      return cb(null, stream)
    }
    else
      transforms[i](stream, function (err, _stream) {
        if(!err && !stream) throw new Error('expected error or stream')
        if(_stream) _stream.meta = _stream.meta || stream.meta
        next(err, _stream, i+1, err ? addr : (addr+'~'+_stream.address))
      })
  })(null, stream, 0, stream.address)
}

function asyncify(f) {
  return function(cb) {
    if (f.length) return f(cb)
    if (cb) {
      var result
      try{
        result = f()
      } catch(err) {return cb(err)}
      return cb(null, result)
    }
    return f()
  }
}

module.exports = function (ary, wrap) {
  if(!wrap) wrap = function (e) { return e }
  var proto = head(ary)
  var trans = tail(ary)

  function parse (str) {
    var parts = SE.parse(str)
    var out = []
    for(var i = 0; i < parts.length; i++) {
      var v = ary[i].parse(parts[i])
      if(!v) return null
      out[i] = v
    }
    return out
  }

  function parseMaybe (str) {
    return  isString(str) ? parse(str) : str
  }

  return {
    name: ary.map(function (e) { return e.name }).join(separator),
    scope: proto.scope,
    client: function (_opts, cb) {
      var opts = parseMaybe(_opts)
      if(!opts) return cb(new Error('could not parse address:'+_opts))
      return proto.client(head(opts), function (err, stream) {
        if(err) return cb(err)
        compose(
          wrap(stream),
          trans.map(function (tr, i) { return tr.create(opts[i+1]) }),
          cb
        )
      })
    },
    // There should be a callback , called with
    // null when the server started to listen.
    // (net.server.listen is async for example)
    server: function (onConnection, onError, onStart) {
      onError = onError || function (err) {
        console.error('server error, from', err.address)
        console.error(err)
      }
      return asyncify(proto.server(function (stream) {
        compose(
          wrap(stream),
          trans.map(function (tr) { return tr.create() }),
          function (err, stream) {
            if(err) onError(err)
            else onConnection(stream)
          }
        )
      }, onStart))
    },
    parse: parse,
    stringify: function (scope) {
      var _ary = []
      var v = proto.stringify(scope)
      if(!v) return
      else {
        // if true, more than one hostname needs to be updated
        if (v.split(';').length > 1) {
          var addresses = v.split(';')
          addresses.forEach(a => {
            _ary.push(a)
          })
        }
        else _ary.push(v)
      }
      return _ary.map(e => {
        var singleAddr = [e].concat(trans.map(t => {
          return t.stringify(scope)
        }))

        return SE.stringify(singleAddr)
      }).join(';')
    }
  }
}


},
"sg1kBY7bVcevi2VujDzDW8qpP0xgeUbr52YgmTFSOH4=":
function (require, module, exports, __dirname, __filename) {
const debug = require('debug')('deweird');

module.exports = {
  name: 'deweirdProducer',
  version: '1.0.0',
  manifest: {
    start: 'async',
    more: 'async',
    close: 'async',
  },
  permissions: {
    master: {
      allow: ['start', 'more', 'close'],
    },
  },

  init: function init(ssb) {
    const streams = new Map();
    let lastId = 0;

    function callNamespace(namespace, args) {
      let result = ssb;
      for (const name of namespace) {
        if (result[name]) {
          result = result[name];
        } else {
          throw new Error(
            'deweird cannot call undefined sbot.' + namespace.join('.'),
          );
        }
      }
      if (Array.isArray(args)) {
        return result(...args);
      } else {
        return result(args);
      }
    }

    return {
      start(namespace, args, cb) {
        const id = ++lastId;
        const stream = callNamespace(namespace, args);
        streams.set(id, stream);
        if (debug.enabled) {
          const method = namespace.join('.');
          const _args = Array.isArray(args)
            ? args.map((a) => JSON.stringify(a)).join(',')
            : JSON.stringify(args);
          debug(`deweird start #${id} sbot.${method}(${_args})`);
        }
        stream(null, (err, data) => {
          if (err) cb(err);
          else cb(null, {id, data});
        });
      },

      more(id, cb) {
        if (!streams.has(id)) {
          throw new Error(`deweird cannot pull unknown stream #${id}`);
        }
        const stream = streams.get(id);
        debug(`deweird more #${id}`);
        stream(null, cb);
      },

      close(id, err, cb) {
        if (!streams.has(id)) {
          throw new Error(`deweird cannot close unknown stream #${id}`);
        }
        const stream = streams.get(id);
        debug(`deweird close #${id}`);
        stream(err, cb);
        streams.delete(id);
      },
    };
  },
};

},
"sj1iJvVfF9fDiUSmoEZ0UkMJsNoYS7h79awiz1fegVw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
const utils_1 = require("ssb-typescript/utils");
const secret_stack_decorators_1 = require("secret-stack-decorators");
const pull = require('pull-stream');
const cat = require('pull-cat');
const sort = require('ssb-sort');
const Ref = require('ssb-ref');
const { where, and, or, not, type, author, descending, live, batch, isPrivate, isPublic, hasRoot, hasFork, toPullStream, } = require('ssb-db2/operators');
const HashtagsPlugin = require("./hashtags");
const hasHashtag = HashtagsPlugin.operator;
const IS_BLOCKING_NEVER = (obj, cb) => {
    cb(null, false);
};
/**
 * 75 msgs kept in memory is rather small (~36kB), but this is large enough to
 * have good performance in JITDB pagination, see https://github.com/ssb-ngi-pointer/jitdb/pull/123#issuecomment-782734363
 */
const BATCH_SIZE = 75;
function getTimestamp(msg) {
    const arrivalTimestamp = msg.timestamp;
    const declaredTimestamp = msg.value.timestamp;
    return Math.min(arrivalTimestamp, declaredTimestamp);
}
function getRootMsgId(msg) {
    var _a;
    if ((_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) {
        const fork = msg.value.content.fork;
        const root = msg.value.content.root;
        if (fork && Ref.isMsgId(fork))
            return fork;
        if (root && Ref.isMsgId(root))
            return root;
    }
    // this msg has no root so we assume this is a root
    return msg.key;
}
function isUniqueMsgId(uniqueRoots) {
    return function checkIsUnique_id(id) {
        if (uniqueRoots.has(id)) {
            return false;
        }
        else {
            uniqueRoots.add(id);
            return true;
        }
    };
}
function hasNoBacklinks(msg) {
    var _a, _b, _c, _d, _e, _f;
    return (!((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.root) &&
        !((_d = (_c = msg === null || msg === void 0 ? void 0 : msg.value) === null || _c === void 0 ? void 0 : _c.content) === null || _d === void 0 ? void 0 : _d.branch) &&
        !((_f = (_e = msg === null || msg === void 0 ? void 0 : msg.value) === null || _e === void 0 ? void 0 : _e.content) === null || _f === void 0 ? void 0 : _f.fork));
}
function makeFilterOperator(opts) {
    if (opts.allowlist) {
        const allowedTypes = opts.allowlist.map((x) => type(x));
        return or(...allowedTypes);
    }
    if (opts.blocklist) {
        const blockedTypes = opts.blocklist.map((x) => not(type(x)));
        return and(...blockedTypes);
    }
    return null;
}
function makePassesFilter(opts) {
    if (opts.allowlist) {
        return (msg) => opts.allowlist.some((type) => { var _a, _b; return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) === type; });
    }
    if (opts.blocklist) {
        return (msg) => opts.blocklist.every((type) => { var _a, _b; return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) !== type; });
    }
    return () => true;
}
let threads = class threads {
    constructor(ssb, _config) {
        var _a;
        //#region PRIVATE
        this.removeMessagesFromBlocked = (source) => pull(source, pull.asyncMap((msg, cb) => {
            this.isBlocking({ source: this.ssb.id, dest: msg.value.author }, (err, blocking) => {
                if (err)
                    cb(err);
                else if (blocking)
                    cb(null, null);
                else
                    cb(null, msg);
            });
        }), pull.filter());
        this.nonBlockedRootToThread = (maxSize, filter, privately = false) => {
            return (root, cb) => {
                pull(cat([
                    pull.values([root]),
                    pull(this.ssb.db.query(where(and(hasRoot(root.key), filter, privately ? isPrivate() : isPublic())), batch(BATCH_SIZE), descending(), toPullStream()), this.removeMessagesFromBlocked, pull.take(maxSize)),
                ]), pull.take(maxSize + 1), pull.collect((err2, arr) => {
                    if (err2)
                        return cb(err2);
                    const full = arr.length <= maxSize;
                    sort(arr);
                    if (arr.length > maxSize && arr.length >= 3)
                        arr.splice(1, 1);
                    cb(null, { messages: arr, full });
                }));
            };
        };
        this.nonBlockedRootToSummary = (filter, timestamps) => {
            return (root, cb) => {
                pull(this.ssb.db.query(where(and(or(hasRoot(root.key), hasFork(root.key)), filter)), batch(BATCH_SIZE), descending(), toPullStream()), this.removeMessagesFromBlocked, pull.collect((err2, arr) => {
                    var _a;
                    if (err2)
                        return cb(err2);
                    const timestamp = Math.max((_a = timestamps.get(root.key)) !== null && _a !== void 0 ? _a : 0, ...arr.map(getTimestamp));
                    cb(null, { root, replyCount: arr.length, timestamp });
                }));
            };
        };
        /**
         * Returns a pull-stream operator that:
         * 1. Checks if there is a Msg in the cache for the source MsgId
         * 2. If not in the cache, do a database lookup
         */
        this.fetchMsgFromIdIfItExists = (source) => pull(source, pull.asyncMap((id, cb) => {
            this.ssb.db.getMsg(id, (err, msg) => {
                if (err)
                    cb(null, null /* missing msg */);
                else
                    cb(err, msg);
            });
        }), pull.filter());
        this.rootToThread = (maxSize, filter, privately) => {
            return pull.asyncMap((root, cb) => {
                this.isBlocking({ source: this.ssb.id, dest: root.value.author }, (err, blocking) => {
                    if (err) {
                        cb(err);
                    }
                    else if (blocking) {
                        cb(new Error('Author Blocked:' + root.value.author));
                    }
                    else {
                        this.nonBlockedRootToThread(maxSize, filter, privately)(root, cb);
                    }
                });
            });
        };
        //#endregion
        //#region PUBLIC API
        this.public = (opts) => {
            var _a, _b;
            const needsDescending = (_a = opts.reverse) !== null && _a !== void 0 ? _a : true;
            const threadMaxSize = (_b = opts.threadMaxSize) !== null && _b !== void 0 ? _b : Infinity;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            return pull(this.ssb.db.query(where(and(isPublic(), filterOperator)), needsDescending ? descending() : null, batch(BATCH_SIZE), toPullStream()), pull.map(getRootMsgId), pull.filter(isUniqueMsgId(new Set())), this.fetchMsgFromIdIfItExists, pull.filter(passesFilter), pull.filter(utils_1.isPublic), pull.filter(hasNoBacklinks), this.removeMessagesFromBlocked, pull.asyncMap(this.nonBlockedRootToThread(threadMaxSize, filterOperator)));
        };
        this.publicSummary = (opts) => {
            var _a;
            const needsDescending = (_a = opts.reverse) !== null && _a !== void 0 ? _a : true;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            const timestamps = new Map();
            return pull(this.ssb.db.query(where(and(isPublic(), filterOperator)), needsDescending ? descending() : null, batch(BATCH_SIZE), toPullStream()), pull.through((msg) => timestamps.set(getRootMsgId(msg), getTimestamp(msg))), pull.map(getRootMsgId), pull.filter(isUniqueMsgId(new Set())), this.fetchMsgFromIdIfItExists, pull.filter(passesFilter), pull.filter(utils_1.isPublic), pull.filter(hasNoBacklinks), this.removeMessagesFromBlocked, pull.asyncMap(this.nonBlockedRootToSummary(filterOperator, timestamps)));
        };
        this.publicUpdates = (opts) => {
            var _a;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            const includeSelf = (_a = opts.includeSelf) !== null && _a !== void 0 ? _a : false;
            return pull(this.ssb.db.query(where(and(isPublic(), filterOperator, includeSelf ? null : not(author(this.ssb.id, { dedicated: true })))), live({ old: false }), toPullStream()), pull.filter(passesFilter), this.removeMessagesFromBlocked, pull.map((msg) => msg.key));
        };
        this.hashtagSummary = (opts) => {
            var _a;
            const needsDescending = (_a = opts.reverse) !== null && _a !== void 0 ? _a : true;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            const timestamps = new Map();
            return pull(this.ssb.db.query(where(and(isPublic(), hasHashtag(opts.hashtag), filterOperator)), needsDescending ? descending() : null, batch(BATCH_SIZE), toPullStream()), pull.through((msg) => timestamps.set(getRootMsgId(msg), getTimestamp(msg))), pull.map(getRootMsgId), pull.filter(isUniqueMsgId(new Set())), this.fetchMsgFromIdIfItExists, pull.filter(passesFilter), pull.filter(utils_1.isPublic), pull.filter(hasNoBacklinks), this.removeMessagesFromBlocked, pull.asyncMap(this.nonBlockedRootToSummary(filterOperator, timestamps)));
        };
        this.private = (opts) => {
            var _a, _b;
            const needsDescending = (_a = opts.reverse) !== null && _a !== void 0 ? _a : true;
            const threadMaxSize = (_b = opts.threadMaxSize) !== null && _b !== void 0 ? _b : Infinity;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            return pull(this.ssb.db.query(where(and(isPrivate(), filterOperator)), needsDescending ? descending() : null, batch(BATCH_SIZE), toPullStream()), pull.map(getRootMsgId), pull.filter(isUniqueMsgId(new Set())), this.fetchMsgFromIdIfItExists, pull.filter(passesFilter), pull.filter(utils_1.isPrivate), pull.filter(hasNoBacklinks), this.removeMessagesFromBlocked, pull.asyncMap(this.nonBlockedRootToThread(threadMaxSize, filterOperator, true)));
        };
        this.privateUpdates = (opts) => {
            var _a;
            const filterOperator = makeFilterOperator(opts);
            const includeSelf = (_a = opts.includeSelf) !== null && _a !== void 0 ? _a : false;
            return pull(this.ssb.db.query(where(and(isPrivate(), filterOperator, includeSelf ? null : not(author(this.ssb.id, { dedicated: true })))), live({ old: false }), toPullStream()), this.removeMessagesFromBlocked, pull.map(getRootMsgId));
        };
        this.profile = (opts) => {
            var _a, _b;
            const id = opts.id;
            const needsDescending = (_a = opts.reverse) !== null && _a !== void 0 ? _a : true;
            const threadMaxSize = (_b = opts.threadMaxSize) !== null && _b !== void 0 ? _b : Infinity;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            return pull(this.ssb.db.query(where(and(author(id), isPublic(), filterOperator)), needsDescending ? descending() : null, batch(BATCH_SIZE), toPullStream()), pull.map(getRootMsgId), pull.filter(isUniqueMsgId(new Set())), this.fetchMsgFromIdIfItExists, pull.filter(passesFilter), pull.filter(utils_1.isPublic), this.removeMessagesFromBlocked, pull.asyncMap(this.nonBlockedRootToThread(threadMaxSize, filterOperator)));
        };
        this.profileSummary = (opts) => {
            var _a;
            const id = opts.id;
            const needsDescending = (_a = opts.reverse) !== null && _a !== void 0 ? _a : true;
            const filterOperator = makeFilterOperator(opts);
            const passesFilter = makePassesFilter(opts);
            const timestamps = new Map();
            return pull(this.ssb.db.query(where(and(author(id), isPublic(), filterOperator)), needsDescending ? descending() : null, batch(BATCH_SIZE), toPullStream()), pull.through((msg) => timestamps.set(getRootMsgId(msg), getTimestamp(msg))), pull.map(getRootMsgId), pull.filter(isUniqueMsgId(new Set())), this.fetchMsgFromIdIfItExists, pull.filter(passesFilter), pull.filter(utils_1.isPublic), pull.filter(hasNoBacklinks), this.removeMessagesFromBlocked, pull.asyncMap(this.nonBlockedRootToSummary(filterOperator, timestamps)));
        };
        this.thread = (opts) => {
            var _a;
            const privately = !!opts.private;
            const threadMaxSize = (_a = opts.threadMaxSize) !== null && _a !== void 0 ? _a : Infinity;
            const optsOk = !opts.allowlist && !opts.blocklist
                ? { ...opts, allowlist: ['post'] }
                : opts;
            const filterOperator = makeFilterOperator(optsOk);
            return pull(pull.values([opts.root]), this.fetchMsgFromIdIfItExists, privately ? pull.through() : pull.filter(utils_1.isPublic), this.rootToThread(threadMaxSize, filterOperator, privately));
        };
        this.threadUpdates = (opts) => {
            const privately = !!opts.private;
            const filterOperator = makeFilterOperator(opts);
            return pull(this.ssb.db.query(where(and(hasRoot(opts.root), filterOperator, privately ? isPrivate() : isPublic())), live({ old: false }), toPullStream()), this.removeMessagesFromBlocked);
        };
        this.ssb = ssb;
        this.isBlocking = ((_a = ssb.friends) === null || _a === void 0 ? void 0 : _a.isBlocking)
            ? ssb.friends.isBlocking
            : IS_BLOCKING_NEVER;
        this.ssb.db.registerIndex(HashtagsPlugin);
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "public", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "publicSummary", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "publicUpdates", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "hashtagSummary", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "private", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "privateUpdates", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "profile", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "profileSummary", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "thread", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], threads.prototype, "threadUpdates", void 0);
threads = __decorate([
    secret_stack_decorators_1.plugin('2.0.0')
], threads);
module.exports = threads;
//# sourceMappingURL=index.js.map
},
"sr4ZuI56+DGxLPSkbLiTDq4lQC4DEnbSXP5/4GyHlWU=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var drain = require('./drain')

module.exports = function log (done) {
  return drain(function (data) {
    console.log(data)
  }, done)
}

},
"t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=":
function (require, module, exports, __dirname, __filename) {
var isCanonicalBase64 = require('is-canonical-base64')
var isDomain = require('is-valid-domain')
var Querystring = require('querystring')
var ip = require('ip')
var MultiServerAddress = require('multiserver-address')

/* classic ssb definitions */
var parseLinkRegex = /^((@|%|&)[A-Za-z0-9/+]{43}=\.[\w\d]+)(\?(.+))?$/
var feedIdRegex = exports.feedIdRegex = isCanonicalBase64('@', '.(?:sha256|ed25519)', 32)
var msgIdRegex = exports.msgIdRegex = isCanonicalBase64('%', '.sha256', 32)
var blobIdRegex = exports.blobIdRegex = isCanonicalBase64('&', '.sha256', 32)

/* BFE type checks for strings */
var SUFFIX = '\\.[a-zA-Z\\d-]+'
var feedTypeIdRegex = exports.feedTypeIdRegex = isCanonicalBase64('@', SUFFIX)
var msgTypeIdRegex = exports.msgTypeIdRegex = isCanonicalBase64('%', SUFFIX)
var blobTypeIdRegex = exports.blobTypeIdRegex = isCanonicalBase64('&', SUFFIX)

var cloakedMsgIdRegex = exports.cloakedMsgIdRegex = isCanonicalBase64('%', '.cloaked', 32)

var extractRegex = /([@%&][A-Za-z0-9/+]{43}=\.[\w\d]+)/

var DEFAULT_PORT = 8008

/* basic validators */
function isString (s) { return typeof s === 'string' }
function isObject (o) { return o && typeof o === 'object' && !Array.isArray(o) }
var isInteger = Number.isInteger
function isIP (s) {
  return ip.isV4Format(s) || ip.isV6Format(s)
}
function isHost (addr) {
  if (!isString(addr)) return
  addr = addr.replace(/^wss?:\/\//, '')
  return (isIP(addr)) || isDomain(addr) || addr === 'localhost'
}
function isPort (p) {
  return isInteger(p) && p <= 65536
}
function isMultiServerAddress (str) {
  // a http url fits into the multiserver scheme,
  // but all ssb address must have a transport and a transform
  // so check there is at least one unescaped ~ in the address
  return MultiServerAddress.check(str) && /[^!][~]/.test(str)
}

/* feed */
var isFeedId = exports.isFeed = exports.isFeedId =
  function (data) {
    return isString(data) && feedIdRegex.test(data)
  }
exports.isFeedType = exports.isFeedTypeId =
  function (data) {
    return isString(data) && feedTypeIdRegex.test(data)
  }

/* msg */
var isMsgId = exports.isMsg = exports.isMsgId =
  function (data) {
    return isString(data) && msgIdRegex.test(data)
  }
exports.isMsgType = exports.isMsgTypeId =
  function (data) {
    return isString(data) && msgTypeIdRegex.test(data)
  }
exports.isCloakedMsg = exports.isCloakedMsgId =
  function (data) {
    return isString(data) && cloakedMsgIdRegex.test(data)
  }

/* blob */
var isBlobId = exports.isBlob = exports.isBlobId =
  function (data) {
    return isString(data) && blobIdRegex.test(data)
  }
exports.isBlobType = exports.isBlobTypeId =
  function (data) {
    return isString(data) && blobTypeIdRegex.test(data)
  }

var isLink = exports.isLink =
  function (data) {
    if (!isString(data)) return false
    var index = data.indexOf('?')
    data = ~index ? data.substring(0, index) : data
    return isString(data) && (isFeedId(data) || isMsgId(data) || isBlobId(data))
  }
exports.isBlobLink = function (s) {
  return s[0] === '&' && isLink(s)
}
exports.isMsgLink = function (s) {
  return s[0] === '%' && isLink(s)
}

exports.normalizeChannel =
  function (data) {
    if (typeof data === 'string') {
      data = data.toLowerCase().replace(/\s|,|\.|\?|!|<|>|\(|\)|\[|\]|"|#/g, '')
      if (data.length > 0) {
        return data.slice(0, 30)
      }
    }
    return null
  }

function deprecate (name, fn) {
  var logged = false
  return function () {
    var args = [].slice.call(arguments)
    if (!logged) {
      console.trace('deprecated api used: ' + name)
      logged = true
    }
    return fn.apply(this, args)
  }
}

var parseMultiServerAddress = function (data) {
  if (!isString(data)) return false
  if (!MultiServerAddress.check(data)) return false

  var addr = MultiServerAddress.decode(data)
  addr = addr.find(function (address) {
    if (!address[0]) return false
    if (!address[1]) return false
    return /^(net|wss?|onion)$/.test(address[0].name) && /^shs/.test(address[1].name)
  })
  if (!Array.isArray(addr)) {
    return false
  }
  var port = +addr[0].data.pop() // last item always port, to handle ipv6

  // preserve protocol type on websocket addresses
  var host = (/^wss?$/.test(addr[0].name) ? addr[0].name + ':' : '') + addr[0].data.join(':')
  var key = '@' + addr[1].data[0] + '.ed25519'
  var seed = addr[1].data[2]
  // allow multiserver addresses that are not currently understood!
  if (!(isHost(host) && isPort(+port) && isFeedId(key))) return false
  var address = {
    host: host,
    port: port,
    key: key
  }
  if (seed) { address.seed = seed }

  return address
}

var toLegacyAddress = parseMultiServerAddress
exports.toLegacyAddress = deprecate('ssb-ref.toLegacyAddress', toLegacyAddress)

exports.isLegacyAddress = function (addr) {
  return isObject(addr) && isHost(addr.host) && isPort(addr.port) && isFeedId(addr.key)
}

var toMultiServerAddress = exports.toMultiServerAddress = function (addr) {
  if (MultiServerAddress.check(addr)) return addr
  if (!isPort(addr.port)) throw new Error('ssb-ref.toMultiServerAddress - invalid port:' + addr.port)
  if (!isHost(addr.host)) throw new Error('ssb-ref.toMultiServerAddress - invalid host:' + addr.host)
  if (!isFeedId(addr.key)) throw new Error('ssb-ref.toMultiServerAddress - invalid key:' + addr.key)

  return (
    /^wss?:/.test(addr.host) ? addr.host
      : /\.onion$/.test(addr.host) ? 'onion:' + addr.host
        : 'net:' + addr.host
  ) + ':' + addr.port + '~shs:' + addr.key.substring(1, addr.key.indexOf('.'))
}

var isAddress = exports.isAddress = function (data) {
  var host, port, id
  if (isObject(data)) {
    id = data.key; host = data.host; port = data.port
  } else if (!isString(data)) return false
  else if (isMultiServerAddress(data)) return true
  else {
    var parts = data.split(':')
    id = parts.pop(); port = parts.pop(); host = parts.join(':')
  }
  return (
    isFeedId(id) && isPort(+port) &&
    isHost(host)
  )
}

// This is somewhat fragile, because maybe non-shs protocols get added...
// it would be better to treat all addresses as opaque or have multiserver handle
// extraction of a signing key from the address.
exports.getKeyFromAddress = function (addr) {
  if (addr.key) return addr.key
  try {
    var data = MultiServerAddress.decode(addr)
  } catch (err) {
    console.error(new Error('Attempted connection with malformed multiserver-address ' + addr))
  }
  if (!data) return undefined
  for (var k in data) {
    var address = data[k]
    for (var j in address) {
      var protocol = address[j]
      if (/^shs/.test(protocol.name)) {
        // forwards compatible with future shs versions...
        return '@' + protocol.data[0] + '.ed25519'
      }
    }
  }
}

var parseAddress = function (e) {
  if (isString(e)) {
    if (~e.indexOf('~')) { return parseMultiServerAddress(e) }
    var parts = e.split(':')
    var id = parts.pop(); var port = parts.pop(); var host = parts.join(':')
    e = {
      host: host,
      port: +(port || DEFAULT_PORT),
      key: id
    }
    return e
  }
  return e
}
exports.parseAddress = deprecate('ssb-ref.parseAddress', parseAddress)

var toAddress = exports.toAddress = function (e) {
  e = parseAddress(e)
  e.port = e.port || DEFAULT_PORT
  e.host = e.host || 'localhost'
  return e
}

var legacyInviteRegex = /^[A-Za-z0-9/+]{43}=$/
var legacyInviteFixerRegex = /#.*$/
var isLegacyInvite = exports.isLegacyInvite =
  function (data) {
    if (!isString(data)) return false
    data = data.replace(legacyInviteFixerRegex, '')
    var parts = data.split('~')
    return parts.length === 2 && isAddress(parts[0]) && legacyInviteRegex.test(parts[1])
  }

var isMultiServerInvite = exports.isMultiServerInvite =
  function (data) {
    if (!isString(data)) return false
    return !!parseMultiServerInvite(data)
  }

var isInvite = exports.isInvite =
  function (data) {
    if (!isString(data)) return false
    return isLegacyInvite(data) || isMultiServerInvite(data)
  }

exports.parseLink = function parseBlob (ref) {
  var match = parseLinkRegex.exec(ref)
  if (match && match[1]) {
    if (match[3]) {
      var query = Querystring.parse(match[4])
      // unbox keys have a '+' in them that is parsed into a ' ', this changes it back
      if (isString(query.unbox)) query.unbox = query.unbox.replace(/ /g, '+')
      return { link: match[1], query }
    } else {
      return { link: match[1] }
    }
  }
}

function parseLegacyInvite (invite) {
  var redirect = invite.split('#')
  invite = redirect.shift()
  var parts = invite.split('~')
  var addr = toAddress(parts[0])// .split(':')
  // convert legacy code to multiserver invite code.
  var remote = toMultiServerAddress(addr)
  invite = remote + ':' + parts[1]
  return {
    invite: remote + ':' + parts[1],
    key: addr.key,
    remote: remote,
    redirect: redirect.length ? '#' + redirect.join('#') : null
  }
}

function parseMultiServerInvite (invite) {
  var redirect = invite.split('#')
  if (!redirect.length) return null

  invite = redirect.shift()
  var addr = toLegacyAddress(invite)
  if (!addr) return null
  delete addr.seed
  return {
    invite: invite,
    remote: toMultiServerAddress(addr),
    key: addr.key,
    redirect: redirect.length ? '#' + redirect.join('#') : null
  }
}

exports.parseLegacyInvite = deprecate('ssb-ref.parseLegacyInvite', parseLegacyInvite)
exports.parseMultiServerInvite = deprecate('ssb-ref.parseMultiServerInvite', parseMultiServerInvite)

exports.parseInvite = deprecate('ssb-ref.parseInvite', function (invite) {
  return (
    isLegacyInvite(invite)
      ? parseLegacyInvite(invite)
      : isMultiServerInvite(invite)
        ? parseMultiServerInvite(invite)
        : null
  )
})

exports.type =
  function (id) {
    if (!isString(id)) return false
    var c = id.charAt(0)
    if (c === '@' && isFeedId(id)) { return 'feed' } else if (c === '%' && isMsgId(id)) { return 'msg' } else if (c === '&' && isBlobId(id)) { return 'blob' } else if (isAddress(id)) return 'address'
    else if (isInvite(id)) return 'invite'
    else { return false }
  }

exports.extract =
  function (data) {
    if (!isString(data)) { return false }

    var _data = data

    var res = extractRegex.exec(_data)
    if (res) {
      return res && res[0]
    } else {
      try {
        _data = decodeURIComponent(data)
      } catch (e) {
        // this may fail if it's not encoded, so don't worry if it does
      }
      _data = _data.replace(/&amp;/g, '&')

      res = extractRegex.exec(_data)
      return res && res[0]
    }
  }

},
"tBXb0zrw8npG9LgueIj3oBYWctXQJAlPteS0BOt/WfU=":
function (require, module, exports, __dirname, __filename) {
var isMsgRef = require('ssb-ref').isMsg

//messages in thread that are not referenced by another message in the thread.
function heads (thread) {
  var counts = messages(thread)

  thread.forEach(function (msg) {
    links(msg.value, function (link) {
      counts[link] = 0
    })
  })
  var ary = []
  for(var k in counts) if(counts[k] !== 0) ary.push(k)
  return ary.sort()
}

function roots (thread) {
  sort(thread)
  var counts = messages(thread)

  thread.forEach(function (msg) {
    links(msg.value, function (link) {
      if(counts[link]) counts[msg.key] = 2
    })
  })

  var ary = []
  for(var k in counts) if(counts[k] === 1) ary.push(k)
  return ary
}

function sort (thread) {
  var dict = arrayToDict(thread)
  function compare(a, b) {
    return ancestorOf(a, b, dict) ? 1 : ancestorOf(b, a, dict) ? -1 : 0
  }

  return thread.sort(function (a, b) {
    return (
      compare(a, b)
      //received timestamp, may not be present
      || a.timestamp - b.timestamp
      //declared timestamp, may by incorrect or a lie
      || a.value.timestamp - b.value.timestamp
      //finially, sort hashes lexiegraphically.
      || (a.key > b.key ? -1 : a.key < b.key ? 1 : 0)
    )
  })
}

function ancestors (thread, start, isTarget) {
  if(Array.isArray(thread))
    thread = arrayToDict(thread)
  start = isString(start) ? start : start.key
  var seen = {}
  function traverse (key) {
    if(seen[key]) return
    seen[key] = true
    if(isTarget(thread[key], key)) return true
    return links(thread[key], function (link) {
      if(thread[link]) return traverse(link)
    })
  }

  return traverse(start)
}

function ancestorOf (a, b, thread) {
  return ancestors(thread, a.key, function (_b, k) {
    return b.key === k
  })
}

function missingContext (thread) {
  var dict = arrayToDict(thread)
  var results = {}

  thread.forEach(function (msg) {
    const noLineage = thread
      .filter(function (m) { return m.key !== msg.key })
      .map(function (m) {
        return areCausallyLinked(m, msg)
          ? null  // if it's an ancestor, that's all good
          : m     // if it's not an ancestor, bingo!
      })
      .filter(Boolean)

    if (noLineage.length) results[msg.key] = noLineage
  })
  return results

  function areCausallyLinked (a, b) {
    return ancestorOf(a, b, dict) || ancestorOf(b, a, dict)
  }
}

exports = module.exports = sort
exports.heads = heads
exports.roots = roots
exports.ancestors = ancestors
exports.missingContext = missingContext


// Utils ///////////////////////////////////

function links (obj, each) {
  if(isMsgRef(obj)) return each(obj)
  if(!obj || 'object' !== typeof obj) return
  for(var k in obj)
    if(links(obj[k], each)) return true
}

//used to initialize sort
function messages (thread) {
  var counts = {}

  for(var i = 0; i < thread.length; i++) {
    var key = thread[i].key
    if(counts[key])
      throw new Error('thread has duplicate message:'+key)
    counts[key] = 1
  }

  return counts
}

function arrayToDict (thread) {
  var o = {}
  thread.forEach(function (e) {
    o[e.key] = e.value
  })
  return o
}

function isString(s) { return 'string' === typeof s }


},
"tH0U05KG/Q1gFRPPteSw/JwtU3lEkSy8wYmXX8GK2o4=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const u = require('./util')

function toArray (str) {
  return Array.isArray(str) ? str : str.split('.')
}

function isPerms (p) {
  return (
    p &&
    typeof p.pre === 'function' &&
    typeof p.test === 'function' &&
    typeof p.post === 'function'
  )
}

/*

perms:

a given capability may be permitted to call a particular api.
but only if a perms function returns true for the arguments
it passes.

suppose, an app may be given access, but may only create functions
with it's own properties.

create perms:
  {
    allow: ['add', 'query'], deny: [...],
    rules: {
      add: {
        call: function (value) {
          return (value.type === 'task' || value.type === '_task')
        },
      query: {
        call: function (value) {
          safe.contains(value, {path: ['content', 'type'], eq: 'task'}) ||
          safe.contains(value, {path: ['content', 'type'], eq: '_task'})
        },
        filter: function (value) {
          return (value.type === 'task' || value.type === '_task')
        }
      }
    }
  }
*/

module.exports = function Permissions (opts) {
  if (isPerms(opts)) return opts
  if (typeof opts === 'function') return { pre: opts }
  let allow = null
  let deny = {}

  function perms (opts) {
    if (opts.allow) {
      allow = {}
      for (const path of opts.allow) {
        u.set(allow, toArray(path), true)
      }
    } else {
      allow = null
    }

    if (opts.deny) {
      for (const path of opts.deny) {
        u.set(deny, toArray(path), true)
      }
    } else {
      deny = {}
    }

    return this
  }

  if (opts) perms(opts)

  perms.pre = (name) => {
    name = Array.isArray(name) ? name : [name]
    if (allow && !u.prefix(allow, name)) {
      return new Error(`method:${name} is not in list of allowed methods`)
    }

    if (deny && u.prefix(deny, name)) {
      return new Error(`method:${name} is on list of disallowed methods`)
    }
  }

  perms.post = () => {
    // TODO
  }

  // alias for pre, used in tests.
  perms.test = (name) => perms.pre(name)

  perms.get = () => ({ allow, deny })

  return perms
}

},
"tab6gtDtlrOnF2IWtyMQI5uctUIXu5/7QqAfWC72lSI=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const EventEmitter = require('events');
const https = require('https');
const http = require('http');
const net = require('net');
const tls = require('tls');
const { randomBytes, createHash } = require('crypto');
const { URL } = require('url');

const PerMessageDeflate = require('./permessage-deflate');
const Receiver = require('./receiver');
const Sender = require('./sender');
const {
  BINARY_TYPES,
  EMPTY_BUFFER,
  GUID,
  kStatusCode,
  kWebSocket,
  NOOP
} = require('./constants');
const { addEventListener, removeEventListener } = require('./event-target');
const { format, parse } = require('./extension');
const { toBuffer } = require('./buffer-util');

const readyStates = ['CONNECTING', 'OPEN', 'CLOSING', 'CLOSED'];
const protocolVersions = [8, 13];
const closeTimeout = 30 * 1000;

/**
 * Class representing a WebSocket.
 *
 * @extends EventEmitter
 */
class WebSocket extends EventEmitter {
  /**
   * Create a new `WebSocket`.
   *
   * @param {(String|url.URL)} address The URL to which to connect
   * @param {(String|String[])} [protocols] The subprotocols
   * @param {Object} [options] Connection options
   */
  constructor(address, protocols, options) {
    super();

    this._binaryType = BINARY_TYPES[0];
    this._closeCode = 1006;
    this._closeFrameReceived = false;
    this._closeFrameSent = false;
    this._closeMessage = '';
    this._closeTimer = null;
    this._extensions = {};
    this._protocol = '';
    this._readyState = WebSocket.CONNECTING;
    this._receiver = null;
    this._sender = null;
    this._socket = null;

    if (address !== null) {
      this._bufferedAmount = 0;
      this._isServer = false;
      this._redirects = 0;

      if (Array.isArray(protocols)) {
        protocols = protocols.join(', ');
      } else if (typeof protocols === 'object' && protocols !== null) {
        options = protocols;
        protocols = undefined;
      }

      initAsClient(this, address, protocols, options);
    } else {
      this._isServer = true;
    }
  }

  /**
   * This deviates from the WHATWG interface since ws doesn't support the
   * required default "blob" type (instead we define a custom "nodebuffer"
   * type).
   *
   * @type {String}
   */
  get binaryType() {
    return this._binaryType;
  }

  set binaryType(type) {
    if (!BINARY_TYPES.includes(type)) return;

    this._binaryType = type;

    //
    // Allow to change `binaryType` on the fly.
    //
    if (this._receiver) this._receiver._binaryType = type;
  }

  /**
   * @type {Number}
   */
  get bufferedAmount() {
    if (!this._socket) return this._bufferedAmount;

    return this._socket._writableState.length + this._sender._bufferedBytes;
  }

  /**
   * @type {String}
   */
  get extensions() {
    return Object.keys(this._extensions).join();
  }

  /**
   * @type {String}
   */
  get protocol() {
    return this._protocol;
  }

  /**
   * @type {Number}
   */
  get readyState() {
    return this._readyState;
  }

  /**
   * @type {String}
   */
  get url() {
    return this._url;
  }

  /**
   * Set up the socket and the internal resources.
   *
   * @param {net.Socket} socket The network socket between the server and client
   * @param {Buffer} head The first packet of the upgraded stream
   * @param {Number} [maxPayload=0] The maximum allowed message size
   * @private
   */
  setSocket(socket, head, maxPayload) {
    const receiver = new Receiver(
      this.binaryType,
      this._extensions,
      this._isServer,
      maxPayload
    );

    this._sender = new Sender(socket, this._extensions);
    this._receiver = receiver;
    this._socket = socket;

    receiver[kWebSocket] = this;
    socket[kWebSocket] = this;

    receiver.on('conclude', receiverOnConclude);
    receiver.on('drain', receiverOnDrain);
    receiver.on('error', receiverOnError);
    receiver.on('message', receiverOnMessage);
    receiver.on('ping', receiverOnPing);
    receiver.on('pong', receiverOnPong);

    socket.setTimeout(0);
    socket.setNoDelay();

    if (head.length > 0) socket.unshift(head);

    socket.on('close', socketOnClose);
    socket.on('data', socketOnData);
    socket.on('end', socketOnEnd);
    socket.on('error', socketOnError);

    this._readyState = WebSocket.OPEN;
    this.emit('open');
  }

  /**
   * Emit the `'close'` event.
   *
   * @private
   */
  emitClose() {
    if (!this._socket) {
      this._readyState = WebSocket.CLOSED;
      this.emit('close', this._closeCode, this._closeMessage);
      return;
    }

    if (this._extensions[PerMessageDeflate.extensionName]) {
      this._extensions[PerMessageDeflate.extensionName].cleanup();
    }

    this._receiver.removeAllListeners();
    this._readyState = WebSocket.CLOSED;
    this.emit('close', this._closeCode, this._closeMessage);
  }

  /**
   * Start a closing handshake.
   *
   *          +----------+   +-----------+   +----------+
   *     - - -|ws.close()|-->|close frame|-->|ws.close()|- - -
   *    |     +----------+   +-----------+   +----------+     |
   *          +----------+   +-----------+         |
   * CLOSING  |ws.close()|<--|close frame|<--+-----+       CLOSING
   *          +----------+   +-----------+   |
   *    |           |                        |   +---+        |
   *                +------------------------+-->|fin| - - - -
   *    |         +---+                      |   +---+
   *     - - - - -|fin|<---------------------+
   *              +---+
   *
   * @param {Number} [code] Status code explaining why the connection is closing
   * @param {String} [data] A string explaining why the connection is closing
   * @public
   */
  close(code, data) {
    if (this.readyState === WebSocket.CLOSED) return;
    if (this.readyState === WebSocket.CONNECTING) {
      const msg = 'WebSocket was closed before the connection was established';
      return abortHandshake(this, this._req, msg);
    }

    if (this.readyState === WebSocket.CLOSING) {
      if (this._closeFrameSent && this._closeFrameReceived) this._socket.end();
      return;
    }

    this._readyState = WebSocket.CLOSING;
    this._sender.close(code, data, !this._isServer, (err) => {
      //
      // This error is handled by the `'error'` listener on the socket. We only
      // want to know if the close frame has been sent here.
      //
      if (err) return;

      this._closeFrameSent = true;
      if (this._closeFrameReceived) this._socket.end();
    });

    //
    // Specify a timeout for the closing handshake to complete.
    //
    this._closeTimer = setTimeout(
      this._socket.destroy.bind(this._socket),
      closeTimeout
    );
  }

  /**
   * Send a ping.
   *
   * @param {*} [data] The data to send
   * @param {Boolean} [mask] Indicates whether or not to mask `data`
   * @param {Function} [cb] Callback which is executed when the ping is sent
   * @public
   */
  ping(data, mask, cb) {
    if (this.readyState === WebSocket.CONNECTING) {
      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');
    }

    if (typeof data === 'function') {
      cb = data;
      data = mask = undefined;
    } else if (typeof mask === 'function') {
      cb = mask;
      mask = undefined;
    }

    if (typeof data === 'number') data = data.toString();

    if (this.readyState !== WebSocket.OPEN) {
      sendAfterClose(this, data, cb);
      return;
    }

    if (mask === undefined) mask = !this._isServer;
    this._sender.ping(data || EMPTY_BUFFER, mask, cb);
  }

  /**
   * Send a pong.
   *
   * @param {*} [data] The data to send
   * @param {Boolean} [mask] Indicates whether or not to mask `data`
   * @param {Function} [cb] Callback which is executed when the pong is sent
   * @public
   */
  pong(data, mask, cb) {
    if (this.readyState === WebSocket.CONNECTING) {
      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');
    }

    if (typeof data === 'function') {
      cb = data;
      data = mask = undefined;
    } else if (typeof mask === 'function') {
      cb = mask;
      mask = undefined;
    }

    if (typeof data === 'number') data = data.toString();

    if (this.readyState !== WebSocket.OPEN) {
      sendAfterClose(this, data, cb);
      return;
    }

    if (mask === undefined) mask = !this._isServer;
    this._sender.pong(data || EMPTY_BUFFER, mask, cb);
  }

  /**
   * Send a data message.
   *
   * @param {*} data The message to send
   * @param {Object} [options] Options object
   * @param {Boolean} [options.compress] Specifies whether or not to compress
   *     `data`
   * @param {Boolean} [options.binary] Specifies whether `data` is binary or
   *     text
   * @param {Boolean} [options.fin=true] Specifies whether the fragment is the
   *     last one
   * @param {Boolean} [options.mask] Specifies whether or not to mask `data`
   * @param {Function} [cb] Callback which is executed when data is written out
   * @public
   */
  send(data, options, cb) {
    if (this.readyState === WebSocket.CONNECTING) {
      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');
    }

    if (typeof options === 'function') {
      cb = options;
      options = {};
    }

    if (typeof data === 'number') data = data.toString();

    if (this.readyState !== WebSocket.OPEN) {
      sendAfterClose(this, data, cb);
      return;
    }

    const opts = {
      binary: typeof data !== 'string',
      mask: !this._isServer,
      compress: true,
      fin: true,
      ...options
    };

    if (!this._extensions[PerMessageDeflate.extensionName]) {
      opts.compress = false;
    }

    this._sender.send(data || EMPTY_BUFFER, opts, cb);
  }

  /**
   * Forcibly close the connection.
   *
   * @public
   */
  terminate() {
    if (this.readyState === WebSocket.CLOSED) return;
    if (this.readyState === WebSocket.CONNECTING) {
      const msg = 'WebSocket was closed before the connection was established';
      return abortHandshake(this, this._req, msg);
    }

    if (this._socket) {
      this._readyState = WebSocket.CLOSING;
      this._socket.destroy();
    }
  }
}

readyStates.forEach((readyState, i) => {
  const descriptor = { enumerable: true, value: i };

  Object.defineProperty(WebSocket.prototype, readyState, descriptor);
  Object.defineProperty(WebSocket, readyState, descriptor);
});

[
  'binaryType',
  'bufferedAmount',
  'extensions',
  'protocol',
  'readyState',
  'url'
].forEach((property) => {
  Object.defineProperty(WebSocket.prototype, property, { enumerable: true });
});

//
// Add the `onopen`, `onerror`, `onclose`, and `onmessage` attributes.
// See https://html.spec.whatwg.org/multipage/comms.html#the-websocket-interface
//
['open', 'error', 'close', 'message'].forEach((method) => {
  Object.defineProperty(WebSocket.prototype, `on${method}`, {
    configurable: true,
    enumerable: true,
    /**
     * Return the listener of the event.
     *
     * @return {(Function|undefined)} The event listener or `undefined`
     * @public
     */
    get() {
      const listeners = this.listeners(method);
      for (let i = 0; i < listeners.length; i++) {
        if (listeners[i]._listener) return listeners[i]._listener;
      }

      return undefined;
    },
    /**
     * Add a listener for the event.
     *
     * @param {Function} listener The listener to add
     * @public
     */
    set(listener) {
      const listeners = this.listeners(method);
      for (let i = 0; i < listeners.length; i++) {
        //
        // Remove only the listeners added via `addEventListener`.
        //
        if (listeners[i]._listener) this.removeListener(method, listeners[i]);
      }
      this.addEventListener(method, listener);
    }
  });
});

WebSocket.prototype.addEventListener = addEventListener;
WebSocket.prototype.removeEventListener = removeEventListener;

module.exports = WebSocket;

/**
 * Initialize a WebSocket client.
 *
 * @param {WebSocket} websocket The client to initialize
 * @param {(String|url.URL)} address The URL to which to connect
 * @param {String} [protocols] The subprotocols
 * @param {Object} [options] Connection options
 * @param {(Boolean|Object)} [options.perMessageDeflate=true] Enable/disable
 *     permessage-deflate
 * @param {Number} [options.handshakeTimeout] Timeout in milliseconds for the
 *     handshake request
 * @param {Number} [options.protocolVersion=13] Value of the
 *     `Sec-WebSocket-Version` header
 * @param {String} [options.origin] Value of the `Origin` or
 *     `Sec-WebSocket-Origin` header
 * @param {Number} [options.maxPayload=104857600] The maximum allowed message
 *     size
 * @param {Boolean} [options.followRedirects=false] Whether or not to follow
 *     redirects
 * @param {Number} [options.maxRedirects=10] The maximum number of redirects
 *     allowed
 * @private
 */
function initAsClient(websocket, address, protocols, options) {
  const opts = {
    protocolVersion: protocolVersions[1],
    maxPayload: 100 * 1024 * 1024,
    perMessageDeflate: true,
    followRedirects: false,
    maxRedirects: 10,
    ...options,
    createConnection: undefined,
    socketPath: undefined,
    hostname: undefined,
    protocol: undefined,
    timeout: undefined,
    method: undefined,
    host: undefined,
    path: undefined,
    port: undefined
  };

  if (!protocolVersions.includes(opts.protocolVersion)) {
    throw new RangeError(
      `Unsupported protocol version: ${opts.protocolVersion} ` +
        `(supported versions: ${protocolVersions.join(', ')})`
    );
  }

  let parsedUrl;

  if (address instanceof URL) {
    parsedUrl = address;
    websocket._url = address.href;
  } else {
    parsedUrl = new URL(address);
    websocket._url = address;
  }

  const isUnixSocket = parsedUrl.protocol === 'ws+unix:';

  if (!parsedUrl.host && (!isUnixSocket || !parsedUrl.pathname)) {
    throw new Error(`Invalid URL: ${websocket.url}`);
  }

  const isSecure =
    parsedUrl.protocol === 'wss:' || parsedUrl.protocol === 'https:';
  const defaultPort = isSecure ? 443 : 80;
  const key = randomBytes(16).toString('base64');
  const get = isSecure ? https.get : http.get;
  let perMessageDeflate;

  opts.createConnection = isSecure ? tlsConnect : netConnect;
  opts.defaultPort = opts.defaultPort || defaultPort;
  opts.port = parsedUrl.port || defaultPort;
  opts.host = parsedUrl.hostname.startsWith('[')
    ? parsedUrl.hostname.slice(1, -1)
    : parsedUrl.hostname;
  opts.headers = {
    'Sec-WebSocket-Version': opts.protocolVersion,
    'Sec-WebSocket-Key': key,
    Connection: 'Upgrade',
    Upgrade: 'websocket',
    ...opts.headers
  };
  opts.path = parsedUrl.pathname + parsedUrl.search;
  opts.timeout = opts.handshakeTimeout;

  if (opts.perMessageDeflate) {
    perMessageDeflate = new PerMessageDeflate(
      opts.perMessageDeflate !== true ? opts.perMessageDeflate : {},
      false,
      opts.maxPayload
    );
    opts.headers['Sec-WebSocket-Extensions'] = format({
      [PerMessageDeflate.extensionName]: perMessageDeflate.offer()
    });
  }
  if (protocols) {
    opts.headers['Sec-WebSocket-Protocol'] = protocols;
  }
  if (opts.origin) {
    if (opts.protocolVersion < 13) {
      opts.headers['Sec-WebSocket-Origin'] = opts.origin;
    } else {
      opts.headers.Origin = opts.origin;
    }
  }
  if (parsedUrl.username || parsedUrl.password) {
    opts.auth = `${parsedUrl.username}:${parsedUrl.password}`;
  }

  if (isUnixSocket) {
    const parts = opts.path.split(':');

    opts.socketPath = parts[0];
    opts.path = parts[1];
  }

  let req = (websocket._req = get(opts));

  if (opts.timeout) {
    req.on('timeout', () => {
      abortHandshake(websocket, req, 'Opening handshake has timed out');
    });
  }

  req.on('error', (err) => {
    if (req === null || req.aborted) return;

    req = websocket._req = null;
    websocket._readyState = WebSocket.CLOSING;
    websocket.emit('error', err);
    websocket.emitClose();
  });

  req.on('response', (res) => {
    const location = res.headers.location;
    const statusCode = res.statusCode;

    if (
      location &&
      opts.followRedirects &&
      statusCode >= 300 &&
      statusCode < 400
    ) {
      if (++websocket._redirects > opts.maxRedirects) {
        abortHandshake(websocket, req, 'Maximum redirects exceeded');
        return;
      }

      req.abort();

      const addr = new URL(location, address);

      initAsClient(websocket, addr, protocols, options);
    } else if (!websocket.emit('unexpected-response', req, res)) {
      abortHandshake(
        websocket,
        req,
        `Unexpected server response: ${res.statusCode}`
      );
    }
  });

  req.on('upgrade', (res, socket, head) => {
    websocket.emit('upgrade', res);

    //
    // The user may have closed the connection from a listener of the `upgrade`
    // event.
    //
    if (websocket.readyState !== WebSocket.CONNECTING) return;

    req = websocket._req = null;

    const digest = createHash('sha1')
      .update(key + GUID)
      .digest('base64');

    if (res.headers['sec-websocket-accept'] !== digest) {
      abortHandshake(websocket, socket, 'Invalid Sec-WebSocket-Accept header');
      return;
    }

    const serverProt = res.headers['sec-websocket-protocol'];
    const protList = (protocols || '').split(/, */);
    let protError;

    if (!protocols && serverProt) {
      protError = 'Server sent a subprotocol but none was requested';
    } else if (protocols && !serverProt) {
      protError = 'Server sent no subprotocol';
    } else if (serverProt && !protList.includes(serverProt)) {
      protError = 'Server sent an invalid subprotocol';
    }

    if (protError) {
      abortHandshake(websocket, socket, protError);
      return;
    }

    if (serverProt) websocket._protocol = serverProt;

    if (perMessageDeflate) {
      try {
        const extensions = parse(res.headers['sec-websocket-extensions']);

        if (extensions[PerMessageDeflate.extensionName]) {
          perMessageDeflate.accept(extensions[PerMessageDeflate.extensionName]);
          websocket._extensions[
            PerMessageDeflate.extensionName
          ] = perMessageDeflate;
        }
      } catch (err) {
        abortHandshake(
          websocket,
          socket,
          'Invalid Sec-WebSocket-Extensions header'
        );
        return;
      }
    }

    websocket.setSocket(socket, head, opts.maxPayload);
  });
}

/**
 * Create a `net.Socket` and initiate a connection.
 *
 * @param {Object} options Connection options
 * @return {net.Socket} The newly created socket used to start the connection
 * @private
 */
function netConnect(options) {
  options.path = options.socketPath;
  return net.connect(options);
}

/**
 * Create a `tls.TLSSocket` and initiate a connection.
 *
 * @param {Object} options Connection options
 * @return {tls.TLSSocket} The newly created socket used to start the connection
 * @private
 */
function tlsConnect(options) {
  options.path = undefined;

  if (!options.servername && options.servername !== '') {
    options.servername = net.isIP(options.host) ? '' : options.host;
  }

  return tls.connect(options);
}

/**
 * Abort the handshake and emit an error.
 *
 * @param {WebSocket} websocket The WebSocket instance
 * @param {(http.ClientRequest|net.Socket)} stream The request to abort or the
 *     socket to destroy
 * @param {String} message The error message
 * @private
 */
function abortHandshake(websocket, stream, message) {
  websocket._readyState = WebSocket.CLOSING;

  const err = new Error(message);
  Error.captureStackTrace(err, abortHandshake);

  if (stream.setHeader) {
    stream.abort();

    if (stream.socket && !stream.socket.destroyed) {
      //
      // On Node.js >= 14.3.0 `request.abort()` does not destroy the socket if
      // called after the request completed. See
      // https://github.com/websockets/ws/issues/1869.
      //
      stream.socket.destroy();
    }

    stream.once('abort', websocket.emitClose.bind(websocket));
    websocket.emit('error', err);
  } else {
    stream.destroy(err);
    stream.once('error', websocket.emit.bind(websocket, 'error'));
    stream.once('close', websocket.emitClose.bind(websocket));
  }
}

/**
 * Handle cases where the `ping()`, `pong()`, or `send()` methods are called
 * when the `readyState` attribute is `CLOSING` or `CLOSED`.
 *
 * @param {WebSocket} websocket The WebSocket instance
 * @param {*} [data] The data to send
 * @param {Function} [cb] Callback
 * @private
 */
function sendAfterClose(websocket, data, cb) {
  if (data) {
    const length = toBuffer(data).length;

    //
    // The `_bufferedAmount` property is used only when the peer is a client and
    // the opening handshake fails. Under these circumstances, in fact, the
    // `setSocket()` method is not called, so the `_socket` and `_sender`
    // properties are set to `null`.
    //
    if (websocket._socket) websocket._sender._bufferedBytes += length;
    else websocket._bufferedAmount += length;
  }

  if (cb) {
    const err = new Error(
      `WebSocket is not open: readyState ${websocket.readyState} ` +
        `(${readyStates[websocket.readyState]})`
    );
    cb(err);
  }
}

/**
 * The listener of the `Receiver` `'conclude'` event.
 *
 * @param {Number} code The status code
 * @param {String} reason The reason for closing
 * @private
 */
function receiverOnConclude(code, reason) {
  const websocket = this[kWebSocket];

  websocket._socket.removeListener('data', socketOnData);
  websocket._socket.resume();

  websocket._closeFrameReceived = true;
  websocket._closeMessage = reason;
  websocket._closeCode = code;

  if (code === 1005) websocket.close();
  else websocket.close(code, reason);
}

/**
 * The listener of the `Receiver` `'drain'` event.
 *
 * @private
 */
function receiverOnDrain() {
  this[kWebSocket]._socket.resume();
}

/**
 * The listener of the `Receiver` `'error'` event.
 *
 * @param {(RangeError|Error)} err The emitted error
 * @private
 */
function receiverOnError(err) {
  const websocket = this[kWebSocket];

  websocket._socket.removeListener('data', socketOnData);

  websocket._readyState = WebSocket.CLOSING;
  websocket._closeCode = err[kStatusCode];
  websocket.emit('error', err);
  websocket._socket.destroy();
}

/**
 * The listener of the `Receiver` `'finish'` event.
 *
 * @private
 */
function receiverOnFinish() {
  this[kWebSocket].emitClose();
}

/**
 * The listener of the `Receiver` `'message'` event.
 *
 * @param {(String|Buffer|ArrayBuffer|Buffer[])} data The message
 * @private
 */
function receiverOnMessage(data) {
  this[kWebSocket].emit('message', data);
}

/**
 * The listener of the `Receiver` `'ping'` event.
 *
 * @param {Buffer} data The data included in the ping frame
 * @private
 */
function receiverOnPing(data) {
  const websocket = this[kWebSocket];

  websocket.pong(data, !websocket._isServer, NOOP);
  websocket.emit('ping', data);
}

/**
 * The listener of the `Receiver` `'pong'` event.
 *
 * @param {Buffer} data The data included in the pong frame
 * @private
 */
function receiverOnPong(data) {
  this[kWebSocket].emit('pong', data);
}

/**
 * The listener of the `net.Socket` `'close'` event.
 *
 * @private
 */
function socketOnClose() {
  const websocket = this[kWebSocket];

  this.removeListener('close', socketOnClose);
  this.removeListener('end', socketOnEnd);

  websocket._readyState = WebSocket.CLOSING;

  //
  // The close frame might not have been received or the `'end'` event emitted,
  // for example, if the socket was destroyed due to an error. Ensure that the
  // `receiver` stream is closed after writing any remaining buffered data to
  // it. If the readable side of the socket is in flowing mode then there is no
  // buffered data as everything has been already written and `readable.read()`
  // will return `null`. If instead, the socket is paused, any possible buffered
  // data will be read as a single chunk and emitted synchronously in a single
  // `'data'` event.
  //
  websocket._socket.read();
  websocket._receiver.end();

  this.removeListener('data', socketOnData);
  this[kWebSocket] = undefined;

  clearTimeout(websocket._closeTimer);

  if (
    websocket._receiver._writableState.finished ||
    websocket._receiver._writableState.errorEmitted
  ) {
    websocket.emitClose();
  } else {
    websocket._receiver.on('error', receiverOnFinish);
    websocket._receiver.on('finish', receiverOnFinish);
  }
}

/**
 * The listener of the `net.Socket` `'data'` event.
 *
 * @param {Buffer} chunk A chunk of data
 * @private
 */
function socketOnData(chunk) {
  if (!this[kWebSocket]._receiver.write(chunk)) {
    this.pause();
  }
}

/**
 * The listener of the `net.Socket` `'end'` event.
 *
 * @private
 */
function socketOnEnd() {
  const websocket = this[kWebSocket];

  websocket._readyState = WebSocket.CLOSING;
  websocket._receiver.end();
  this.end();
}

/**
 * The listener of the `net.Socket` `'error'` event.
 *
 * @private
 */
function socketOnError() {
  const websocket = this[kWebSocket];

  this.removeListener('error', socketOnError);
  this.on('error', NOOP);

  if (websocket) {
    websocket._readyState = WebSocket.CLOSING;
    this.destroy();
  }
}

},
"tf5U14dxc7PYAAXmvBsky40qOlhjmF0r/85RTn79O8A=":
function (require, module, exports, __dirname, __filename) {
var levelup = require('levelup')
var encode = require('encoding-down')

function packager (leveldown) {
  function Level (location, options, callback) {
    if (typeof options === 'function') {
      callback = options
    }
    if (typeof options !== 'object' || options === null) {
      options = {}
    }

    return levelup(encode(leveldown(location), options), options, callback)
  }

  [ 'destroy', 'repair' ].forEach(function (m) {
    if (typeof leveldown[m] === 'function') {
      Level[m] = function () {
        leveldown[m].apply(leveldown, arguments)
      }
    }
  })

  Level.errors = levelup.errors

  return Level
}

module.exports = packager

},
"tpdn/6R1cMVMtxMP9vbiO7gcDf21nsi96QKevLmZ/RU=":
function (require, module, exports, __dirname, __filename) {
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.prototype = Object.create(Buffer.prototype)

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},
"tq7oTpkr4LkzfLPQwnEXkKky6zNNCUVf47lfR3Ed7Vc=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var ws = require('./')
var WebSocket = require('ws')
var http = require('http')
var https = require('https')

var EventEmitter = require('events').EventEmitter
module.exports = !WebSocket.Server ? null : function (opts, onConnection) {
    var emitter = new EventEmitter()
    var server
    if (typeof opts === 'function'){
      onConnection = opts
      opts = null
    }
    opts = opts || {}

    if(onConnection)
      emitter.on('connection', onConnection)

    function proxy (server, event) {
      return server.on(event, function () {
        var args = [].slice.call(arguments)
        args.unshift(event)
        emitter.emit.apply(emitter, args)
      })
    }

    server = opts.server ||
      (opts.key && opts.cert ? https.createServer(opts) : http.createServer())

    var wsServer = new WebSocket.Server({
      server: server,
      perMessageDeflate: false,
      verifyClient: opts.verifyClient
    })

    proxy(server, 'listening')
    proxy(server, 'request')
    proxy(server, 'close')

    wsServer.on('connection', function (socket, req) {
      socket.upgradeReq = req // mix: kinda gross hack to preserve the API of duplex.js, but might confuse users...
      var stream = ws(socket)
      stream.remoteAddress = req.connection.remoteAddress
      emitter.emit('connection', stream)
    })

    emitter.listen = function (addr, onListening) {
      if(onListening)
        emitter.once('listening', onListening)
      server.listen(addr.port || addr)
      return emitter
    }

    emitter.close = function (onClose) {
      server.close(onClose)
      wsServer.close()

      // soft close
      wsServer.clients.forEach((socket) => {
        socket.close()
      })

      setTimeout(() => {
        // Second sweep, hard close
        // for everyone who's left
        wsServer.clients.forEach((socket) => {
          if ([socket.OPEN, socket.CLOSING].includes(socket.readyState)) {
            socket.terminate()
          }
        })
      }, 1000)

      return emitter
    }

    emitter.address = server.address.bind(server)
    return emitter
  }

},
"txXy8KMSq0OQ5jAkMlDRgkXCGtxzWojt7TDHa4tFxWw=":
function (require, module, exports, __dirname, __filename) {
var cl = require('sodium-chloride');
var snnm = require('sodium-native-nodejs-mobile');
module.exports = cl(snnm);

},
"u31cfWGdWCm6oJyY0157VZbLMYDWViuTy7rw7tV1xsI=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var required = require('requires-port')
  , qs = require('querystringify')
  , slashes = /^[A-Za-z][A-Za-z0-9+-.]*:\/\//
  , protocolre = /^([a-z][a-z0-9.+-]*:)?(\/\/)?([\\/]+)?([\S\s]*)/i
  , windowsDriveLetter = /^[a-zA-Z]:/
  , whitespace = '[\\x09\\x0A\\x0B\\x0C\\x0D\\x20\\xA0\\u1680\\u180E\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u202F\\u205F\\u3000\\u2028\\u2029\\uFEFF]'
  , left = new RegExp('^'+ whitespace +'+');

/**
 * Trim a given string.
 *
 * @param {String} str String to trim.
 * @public
 */
function trimLeft(str) {
  return (str ? str : '').toString().replace(left, '');
}

/**
 * These are the parse rules for the URL parser, it informs the parser
 * about:
 *
 * 0. The char it Needs to parse, if it's a string it should be done using
 *    indexOf, RegExp using exec and NaN means set as current value.
 * 1. The property we should set when parsing this value.
 * 2. Indication if it's backwards or forward parsing, when set as number it's
 *    the value of extra chars that should be split off.
 * 3. Inherit from location if non existing in the parser.
 * 4. `toLowerCase` the resulting value.
 */
var rules = [
  ['#', 'hash'],                        // Extract from the back.
  ['?', 'query'],                       // Extract from the back.
  function sanitize(address, url) {     // Sanitize what is left of the address
    return isSpecial(url.protocol) ? address.replace(/\\/g, '/') : address;
  },
  ['/', 'pathname'],                    // Extract from the back.
  ['@', 'auth', 1],                     // Extract from the front.
  [NaN, 'host', undefined, 1, 1],       // Set left over value.
  [/:(\d+)$/, 'port', undefined, 1],    // RegExp the back.
  [NaN, 'hostname', undefined, 1, 1]    // Set left over.
];

/**
 * These properties should not be copied or inherited from. This is only needed
 * for all non blob URL's as a blob URL does not include a hash, only the
 * origin.
 *
 * @type {Object}
 * @private
 */
var ignore = { hash: 1, query: 1 };

/**
 * The location object differs when your code is loaded through a normal page,
 * Worker or through a worker using a blob. And with the blobble begins the
 * trouble as the location object will contain the URL of the blob, not the
 * location of the page where our code is loaded in. The actual origin is
 * encoded in the `pathname` so we can thankfully generate a good "default"
 * location from it so we can generate proper relative URL's again.
 *
 * @param {Object|String} loc Optional default location object.
 * @returns {Object} lolcation object.
 * @public
 */
function lolcation(loc) {
  var globalVar;

  if (typeof window !== 'undefined') globalVar = window;
  else if (typeof global !== 'undefined') globalVar = global;
  else if (typeof self !== 'undefined') globalVar = self;
  else globalVar = {};

  var location = globalVar.location || {};
  loc = loc || location;

  var finaldestination = {}
    , type = typeof loc
    , key;

  if ('blob:' === loc.protocol) {
    finaldestination = new Url(unescape(loc.pathname), {});
  } else if ('string' === type) {
    finaldestination = new Url(loc, {});
    for (key in ignore) delete finaldestination[key];
  } else if ('object' === type) {
    for (key in loc) {
      if (key in ignore) continue;
      finaldestination[key] = loc[key];
    }

    if (finaldestination.slashes === undefined) {
      finaldestination.slashes = slashes.test(loc.href);
    }
  }

  return finaldestination;
}

/**
 * Check whether a protocol scheme is special.
 *
 * @param {String} The protocol scheme of the URL
 * @return {Boolean} `true` if the protocol scheme is special, else `false`
 * @private
 */
function isSpecial(scheme) {
  return (
    scheme === 'file:' ||
    scheme === 'ftp:' ||
    scheme === 'http:' ||
    scheme === 'https:' ||
    scheme === 'ws:' ||
    scheme === 'wss:'
  );
}

/**
 * @typedef ProtocolExtract
 * @type Object
 * @property {String} protocol Protocol matched in the URL, in lowercase.
 * @property {Boolean} slashes `true` if protocol is followed by "//", else `false`.
 * @property {String} rest Rest of the URL that is not part of the protocol.
 */

/**
 * Extract protocol information from a URL with/without double slash ("//").
 *
 * @param {String} address URL we want to extract from.
 * @param {Object} location
 * @return {ProtocolExtract} Extracted information.
 * @private
 */
function extractProtocol(address, location) {
  address = trimLeft(address);
  location = location || {};

  var match = protocolre.exec(address);
  var protocol = match[1] ? match[1].toLowerCase() : '';
  var forwardSlashes = !!match[2];
  var otherSlashes = !!match[3];
  var slashesCount = 0;
  var rest;

  if (forwardSlashes) {
    if (otherSlashes) {
      rest = match[2] + match[3] + match[4];
      slashesCount = match[2].length + match[3].length;
    } else {
      rest = match[2] + match[4];
      slashesCount = match[2].length;
    }
  } else {
    if (otherSlashes) {
      rest = match[3] + match[4];
      slashesCount = match[3].length;
    } else {
      rest = match[4]
    }
  }

  if (protocol === 'file:') {
    if (slashesCount >= 2) {
      rest = rest.slice(2);
    }
  } else if (isSpecial(protocol)) {
    rest = match[4];
  } else if (protocol) {
    if (forwardSlashes) {
      rest = rest.slice(2);
    }
  } else if (slashesCount >= 2 && isSpecial(location.protocol)) {
    rest = match[4];
  }

  return {
    protocol: protocol,
    slashes: forwardSlashes || isSpecial(protocol),
    slashesCount: slashesCount,
    rest: rest
  };
}

/**
 * Resolve a relative URL pathname against a base URL pathname.
 *
 * @param {String} relative Pathname of the relative URL.
 * @param {String} base Pathname of the base URL.
 * @return {String} Resolved pathname.
 * @private
 */
function resolve(relative, base) {
  if (relative === '') return base;

  var path = (base || '/').split('/').slice(0, -1).concat(relative.split('/'))
    , i = path.length
    , last = path[i - 1]
    , unshift = false
    , up = 0;

  while (i--) {
    if (path[i] === '.') {
      path.splice(i, 1);
    } else if (path[i] === '..') {
      path.splice(i, 1);
      up++;
    } else if (up) {
      if (i === 0) unshift = true;
      path.splice(i, 1);
      up--;
    }
  }

  if (unshift) path.unshift('');
  if (last === '.' || last === '..') path.push('');

  return path.join('/');
}

/**
 * The actual URL instance. Instead of returning an object we've opted-in to
 * create an actual constructor as it's much more memory efficient and
 * faster and it pleases my OCD.
 *
 * It is worth noting that we should not use `URL` as class name to prevent
 * clashes with the global URL instance that got introduced in browsers.
 *
 * @constructor
 * @param {String} address URL we want to parse.
 * @param {Object|String} [location] Location defaults for relative paths.
 * @param {Boolean|Function} [parser] Parser for the query string.
 * @private
 */
function Url(address, location, parser) {
  address = trimLeft(address);

  if (!(this instanceof Url)) {
    return new Url(address, location, parser);
  }

  var relative, extracted, parse, instruction, index, key
    , instructions = rules.slice()
    , type = typeof location
    , url = this
    , i = 0;

  //
  // The following if statements allows this module two have compatibility with
  // 2 different API:
  //
  // 1. Node.js's `url.parse` api which accepts a URL, boolean as arguments
  //    where the boolean indicates that the query string should also be parsed.
  //
  // 2. The `URL` interface of the browser which accepts a URL, object as
  //    arguments. The supplied object will be used as default values / fall-back
  //    for relative paths.
  //
  if ('object' !== type && 'string' !== type) {
    parser = location;
    location = null;
  }

  if (parser && 'function' !== typeof parser) parser = qs.parse;

  location = lolcation(location);

  //
  // Extract protocol information before running the instructions.
  //
  extracted = extractProtocol(address || '', location);
  relative = !extracted.protocol && !extracted.slashes;
  url.slashes = extracted.slashes || relative && location.slashes;
  url.protocol = extracted.protocol || location.protocol || '';
  address = extracted.rest;

  //
  // When the authority component is absent the URL starts with a path
  // component.
  //
  if (
    extracted.protocol === 'file:' && (
      extracted.slashesCount !== 2 || windowsDriveLetter.test(address)) ||
    (!extracted.slashes &&
      (extracted.protocol ||
        extracted.slashesCount < 2 ||
        !isSpecial(url.protocol)))
  ) {
    instructions[3] = [/(.*)/, 'pathname'];
  }

  for (; i < instructions.length; i++) {
    instruction = instructions[i];

    if (typeof instruction === 'function') {
      address = instruction(address, url);
      continue;
    }

    parse = instruction[0];
    key = instruction[1];

    if (parse !== parse) {
      url[key] = address;
    } else if ('string' === typeof parse) {
      if (~(index = address.indexOf(parse))) {
        if ('number' === typeof instruction[2]) {
          url[key] = address.slice(0, index);
          address = address.slice(index + instruction[2]);
        } else {
          url[key] = address.slice(index);
          address = address.slice(0, index);
        }
      }
    } else if ((index = parse.exec(address))) {
      url[key] = index[1];
      address = address.slice(0, index.index);
    }

    url[key] = url[key] || (
      relative && instruction[3] ? location[key] || '' : ''
    );

    //
    // Hostname, host and protocol should be lowercased so they can be used to
    // create a proper `origin`.
    //
    if (instruction[4]) url[key] = url[key].toLowerCase();
  }

  //
  // Also parse the supplied query string in to an object. If we're supplied
  // with a custom parser as function use that instead of the default build-in
  // parser.
  //
  if (parser) url.query = parser(url.query);

  //
  // If the URL is relative, resolve the pathname against the base URL.
  //
  if (
      relative
    && location.slashes
    && url.pathname.charAt(0) !== '/'
    && (url.pathname !== '' || location.pathname !== '')
  ) {
    url.pathname = resolve(url.pathname, location.pathname);
  }

  //
  // Default to a / for pathname if none exists. This normalizes the URL
  // to always have a /
  //
  if (url.pathname.charAt(0) !== '/' && isSpecial(url.protocol)) {
    url.pathname = '/' + url.pathname;
  }

  //
  // We should not add port numbers if they are already the default port number
  // for a given protocol. As the host also contains the port number we're going
  // override it with the hostname which contains no port number.
  //
  if (!required(url.port, url.protocol)) {
    url.host = url.hostname;
    url.port = '';
  }

  //
  // Parse down the `auth` for the username and password.
  //
  url.username = url.password = '';
  if (url.auth) {
    instruction = url.auth.split(':');
    url.username = instruction[0] || '';
    url.password = instruction[1] || '';
  }

  url.origin = url.protocol !== 'file:' && isSpecial(url.protocol) && url.host
    ? url.protocol +'//'+ url.host
    : 'null';

  //
  // The href is just the compiled result.
  //
  url.href = url.toString();
}

/**
 * This is convenience method for changing properties in the URL instance to
 * insure that they all propagate correctly.
 *
 * @param {String} part          Property we need to adjust.
 * @param {Mixed} value          The newly assigned value.
 * @param {Boolean|Function} fn  When setting the query, it will be the function
 *                               used to parse the query.
 *                               When setting the protocol, double slash will be
 *                               removed from the final url if it is true.
 * @returns {URL} URL instance for chaining.
 * @public
 */
function set(part, value, fn) {
  var url = this;

  switch (part) {
    case 'query':
      if ('string' === typeof value && value.length) {
        value = (fn || qs.parse)(value);
      }

      url[part] = value;
      break;

    case 'port':
      url[part] = value;

      if (!required(value, url.protocol)) {
        url.host = url.hostname;
        url[part] = '';
      } else if (value) {
        url.host = url.hostname +':'+ value;
      }

      break;

    case 'hostname':
      url[part] = value;

      if (url.port) value += ':'+ url.port;
      url.host = value;
      break;

    case 'host':
      url[part] = value;

      if (/:\d+$/.test(value)) {
        value = value.split(':');
        url.port = value.pop();
        url.hostname = value.join(':');
      } else {
        url.hostname = value;
        url.port = '';
      }

      break;

    case 'protocol':
      url.protocol = value.toLowerCase();
      url.slashes = !fn;
      break;

    case 'pathname':
    case 'hash':
      if (value) {
        var char = part === 'pathname' ? '/' : '#';
        url[part] = value.charAt(0) !== char ? char + value : value;
      } else {
        url[part] = value;
      }
      break;

    default:
      url[part] = value;
  }

  for (var i = 0; i < rules.length; i++) {
    var ins = rules[i];

    if (ins[4]) url[ins[1]] = url[ins[1]].toLowerCase();
  }

  url.origin = url.protocol !== 'file:' && isSpecial(url.protocol) && url.host
    ? url.protocol +'//'+ url.host
    : 'null';

  url.href = url.toString();

  return url;
}

/**
 * Transform the properties back in to a valid and full URL string.
 *
 * @param {Function} stringify Optional query stringify function.
 * @returns {String} Compiled version of the URL.
 * @public
 */
function toString(stringify) {
  if (!stringify || 'function' !== typeof stringify) stringify = qs.stringify;

  var query
    , url = this
    , protocol = url.protocol;

  if (protocol && protocol.charAt(protocol.length - 1) !== ':') protocol += ':';

  var result = protocol + (url.slashes || isSpecial(url.protocol) ? '//' : '');

  if (url.username) {
    result += url.username;
    if (url.password) result += ':'+ url.password;
    result += '@';
  }

  result += url.host + url.pathname;

  query = 'object' === typeof url.query ? stringify(url.query) : url.query;
  if (query) result += '?' !== query.charAt(0) ? '?'+ query : query;

  if (url.hash) result += url.hash;

  return result;
}

Url.prototype = { set: set, toString: toString };

//
// Expose the URL parser and some additional properties that might be useful for
// others or testing.
//
Url.extractProtocol = extractProtocol;
Url.location = lolcation;
Url.trimLeft = trimLeft;
Url.qs = qs;

module.exports = Url;

},
"u6cUVLTSQT2T15LdiO8t/iLDApfzU2vGoBCouTtwntU=":
function (require, module, exports, __dirname, __filename) {
var exports = module.exports = require('./duplex')

exports.source = require('./source');
exports.sink = require('./sink');
exports.createServer = require('./server')
exports.connect = require('./client')

},
"uDwvQE69haX7Ha1KXpbIxpyqbRXpu8KQwRW/yHySsTw=":
function (require, module, exports, __dirname, __filename) {
'use strict'
module.exports = function infinite (generate) {
  generate = generate || Math.random
  return function (end, cb) {
    if(end) return cb && cb(end)
    return cb(null, generate())
  }
}



},
"uEm695RlEddYSb7pPT2euxFceGvlMIwUb0AfFuicQms=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __assign = (this && this.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
var u = require("./util");
var Muxrpc = require('muxrpc');
var pull = require('pull-stream');
var MultiServer = require('multiserver');
var Inactive = require('pull-inactivity');
var debug = require('debug')('secret-stack');
function isPlainObject(o) {
    return o && typeof o === 'object' && !Array.isArray(o);
}
function toBase64(s) {
    if (typeof s === 'string')
        return s;
    else
        return s.toString('base64');
}
function each(objOrArr, iter) {
    if (Array.isArray(objOrArr)) {
        objOrArr.forEach(iter);
    }
    else {
        for (var key in objOrArr)
            iter(objOrArr[key], key, objOrArr);
    }
}
function assertHasNameAndCreate(obj, type) {
    if (!isPlainObject(obj) ||
        typeof obj.name !== 'string' ||
        typeof obj.create !== 'function') {
        throw new Error(type + ' must be {name: string, create: function}');
    }
}
function coearseAddress(address) {
    if (isPlainObject(address)) {
        var protocol = 'net';
        if (typeof address.host === 'string' && address.host.endsWith('.onion')) {
            protocol = 'onion';
        }
        return ([protocol, address.host, address.port].join(':') +
            '~' +
            ['shs', toBase64(address.key)].join(':'));
    }
    return address;
}
function isPermsList(list) {
    if (list === null)
        return true;
    if (typeof list === 'undefined')
        return true;
    return Array.isArray(list) && list.every(function (x) { return typeof x === 'string'; });
}
function isPermissions(perms) {
    return (perms &&
        isPlainObject(perms) &&
        isPermsList(perms.allow) &&
        isPermsList(perms.deny));
}
module.exports = {
    manifest: {
        auth: 'async',
        address: 'sync',
        manifest: 'sync',
        multiserver: {
            parse: 'sync',
            address: 'sync'
        }
    },
    permissions: {
        anonymous: {
            allow: ['manifest']
        }
    },
    init: function (api, opts, permissions, manifest) {
        var _a, _b;
        var timeoutInactivity;
        if (!isNaN((_a = opts.timers) === null || _a === void 0 ? void 0 : _a.inactivity)) {
            timeoutInactivity = (_b = opts.timers) === null || _b === void 0 ? void 0 : _b.inactivity;
        }
        timeoutInactivity = timeoutInactivity || (opts.timers ? 600e3 : 5e3);
        if (!opts.connections) {
            var netIn = __assign(__assign({ scope: ['device', 'local', 'public'], transform: 'shs' }, (opts.host ? { host: opts.host } : null)), (opts.port ? { port: opts.port } : null));
            var netOut = {
                transform: 'shs'
            };
            opts.connections = {
                incoming: {
                    net: [netIn]
                },
                outgoing: {
                    net: [netOut]
                }
            };
        }
        var peers = (api.peers = {});
        var transports = [];
        var transforms = [];
        var server;
        var ms;
        var msClient;
        function setupMultiserver() {
            if (api.closed)
                return;
            if (server)
                return server;
            if (transforms.length < 1) {
                throw new Error('secret-stack needs at least 1 transform protocol');
            }
            var serverSuites = [];
            var clientSuites = [];
            var _loop_1 = function (incTransport) {
                opts.connections.incoming[incTransport].forEach(function (inc) {
                    transforms.forEach(function (transform) {
                        transports.forEach(function (transport) {
                            if (transport.name === incTransport &&
                                transform.name === inc.transform) {
                                var msPlugin = transport.create(inc);
                                var msTransformPlugin = transform.create();
                                if (msPlugin.scope() !== inc.scope) {
                                    throw new Error('transport:' +
                                        transport.name +
                                        ' did not remember scope, expected:' +
                                        inc.scope +
                                        ' got:' +
                                        msPlugin.scope());
                                }
                                debug('creating server %s %s host=%s port=%d scope=%s', incTransport, transform.name, inc.host, inc.port, inc.scope || 'undefined');
                                serverSuites.push([msPlugin, msTransformPlugin]);
                            }
                        });
                    });
                });
            };
            for (var incTransport in opts.connections.incoming) {
                _loop_1(incTransport);
            }
            var _loop_2 = function (outTransport) {
                opts.connections.outgoing[outTransport].forEach(function (out) {
                    transforms.forEach(function (transform) {
                        transports.forEach(function (transport) {
                            if (transport.name === outTransport &&
                                transform.name === out.transform) {
                                var msPlugin = transport.create(out);
                                var msTransformPlugin = transform.create();
                                clientSuites.push([msPlugin, msTransformPlugin]);
                            }
                        });
                    });
                });
            };
            for (var outTransport in opts.connections.outgoing) {
                _loop_2(outTransport);
            }
            msClient = MultiServer(clientSuites);
            ms = MultiServer(serverSuites);
            server = ms.server(setupRPC, null, function () {
                api.emit('multiserver:listening');
            });
            if (!server)
                throw new Error('expected server');
            return server;
        }
        setImmediate(setupMultiserver);
        function setupRPC(stream, manf, isClient) {
            var _id = '@' + u.toId(stream.remote);
            var rpc = Muxrpc(manifest, manf !== null && manf !== void 0 ? manf : manifest, api, _id, isClient
                ? permissions.anonymous
                : isPermissions(stream.auth)
                    ? stream.auth
                    : permissions.anonymous, false);
            rpc.id = _id;
            var rpcStream = rpc.stream;
            if (timeoutInactivity > 0 && api.id !== rpc.id) {
                rpcStream = Inactive(rpcStream, timeoutInactivity);
            }
            rpc.meta = stream.meta;
            rpc.stream.address = stream.address;
            pull(stream, rpcStream, stream);
            if (!peers[rpc.id])
                peers[rpc.id] = [];
            peers[rpc.id].push(rpc);
            rpc.once('closed', function () {
                peers[rpc.id].splice(peers[rpc.id].indexOf(rpc), 1);
            });
            api.emit('rpc:connect', rpc, !!isClient);
            return rpc;
        }
        return {
            config: opts,
            auth: function (_pub, cb) {
                cb();
            },
            address: function (scope) {
                return api.getAddress(scope);
            },
            getAddress: function (scope) {
                setupMultiserver();
                return ms.stringify(scope) || null;
            },
            manifest: function () {
                return manifest;
            },
            getManifest: function () {
                return this.manifest();
            },
            connect: function (address, cb) {
                setupMultiserver();
                msClient.client(coearseAddress(address), function (err, stream) {
                    if (err)
                        cb(err);
                    else
                        cb(null, setupRPC(stream, null, true));
                });
            },
            multiserver: {
                transport: function (transport) {
                    if (server) {
                        throw new Error('cannot add protocol after server initialized');
                    }
                    assertHasNameAndCreate(transport, 'transport');
                    debug('Adding transport %s', transport.name);
                    transports.push(transport);
                    return this;
                },
                transform: function (transform) {
                    assertHasNameAndCreate(transform, 'transform');
                    debug('Adding transform %s', transform.name);
                    transforms.push(transform);
                    return this;
                },
                parse: function (str) {
                    return ms.parse(str);
                },
                address: function (scope) {
                    setupMultiserver();
                    return ms.stringify(scope) || null;
                }
            },
            close: function (err, cb) {
                var _a;
                if (typeof err === 'function') {
                    cb = err;
                    err = null;
                }
                api.closed = true;
                if (!server)
                    cb && cb();
                else {
                    ((_a = server.close) !== null && _a !== void 0 ? _a : server)(function (err) {
                        api.emit('close', err);
                        cb && cb(err);
                    });
                }
                if (err) {
                    each(peers, function (connections) {
                        each(connections, function (rpc) {
                            rpc.close(err);
                        });
                    });
                }
            }
        };
    }
};

},
"uL61TlttIPMJUhjfIE+mrAcTOzy7we9x83UbcC58j+U=":
function (require, module, exports, __dirname, __filename) {
/*! typedarray-to-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
/**
 * Convert a typed array to a Buffer without a copy
 *
 * Author:   Feross Aboukhadijeh <https://feross.org>
 * License:  MIT
 *
 * `npm install typedarray-to-buffer`
 */

module.exports = function typedarrayToBuffer (arr) {
  return ArrayBuffer.isView(arr)
    // To avoid a copy, use the typed array's underlying ArrayBuffer to back
    // new Buffer, respecting the "view", i.e. byteOffset and byteLength
    ? Buffer.from(arr.buffer, arr.byteOffset, arr.byteLength)
    // Pass through all other types to `Buffer.from`
    : Buffer.from(arr)
}

},
"uMt0kvwcnRi+ULOk8HcWo6hfu8zIzqslNq+Oi9mMC6U=":
function (require, module, exports, __dirname, __filename) {

/* jshint node: true */
'use strict';

var fs = require('fs');
var Decoder = require('pull-utf8-decoder')
/**
  # pull-file

  This is a simple module which uses raw file reading methods available in
  the node `fs` module to read files on-demand.  It's a work in progress
  and feedback is welcome :)

  ## Example Usage

  <<< examples/ipsum-chunks.js

**/
module.exports = function(filename, opts) {
  var mode = opts && opts.mode || 0x1B6; // 0666
  var bufferSize = opts && (opts.bufferSize || (opts.buffer && opts.buffer.length))  || 1024*64;
  var start = opts && opts.start || 0
  var end = opts && opts.end || Number.MAX_SAFE_INTEGER
  var fd = opts && opts.fd

  var ended, closeNext, busy;
  var _buffer = opts && opts.buffer || new Buffer(bufferSize)
  var live = opts && !!opts.live
  var liveCb, closeCb
  var watcher
  if(live) {
    watcher = fs.watch(filename, {
      persistent: opts.persistent !== false,
    },
    function (event) {
      if(liveCb && event === 'change') {
        var cb = liveCb
        liveCb = null
        closeNext = false
        readNext(cb)
      }
    })

  }

  var flags = opts && opts.flags || 'r'

  function readNext(cb) {
    if(closeNext) {
      if(!live) close(cb);
      else liveCb = cb;
      return
    }
    var toRead = Math.min(end - start, bufferSize);
    busy = true;

    fs.read(
      fd,
      _buffer,
      0,
      toRead,
      start,
      function(err, count, buffer) {
        busy = false;
        start += count;
        // if we have received an end noticiation, just discard this data
        if(closeNext && !live) {
          close(closeCb);
          return cb(closeNext);
        }

        if (ended) {
          return cb(err || ended);
        }

        // if we encountered a read error pass it on
        if (err) {
          return cb(err);
        }

        if(count === buffer.length) {
          cb(null, buffer);
        } else if(count === 0 && live) {
          liveCb = cb; closeNext = true
        } else {
          closeNext = true;
          cb(null, buffer.slice(0, count));
        }
      }
    );
    _buffer = opts && opts.buffer || new Buffer(Math.min(end - start, bufferSize))
  }

  function open(cb) {
    busy = true;
    fs.open(filename, flags, mode, function(err, descriptor) {
      // save the file descriptor
      fd = descriptor;

      busy = false
      if(closeNext) {
        close(closeCb);
        return cb(closeNext);
      }

      if (err) {
        return cb(err);
      }

      // read the next bytes
      return readNext(cb);
    });
  }

  function close (cb) {
    if(!cb) throw new Error('close must have cb')
    if(watcher) watcher.close()
    //if auto close is disabled, then user manages fd.
    if(opts && opts.autoClose === false) return cb(true)

    //wait until we have got out of bed, then go back to bed.
    //or if we are reading, wait till we read, then go back to bed.
    else if(busy) {
      closeCb = cb
      return closeNext = true
    }

    //first read was close, don't even get out of bed.
    else if(!fd) {
      return cb(true)
    }

    //go back to bed
    else {
      fs.close(fd, function(err) {
        fd = null;
        cb(err || true);
      });
    }
  }

  function source (end, cb) {
    if (end) {
      ended = end;
      live = false;
      if(liveCb) {
        liveCb(end || true);
      }
      close(cb);
    }
    // if we have already received the end notification, abort further
    else if (ended) {
      cb(ended);
    }

    else if (! fd) {
      open(cb);
    }

    else
      readNext(cb);
  };

  //read directly to text
  if(opts && opts.encoding)
    return Decoder(opts.encoding)(source)

  return source

};

},
"uPQ41FZx81sDszYzXDS7+9JihCfkNL0TmQouJWRj900=":
function (require, module, exports, __dirname, __filename) {

const map = require('pull-stream/throughs/async-map')

module.exports = through

function through (createPromise) {
  return map(function (v, cb) {
    return createPromise(v)
      .then(function (res) {
        cb(null, res)
      })
      .catch(function (err) {
        cb(err)
      })
  })
}

},
"uWOt3+QAzT8LY/cURWwIaprSiVt/LX81hmLTEf7gniU=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.Gossip = void 0;
const secret_stack_decorators_1 = require("secret-stack-decorators");
let Gossip = class Gossip {
    constructor(ssb) {
        this.ping = () => this.ssb.conn.ping();
        this.ssb = ssb;
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('duplex', { anonymous: 'allow' })
], Gossip.prototype, "ping", void 0);
Gossip = __decorate([
    secret_stack_decorators_1.plugin('1.0.0')
], Gossip);
exports.Gossip = Gossip;

},
"ugR+w4XZMN/3juELVikZ64t5T3QAEtcBtleh6bAHr/A=":
function (require, module, exports, __dirname, __filename) {
var Buffer = require('buffer').Buffer

var BLAKE2s = (function () {
    function BLAKE2s(digestLength, key) {
        if(!(this instanceof BLAKE2s)) return new BLAKE2s(digestLength, key)
        if (typeof digestLength === "undefined") { digestLength = 32; }
        this.isFinished = false;
        this.digestLength = 32;
        this.blockLength = 64;
        this.iv = [
            0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
            0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
        ];
        //TODO tree mode.
        if (digestLength <= 0) {
            digestLength = this.digestLength;
        } else if (digestLength > 32) {
            throw 'digestLength is too large';
        }
        var keyLength = 0;
        if (typeof key == 'string') {
            key = this.stringToUtf8Array(key);
            keyLength = key.length;
        } else if (typeof key == 'object') {
            keyLength = key.length;
        }
        if (keyLength > 32) {
            throw 'key too long';
        }

        var param = [digestLength & 0xff, keyLength, 1, 1];
        this.h = this.iv.slice(0);

        // XOR part of parameter block.
        this.h[0] ^= this.load32(param, 0);

        this.x = new Array(64);
        this.t0 = 0;
        this.t1 = 0;
        this.f0 = 0;
        this.f1 = 0;
        this.nx = 0;
        this.digestLength = digestLength;

        if (keyLength > 0) {
            for (var i = 0; i < keyLength; i++) {
                this.x[i] = key[i];
            }
            for (var i = keyLength; i < 64; i++) {
                this.x[i] = 0;
            }
            this.nx = 64;
        }
    }
    BLAKE2s.prototype.load32 = function (p, pos) {
        return ((p[pos] & 0xff) | ((p[pos + 1] & 0xff) << 8) | ((p[pos + 2] & 0xff) << 16) | ((p[pos + 3] & 0xff) << 24)) >>> 0;
    };

    BLAKE2s.prototype.store32 = function (p, pos, v) {
        p[pos] = (v >>> 0) & 0xff;
        p[pos + 1] = (v >>> 8) & 0xff;
        p[pos + 2] = (v >>> 16) & 0xff;
        p[pos + 3] = (v >>> 24) & 0xff;
    };

    BLAKE2s.prototype.processBlock = function (length) {
        this.t0 += length;
        if (this.t0 != this.t0 >>> 0) {
            this.t0 = 0;
            this.t1++;
        }

        var v0 = this.h[0], v1 = this.h[1], v2 = this.h[2], v3 = this.h[3], v4 = this.h[4], v5 = this.h[5], v6 = this.h[6], v7 = this.h[7], v8 = this.iv[0], v9 = this.iv[1], v10 = this.iv[2], v11 = this.iv[3], v12 = this.iv[4] ^ this.t0, v13 = this.iv[5] ^ this.t1, v14 = this.iv[6] ^ this.f0, v15 = this.iv[7] ^ this.f1;

        var m0 = this.load32(this.x, 0), m1 = this.load32(this.x, 4), m2 = this.load32(this.x, 8), m3 = this.load32(this.x, 12), m4 = this.load32(this.x, 16), m5 = this.load32(this.x, 20), m6 = this.load32(this.x, 24), m7 = this.load32(this.x, 28), m8 = this.load32(this.x, 32), m9 = this.load32(this.x, 36), m10 = this.load32(this.x, 40), m11 = this.load32(this.x, 44), m12 = this.load32(this.x, 48), m13 = this.load32(this.x, 52), m14 = this.load32(this.x, 56), m15 = this.load32(this.x, 60);

        // Round 1.
        v0 += m0;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m2;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m4;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m6;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m5;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m7;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m3;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m1;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m8;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m10;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m12;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m14;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m13;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m15;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m11;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m9;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 2.
        v0 += m14;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m4;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m9;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m13;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m15;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m6;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m8;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m10;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m1;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m0;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m11;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m5;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m7;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m3;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m2;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m12;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 3.
        v0 += m11;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m12;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m5;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m15;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m2;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m13;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m0;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m8;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m10;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m3;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m7;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m9;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m1;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m4;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m6;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m14;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 4.
        v0 += m7;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m3;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m13;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m11;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m12;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m14;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m1;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m9;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m2;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m5;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m4;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m15;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m0;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m8;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m10;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m6;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 5.
        v0 += m9;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m5;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m2;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m10;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m4;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m15;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m7;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m0;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m14;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m11;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m6;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m3;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m8;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m13;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m12;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m1;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 6.
        v0 += m2;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m6;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m0;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m8;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m11;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m3;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m10;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m12;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m4;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m7;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m15;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m1;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m14;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m9;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m5;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m13;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 7.
        v0 += m12;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m1;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m14;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m4;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m13;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m10;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m15;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m5;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m0;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m6;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m9;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m8;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m2;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m11;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m3;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m7;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 8.
        v0 += m13;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m7;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m12;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m3;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m1;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m9;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m14;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m11;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m5;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m15;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m8;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m2;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m6;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m10;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m4;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m0;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 9.
        v0 += m6;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m14;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m11;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m0;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m3;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m8;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m9;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m15;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m12;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m13;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m1;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m10;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m4;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m5;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m7;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v0 += m2;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 7) | v5 >>> 7;

        // Round 10.
        v0 += m10;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v1 += m8;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v2 += m7;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v3 += m1;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v2 += m6;
        v2 += v6;
        v14 ^= v2;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v10 += v14;
        v6 ^= v10;
        v6 = v6 << (32 - 7) | v6 >>> 7;
        v3 += m5;
        v3 += v7;
        v15 ^= v3;
        v15 = v15 << (32 - 8) | v15 >>> 8;
        v11 += v15;
        v7 ^= v11;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v1 += m4;
        v1 += v5;
        v13 ^= v1;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v9 += v13;
        v5 ^= v9;
        v5 = v5 << (32 - 7) | v5 >>> 7;
        v0 += m2;
        v0 += v4;
        v12 ^= v0;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v8 += v12;
        v4 ^= v8;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v0 += m15;
        v0 += v5;
        v15 ^= v0;
        v15 = v15 << (32 - 16) | v15 >>> 16;
        v10 += v15;
        v5 ^= v10;
        v5 = v5 << (32 - 12) | v5 >>> 12;
        v1 += m9;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 16) | v12 >>> 16;
        v11 += v12;
        v6 ^= v11;
        v6 = v6 << (32 - 12) | v6 >>> 12;
        v2 += m3;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 16) | v13 >>> 16;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 12) | v7 >>> 12;
        v3 += m13;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 16) | v14 >>> 16;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 12) | v4 >>> 12;
        v2 += m12;
        v2 += v7;
        v13 ^= v2;
        v13 = v13 << (32 - 8) | v13 >>> 8;
        v8 += v13;
        v7 ^= v8;
        v7 = v7 << (32 - 7) | v7 >>> 7;
        v3 += m0;
        v3 += v4;
        v14 ^= v3;
        v14 = v14 << (32 - 8) | v14 >>> 8;
        v9 += v14;
        v4 ^= v9;
        v4 = v4 << (32 - 7) | v4 >>> 7;
        v1 += m14;
        v1 += v6;
        v12 ^= v1;
        v12 = v12 << (32 - 8) | v12 >>> 8;
        v11 += v12;
        v6 ^= v11;
        v6 = (v6 << (32 - 7)) | (v6 >>> 7);
        v0 += m11;
        v0 += v5;
        v15 ^= v0;
        v15 = (v15 << (32 - 8)) | (v15 >>> 8);
        v10 += v15;
        v5 ^= v10;
        v5 = (v5 << (32 - 7)) | (v5 >>> 7);

        this.h[0] ^= v0 ^ v8;
        this.h[1] ^= v1 ^ v9;
        this.h[2] ^= v2 ^ v10;
        this.h[3] ^= v3 ^ v11;
        this.h[4] ^= v4 ^ v12;
        this.h[5] ^= v5 ^ v13;
        this.h[6] ^= v6 ^ v14;
        this.h[7] ^= v7 ^ v15;
    };

    BLAKE2s.prototype.stringToUtf8Array = function (s) {
        var arr = [];
        for (var i = 0; i < s.length; i++) {
            var c = s.charCodeAt(i);
            if (c < 128) {
                arr.push(c);
            } else if (c > 127 && c < 2048) {
                arr.push((c >> 6) | 192);
                arr.push((c & 63) | 128);
            } else {
                arr.push((c >> 12) | 224);
                arr.push(((c >> 6) & 63) | 128);
                arr.push((c & 64) | 128);
            }
        }
        return arr;
    };

    BLAKE2s.prototype._update = function (p, offset, length) {
        if (typeof offset === "undefined") { offset = 0; }
        if (typeof length === "undefined") { length = p.length; }
        if (this.isFinished) {
            throw 'update() after calling digest()';
        }
        if (typeof p == 'string') {
            if (offset != 0) {
                throw 'offset not supported for strings';
            }
            p = this.stringToUtf8Array(p);
            length = p.length;
            offset = 0;
        } else if (typeof p != 'object') {
            throw 'unsupported object: string or array required';
        }
        if (length == 0) {
            return;
        }
        var left = 64 - this.nx;
        if (length > left) {
            for (var i = 0; i < left; i++) {
                this.x[this.nx + i] = p[offset + i];
            }
            this.processBlock(64);
            offset += left;
            length -= left;
            this.nx = 0;
        }
        while (length > 64) {
            for (var i = 0; i < 64; i++) {
                this.x[i] = p[offset + i];
            }
            this.processBlock(64);
            offset += 64;
            length -= 64;
            this.nx = 0;
        }
        for (var i = 0; i < length; i++) {
            this.x[this.nx + i] = p[offset + i];
        }
        this.nx += length;
    };

    BLAKE2s.prototype.update = function (buffer, enc) {
      if(enc)
        buffer = new Buffer(buffer, enc)
      this._update(buffer)
      return this
    }

    BLAKE2s.prototype.digest = function (enc) {
        if (this.isFinished) {
            return this.result;
        }

        for (var i = this.nx; i < 64; i++) {
            this.x[i] = 0;
        }

        // Set last block flag.
        this.f0 = 0xffffffff;

        //TODO in tree mode, set f1 to 0xffffffff.
        this.processBlock(this.nx);

        var out = new Buffer(32);
        for (var i = 0; i < 8; i++) {
            var h = this.h[i];
            out[i * 4 + 0] = (h >>> 0) & 0xff;
            out[i * 4 + 1] = (h >>> 8) & 0xff;
            out[i * 4 + 2] = (h >>> 16) & 0xff;
            out[i * 4 + 3] = (h >>> 24) & 0xff;
        }
        this.result = out.slice(0, this.digestLength);
        this.isFinished = true;
        return enc ? this.result.toString(enc) : this.result;
    };

    return BLAKE2s;
})();

if('undefined' === typeof module)
  window.Blake2s = BLAKE2s
else
  module.exports = BLAKE2s

},
"uiS7pqqXD1yZqgN/avrOI/OfYpp1iUKKoM1/SCx4A8s=":
function (require, module, exports, __dirname, __filename) {
'use strict'
var ready = require('./ready');

/**
  ### `sink(socket, opts?)`

  Create a pull-stream `Sink` that will write data to the `socket`.

  <<< examples/write.js

**/

var nextTick = typeof setImmediate !== 'undefined' ? setImmediate : process.nextTick

module.exports = function(socket, opts) {
  return function (read) {
    opts = opts || {}
    var closeOnEnd = opts.closeOnEnd !== false;
    var onClose = 'function' === typeof opts ? opts : opts.onClose;

    function next(end, data) {
      // if the stream has ended, simply return
      if (end) {
        if (closeOnEnd && socket.readyState <= 1) {
          if(onClose)
            socket.addEventListener('close', function (ev) {
              if(ev.wasClean || ev.code === 1006) onClose()
              else {
                var err = new Error('ws error')
                err.event = ev
                onClose(err)
              }
            });

          socket.close()
        }

        return;
      }

      // socket ready?
      ready(socket, function(end) {
        if (end) {
          return read(end === true ? true : end.error, function () {});
        }
        socket.send(data);
        nextTick(function() {
          read(null, next);
        });
      });
    }

    read(null, next);
  }
}

},
"umkKKpEGau7k61gQBI0wq42O3weWyfCzB1xBb1fTMqY=":
function (require, module, exports, __dirname, __filename) {
var AbstractLevelDOWN = require('abstract-leveldown').AbstractLevelDOWN
var inherits = require('inherits')
var DeferredIterator = require('./deferred-iterator')
var deferrables = 'put get del batch clear'.split(' ')
var optionalDeferrables = 'approximateSize compactRange'.split(' ')

function DeferredLevelDOWN (db) {
  AbstractLevelDOWN.call(this, db.supports || {})

  // TODO (future major): remove this fallback; db must have manifest that
  // declares approximateSize and compactRange in additionalMethods.
  optionalDeferrables.forEach(function (m) {
    if (typeof db[m] === 'function' && !this.supports.additionalMethods[m]) {
      this.supports.additionalMethods[m] = true
    }
  }, this)

  this._db = db
  this._operations = []
  closed(this)
}

inherits(DeferredLevelDOWN, AbstractLevelDOWN)

DeferredLevelDOWN.prototype.type = 'deferred-leveldown'

DeferredLevelDOWN.prototype._open = function (options, callback) {
  var self = this

  this._db.open(options, function (err) {
    if (err) return callback(err)

    self._operations.forEach(function (op) {
      if (op.iterator) {
        op.iterator.setDb(self._db)
      } else {
        self._db[op.method].apply(self._db, op.args)
      }
    })
    self._operations = []

    open(self)
    callback()
  })
}

DeferredLevelDOWN.prototype._close = function (callback) {
  var self = this

  this._db.close(function (err) {
    if (err) return callback(err)
    closed(self)
    callback()
  })
}

function open (self) {
  deferrables.concat('iterator').forEach(function (m) {
    self['_' + m] = function () {
      return this._db[m].apply(this._db, arguments)
    }
  })
  Object.keys(self.supports.additionalMethods).forEach(function (m) {
    self[m] = function () {
      return this._db[m].apply(this._db, arguments)
    }
  })
}

function closed (self) {
  deferrables.forEach(function (m) {
    self['_' + m] = function () {
      this._operations.push({ method: m, args: arguments })
    }
  })
  Object.keys(self.supports.additionalMethods).forEach(function (m) {
    self[m] = function () {
      this._operations.push({ method: m, args: arguments })
    }
  })
  self._iterator = function (options) {
    var it = new DeferredIterator(self, options)
    this._operations.push({ iterator: it })
    return it
  }
}

DeferredLevelDOWN.prototype._serializeKey = function (key) {
  return key
}

DeferredLevelDOWN.prototype._serializeValue = function (value) {
  return value
}

module.exports = DeferredLevelDOWN
module.exports.DeferredIterator = DeferredIterator

},
"unnOKzF5Ubb6CRwfvBY0tfhGPLN2FeveP9BOFVEdvNQ=":
function (require, module, exports, __dirname, __filename) {
var looper = require('looper')

module.exports = function (read) {
  var _abort, _cb
  var loop = looper(function () {
    read(_abort, _cb)
  })
  return function (abort, cb) {
    _abort = abort
    _cb = cb
    loop()
  }
}

},
"uwGJS8pFXXzEfElXaHKT7w+nQPxQ6a8TUVF+etZn0Ao=":
function (require, module, exports, __dirname, __filename) {
const {dirname} = require('path')
const {findMade, findMadeSync} = require('./find-made.js')
const {mkdirpManual, mkdirpManualSync} = require('./mkdirp-manual.js')

const mkdirpNative = (path, opts) => {
  opts.recursive = true
  const parent = dirname(path)
  if (parent === path)
    return opts.mkdirAsync(path, opts)

  return findMade(opts, path).then(made =>
    opts.mkdirAsync(path, opts).then(() => made)
    .catch(er => {
      if (er.code === 'ENOENT')
        return mkdirpManual(path, opts)
      else
        throw er
    }))
}

const mkdirpNativeSync = (path, opts) => {
  opts.recursive = true
  const parent = dirname(path)
  if (parent === path)
    return opts.mkdirSync(path, opts)

  const made = findMadeSync(opts, path)
  try {
    opts.mkdirSync(path, opts)
    return made
  } catch (er) {
    if (er.code === 'ENOENT')
      return mkdirpManualSync(path, opts)
    else
      throw er
  }
}

module.exports = {mkdirpNative, mkdirpNativeSync}

},
"uxR9z+4gBSzxWxqRy5/zeTtiI+77Mk8mXN9xGbEXEGk=":
function (require, module, exports, __dirname, __filename) {
"use strict";
/**
 * Module convert fs functions to promise based functions
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.readFile = exports.writeFileSync = exports.writeFile = exports.read = exports.open = exports.close = exports.stat = exports.createReadStream = exports.pathExists = void 0;
const fs = require("fs");
exports.pathExists = fs.existsSync;
exports.createReadStream = fs.createReadStream;
async function stat(path) {
    return new Promise((resolve, reject) => {
        fs.stat(path, (err, stats) => {
            if (err)
                reject(err);
            else
                resolve(stats);
        });
    });
}
exports.stat = stat;
async function close(fd) {
    return new Promise((resolve, reject) => {
        fs.close(fd, err => {
            if (err)
                reject(err);
            else
                resolve();
        });
    });
}
exports.close = close;
async function open(path, mode) {
    return new Promise((resolve, reject) => {
        fs.open(path, mode, (err, fd) => {
            if (err)
                reject(err);
            else
                resolve(fd);
        });
    });
}
exports.open = open;
async function read(fd, buffer, offset, length, position) {
    return new Promise((resolve, reject) => {
        fs.read(fd, buffer, offset, length, position, (err, bytesRead, _buffer) => {
            if (err)
                reject(err);
            else
                resolve({ bytesRead, buffer: _buffer });
        });
    });
}
exports.read = read;
async function writeFile(path, data) {
    return new Promise((resolve, reject) => {
        fs.writeFile(path, data, err => {
            if (err)
                reject(err);
            else
                resolve();
        });
    });
}
exports.writeFile = writeFile;
function writeFileSync(path, data) {
    fs.writeFileSync(path, data);
}
exports.writeFileSync = writeFileSync;
async function readFile(path) {
    return new Promise((resolve, reject) => {
        fs.readFile(path, (err, buffer) => {
            if (err)
                reject(err);
            else
                resolve(buffer);
        });
    });
}
exports.readFile = readFile;

},
"uzgPMr71/rGGePD0X4gHP+1degBpowkTLLIIDNVT1cc=":
function (require, module, exports, __dirname, __filename) {
try {
  var util = require('util');
  /* istanbul ignore next */
  if (typeof util.inherits !== 'function') throw '';
  module.exports = util.inherits;
} catch (e) {
  /* istanbul ignore next */
  module.exports = require('./inherits_browser.js');
}

},
"v1JJsvB84WMOaJeajnHp6rZ4y/7uHk4RMQQpWljccnM=":
function (require, module, exports, __dirname, __filename) {
module.exports = error

// error := (Error) => Continuable<void>
function error(err) {
    return function continuable(callback) {
        callback(err)
    }
}

},
"v4J0FVF4WmGxbPDZEqMP0dXbZqcjBIrdbvjPDIZGVlg=":
function (require, module, exports, __dirname, __filename) {
const util = require('util')
const AbstractIterator = require('abstract-leveldown').AbstractIterator
const binding = require('./binding')

function Iterator (db, options) {
  AbstractIterator.call(this, db)

  this.context = binding.iterator_init(db.context, options)
  this.cache = null
  this.finished = false
}

util.inherits(Iterator, AbstractIterator)

Iterator.prototype._seek = function (target) {
  if (target.length === 0) {
    throw new Error('cannot seek() to an empty target')
  }

  this.cache = null
  binding.iterator_seek(this.context, target)
  this.finished = false
}

Iterator.prototype._next = function (callback) {
  var that = this

  if (this.cache && this.cache.length) {
    process.nextTick(callback, null, this.cache.pop(), this.cache.pop())
  } else if (this.finished) {
    process.nextTick(callback)
  } else {
    binding.iterator_next(this.context, function (err, array, finished) {
      if (err) return callback(err)

      that.cache = array
      that.finished = finished
      that._next(callback)
    })
  }

  return this
}

Iterator.prototype._end = function (callback) {
  delete this.cache
  binding.iterator_end(this.context, callback)
}

module.exports = Iterator

},
"v4tcZrpwSGJnagS9urzPN03rp3UGiREWn5xfYhbbXUM=":
function (require, module, exports, __dirname, __filename) {
module.exports = function run(fn) {
  return (...args) =>
    new Promise(resolve => {
      fn(...args, (err, res) => resolve([err, res]));
    });
};

},
"v8QBy1kW50yvZsdyrwAo5hCAdx0uGV5haJuf+4/ronM=":
function (require, module, exports, __dirname, __filename) {
'use strict';

module.exports = async (fn, ...args) => {
    check(fn);
    
    try {
        return [null, await fn(...args)];
    } catch(e) {
        return [e];
    }
};

function check(fn) {
    if (typeof fn !== 'function')
        throw Error('fn should be a function!');
}


},
"vHm/pcwRyBehzxEtphC1pDh+OUrUB4NLdjVQ02UJToY=":
function (require, module, exports, __dirname, __filename) {

var pushable = require('pull-pushable')

module.exports = function () {
  var listeners = []
  var closed = false

  function notify (message) {
    // notify by pushing to all listeners
    for (var i = 0; i < listeners.length; i++) {
      if (closed) return message
      listeners[i].push(message)
    }
    return message
  }

  notify.listen = function () {
    // create listener with `onClose` handler
    var listener = pushable()
    listeners.push(listener)
    return listener
  }

  notify.abort = function (err) {
    // abort by ending all listeners
    closed = true
    while (listeners.length) listeners.shift().end(err)
  }

  notify.end = function () {
    return notify.abort(true)
  }

  return notify
}

},
"vHqmQ8fMMsT4AexObfLXsD7uE3ZeB4tGqJUC+NWK7Sk=":
function (require, module, exports, __dirname, __filename) {
"use strict";
module.exports = [
    require('./plugin-tunnel'),
    require('./plugin-room-client'),
    require('./plugin-room'),
];

},
"vJ76/FgQ+IqOSfnX3bm9Dg8+HblwxfflyX7SWhNHpWY=":
function (require, module, exports, __dirname, __filename) {
var looper = require('looper')

var window = module.exports = function (init, start) {
return function (read) {
  start = start || function (start, data) {
    return {start: start, data: data}
  }
  var windows = [], output = [], ended = null
  var data, end
  var j = 0

  return function (abort, cb) {
    if(output.length)
      return cb(null, output.shift())
    if(ended)
      return cb(ended)
    var i = 0
    var k = j ++
    read(abort, looper(function (end, data) {
      var next = this
      var reduce, update, once = false
      if(end)
        ended = end

      function _update (end, _data) {
        if(once) return
        once = true
        delete windows[windows.indexOf(update)]
        output.push(start(data, _data))
      }

      if(!ended)
        update = init(data, _update)

      if(update)
        windows.push(update)
      else
        //don't allow data unless a window started here!
        once = true

      windows.forEach(function (update, i) {
        update(end, data)
      })

      if(output.length)
        return cb(null, output.shift())
      else if(ended)
        return cb(ended)
      else
        read(null, next)

  }))
  }
}}

window.recent = function (size, time) {
  var current = null
  return window(function (data, cb) {
    if(current) return
    current = []
    var timer
      
    function done () {
      var _current = current
      current = null
      clearTimeout(timer)
      cb(null, _current)
    }

    if(time)
      timer = setTimeout(done, time)

    return function (end, data) {
      if(end) return done()
      current.push(data)
      if(size != null && current.length >= size)
        done()
    }
  }, function (_, data) {
    return data
  })
}

window.sliding = function (reduce, width) {
  width = width || 10
  var k = 0
  return window(function (data, cb) {
    var acc
    var i = 0
    var l = k++
    return function (end, data) {
      if(end) return
      acc = reduce(acc, data)
      if(width <= ++ i)
        cb(null, acc)
    }
  })
}


},
"vWGPEPruisJL6vrBmo/JgkQSHMKXhCHdSGs4HmDoNbM=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const { deferred } = require('jitdb/operators')

module.exports = function mentions(key) {
  return deferred((meta, cb) => {
    meta.db.onDrain('fullMentions', () => {
      meta.db.getIndex('fullMentions').getMessagesByMention(key, meta.live, cb)
    })
  })
}

},
"vXr06kAjV1uxhCmbeWEi2J2oQtJSPqHkTD6Vf5NMgus=":
function (require, module, exports, __dirname, __filename) {

var Decode = require('string_decoder').StringDecoder

module.exports = function (enc) {
  var decoder = new Decode(enc), ended
  return function (read) {
    return function (abort, cb) {
      if(ended) return cb(ended)
      read(abort, function (end, data) {
        ended = end
        if(true === end) {
          if(data = decoder.end()) cb(null, data)
          else                     cb(true)
        }
        else if(end && (true !== end))
          cb(end)
        else
          cb(null, decoder.write(data))
      })
    }
  }
}

},
"vbdI62o94a9x5thTSnOwtqgzR/r+J89nsb8aKGRU/zw=":
function (require, module, exports, __dirname, __filename) {
const util = require('util')
const AbstractChainedBatch = require('abstract-leveldown').AbstractChainedBatch
const binding = require('./binding')

function ChainedBatch (db) {
  AbstractChainedBatch.call(this, db)
  this.context = binding.batch_init(db.context)
}

ChainedBatch.prototype._put = function (key, value) {
  binding.batch_put(this.context, key, value)
}

ChainedBatch.prototype._del = function (key) {
  binding.batch_del(this.context, key)
}

ChainedBatch.prototype._clear = function () {
  binding.batch_clear(this.context)
}

ChainedBatch.prototype._write = function (options, callback) {
  binding.batch_write(this.context, options, callback)
}

util.inherits(ChainedBatch, AbstractChainedBatch)

module.exports = ChainedBatch

},
"vezOi3+97in0OUM1iocZ1iMnRo0fKLIffm1VHVAkOCg=":
function (require, module, exports, __dirname, __filename) {
'use strict'; // undocumented cb() API, needed for core, not for public API

function destroy(err, cb) {
  var _this = this;

  var readableDestroyed = this._readableState && this._readableState.destroyed;
  var writableDestroyed = this._writableState && this._writableState.destroyed;

  if (readableDestroyed || writableDestroyed) {
    if (cb) {
      cb(err);
    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {
      process.nextTick(emitErrorNT, this, err);
    }

    return this;
  } // we set destroyed to true before firing error callbacks in order
  // to make it re-entrance safe in case destroy() is called within callbacks


  if (this._readableState) {
    this._readableState.destroyed = true;
  } // if this is a duplex stream mark the writable part as destroyed as well


  if (this._writableState) {
    this._writableState.destroyed = true;
  }

  this._destroy(err || null, function (err) {
    if (!cb && err) {
      process.nextTick(emitErrorAndCloseNT, _this, err);

      if (_this._writableState) {
        _this._writableState.errorEmitted = true;
      }
    } else if (cb) {
      process.nextTick(emitCloseNT, _this);
      cb(err);
    } else {
      process.nextTick(emitCloseNT, _this);
    }
  });

  return this;
}

function emitErrorAndCloseNT(self, err) {
  emitErrorNT(self, err);
  emitCloseNT(self);
}

function emitCloseNT(self) {
  if (self._writableState && !self._writableState.emitClose) return;
  if (self._readableState && !self._readableState.emitClose) return;
  self.emit('close');
}

function undestroy() {
  if (this._readableState) {
    this._readableState.destroyed = false;
    this._readableState.reading = false;
    this._readableState.ended = false;
    this._readableState.endEmitted = false;
  }

  if (this._writableState) {
    this._writableState.destroyed = false;
    this._writableState.ended = false;
    this._writableState.ending = false;
    this._writableState.finalCalled = false;
    this._writableState.prefinished = false;
    this._writableState.finished = false;
    this._writableState.errorEmitted = false;
  }
}

function emitErrorNT(self, err) {
  self.emit('error', err);
}

module.exports = {
  destroy: destroy,
  undestroy: undestroy
};
},
"vh1sso/6T5hxzkJ4j7B953lMLenDDUF3uPJQTTQXVMA=":
function (require, module, exports, __dirname, __filename) {
'use strict'

function id (e) { return e }
var prop = require('../util/prop')
var drain = require('./drain')

module.exports = function find (test, cb) {
  var ended = false
  if(!cb)
    cb = test, test = id
  else
    test = prop(test) || id

  return drain(function (data) {
    if(test(data)) {
      ended = true
      cb(null, data)
    return false
    }
  }, function (err) {
    if(ended) return //already called back
    cb(err === true ? null : err, null)
  })
}





},
"vrzqLIyoiY9n8Ux8m/+gpkaGs3T2/2ixQlvSfT+BXYQ=":
function (require, module, exports, __dirname, __filename) {
var ip = require('non-private-ip')

module.exports = {
  host: function(scope) {
    var f = {
      device: function () {return 'localhost'},
      local: ip.private,
      private: ip.private,
      public: ip
    }[scope]
    if (!f) throw new Error('invalid scope: ' + scope)
    return f()
  }
}

},
"vu5k+583N6JkAv3Qh2k5aHhsEis/lIiDj57B09nXFuw=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const pull = require('pull-stream');
module.exports = {
    name: 'room',
    version: '1.0.0',
    manifest: {
        registerAlias: 'async',
        revokeAlias: 'async',
        metadata: 'async',
        attendants: 'source',
    },
    init() {
        return {
            registerAlias(_alias, _sig, cb) {
                cb(new Error('not implemented on the client'));
            },
            revokeAlias(_alias, cb) {
                cb(new Error('not implemented on the client'));
            },
            metadata(cb) {
                cb(new Error('not implemented on the client'));
            },
            attendants() {
                return pull.error(new Error('not implemented on the client'));
            },
        };
    },
};

},
"w6X69DnJuxqXA5+vnqOFa6YQtgcc1FPf+aHhW7MjSmE=":
function (require, module, exports, __dirname, __filename) {
'use strict'
module.exports = require('./protocol')(require('./crypto'))

},
"w79prpAb+6NCPSE7aITlZyMi4X1+tQXmILfQfh0AXvU=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (since, getMeta) {
  return function (cursor, live, reverse, format, test, cache) {
    if(!format)
      format = function (_, value) { return value }

    return function (abort, cb) {
      if(abort) return cb(abort)

      if(test && cursor != null && !test(cursor))
        return cb(true)

      since.once(function (_offset) {
        if(cursor == null)
          cursor = _offset

        if(cursor < 0 && reverse)
          cb(true)
        else if(cursor <= _offset)
          next()
        else if(live)
          since.once(next, false)
        else
          cb(true) //end of the stream

        function next () {
          getMeta(cursor, cache, function (err, value, prev, next) {
            //this should also handle ended state.
            if(err) return cb(err)
            var _cursor = cursor
            cursor = reverse ? prev : next
            cb(null, format(_cursor, value))
          })
        }
      })
    }
  }
}


},
"w9J85IsmhUO/SCkzmKVEl6BaPW1P/Asp3WBG+DrBvYE=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.isBlogMsg = exports.isPublic = exports.isPrivate = exports.isVoteMsg = exports.isContactMsg = exports.isAboutMsg = exports.isReplyPostMsg = exports.isRootPostMsg = exports.isPostMsg = exports.isIndirectReplyMsgToRoot = exports.isReplyMsgToRoot = exports.isRootMsg = exports.isMsg = void 0;
function isMsg(msg) {
    return msg && msg.key && msg.value && typeof msg.value === 'object';
}
exports.isMsg = isMsg;
function isRootMsg(msg) {
    var _a, _b;
    return !((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.root);
}
exports.isRootMsg = isRootMsg;
function isReplyMsgToRoot(rootKey) {
    return function (msg) { var _a, _b; return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.root) === rootKey; };
}
exports.isReplyMsgToRoot = isReplyMsgToRoot;
function isIndirectReplyMsgToRoot(rootKey) {
    return function (msg) {
        var _a, _b, _c, _d, _e, _f;
        return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.root) === rootKey ||
            ((_d = (_c = msg === null || msg === void 0 ? void 0 : msg.value) === null || _c === void 0 ? void 0 : _c.content) === null || _d === void 0 ? void 0 : _d.branch) === rootKey ||
            ((_f = (_e = msg === null || msg === void 0 ? void 0 : msg.value) === null || _e === void 0 ? void 0 : _e.content) === null || _f === void 0 ? void 0 : _f.fork) === rootKey;
    };
}
exports.isIndirectReplyMsgToRoot = isIndirectReplyMsgToRoot;
function isPostMsg(msg) {
    var _a, _b;
    return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) === 'post';
}
exports.isPostMsg = isPostMsg;
function isRootPostMsg(msg) {
    var _a, _b;
    return isPostMsg(msg) && !((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.root);
}
exports.isRootPostMsg = isRootPostMsg;
function isReplyPostMsg(msg) {
    var _a, _b;
    return isPostMsg(msg) && !!((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.root);
}
exports.isReplyPostMsg = isReplyPostMsg;
function isAboutMsg(msg) {
    var _a, _b;
    return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) === 'about';
}
exports.isAboutMsg = isAboutMsg;
function isContactMsg(msg) {
    var _a, _b;
    return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) === 'contact';
}
exports.isContactMsg = isContactMsg;
function isVoteMsg(msg) {
    var _a, _b;
    return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) === 'vote';
}
exports.isVoteMsg = isVoteMsg;
function isPrivate(msg) {
    var _a, _b, _c;
    if ((_a = msg.meta) === null || _a === void 0 ? void 0 : _a.private)
        return true;
    if (msg.value.private)
        return true;
    if (Array.isArray((_b = msg.value.content) === null || _b === void 0 ? void 0 : _b.recps))
        return true;
    return typeof ((_c = msg === null || msg === void 0 ? void 0 : msg.value) === null || _c === void 0 ? void 0 : _c.content) === 'string';
}
exports.isPrivate = isPrivate;
function isPublic(msg) {
    var _a, _b, _c;
    if ((_a = msg.meta) === null || _a === void 0 ? void 0 : _a.private)
        return false;
    if (msg.value.private)
        return false;
    if (Array.isArray((_b = msg.value.content) === null || _b === void 0 ? void 0 : _b.recps))
        return false;
    return typeof ((_c = msg === null || msg === void 0 ? void 0 : msg.value) === null || _c === void 0 ? void 0 : _c.content) !== 'string';
}
exports.isPublic = isPublic;
function isBlogMsg(msg) {
    var _a, _b;
    return ((_b = (_a = msg === null || msg === void 0 ? void 0 : msg.value) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.type) === 'blog';
}
exports.isBlogMsg = isBlogMsg;
//# sourceMappingURL=utils.js.map
},
"w9l2Bit3C0qIyR0kRVe76agotV3C3h+ayFwtXpCTicQ=":
function (require, module, exports, __dirname, __filename) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a duplex stream is just a stream that is both readable and writable.
// Since JS doesn't have multiple prototypal inheritance, this class
// prototypally inherits from Readable, and then parasitically from
// Writable.
'use strict';
/*<replacement>*/

var objectKeys = Object.keys || function (obj) {
  var keys = [];

  for (var key in obj) {
    keys.push(key);
  }

  return keys;
};
/*</replacement>*/


module.exports = Duplex;

var Readable = require('./_stream_readable');

var Writable = require('./_stream_writable');

require('inherits')(Duplex, Readable);

{
  // Allow the keys array to be GC'ed.
  var keys = objectKeys(Writable.prototype);

  for (var v = 0; v < keys.length; v++) {
    var method = keys[v];
    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];
  }
}

function Duplex(options) {
  if (!(this instanceof Duplex)) return new Duplex(options);
  Readable.call(this, options);
  Writable.call(this, options);
  this.allowHalfOpen = true;

  if (options) {
    if (options.readable === false) this.readable = false;
    if (options.writable === false) this.writable = false;

    if (options.allowHalfOpen === false) {
      this.allowHalfOpen = false;
      this.once('end', onend);
    }
  }
}

Object.defineProperty(Duplex.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.highWaterMark;
  }
});
Object.defineProperty(Duplex.prototype, 'writableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState && this._writableState.getBuffer();
  }
});
Object.defineProperty(Duplex.prototype, 'writableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.length;
  }
}); // the no-half-open enforcer

function onend() {
  // If the writable side ended, then we're ok.
  if (this._writableState.ended) return; // no more data can be written.
  // But allow more writes to happen in this tick.

  process.nextTick(onEndNT, this);
}

function onEndNT(self) {
  self.end();
}

Object.defineProperty(Duplex.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._readableState === undefined || this._writableState === undefined) {
      return false;
    }

    return this._readableState.destroyed && this._writableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (this._readableState === undefined || this._writableState === undefined) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._readableState.destroyed = value;
    this._writableState.destroyed = value;
  }
});
},
"wCjG5RX/lhZqNW+n+TXsJsVIyG5nX7hngZgg5ESu9Go=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('level-packager')(require('leveldown'))

},
"wD+3NzhAZwc5cdGOekVNfAL4ET9/i2BIUS2AA3XmUhM=":
function (require, module, exports, __dirname, __filename) {
module.exports = [
    "的",
    "一",
    "是",
    "在",
    "不",
    "了",
    "有",
    "和",
    "人",
    "這",
    "中",
    "大",
    "為",
    "上",
    "個",
    "國",
    "我",
    "以",
    "要",
    "他",
    "時",
    "來",
    "用",
    "們",
    "生",
    "到",
    "作",
    "地",
    "於",
    "出",
    "就",
    "分",
    "對",
    "成",
    "會",
    "可",
    "主",
    "發",
    "年",
    "動",
    "同",
    "工",
    "也",
    "能",
    "下",
    "過",
    "子",
    "說",
    "產",
    "種",
    "面",
    "而",
    "方",
    "後",
    "多",
    "定",
    "行",
    "學",
    "法",
    "所",
    "民",
    "得",
    "經",
    "十",
    "三",
    "之",
    "進",
    "著",
    "等",
    "部",
    "度",
    "家",
    "電",
    "力",
    "裡",
    "如",
    "水",
    "化",
    "高",
    "自",
    "二",
    "理",
    "起",
    "小",
    "物",
    "現",
    "實",
    "加",
    "量",
    "都",
    "兩",
    "體",
    "制",
    "機",
    "當",
    "使",
    "點",
    "從",
    "業",
    "本",
    "去",
    "把",
    "性",
    "好",
    "應",
    "開",
    "它",
    "合",
    "還",
    "因",
    "由",
    "其",
    "些",
    "然",
    "前",
    "外",
    "天",
    "政",
    "四",
    "日",
    "那",
    "社",
    "義",
    "事",
    "平",
    "形",
    "相",
    "全",
    "表",
    "間",
    "樣",
    "與",
    "關",
    "各",
    "重",
    "新",
    "線",
    "內",
    "數",
    "正",
    "心",
    "反",
    "你",
    "明",
    "看",
    "原",
    "又",
    "麼",
    "利",
    "比",
    "或",
    "但",
    "質",
    "氣",
    "第",
    "向",
    "道",
    "命",
    "此",
    "變",
    "條",
    "只",
    "沒",
    "結",
    "解",
    "問",
    "意",
    "建",
    "月",
    "公",
    "無",
    "系",
    "軍",
    "很",
    "情",
    "者",
    "最",
    "立",
    "代",
    "想",
    "已",
    "通",
    "並",
    "提",
    "直",
    "題",
    "黨",
    "程",
    "展",
    "五",
    "果",
    "料",
    "象",
    "員",
    "革",
    "位",
    "入",
    "常",
    "文",
    "總",
    "次",
    "品",
    "式",
    "活",
    "設",
    "及",
    "管",
    "特",
    "件",
    "長",
    "求",
    "老",
    "頭",
    "基",
    "資",
    "邊",
    "流",
    "路",
    "級",
    "少",
    "圖",
    "山",
    "統",
    "接",
    "知",
    "較",
    "將",
    "組",
    "見",
    "計",
    "別",
    "她",
    "手",
    "角",
    "期",
    "根",
    "論",
    "運",
    "農",
    "指",
    "幾",
    "九",
    "區",
    "強",
    "放",
    "決",
    "西",
    "被",
    "幹",
    "做",
    "必",
    "戰",
    "先",
    "回",
    "則",
    "任",
    "取",
    "據",
    "處",
    "隊",
    "南",
    "給",
    "色",
    "光",
    "門",
    "即",
    "保",
    "治",
    "北",
    "造",
    "百",
    "規",
    "熱",
    "領",
    "七",
    "海",
    "口",
    "東",
    "導",
    "器",
    "壓",
    "志",
    "世",
    "金",
    "增",
    "爭",
    "濟",
    "階",
    "油",
    "思",
    "術",
    "極",
    "交",
    "受",
    "聯",
    "什",
    "認",
    "六",
    "共",
    "權",
    "收",
    "證",
    "改",
    "清",
    "美",
    "再",
    "採",
    "轉",
    "更",
    "單",
    "風",
    "切",
    "打",
    "白",
    "教",
    "速",
    "花",
    "帶",
    "安",
    "場",
    "身",
    "車",
    "例",
    "真",
    "務",
    "具",
    "萬",
    "每",
    "目",
    "至",
    "達",
    "走",
    "積",
    "示",
    "議",
    "聲",
    "報",
    "鬥",
    "完",
    "類",
    "八",
    "離",
    "華",
    "名",
    "確",
    "才",
    "科",
    "張",
    "信",
    "馬",
    "節",
    "話",
    "米",
    "整",
    "空",
    "元",
    "況",
    "今",
    "集",
    "溫",
    "傳",
    "土",
    "許",
    "步",
    "群",
    "廣",
    "石",
    "記",
    "需",
    "段",
    "研",
    "界",
    "拉",
    "林",
    "律",
    "叫",
    "且",
    "究",
    "觀",
    "越",
    "織",
    "裝",
    "影",
    "算",
    "低",
    "持",
    "音",
    "眾",
    "書",
    "布",
    "复",
    "容",
    "兒",
    "須",
    "際",
    "商",
    "非",
    "驗",
    "連",
    "斷",
    "深",
    "難",
    "近",
    "礦",
    "千",
    "週",
    "委",
    "素",
    "技",
    "備",
    "半",
    "辦",
    "青",
    "省",
    "列",
    "習",
    "響",
    "約",
    "支",
    "般",
    "史",
    "感",
    "勞",
    "便",
    "團",
    "往",
    "酸",
    "歷",
    "市",
    "克",
    "何",
    "除",
    "消",
    "構",
    "府",
    "稱",
    "太",
    "準",
    "精",
    "值",
    "號",
    "率",
    "族",
    "維",
    "劃",
    "選",
    "標",
    "寫",
    "存",
    "候",
    "毛",
    "親",
    "快",
    "效",
    "斯",
    "院",
    "查",
    "江",
    "型",
    "眼",
    "王",
    "按",
    "格",
    "養",
    "易",
    "置",
    "派",
    "層",
    "片",
    "始",
    "卻",
    "專",
    "狀",
    "育",
    "廠",
    "京",
    "識",
    "適",
    "屬",
    "圓",
    "包",
    "火",
    "住",
    "調",
    "滿",
    "縣",
    "局",
    "照",
    "參",
    "紅",
    "細",
    "引",
    "聽",
    "該",
    "鐵",
    "價",
    "嚴",
    "首",
    "底",
    "液",
    "官",
    "德",
    "隨",
    "病",
    "蘇",
    "失",
    "爾",
    "死",
    "講",
    "配",
    "女",
    "黃",
    "推",
    "顯",
    "談",
    "罪",
    "神",
    "藝",
    "呢",
    "席",
    "含",
    "企",
    "望",
    "密",
    "批",
    "營",
    "項",
    "防",
    "舉",
    "球",
    "英",
    "氧",
    "勢",
    "告",
    "李",
    "台",
    "落",
    "木",
    "幫",
    "輪",
    "破",
    "亞",
    "師",
    "圍",
    "注",
    "遠",
    "字",
    "材",
    "排",
    "供",
    "河",
    "態",
    "封",
    "另",
    "施",
    "減",
    "樹",
    "溶",
    "怎",
    "止",
    "案",
    "言",
    "士",
    "均",
    "武",
    "固",
    "葉",
    "魚",
    "波",
    "視",
    "僅",
    "費",
    "緊",
    "愛",
    "左",
    "章",
    "早",
    "朝",
    "害",
    "續",
    "輕",
    "服",
    "試",
    "食",
    "充",
    "兵",
    "源",
    "判",
    "護",
    "司",
    "足",
    "某",
    "練",
    "差",
    "致",
    "板",
    "田",
    "降",
    "黑",
    "犯",
    "負",
    "擊",
    "范",
    "繼",
    "興",
    "似",
    "餘",
    "堅",
    "曲",
    "輸",
    "修",
    "故",
    "城",
    "夫",
    "夠",
    "送",
    "筆",
    "船",
    "佔",
    "右",
    "財",
    "吃",
    "富",
    "春",
    "職",
    "覺",
    "漢",
    "畫",
    "功",
    "巴",
    "跟",
    "雖",
    "雜",
    "飛",
    "檢",
    "吸",
    "助",
    "昇",
    "陽",
    "互",
    "初",
    "創",
    "抗",
    "考",
    "投",
    "壞",
    "策",
    "古",
    "徑",
    "換",
    "未",
    "跑",
    "留",
    "鋼",
    "曾",
    "端",
    "責",
    "站",
    "簡",
    "述",
    "錢",
    "副",
    "盡",
    "帝",
    "射",
    "草",
    "衝",
    "承",
    "獨",
    "令",
    "限",
    "阿",
    "宣",
    "環",
    "雙",
    "請",
    "超",
    "微",
    "讓",
    "控",
    "州",
    "良",
    "軸",
    "找",
    "否",
    "紀",
    "益",
    "依",
    "優",
    "頂",
    "礎",
    "載",
    "倒",
    "房",
    "突",
    "坐",
    "粉",
    "敵",
    "略",
    "客",
    "袁",
    "冷",
    "勝",
    "絕",
    "析",
    "塊",
    "劑",
    "測",
    "絲",
    "協",
    "訴",
    "念",
    "陳",
    "仍",
    "羅",
    "鹽",
    "友",
    "洋",
    "錯",
    "苦",
    "夜",
    "刑",
    "移",
    "頻",
    "逐",
    "靠",
    "混",
    "母",
    "短",
    "皮",
    "終",
    "聚",
    "汽",
    "村",
    "雲",
    "哪",
    "既",
    "距",
    "衛",
    "停",
    "烈",
    "央",
    "察",
    "燒",
    "迅",
    "境",
    "若",
    "印",
    "洲",
    "刻",
    "括",
    "激",
    "孔",
    "搞",
    "甚",
    "室",
    "待",
    "核",
    "校",
    "散",
    "侵",
    "吧",
    "甲",
    "遊",
    "久",
    "菜",
    "味",
    "舊",
    "模",
    "湖",
    "貨",
    "損",
    "預",
    "阻",
    "毫",
    "普",
    "穩",
    "乙",
    "媽",
    "植",
    "息",
    "擴",
    "銀",
    "語",
    "揮",
    "酒",
    "守",
    "拿",
    "序",
    "紙",
    "醫",
    "缺",
    "雨",
    "嗎",
    "針",
    "劉",
    "啊",
    "急",
    "唱",
    "誤",
    "訓",
    "願",
    "審",
    "附",
    "獲",
    "茶",
    "鮮",
    "糧",
    "斤",
    "孩",
    "脫",
    "硫",
    "肥",
    "善",
    "龍",
    "演",
    "父",
    "漸",
    "血",
    "歡",
    "械",
    "掌",
    "歌",
    "沙",
    "剛",
    "攻",
    "謂",
    "盾",
    "討",
    "晚",
    "粒",
    "亂",
    "燃",
    "矛",
    "乎",
    "殺",
    "藥",
    "寧",
    "魯",
    "貴",
    "鐘",
    "煤",
    "讀",
    "班",
    "伯",
    "香",
    "介",
    "迫",
    "句",
    "豐",
    "培",
    "握",
    "蘭",
    "擔",
    "弦",
    "蛋",
    "沉",
    "假",
    "穿",
    "執",
    "答",
    "樂",
    "誰",
    "順",
    "煙",
    "縮",
    "徵",
    "臉",
    "喜",
    "松",
    "腳",
    "困",
    "異",
    "免",
    "背",
    "星",
    "福",
    "買",
    "染",
    "井",
    "概",
    "慢",
    "怕",
    "磁",
    "倍",
    "祖",
    "皇",
    "促",
    "靜",
    "補",
    "評",
    "翻",
    "肉",
    "踐",
    "尼",
    "衣",
    "寬",
    "揚",
    "棉",
    "希",
    "傷",
    "操",
    "垂",
    "秋",
    "宜",
    "氫",
    "套",
    "督",
    "振",
    "架",
    "亮",
    "末",
    "憲",
    "慶",
    "編",
    "牛",
    "觸",
    "映",
    "雷",
    "銷",
    "詩",
    "座",
    "居",
    "抓",
    "裂",
    "胞",
    "呼",
    "娘",
    "景",
    "威",
    "綠",
    "晶",
    "厚",
    "盟",
    "衡",
    "雞",
    "孫",
    "延",
    "危",
    "膠",
    "屋",
    "鄉",
    "臨",
    "陸",
    "顧",
    "掉",
    "呀",
    "燈",
    "歲",
    "措",
    "束",
    "耐",
    "劇",
    "玉",
    "趙",
    "跳",
    "哥",
    "季",
    "課",
    "凱",
    "胡",
    "額",
    "款",
    "紹",
    "卷",
    "齊",
    "偉",
    "蒸",
    "殖",
    "永",
    "宗",
    "苗",
    "川",
    "爐",
    "岩",
    "弱",
    "零",
    "楊",
    "奏",
    "沿",
    "露",
    "桿",
    "探",
    "滑",
    "鎮",
    "飯",
    "濃",
    "航",
    "懷",
    "趕",
    "庫",
    "奪",
    "伊",
    "靈",
    "稅",
    "途",
    "滅",
    "賽",
    "歸",
    "召",
    "鼓",
    "播",
    "盤",
    "裁",
    "險",
    "康",
    "唯",
    "錄",
    "菌",
    "純",
    "借",
    "糖",
    "蓋",
    "橫",
    "符",
    "私",
    "努",
    "堂",
    "域",
    "槍",
    "潤",
    "幅",
    "哈",
    "竟",
    "熟",
    "蟲",
    "澤",
    "腦",
    "壤",
    "碳",
    "歐",
    "遍",
    "側",
    "寨",
    "敢",
    "徹",
    "慮",
    "斜",
    "薄",
    "庭",
    "納",
    "彈",
    "飼",
    "伸",
    "折",
    "麥",
    "濕",
    "暗",
    "荷",
    "瓦",
    "塞",
    "床",
    "築",
    "惡",
    "戶",
    "訪",
    "塔",
    "奇",
    "透",
    "梁",
    "刀",
    "旋",
    "跡",
    "卡",
    "氯",
    "遇",
    "份",
    "毒",
    "泥",
    "退",
    "洗",
    "擺",
    "灰",
    "彩",
    "賣",
    "耗",
    "夏",
    "擇",
    "忙",
    "銅",
    "獻",
    "硬",
    "予",
    "繁",
    "圈",
    "雪",
    "函",
    "亦",
    "抽",
    "篇",
    "陣",
    "陰",
    "丁",
    "尺",
    "追",
    "堆",
    "雄",
    "迎",
    "泛",
    "爸",
    "樓",
    "避",
    "謀",
    "噸",
    "野",
    "豬",
    "旗",
    "累",
    "偏",
    "典",
    "館",
    "索",
    "秦",
    "脂",
    "潮",
    "爺",
    "豆",
    "忽",
    "托",
    "驚",
    "塑",
    "遺",
    "愈",
    "朱",
    "替",
    "纖",
    "粗",
    "傾",
    "尚",
    "痛",
    "楚",
    "謝",
    "奮",
    "購",
    "磨",
    "君",
    "池",
    "旁",
    "碎",
    "骨",
    "監",
    "捕",
    "弟",
    "暴",
    "割",
    "貫",
    "殊",
    "釋",
    "詞",
    "亡",
    "壁",
    "頓",
    "寶",
    "午",
    "塵",
    "聞",
    "揭",
    "炮",
    "殘",
    "冬",
    "橋",
    "婦",
    "警",
    "綜",
    "招",
    "吳",
    "付",
    "浮",
    "遭",
    "徐",
    "您",
    "搖",
    "谷",
    "贊",
    "箱",
    "隔",
    "訂",
    "男",
    "吹",
    "園",
    "紛",
    "唐",
    "敗",
    "宋",
    "玻",
    "巨",
    "耕",
    "坦",
    "榮",
    "閉",
    "灣",
    "鍵",
    "凡",
    "駐",
    "鍋",
    "救",
    "恩",
    "剝",
    "凝",
    "鹼",
    "齒",
    "截",
    "煉",
    "麻",
    "紡",
    "禁",
    "廢",
    "盛",
    "版",
    "緩",
    "淨",
    "睛",
    "昌",
    "婚",
    "涉",
    "筒",
    "嘴",
    "插",
    "岸",
    "朗",
    "莊",
    "街",
    "藏",
    "姑",
    "貿",
    "腐",
    "奴",
    "啦",
    "慣",
    "乘",
    "夥",
    "恢",
    "勻",
    "紗",
    "扎",
    "辯",
    "耳",
    "彪",
    "臣",
    "億",
    "璃",
    "抵",
    "脈",
    "秀",
    "薩",
    "俄",
    "網",
    "舞",
    "店",
    "噴",
    "縱",
    "寸",
    "汗",
    "掛",
    "洪",
    "賀",
    "閃",
    "柬",
    "爆",
    "烯",
    "津",
    "稻",
    "牆",
    "軟",
    "勇",
    "像",
    "滾",
    "厘",
    "蒙",
    "芳",
    "肯",
    "坡",
    "柱",
    "盪",
    "腿",
    "儀",
    "旅",
    "尾",
    "軋",
    "冰",
    "貢",
    "登",
    "黎",
    "削",
    "鑽",
    "勒",
    "逃",
    "障",
    "氨",
    "郭",
    "峰",
    "幣",
    "港",
    "伏",
    "軌",
    "畝",
    "畢",
    "擦",
    "莫",
    "刺",
    "浪",
    "秘",
    "援",
    "株",
    "健",
    "售",
    "股",
    "島",
    "甘",
    "泡",
    "睡",
    "童",
    "鑄",
    "湯",
    "閥",
    "休",
    "匯",
    "舍",
    "牧",
    "繞",
    "炸",
    "哲",
    "磷",
    "績",
    "朋",
    "淡",
    "尖",
    "啟",
    "陷",
    "柴",
    "呈",
    "徒",
    "顏",
    "淚",
    "稍",
    "忘",
    "泵",
    "藍",
    "拖",
    "洞",
    "授",
    "鏡",
    "辛",
    "壯",
    "鋒",
    "貧",
    "虛",
    "彎",
    "摩",
    "泰",
    "幼",
    "廷",
    "尊",
    "窗",
    "綱",
    "弄",
    "隸",
    "疑",
    "氏",
    "宮",
    "姐",
    "震",
    "瑞",
    "怪",
    "尤",
    "琴",
    "循",
    "描",
    "膜",
    "違",
    "夾",
    "腰",
    "緣",
    "珠",
    "窮",
    "森",
    "枝",
    "竹",
    "溝",
    "催",
    "繩",
    "憶",
    "邦",
    "剩",
    "幸",
    "漿",
    "欄",
    "擁",
    "牙",
    "貯",
    "禮",
    "濾",
    "鈉",
    "紋",
    "罷",
    "拍",
    "咱",
    "喊",
    "袖",
    "埃",
    "勤",
    "罰",
    "焦",
    "潛",
    "伍",
    "墨",
    "欲",
    "縫",
    "姓",
    "刊",
    "飽",
    "仿",
    "獎",
    "鋁",
    "鬼",
    "麗",
    "跨",
    "默",
    "挖",
    "鏈",
    "掃",
    "喝",
    "袋",
    "炭",
    "污",
    "幕",
    "諸",
    "弧",
    "勵",
    "梅",
    "奶",
    "潔",
    "災",
    "舟",
    "鑑",
    "苯",
    "訟",
    "抱",
    "毀",
    "懂",
    "寒",
    "智",
    "埔",
    "寄",
    "屆",
    "躍",
    "渡",
    "挑",
    "丹",
    "艱",
    "貝",
    "碰",
    "拔",
    "爹",
    "戴",
    "碼",
    "夢",
    "芽",
    "熔",
    "赤",
    "漁",
    "哭",
    "敬",
    "顆",
    "奔",
    "鉛",
    "仲",
    "虎",
    "稀",
    "妹",
    "乏",
    "珍",
    "申",
    "桌",
    "遵",
    "允",
    "隆",
    "螺",
    "倉",
    "魏",
    "銳",
    "曉",
    "氮",
    "兼",
    "隱",
    "礙",
    "赫",
    "撥",
    "忠",
    "肅",
    "缸",
    "牽",
    "搶",
    "博",
    "巧",
    "殼",
    "兄",
    "杜",
    "訊",
    "誠",
    "碧",
    "祥",
    "柯",
    "頁",
    "巡",
    "矩",
    "悲",
    "灌",
    "齡",
    "倫",
    "票",
    "尋",
    "桂",
    "鋪",
    "聖",
    "恐",
    "恰",
    "鄭",
    "趣",
    "抬",
    "荒",
    "騰",
    "貼",
    "柔",
    "滴",
    "猛",
    "闊",
    "輛",
    "妻",
    "填",
    "撤",
    "儲",
    "簽",
    "鬧",
    "擾",
    "紫",
    "砂",
    "遞",
    "戲",
    "吊",
    "陶",
    "伐",
    "餵",
    "療",
    "瓶",
    "婆",
    "撫",
    "臂",
    "摸",
    "忍",
    "蝦",
    "蠟",
    "鄰",
    "胸",
    "鞏",
    "擠",
    "偶",
    "棄",
    "槽",
    "勁",
    "乳",
    "鄧",
    "吉",
    "仁",
    "爛",
    "磚",
    "租",
    "烏",
    "艦",
    "伴",
    "瓜",
    "淺",
    "丙",
    "暫",
    "燥",
    "橡",
    "柳",
    "迷",
    "暖",
    "牌",
    "秧",
    "膽",
    "詳",
    "簧",
    "踏",
    "瓷",
    "譜",
    "呆",
    "賓",
    "糊",
    "洛",
    "輝",
    "憤",
    "競",
    "隙",
    "怒",
    "粘",
    "乃",
    "緒",
    "肩",
    "籍",
    "敏",
    "塗",
    "熙",
    "皆",
    "偵",
    "懸",
    "掘",
    "享",
    "糾",
    "醒",
    "狂",
    "鎖",
    "淀",
    "恨",
    "牲",
    "霸",
    "爬",
    "賞",
    "逆",
    "玩",
    "陵",
    "祝",
    "秒",
    "浙",
    "貌",
    "役",
    "彼",
    "悉",
    "鴨",
    "趨",
    "鳳",
    "晨",
    "畜",
    "輩",
    "秩",
    "卵",
    "署",
    "梯",
    "炎",
    "灘",
    "棋",
    "驅",
    "篩",
    "峽",
    "冒",
    "啥",
    "壽",
    "譯",
    "浸",
    "泉",
    "帽",
    "遲",
    "矽",
    "疆",
    "貸",
    "漏",
    "稿",
    "冠",
    "嫩",
    "脅",
    "芯",
    "牢",
    "叛",
    "蝕",
    "奧",
    "鳴",
    "嶺",
    "羊",
    "憑",
    "串",
    "塘",
    "繪",
    "酵",
    "融",
    "盆",
    "錫",
    "廟",
    "籌",
    "凍",
    "輔",
    "攝",
    "襲",
    "筋",
    "拒",
    "僚",
    "旱",
    "鉀",
    "鳥",
    "漆",
    "沈",
    "眉",
    "疏",
    "添",
    "棒",
    "穗",
    "硝",
    "韓",
    "逼",
    "扭",
    "僑",
    "涼",
    "挺",
    "碗",
    "栽",
    "炒",
    "杯",
    "患",
    "餾",
    "勸",
    "豪",
    "遼",
    "勃",
    "鴻",
    "旦",
    "吏",
    "拜",
    "狗",
    "埋",
    "輥",
    "掩",
    "飲",
    "搬",
    "罵",
    "辭",
    "勾",
    "扣",
    "估",
    "蔣",
    "絨",
    "霧",
    "丈",
    "朵",
    "姆",
    "擬",
    "宇",
    "輯",
    "陝",
    "雕",
    "償",
    "蓄",
    "崇",
    "剪",
    "倡",
    "廳",
    "咬",
    "駛",
    "薯",
    "刷",
    "斥",
    "番",
    "賦",
    "奉",
    "佛",
    "澆",
    "漫",
    "曼",
    "扇",
    "鈣",
    "桃",
    "扶",
    "仔",
    "返",
    "俗",
    "虧",
    "腔",
    "鞋",
    "棱",
    "覆",
    "框",
    "悄",
    "叔",
    "撞",
    "騙",
    "勘",
    "旺",
    "沸",
    "孤",
    "吐",
    "孟",
    "渠",
    "屈",
    "疾",
    "妙",
    "惜",
    "仰",
    "狠",
    "脹",
    "諧",
    "拋",
    "黴",
    "桑",
    "崗",
    "嘛",
    "衰",
    "盜",
    "滲",
    "臟",
    "賴",
    "湧",
    "甜",
    "曹",
    "閱",
    "肌",
    "哩",
    "厲",
    "烴",
    "緯",
    "毅",
    "昨",
    "偽",
    "症",
    "煮",
    "嘆",
    "釘",
    "搭",
    "莖",
    "籠",
    "酷",
    "偷",
    "弓",
    "錐",
    "恆",
    "傑",
    "坑",
    "鼻",
    "翼",
    "綸",
    "敘",
    "獄",
    "逮",
    "罐",
    "絡",
    "棚",
    "抑",
    "膨",
    "蔬",
    "寺",
    "驟",
    "穆",
    "冶",
    "枯",
    "冊",
    "屍",
    "凸",
    "紳",
    "坯",
    "犧",
    "焰",
    "轟",
    "欣",
    "晉",
    "瘦",
    "禦",
    "錠",
    "錦",
    "喪",
    "旬",
    "鍛",
    "壟",
    "搜",
    "撲",
    "邀",
    "亭",
    "酯",
    "邁",
    "舒",
    "脆",
    "酶",
    "閒",
    "憂",
    "酚",
    "頑",
    "羽",
    "漲",
    "卸",
    "仗",
    "陪",
    "闢",
    "懲",
    "杭",
    "姚",
    "肚",
    "捉",
    "飄",
    "漂",
    "昆",
    "欺",
    "吾",
    "郎",
    "烷",
    "汁",
    "呵",
    "飾",
    "蕭",
    "雅",
    "郵",
    "遷",
    "燕",
    "撒",
    "姻",
    "赴",
    "宴",
    "煩",
    "債",
    "帳",
    "斑",
    "鈴",
    "旨",
    "醇",
    "董",
    "餅",
    "雛",
    "姿",
    "拌",
    "傅",
    "腹",
    "妥",
    "揉",
    "賢",
    "拆",
    "歪",
    "葡",
    "胺",
    "丟",
    "浩",
    "徽",
    "昂",
    "墊",
    "擋",
    "覽",
    "貪",
    "慰",
    "繳",
    "汪",
    "慌",
    "馮",
    "諾",
    "姜",
    "誼",
    "兇",
    "劣",
    "誣",
    "耀",
    "昏",
    "躺",
    "盈",
    "騎",
    "喬",
    "溪",
    "叢",
    "盧",
    "抹",
    "悶",
    "諮",
    "刮",
    "駕",
    "纜",
    "悟",
    "摘",
    "鉺",
    "擲",
    "頗",
    "幻",
    "柄",
    "惠",
    "慘",
    "佳",
    "仇",
    "臘",
    "窩",
    "滌",
    "劍",
    "瞧",
    "堡",
    "潑",
    "蔥",
    "罩",
    "霍",
    "撈",
    "胎",
    "蒼",
    "濱",
    "倆",
    "捅",
    "湘",
    "砍",
    "霞",
    "邵",
    "萄",
    "瘋",
    "淮",
    "遂",
    "熊",
    "糞",
    "烘",
    "宿",
    "檔",
    "戈",
    "駁",
    "嫂",
    "裕",
    "徙",
    "箭",
    "捐",
    "腸",
    "撐",
    "曬",
    "辨",
    "殿",
    "蓮",
    "攤",
    "攪",
    "醬",
    "屏",
    "疫",
    "哀",
    "蔡",
    "堵",
    "沫",
    "皺",
    "暢",
    "疊",
    "閣",
    "萊",
    "敲",
    "轄",
    "鉤",
    "痕",
    "壩",
    "巷",
    "餓",
    "禍",
    "丘",
    "玄",
    "溜",
    "曰",
    "邏",
    "彭",
    "嘗",
    "卿",
    "妨",
    "艇",
    "吞",
    "韋",
    "怨",
    "矮",
    "歇"
]

},
"wDUddFoUUfikwogs68Z2pOEFmTJpppgiAcPj6Xt0U5I=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const path = require("path");
const fs = require("fs");
const util = require("util");
const rimraf = require('rimraf');
const BIPF = require('bipf');
const defaults = require('ssb-db2/defaults');
const AAOL = require('async-append-only-log');
if (!process.env.SSB_DIR) {
    throw new Error('misconfigured SSB_DIR in the backend');
}
const SSB_DIR = process.env.SSB_DIR;
const KEYS_PATH = path.join(SSB_DIR, 'secret');
const OLD_LOG_PATH = defaults.oldLogPath(SSB_DIR);
const NEW_LOG_PATH = defaults.newLogPath(SSB_DIR);
async function deleteDuplicateRecordsOnLog() {
    const log = AAOL(NEW_LOG_PATH, {
        blockSize: defaults.BLOCK_SIZE,
        validateRecord: (data) => {
            try {
                BIPF.decode(data, 0);
                return true;
            }
            catch (ex) {
                return false;
            }
        },
    });
    const B_KEY = Buffer.from('key');
    const existing = new Set();
    const deletables = new Set();
    // Find deletables
    await new Promise((resolve) => {
        log.stream({ gt: -1 }).pipe({
            paused: false,
            write: function (record) {
                const buffer = record.value;
                if (!buffer)
                    return;
                const pKey = BIPF.seekKey(buffer, 0, B_KEY);
                const shortKey = BIPF.decode(buffer, pKey).slice(1, 33);
                if (existing.has(shortKey)) {
                    deletables.add(record.offset);
                }
                else {
                    existing.add(shortKey);
                }
            },
            end: () => {
                resolve();
            },
        });
    });
    const del = util.promisify(log.del);
    for (const offset of deletables) {
        await del(offset);
    }
    existing.clear();
    deletables.clear();
}
/**
 * One-time fixes for special issues.
 *
 * Sometimes things go wrong in the database and we need to reset indexes or
 * others to make the database work again, but only once. This file accounts for
 * all those cases, and each of these "issues" refers to GitLab issue codes.
 */
async function oneTimeFixes() {
    const ISSUE_1223 = path.join(SSB_DIR, 'issue1223');
    if (!fs.existsSync(ISSUE_1223) && fs.existsSync(OLD_LOG_PATH)) {
        rimraf.sync(path.join(SSB_DIR, 'db2'));
        fs.closeSync(fs.openSync(ISSUE_1223, 'w'));
    }
    const ISSUE_1328 = path.join(SSB_DIR, 'issue1328');
    if (!fs.existsSync(ISSUE_1328)) {
        rimraf.sync(defaults.indexesPath(SSB_DIR) + '/*.*');
        fs.closeSync(fs.openSync(ISSUE_1328, 'w'));
    }
    const ISSUE_1486 = path.join(SSB_DIR, 'issue1486');
    if (!fs.existsSync(ISSUE_1486)) {
        rimraf.sync(defaults.indexesPath(SSB_DIR) + '/!(*.*)');
        fs.closeSync(fs.openSync(ISSUE_1486, 'w'));
    }
    // Fix issue #1518:
    if (fs.existsSync(KEYS_PATH) && fs.lstatSync(KEYS_PATH).isDirectory()) {
        const keysPathWrong = path.join(KEYS_PATH, 'secret');
        const keysPathTmp = path.join(SSB_DIR, 'tmpsecret');
        fs.renameSync(keysPathWrong, keysPathTmp);
        rimraf.sync(KEYS_PATH);
        fs.renameSync(keysPathTmp, KEYS_PATH);
    }
    const ISSUE_1628 = path.join(SSB_DIR, 'issue1628');
    if (!fs.existsSync(ISSUE_1628)) {
        rimraf.sync(defaults.indexesPath(SSB_DIR));
        fs.closeSync(fs.openSync(ISSUE_1628, 'w'));
        await deleteDuplicateRecordsOnLog();
    }
}
module.exports = oneTimeFixes;
//# sourceMappingURL=one-time-fixes.js.map
},
"wDldIgTWkq3WWCNiCxvD5kG+5npYBS8nTJk+tkylzvU=":
function (require, module, exports, __dirname, __filename) {
'use strict'

// For (old) browser support
var xtend = require('xtend')
var assign = require('xtend/mutable')

module.exports = function supports () {
  var manifest = xtend.apply(null, arguments)

  return assign(manifest, {
    // Features of abstract-leveldown
    bufferKeys: manifest.bufferKeys || false,
    snapshots: manifest.snapshots || false,
    permanence: manifest.permanence || false,
    seek: manifest.seek || false,
    clear: manifest.clear || false,

    // Features of abstract-leveldown that levelup doesn't have
    status: manifest.status || false,

    // Features of disk-based implementations
    createIfMissing: manifest.createIfMissing || false,
    errorIfExists: manifest.errorIfExists || false,

    // Features of level(up) that abstract-leveldown doesn't have yet
    deferredOpen: manifest.deferredOpen || false,
    openCallback: manifest.openCallback || false,
    promises: manifest.promises || false,
    streams: manifest.streams || false,
    encodings: manifest.encodings || false,

    // Methods that are not part of abstract-leveldown or levelup
    additionalMethods: xtend(manifest.additionalMethods)
  })
}

},
"wOsU2J+v8D5povtXnv2iaAG82fiQsfmMwudy5EjJN1w=":
function (require, module, exports, __dirname, __filename) {
module.exports = minimatch
minimatch.Minimatch = Minimatch

var path = { sep: '/' }
try {
  path = require('path')
} catch (er) {}

var GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}
var expand = require('brace-expansion')

var plTypes = {
  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},
  '?': { open: '(?:', close: ')?' },
  '+': { open: '(?:', close: ')+' },
  '*': { open: '(?:', close: ')*' },
  '@': { open: '(?:', close: ')' }
}

// any single thing other than /
// don't need to escape / when using new RegExp()
var qmark = '[^/]'

// * => any number of characters
var star = qmark + '*?'

// ** when dots are allowed.  Anything goes, except .. and .
// not (^ or / followed by one or two dots followed by $ or /),
// followed by anything, any number of times.
var twoStarDot = '(?:(?!(?:\\\/|^)(?:\\.{1,2})($|\\\/)).)*?'

// not a ^ or / followed by a dot,
// followed by anything, any number of times.
var twoStarNoDot = '(?:(?!(?:\\\/|^)\\.).)*?'

// characters that need to be escaped in RegExp.
var reSpecials = charSet('().*{}+?[]^$\\!')

// "abc" -> { a:true, b:true, c:true }
function charSet (s) {
  return s.split('').reduce(function (set, c) {
    set[c] = true
    return set
  }, {})
}

// normalizes slashes.
var slashSplit = /\/+/

minimatch.filter = filter
function filter (pattern, options) {
  options = options || {}
  return function (p, i, list) {
    return minimatch(p, pattern, options)
  }
}

function ext (a, b) {
  a = a || {}
  b = b || {}
  var t = {}
  Object.keys(b).forEach(function (k) {
    t[k] = b[k]
  })
  Object.keys(a).forEach(function (k) {
    t[k] = a[k]
  })
  return t
}

minimatch.defaults = function (def) {
  if (!def || !Object.keys(def).length) return minimatch

  var orig = minimatch

  var m = function minimatch (p, pattern, options) {
    return orig.minimatch(p, pattern, ext(def, options))
  }

  m.Minimatch = function Minimatch (pattern, options) {
    return new orig.Minimatch(pattern, ext(def, options))
  }

  return m
}

Minimatch.defaults = function (def) {
  if (!def || !Object.keys(def).length) return Minimatch
  return minimatch.defaults(def).Minimatch
}

function minimatch (p, pattern, options) {
  if (typeof pattern !== 'string') {
    throw new TypeError('glob pattern string required')
  }

  if (!options) options = {}

  // shortcut: comments match nothing.
  if (!options.nocomment && pattern.charAt(0) === '#') {
    return false
  }

  // "" only matches ""
  if (pattern.trim() === '') return p === ''

  return new Minimatch(pattern, options).match(p)
}

function Minimatch (pattern, options) {
  if (!(this instanceof Minimatch)) {
    return new Minimatch(pattern, options)
  }

  if (typeof pattern !== 'string') {
    throw new TypeError('glob pattern string required')
  }

  if (!options) options = {}
  pattern = pattern.trim()

  // windows support: need to use /, not \
  if (path.sep !== '/') {
    pattern = pattern.split(path.sep).join('/')
  }

  this.options = options
  this.set = []
  this.pattern = pattern
  this.regexp = null
  this.negate = false
  this.comment = false
  this.empty = false

  // make the set of regexps etc.
  this.make()
}

Minimatch.prototype.debug = function () {}

Minimatch.prototype.make = make
function make () {
  // don't do it more than once.
  if (this._made) return

  var pattern = this.pattern
  var options = this.options

  // empty patterns and comments match nothing.
  if (!options.nocomment && pattern.charAt(0) === '#') {
    this.comment = true
    return
  }
  if (!pattern) {
    this.empty = true
    return
  }

  // step 1: figure out negation, etc.
  this.parseNegate()

  // step 2: expand braces
  var set = this.globSet = this.braceExpand()

  if (options.debug) this.debug = console.error

  this.debug(this.pattern, set)

  // step 3: now we have a set, so turn each one into a series of path-portion
  // matching patterns.
  // These will be regexps, except in the case of "**", which is
  // set to the GLOBSTAR object for globstar behavior,
  // and will not contain any / characters
  set = this.globParts = set.map(function (s) {
    return s.split(slashSplit)
  })

  this.debug(this.pattern, set)

  // glob --> regexps
  set = set.map(function (s, si, set) {
    return s.map(this.parse, this)
  }, this)

  this.debug(this.pattern, set)

  // filter out everything that didn't compile properly.
  set = set.filter(function (s) {
    return s.indexOf(false) === -1
  })

  this.debug(this.pattern, set)

  this.set = set
}

Minimatch.prototype.parseNegate = parseNegate
function parseNegate () {
  var pattern = this.pattern
  var negate = false
  var options = this.options
  var negateOffset = 0

  if (options.nonegate) return

  for (var i = 0, l = pattern.length
    ; i < l && pattern.charAt(i) === '!'
    ; i++) {
    negate = !negate
    negateOffset++
  }

  if (negateOffset) this.pattern = pattern.substr(negateOffset)
  this.negate = negate
}

// Brace expansion:
// a{b,c}d -> abd acd
// a{b,}c -> abc ac
// a{0..3}d -> a0d a1d a2d a3d
// a{b,c{d,e}f}g -> abg acdfg acefg
// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg
//
// Invalid sets are not expanded.
// a{2..}b -> a{2..}b
// a{b}c -> a{b}c
minimatch.braceExpand = function (pattern, options) {
  return braceExpand(pattern, options)
}

Minimatch.prototype.braceExpand = braceExpand

function braceExpand (pattern, options) {
  if (!options) {
    if (this instanceof Minimatch) {
      options = this.options
    } else {
      options = {}
    }
  }

  pattern = typeof pattern === 'undefined'
    ? this.pattern : pattern

  if (typeof pattern === 'undefined') {
    throw new TypeError('undefined pattern')
  }

  if (options.nobrace ||
    !pattern.match(/\{.*\}/)) {
    // shortcut. no need to expand.
    return [pattern]
  }

  return expand(pattern)
}

// parse a component of the expanded set.
// At this point, no pattern may contain "/" in it
// so we're going to return a 2d array, where each entry is the full
// pattern, split on '/', and then turned into a regular expression.
// A regexp is made at the end which joins each array with an
// escaped /, and another full one which joins each regexp with |.
//
// Following the lead of Bash 4.1, note that "**" only has special meaning
// when it is the *only* thing in a path portion.  Otherwise, any series
// of * is equivalent to a single *.  Globstar behavior is enabled by
// default, and can be disabled by setting options.noglobstar.
Minimatch.prototype.parse = parse
var SUBPARSE = {}
function parse (pattern, isSub) {
  if (pattern.length > 1024 * 64) {
    throw new TypeError('pattern is too long')
  }

  var options = this.options

  // shortcuts
  if (!options.noglobstar && pattern === '**') return GLOBSTAR
  if (pattern === '') return ''

  var re = ''
  var hasMagic = !!options.nocase
  var escaping = false
  // ? => one single character
  var patternListStack = []
  var negativeLists = []
  var stateChar
  var inClass = false
  var reClassStart = -1
  var classStart = -1
  // . and .. never match anything that doesn't start with .,
  // even when options.dot is set.
  var patternStart = pattern.charAt(0) === '.' ? '' // anything
  // not (start or / followed by . or .. followed by / or end)
  : options.dot ? '(?!(?:^|\\\/)\\.{1,2}(?:$|\\\/))'
  : '(?!\\.)'
  var self = this

  function clearStateChar () {
    if (stateChar) {
      // we had some state-tracking character
      // that wasn't consumed by this pass.
      switch (stateChar) {
        case '*':
          re += star
          hasMagic = true
        break
        case '?':
          re += qmark
          hasMagic = true
        break
        default:
          re += '\\' + stateChar
        break
      }
      self.debug('clearStateChar %j %j', stateChar, re)
      stateChar = false
    }
  }

  for (var i = 0, len = pattern.length, c
    ; (i < len) && (c = pattern.charAt(i))
    ; i++) {
    this.debug('%s\t%s %s %j', pattern, i, re, c)

    // skip over any that are escaped.
    if (escaping && reSpecials[c]) {
      re += '\\' + c
      escaping = false
      continue
    }

    switch (c) {
      case '/':
        // completely not allowed, even escaped.
        // Should already be path-split by now.
        return false

      case '\\':
        clearStateChar()
        escaping = true
      continue

      // the various stateChar values
      // for the "extglob" stuff.
      case '?':
      case '*':
      case '+':
      case '@':
      case '!':
        this.debug('%s\t%s %s %j <-- stateChar', pattern, i, re, c)

        // all of those are literals inside a class, except that
        // the glob [!a] means [^a] in regexp
        if (inClass) {
          this.debug('  in class')
          if (c === '!' && i === classStart + 1) c = '^'
          re += c
          continue
        }

        // if we already have a stateChar, then it means
        // that there was something like ** or +? in there.
        // Handle the stateChar, then proceed with this one.
        self.debug('call clearStateChar %j', stateChar)
        clearStateChar()
        stateChar = c
        // if extglob is disabled, then +(asdf|foo) isn't a thing.
        // just clear the statechar *now*, rather than even diving into
        // the patternList stuff.
        if (options.noext) clearStateChar()
      continue

      case '(':
        if (inClass) {
          re += '('
          continue
        }

        if (!stateChar) {
          re += '\\('
          continue
        }

        patternListStack.push({
          type: stateChar,
          start: i - 1,
          reStart: re.length,
          open: plTypes[stateChar].open,
          close: plTypes[stateChar].close
        })
        // negation is (?:(?!js)[^/]*)
        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'
        this.debug('plType %j %j', stateChar, re)
        stateChar = false
      continue

      case ')':
        if (inClass || !patternListStack.length) {
          re += '\\)'
          continue
        }

        clearStateChar()
        hasMagic = true
        var pl = patternListStack.pop()
        // negation is (?:(?!js)[^/]*)
        // The others are (?:<pattern>)<type>
        re += pl.close
        if (pl.type === '!') {
          negativeLists.push(pl)
        }
        pl.reEnd = re.length
      continue

      case '|':
        if (inClass || !patternListStack.length || escaping) {
          re += '\\|'
          escaping = false
          continue
        }

        clearStateChar()
        re += '|'
      continue

      // these are mostly the same in regexp and glob
      case '[':
        // swallow any state-tracking char before the [
        clearStateChar()

        if (inClass) {
          re += '\\' + c
          continue
        }

        inClass = true
        classStart = i
        reClassStart = re.length
        re += c
      continue

      case ']':
        //  a right bracket shall lose its special
        //  meaning and represent itself in
        //  a bracket expression if it occurs
        //  first in the list.  -- POSIX.2 2.8.3.2
        if (i === classStart + 1 || !inClass) {
          re += '\\' + c
          escaping = false
          continue
        }

        // handle the case where we left a class open.
        // "[z-a]" is valid, equivalent to "\[z-a\]"
        if (inClass) {
          // split where the last [ was, make sure we don't have
          // an invalid re. if so, re-walk the contents of the
          // would-be class to re-translate any characters that
          // were passed through as-is
          // TODO: It would probably be faster to determine this
          // without a try/catch and a new RegExp, but it's tricky
          // to do safely.  For now, this is safe and works.
          var cs = pattern.substring(classStart + 1, i)
          try {
            RegExp('[' + cs + ']')
          } catch (er) {
            // not a valid class!
            var sp = this.parse(cs, SUBPARSE)
            re = re.substr(0, reClassStart) + '\\[' + sp[0] + '\\]'
            hasMagic = hasMagic || sp[1]
            inClass = false
            continue
          }
        }

        // finish up the class.
        hasMagic = true
        inClass = false
        re += c
      continue

      default:
        // swallow any state char that wasn't consumed
        clearStateChar()

        if (escaping) {
          // no need
          escaping = false
        } else if (reSpecials[c]
          && !(c === '^' && inClass)) {
          re += '\\'
        }

        re += c

    } // switch
  } // for

  // handle the case where we left a class open.
  // "[abc" is valid, equivalent to "\[abc"
  if (inClass) {
    // split where the last [ was, and escape it
    // this is a huge pita.  We now have to re-walk
    // the contents of the would-be class to re-translate
    // any characters that were passed through as-is
    cs = pattern.substr(classStart + 1)
    sp = this.parse(cs, SUBPARSE)
    re = re.substr(0, reClassStart) + '\\[' + sp[0]
    hasMagic = hasMagic || sp[1]
  }

  // handle the case where we had a +( thing at the *end*
  // of the pattern.
  // each pattern list stack adds 3 chars, and we need to go through
  // and escape any | chars that were passed through as-is for the regexp.
  // Go through and escape them, taking care not to double-escape any
  // | chars that were already escaped.
  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {
    var tail = re.slice(pl.reStart + pl.open.length)
    this.debug('setting tail', re, pl)
    // maybe some even number of \, then maybe 1 \, followed by a |
    tail = tail.replace(/((?:\\{2}){0,64})(\\?)\|/g, function (_, $1, $2) {
      if (!$2) {
        // the | isn't already escaped, so escape it.
        $2 = '\\'
      }

      // need to escape all those slashes *again*, without escaping the
      // one that we need for escaping the | character.  As it works out,
      // escaping an even number of slashes can be done by simply repeating
      // it exactly after itself.  That's why this trick works.
      //
      // I am sorry that you have to see this.
      return $1 + $1 + $2 + '|'
    })

    this.debug('tail=%j\n   %s', tail, tail, pl, re)
    var t = pl.type === '*' ? star
      : pl.type === '?' ? qmark
      : '\\' + pl.type

    hasMagic = true
    re = re.slice(0, pl.reStart) + t + '\\(' + tail
  }

  // handle trailing things that only matter at the very end.
  clearStateChar()
  if (escaping) {
    // trailing \\
    re += '\\\\'
  }

  // only need to apply the nodot start if the re starts with
  // something that could conceivably capture a dot
  var addPatternStart = false
  switch (re.charAt(0)) {
    case '.':
    case '[':
    case '(': addPatternStart = true
  }

  // Hack to work around lack of negative lookbehind in JS
  // A pattern like: *.!(x).!(y|z) needs to ensure that a name
  // like 'a.xyz.yz' doesn't match.  So, the first negative
  // lookahead, has to look ALL the way ahead, to the end of
  // the pattern.
  for (var n = negativeLists.length - 1; n > -1; n--) {
    var nl = negativeLists[n]

    var nlBefore = re.slice(0, nl.reStart)
    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)
    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)
    var nlAfter = re.slice(nl.reEnd)

    nlLast += nlAfter

    // Handle nested stuff like *(*.js|!(*.json)), where open parens
    // mean that we should *not* include the ) in the bit that is considered
    // "after" the negated section.
    var openParensBefore = nlBefore.split('(').length - 1
    var cleanAfter = nlAfter
    for (i = 0; i < openParensBefore; i++) {
      cleanAfter = cleanAfter.replace(/\)[+*?]?/, '')
    }
    nlAfter = cleanAfter

    var dollar = ''
    if (nlAfter === '' && isSub !== SUBPARSE) {
      dollar = '$'
    }
    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast
    re = newRe
  }

  // if the re is not "" at this point, then we need to make sure
  // it doesn't match against an empty path part.
  // Otherwise a/* will match a/, which it should not.
  if (re !== '' && hasMagic) {
    re = '(?=.)' + re
  }

  if (addPatternStart) {
    re = patternStart + re
  }

  // parsing just a piece of a larger pattern.
  if (isSub === SUBPARSE) {
    return [re, hasMagic]
  }

  // skip the regexp for non-magical patterns
  // unescape anything in it, though, so that it'll be
  // an exact match against a file etc.
  if (!hasMagic) {
    return globUnescape(pattern)
  }

  var flags = options.nocase ? 'i' : ''
  try {
    var regExp = new RegExp('^' + re + '$', flags)
  } catch (er) {
    // If it was an invalid regular expression, then it can't match
    // anything.  This trick looks for a character after the end of
    // the string, which is of course impossible, except in multi-line
    // mode, but it's not a /m regex.
    return new RegExp('$.')
  }

  regExp._glob = pattern
  regExp._src = re

  return regExp
}

minimatch.makeRe = function (pattern, options) {
  return new Minimatch(pattern, options || {}).makeRe()
}

Minimatch.prototype.makeRe = makeRe
function makeRe () {
  if (this.regexp || this.regexp === false) return this.regexp

  // at this point, this.set is a 2d array of partial
  // pattern strings, or "**".
  //
  // It's better to use .match().  This function shouldn't
  // be used, really, but it's pretty convenient sometimes,
  // when you just want to work with a regex.
  var set = this.set

  if (!set.length) {
    this.regexp = false
    return this.regexp
  }
  var options = this.options

  var twoStar = options.noglobstar ? star
    : options.dot ? twoStarDot
    : twoStarNoDot
  var flags = options.nocase ? 'i' : ''

  var re = set.map(function (pattern) {
    return pattern.map(function (p) {
      return (p === GLOBSTAR) ? twoStar
      : (typeof p === 'string') ? regExpEscape(p)
      : p._src
    }).join('\\\/')
  }).join('|')

  // must match entire pattern
  // ending in a * or ** will make it less strict.
  re = '^(?:' + re + ')$'

  // can match anything, as long as it's not this.
  if (this.negate) re = '^(?!' + re + ').*$'

  try {
    this.regexp = new RegExp(re, flags)
  } catch (ex) {
    this.regexp = false
  }
  return this.regexp
}

minimatch.match = function (list, pattern, options) {
  options = options || {}
  var mm = new Minimatch(pattern, options)
  list = list.filter(function (f) {
    return mm.match(f)
  })
  if (mm.options.nonull && !list.length) {
    list.push(pattern)
  }
  return list
}

Minimatch.prototype.match = match
function match (f, partial) {
  this.debug('match', f, this.pattern)
  // short-circuit in the case of busted things.
  // comments, etc.
  if (this.comment) return false
  if (this.empty) return f === ''

  if (f === '/' && partial) return true

  var options = this.options

  // windows: need to use /, not \
  if (path.sep !== '/') {
    f = f.split(path.sep).join('/')
  }

  // treat the test path as a set of pathparts.
  f = f.split(slashSplit)
  this.debug(this.pattern, 'split', f)

  // just ONE of the pattern sets in this.set needs to match
  // in order for it to be valid.  If negating, then just one
  // match means that we have failed.
  // Either way, return on the first hit.

  var set = this.set
  this.debug(this.pattern, 'set', set)

  // Find the basename of the path by looking for the last non-empty segment
  var filename
  var i
  for (i = f.length - 1; i >= 0; i--) {
    filename = f[i]
    if (filename) break
  }

  for (i = 0; i < set.length; i++) {
    var pattern = set[i]
    var file = f
    if (options.matchBase && pattern.length === 1) {
      file = [filename]
    }
    var hit = this.matchOne(file, pattern, partial)
    if (hit) {
      if (options.flipNegate) return true
      return !this.negate
    }
  }

  // didn't get any hits.  this is success if it's a negative
  // pattern, failure otherwise.
  if (options.flipNegate) return false
  return this.negate
}

// set partial to true to test if, for example,
// "/a/b" matches the start of "/*/b/*/d"
// Partial means, if you run out of file before you run
// out of pattern, then that's fine, as long as all
// the parts match.
Minimatch.prototype.matchOne = function (file, pattern, partial) {
  var options = this.options

  this.debug('matchOne',
    { 'this': this, file: file, pattern: pattern })

  this.debug('matchOne', file.length, pattern.length)

  for (var fi = 0,
      pi = 0,
      fl = file.length,
      pl = pattern.length
      ; (fi < fl) && (pi < pl)
      ; fi++, pi++) {
    this.debug('matchOne loop')
    var p = pattern[pi]
    var f = file[fi]

    this.debug(pattern, p, f)

    // should be impossible.
    // some invalid regexp stuff in the set.
    if (p === false) return false

    if (p === GLOBSTAR) {
      this.debug('GLOBSTAR', [pattern, p, f])

      // "**"
      // a/**/b/**/c would match the following:
      // a/b/x/y/z/c
      // a/x/y/z/b/c
      // a/b/x/b/x/c
      // a/b/c
      // To do this, take the rest of the pattern after
      // the **, and see if it would match the file remainder.
      // If so, return success.
      // If not, the ** "swallows" a segment, and try again.
      // This is recursively awful.
      //
      // a/**/b/**/c matching a/b/x/y/z/c
      // - a matches a
      // - doublestar
      //   - matchOne(b/x/y/z/c, b/**/c)
      //     - b matches b
      //     - doublestar
      //       - matchOne(x/y/z/c, c) -> no
      //       - matchOne(y/z/c, c) -> no
      //       - matchOne(z/c, c) -> no
      //       - matchOne(c, c) yes, hit
      var fr = fi
      var pr = pi + 1
      if (pr === pl) {
        this.debug('** at the end')
        // a ** at the end will just swallow the rest.
        // We have found a match.
        // however, it will not swallow /.x, unless
        // options.dot is set.
        // . and .. are *never* matched by **, for explosively
        // exponential reasons.
        for (; fi < fl; fi++) {
          if (file[fi] === '.' || file[fi] === '..' ||
            (!options.dot && file[fi].charAt(0) === '.')) return false
        }
        return true
      }

      // ok, let's see if we can swallow whatever we can.
      while (fr < fl) {
        var swallowee = file[fr]

        this.debug('\nglobstar while', file, fr, pattern, pr, swallowee)

        // XXX remove this slice.  Just pass the start index.
        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {
          this.debug('globstar found match!', fr, fl, swallowee)
          // found a match.
          return true
        } else {
          // can't swallow "." or ".." ever.
          // can only swallow ".foo" when explicitly asked.
          if (swallowee === '.' || swallowee === '..' ||
            (!options.dot && swallowee.charAt(0) === '.')) {
            this.debug('dot detected!', file, fr, pattern, pr)
            break
          }

          // ** swallows a segment, and continue.
          this.debug('globstar swallow a segment, and continue')
          fr++
        }
      }

      // no match was found.
      // However, in partial mode, we can't say this is necessarily over.
      // If there's more *pattern* left, then
      if (partial) {
        // ran out of file
        this.debug('\n>>> no match, partial?', file, fr, pattern, pr)
        if (fr === fl) return true
      }
      return false
    }

    // something other than **
    // non-magic patterns just have to match exactly
    // patterns with magic have been turned into regexps.
    var hit
    if (typeof p === 'string') {
      if (options.nocase) {
        hit = f.toLowerCase() === p.toLowerCase()
      } else {
        hit = f === p
      }
      this.debug('string match', p, f, hit)
    } else {
      hit = f.match(p)
      this.debug('pattern match', p, f, hit)
    }

    if (!hit) return false
  }

  // Note: ending in / means that we'll get a final ""
  // at the end of the pattern.  This can only match a
  // corresponding "" at the end of the file.
  // If the file ends in /, then it can only match a
  // a pattern that ends in /, unless the pattern just
  // doesn't have any more for it. But, a/b/ should *not*
  // match "a/b/*", even though "" matches against the
  // [^/]*? pattern, except in partial mode, where it might
  // simply not be reached yet.
  // However, a/b/ should still satisfy a/*

  // now either we fell off the end of the pattern, or we're done.
  if (fi === fl && pi === pl) {
    // ran out of pattern and filename at the same time.
    // an exact hit!
    return true
  } else if (fi === fl) {
    // ran out of file, but still had pattern left.
    // this is ok if we're doing the match as part of
    // a glob fs traversal.
    return partial
  } else if (pi === pl) {
    // ran out of pattern, still have file left.
    // this is only acceptable if we're on the very last
    // empty segment of a file with a trailing slash.
    // a/* should match a/b/
    var emptyFileEnd = (fi === fl - 1) && (file[fi] === '')
    return emptyFileEnd
  }

  // should be unreachable.
  throw new Error('wtf?')
}

// replace stuff like \* with *
function globUnescape (s) {
  return s.replace(/\\(.)/g, '$1')
}

function regExpEscape (s) {
  return s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&')
}

},
"wT7PotLvX9d6oTqh/VVsMDb+dKwVQSs7lC0xkNiQghU=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const bipf = require('bipf')
const Plugin = require('./plugin')
const { seqs } = require('../operators')

const B_KEY = Buffer.from('key')

// msgId => seq
module.exports = class Keys extends Plugin {
  constructor(log, dir) {
    super(log, dir, 'keys', 1)
  }

  processRecord(record, seq) {
    const buf = record.value
    const pKey = bipf.seekKey(buf, 0, B_KEY)
    if (pKey < 0) return
    const key = bipf.decode(buf, pKey)
    this.batch.push({
      type: 'put',
      key: key,
      value: seq,
    })
  }

  indexesContent() {
    return false
  }

  getMsgByKey(msgId, cb) {
    this.level.get(msgId, (err, seqNum) => {
      if (err) cb(null, seqs([]))
      else cb(null, seqs([parseInt(seqNum, 10)]))
    })
  }

  getSeq(msgId, cb) {
    this.level.get(msgId, cb)
  }

  delMsg(msgId) {
    this.level.del(msgId, (err) => {
      if (err) throw err
    })
  }
}

},
"wcrwnTx0GBU4XGAxzPhRt4q5CLXY0M2GgN7m8YPVpQc=":
function (require, module, exports, __dirname, __filename) {

/**
 * Module dependencies.
 */

var fs = require('fs')
  , path = require('path')
  , join = path.join
  , dirname = path.dirname
  , exists = ((fs.accessSync && function (path) { try { fs.accessSync(path); } catch (e) { return false; } return true; })
    || fs.existsSync || path.existsSync)
  , defaults = {
    arrow: process.env.NODE_BINDINGS_ARROW || ' → '
    , compiled: process.env.NODE_BINDINGS_COMPILED_DIR || 'compiled'
    , platform: process.platform
    , arch: process.arch
    , version: process.versions.node
    , bindings: 'bindings.node'
    , try: [
      // node-gyp's linked version in the "build" dir
      ['module_root', 'node_modules', 'name', 'build', 'bindings']
      // node-waf and gyp_addon (a.k.a node-gyp)
      , ['module_root', 'node_modules', 'name', 'build', 'Debug', 'bindings']
      , ['module_root', 'node_modules', 'name', 'build', 'Release', 'bindings']
      // Debug files, for development (legacy behavior, remove for node v0.9)
      , ['module_root', 'node_modules', 'name', 'out', 'Debug', 'bindings']
      , ['module_root', 'node_modules', 'name', 'Debug', 'bindings']
      // Release files, but manually compiled (legacy behavior, remove for node v0.9)
      , ['module_root', 'node_modules', 'name', 'out', 'Release', 'bindings']
      , ['module_root', 'node_modules', 'name', 'Release', 'bindings']
      // Legacy from node-waf, node <= 0.4.x
      , ['module_root', 'node_modules', 'name', 'build', 'default', 'bindings']
      // Production "Release" buildtype binary (meh...)
      , ['module_root', 'node_modules', 'name', 'compiled', 'version', 'platform', 'arch', 'bindings']
    ]
  }

/**
 * The main `bindings()` function loads the compiled bindings for a given module.
 * It uses V8's Error API to determine the parent filename that this function is
 * being invoked from, which is then used to find the root directory.
 */

function bindings(opts) {

  // Argument surgery
  if (typeof opts == 'string') {
    opts = { bindings: opts }
  } else if (!opts) {
    opts = {}
  }

  // maps `defaults` onto `opts` object
  Object.keys(defaults).map(function (i) {
    if (!(i in opts)) opts[i] = defaults[i];
  });

  // Get the module root
  if (!opts.module_root) {
    opts.module_root = exports.getRoot(exports.getFileName())
  }

  // Ensure the given bindings name ends with .node
  if (path.extname(opts.bindings) != '.node') {
    opts.name = opts.bindings;
    opts.bindings += '.node'
  }

  var tries = []
    , i = 0
    , l = opts.try.length
    , n
    , b
    , err

  for (; i < l; i++) {
    n = join.apply(null, opts.try[i].map(function (p) {
      return opts[p] || p
    }))
    tries.push(n)
    try {
      b = opts.path ? require.resolve(n) : require(n)
      if (!opts.path) {
        b.path = n
      }
      return b
    } catch (e) {
      if (!/not find/i.test(e.message)) {
        throw e
      }
    }
  }

  err = new Error('Could not locate the bindings file. Tried:\n'
    + tries.map(function (a) { return opts.arrow + a }).join('\n'))
  err.tries = tries
  throw err
}
module.exports = exports = bindings


/**
 * Gets the filename of the JavaScript file that invokes this function.
 * Used to help find the root directory of a module.
 * Optionally accepts an filename argument to skip when searching for the invoking filename
 */

exports.getFileName = function getFileName(calling_file) {
  var origPST = Error.prepareStackTrace
    , origSTL = Error.stackTraceLimit
    , dummy = {}
    , fileName

  Error.stackTraceLimit = 10

  Error.prepareStackTrace = function (e, st) {
    for (var i = 0, l = st.length; i < l; i++) {
      fileName = st[i].getFileName()
      if (fileName !== __filename) {
        if (calling_file) {
          if (fileName !== calling_file) {
            return
          }
        } else {
          return
        }
      }
    }
  }

  // run the 'prepareStackTrace' function above
  Error.captureStackTrace(dummy)
  dummy.stack

  // cleanup
  Error.prepareStackTrace = origPST
  Error.stackTraceLimit = origSTL

  return fileName
}

/**
 * Gets the root directory of a module, given an arbitrary filename
 * somewhere in the module tree. The "root directory" is the directory
 * containing the `package.json` file.
 *
 *   In:  /home/nate/node-native-module/lib/index.js
 *   Out: /home/nate/node-native-module
 */

exports.getRoot = function getRoot(file) {
  var dir = dirname(file)
    , prev
  while (true) {
    if (dir === '.') {
      // Avoids an infinite loop in rare cases, like the REPL
      dir = process.cwd()
    }
    if (exists(join(dir, 'package.json')) || exists(join(dir, 'node_modules'))) {
      // Found the 'package.json' file or 'node_modules' dir; we're done
      return dir
    }
    if (prev === dir) {
      // Got to the top
      throw new Error('Could not find module root given file: "' + file
        + '". Do you have a `package.json` file? ')
    }
    // Try the parent dir next
    prev = dir
    dir = join(dir, '..')
  }
}

},
"wlWpEMyyQXJHi0o8aS8IyFXgiv1if1amTRaJE1CjFwQ=":
function (require, module, exports, __dirname, __filename) {
module.exports = (fn) => (...args) =>
  new Promise((resolve, reject) => {
    fn(...args, (err, val) => err ? reject(err) : resolve(val))
  })

},
"wnpUVC5FDGsUfwBvb8IBrsGkVCXo1cnR52yWi7EBjGg=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const pull = require('pull-stream')

// exports.name is blank to merge into global namespace

exports.manifest = {
  publish: 'async',
  whoami: 'sync',
  createWriteStream: 'sink',
}

exports.init = function (sbot, config) {
  sbot.add = sbot.db.add
  sbot.get = function get(idOrObject, cb) {
    if (typeof idOrObject === 'object' && idOrObject.meta)
      sbot.db.getMsg(idOrObject.id, cb)
    else if (typeof idOrObject === 'object')
      sbot.db.get(idOrObject.id, cb)
    else
      sbot.db.get(idOrObject, cb)
  }
  sbot.publish = sbot.db.publish
  sbot.whoami = () => ({ id: sbot.id })
  sbot.ready = () => true
  sbot.keys = config.keys
  sbot.createWriteStream = function createWriteStream(cb) {
    return pull(
      pull.asyncMap(sbot.db.add),
      pull.drain(
        () => {},
        cb ||
          ((err) => {
            console.error(`ssb-db2 createWriteStream got an error: ${err}`)
          })
      )
    )
  }
}

},
"wo8eZ38QomU23+HuhoRiapqt6BWw19qBYJHtnuMpDQI=":
function (require, module, exports, __dirname, __filename) {
var SHS = require('secret-handshake')
var pull = require('pull-stream')

function isString(s) {
  return 'string' === typeof s
}

module.exports = function (opts) {
  var keys = SHS.toKeys(opts.keys || opts.seed)
  var appKey = isString(opts.appKey) ? Buffer.from(opts.appKey, 'base64') : opts.appKey

  var server = SHS.createServer(
    keys, opts.auth || opts.authenticate, appKey, opts.timeout
  )
  var client = SHS.createClient(
    keys, appKey, opts.timeout
  )

  return {
    name: 'shs',
    create: function (_opts) {
      return function (stream, cb) {
        function _cb (err, stream) {
          if(err) {
            //shs is designed so that we do not _know_ who is connecting if it fails,
            //so we probably can't add the connecting address. (unless it was client unauthorized)
            err.address = 'shs:'
            return cb(err)
          }
          stream.address = 'shs:'+stream.remote.toString('base64')
          cb(null, stream)
        }
        pull(
          stream.source,
          _opts && _opts.key ? client(_opts.key, _opts.seed, _cb) : server(_cb),
          stream.sink
        )
      }
    },
    parse: function (str) {
      var ary = str.split(':')
      if(ary[0] !== 'shs') return null
      var seed = undefined

      //seed of private key to connect with, optional.

      if(ary.length > 2) {
        seed = Buffer.from(ary[2], 'base64')
        if(seed.length !== 32) return null
      }
      var key = Buffer.from(ary[1], 'base64')
      if(key.length !== 32) return null

      return {key: key, seed: seed}
    },
    stringify: function () {
      if(!keys) return
      return 'shs:'+keys.publicKey.toString('base64')
    },
    publicKey: keys && keys.publicKey
  }
}






},
"wrDJkFVApRrLJ2UjuwJO88Eb0RiwOpDZKWIIDr0H/sk=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const WebSocket = require('./lib/websocket');

WebSocket.createWebSocketStream = require('./lib/stream');
WebSocket.Server = require('./lib/websocket-server');
WebSocket.Receiver = require('./lib/receiver');
WebSocket.Sender = require('./lib/sender');

module.exports = WebSocket;

},
"x0iMaqNlst14z89o06Dn5qILdB4SVT1ZLCwHt7tYY3s=":
function (require, module, exports, __dirname, __filename) {
var xtend = require('xtend')
var supports = require('level-supports')
var Buffer = require('buffer').Buffer
var AbstractIterator = require('./abstract-iterator')
var AbstractChainedBatch = require('./abstract-chained-batch')
var nextTick = require('./next-tick')
var hasOwnProperty = Object.prototype.hasOwnProperty
var rangeOptions = 'start end gt gte lt lte'.split(' ')

function AbstractLevelDOWN (manifest) {
  this.status = 'new'

  // TODO (next major): make this mandatory
  this.supports = supports(manifest, {
    status: true
  })
}

AbstractLevelDOWN.prototype.open = function (options, callback) {
  var self = this
  var oldStatus = this.status

  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('open() requires a callback argument')
  }

  if (typeof options !== 'object' || options === null) options = {}

  options.createIfMissing = options.createIfMissing !== false
  options.errorIfExists = !!options.errorIfExists

  this.status = 'opening'
  this._open(options, function (err) {
    if (err) {
      self.status = oldStatus
      return callback(err)
    }
    self.status = 'open'
    callback()
  })
}

AbstractLevelDOWN.prototype._open = function (options, callback) {
  nextTick(callback)
}

AbstractLevelDOWN.prototype.close = function (callback) {
  var self = this
  var oldStatus = this.status

  if (typeof callback !== 'function') {
    throw new Error('close() requires a callback argument')
  }

  this.status = 'closing'
  this._close(function (err) {
    if (err) {
      self.status = oldStatus
      return callback(err)
    }
    self.status = 'closed'
    callback()
  })
}

AbstractLevelDOWN.prototype._close = function (callback) {
  nextTick(callback)
}

AbstractLevelDOWN.prototype.get = function (key, options, callback) {
  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('get() requires a callback argument')
  }

  var err = this._checkKey(key)
  if (err) return nextTick(callback, err)

  key = this._serializeKey(key)

  if (typeof options !== 'object' || options === null) options = {}

  options.asBuffer = options.asBuffer !== false

  this._get(key, options, callback)
}

AbstractLevelDOWN.prototype._get = function (key, options, callback) {
  nextTick(function () { callback(new Error('NotFound')) })
}

AbstractLevelDOWN.prototype.put = function (key, value, options, callback) {
  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('put() requires a callback argument')
  }

  var err = this._checkKey(key) || this._checkValue(value)
  if (err) return nextTick(callback, err)

  key = this._serializeKey(key)
  value = this._serializeValue(value)

  if (typeof options !== 'object' || options === null) options = {}

  this._put(key, value, options, callback)
}

AbstractLevelDOWN.prototype._put = function (key, value, options, callback) {
  nextTick(callback)
}

AbstractLevelDOWN.prototype.del = function (key, options, callback) {
  if (typeof options === 'function') callback = options

  if (typeof callback !== 'function') {
    throw new Error('del() requires a callback argument')
  }

  var err = this._checkKey(key)
  if (err) return nextTick(callback, err)

  key = this._serializeKey(key)

  if (typeof options !== 'object' || options === null) options = {}

  this._del(key, options, callback)
}

AbstractLevelDOWN.prototype._del = function (key, options, callback) {
  nextTick(callback)
}

AbstractLevelDOWN.prototype.batch = function (array, options, callback) {
  if (!arguments.length) return this._chainedBatch()

  if (typeof options === 'function') callback = options

  if (typeof array === 'function') callback = array

  if (typeof callback !== 'function') {
    throw new Error('batch(array) requires a callback argument')
  }

  if (!Array.isArray(array)) {
    return nextTick(callback, new Error('batch(array) requires an array argument'))
  }

  if (array.length === 0) {
    return nextTick(callback)
  }

  if (typeof options !== 'object' || options === null) options = {}

  var serialized = new Array(array.length)

  for (var i = 0; i < array.length; i++) {
    if (typeof array[i] !== 'object' || array[i] === null) {
      return nextTick(callback, new Error('batch(array) element must be an object and not `null`'))
    }

    var e = xtend(array[i])

    if (e.type !== 'put' && e.type !== 'del') {
      return nextTick(callback, new Error("`type` must be 'put' or 'del'"))
    }

    var err = this._checkKey(e.key)
    if (err) return nextTick(callback, err)

    e.key = this._serializeKey(e.key)

    if (e.type === 'put') {
      var valueErr = this._checkValue(e.value)
      if (valueErr) return nextTick(callback, valueErr)

      e.value = this._serializeValue(e.value)
    }

    serialized[i] = e
  }

  this._batch(serialized, options, callback)
}

AbstractLevelDOWN.prototype._batch = function (array, options, callback) {
  nextTick(callback)
}

AbstractLevelDOWN.prototype.clear = function (options, callback) {
  if (typeof options === 'function') {
    callback = options
  } else if (typeof callback !== 'function') {
    throw new Error('clear() requires a callback argument')
  }

  options = cleanRangeOptions(this, options)
  options.reverse = !!options.reverse
  options.limit = 'limit' in options ? options.limit : -1

  this._clear(options, callback)
}

AbstractLevelDOWN.prototype._clear = function (options, callback) {
  // Avoid setupIteratorOptions, would serialize range options a second time.
  options.keys = true
  options.values = false
  options.keyAsBuffer = true
  options.valueAsBuffer = true

  var iterator = this._iterator(options)
  var emptyOptions = {}
  var self = this

  var next = function (err) {
    if (err) {
      return iterator.end(function () {
        callback(err)
      })
    }

    iterator.next(function (err, key) {
      if (err) return next(err)
      if (key === undefined) return iterator.end(callback)

      // This could be optimized by using a batch, but the default _clear
      // is not meant to be fast. Implementations have more room to optimize
      // if they override _clear. Note: using _del bypasses key serialization.
      self._del(key, emptyOptions, next)
    })
  }

  next()
}

AbstractLevelDOWN.prototype._setupIteratorOptions = function (options) {
  options = cleanRangeOptions(this, options)

  options.reverse = !!options.reverse
  options.keys = options.keys !== false
  options.values = options.values !== false
  options.limit = 'limit' in options ? options.limit : -1
  options.keyAsBuffer = options.keyAsBuffer !== false
  options.valueAsBuffer = options.valueAsBuffer !== false

  return options
}

function cleanRangeOptions (db, options) {
  var result = {}

  for (var k in options) {
    if (!hasOwnProperty.call(options, k)) continue

    var opt = options[k]

    if (isRangeOption(k)) {
      // Note that we don't reject nullish and empty options here. While
      // those types are invalid as keys, they are valid as range options.
      opt = db._serializeKey(opt)
    }

    result[k] = opt
  }

  return result
}

function isRangeOption (k) {
  return rangeOptions.indexOf(k) !== -1
}

AbstractLevelDOWN.prototype.iterator = function (options) {
  if (typeof options !== 'object' || options === null) options = {}
  options = this._setupIteratorOptions(options)
  return this._iterator(options)
}

AbstractLevelDOWN.prototype._iterator = function (options) {
  return new AbstractIterator(this)
}

AbstractLevelDOWN.prototype._chainedBatch = function () {
  return new AbstractChainedBatch(this)
}

AbstractLevelDOWN.prototype._serializeKey = function (key) {
  return key
}

AbstractLevelDOWN.prototype._serializeValue = function (value) {
  return value
}

AbstractLevelDOWN.prototype._checkKey = function (key) {
  if (key === null || key === undefined) {
    return new Error('key cannot be `null` or `undefined`')
  } else if (Buffer.isBuffer(key) && key.length === 0) {
    return new Error('key cannot be an empty Buffer')
  } else if (key === '') {
    return new Error('key cannot be an empty String')
  } else if (Array.isArray(key) && key.length === 0) {
    return new Error('key cannot be an empty Array')
  }
}

AbstractLevelDOWN.prototype._checkValue = function (value) {
  if (value === null || value === undefined) {
    return new Error('value cannot be `null` or `undefined`')
  }
}

// Expose browser-compatible nextTick for dependents
AbstractLevelDOWN.prototype._nextTick = nextTick

module.exports = AbstractLevelDOWN

},
"xA8pUYHbmyFv8yRIInUee/Papd2wIiHeL8KpOgUueLc=":
function (require, module, exports, __dirname, __filename) {
'use strict'

var drain = require('./drain')

module.exports = function onEnd (done) {
  return drain(null, done)
}

},
"xDHh0C6g2r9Qe+wYtDJqKLYbO2MUg2fZY/nndbP2QyY=":
function (require, module, exports, __dirname, __filename) {
module.exports = require('bindings')({ bindings: 'leveldown.node', name: 'leveldown-nodejs-mobile' })

},
"xFswaLS+LEcypI3weUYW9sI8wzQNMsVE/jUOa+NfKrk=":
function (require, module, exports, __dirname, __filename) {
const DEFAULT_PORT = require('./port');

module.exports = function idToUrl(blobId, params) {
  const port = (params && params.port) || DEFAULT_PORT;
  const blobRef = encodeURIComponent(blobId);
  const paramsStr = (params && params.unbox)
    ? `?unbox=${encodeURIComponent(params.unbox.toString('base64'))}.boxs`
    : '';

  return `http://localhost:${port}/get/${blobRef}${paramsStr}`;
}

},
"xLi/JLFBZ7UsaNkZ0Tp7DoQPUnAAp520pqEH7pxZ3r8=":
function (require, module, exports, __dirname, __filename) {

var ThroughStream = require('./through')

function MapStream(fn) {
  ThroughStream.call(this)
  this.fn = fn
}

MapStream.prototype = new ThroughStream()

MapStream.prototype.write = function (data) {
  this.sink.write(this.fn(data))
  this.paused = this.sink.paused
}

module.exports = MapStream

},
"xPbNzdTI39I17WGLPy44fNIntC+JebKS/V60dQSirrE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var getPolyfill = require('./polyfill');
var define = require('define-properties');

module.exports = function shimObjectIs() {
	var polyfill = getPolyfill();
	define(Object, { is: polyfill }, {
		is: function testObjectIs() {
			return Object.is !== polyfill;
		}
	});
	return polyfill;
};

},
"xSRq8n3FIcXzFSl9Byiz7J1D2CyiAtSlGAUztSy6ad8=":
function (require, module, exports, __dirname, __filename) {

module.exports = function (filter) {
  var value = null, listeners = [], oncers = []
  function trigger (_value) {
    value = _value
    var length = listeners.length
    for(var i = 0; i< length && value === _value; i++) {
      var listener = listeners[i](value)
      //if we remove a listener, must decrement i also
    }
    // decrement from length, incase a !immediately
    // listener is added during a trigger
    var l = oncers.length
    var _oncers = oncers
    oncers = []
    while(l-- && _value === value) {
      _oncers.shift()(value)
    }
  }

  function many (ready, immediately) {
    var i = listeners.push(ready) - 1
    if(value !== null && immediately !== false) ready(value)
    return function () { //manually remove...
      //fast path, will happen if an earlier listener has not been removed.
      if(listeners[i] !== ready)
        i = listeners.indexOf(ready)
      listeners.splice(i, 1)
    }
  }

  many.set = function (_value) {
    if(filter ? filter(value, _value) : true) trigger(many.value = _value)
    return many
  }

  many.once = function (once, immediately) {
    if(value !== null && immediately !== false) {
      once(value)
      return function () {}
    }
    else {
      var i = oncers.push(once) - 1
      return function () {
        if(oncers[i] !== once)
          i = oncers.indexOf(once)
      }
    }
  }

  return many
}



},
"xY66vPoTm/ZFEhk7hnzUAtTkROIeaQGrZYqfhGacHuk=":
function (require, module, exports, __dirname, __filename) {
var AbstractIterator = require('abstract-leveldown').AbstractIterator
var inherits = require('inherits')

function DeferredIterator (options) {
  AbstractIterator.call(this, options)

  this._options = options
  this._iterator = null
  this._operations = []
}

inherits(DeferredIterator, AbstractIterator)

DeferredIterator.prototype.setDb = function (db) {
  var it = this._iterator = db.iterator(this._options)
  this._operations.forEach(function (op) {
    it[op.method].apply(it, op.args)
  })
}

DeferredIterator.prototype._operation = function (method, args) {
  if (this._iterator) return this._iterator[method].apply(this._iterator, args)
  this._operations.push({ method: method, args: args })
}

'next end'.split(' ').forEach(function (m) {
  DeferredIterator.prototype['_' + m] = function () {
    this._operation(m, arguments)
  }
})

// Must defer seek() rather than _seek() because it requires db._serializeKey to be available
DeferredIterator.prototype.seek = function () {
  this._operation('seek', arguments)
}

module.exports = DeferredIterator

},
"xcdD0oBlUhcQEiSfz18Nr9LzrQTiltGSnIbIxx/micM=":
function (require, module, exports, __dirname, __filename) {
'use strict';

/**
 * Check if we're required to add a port number.
 *
 * @see https://url.spec.whatwg.org/#default-port
 * @param {Number|String} port Port number we need to check
 * @param {String} protocol Protocol we need to check against.
 * @returns {Boolean} Is it a default port for the given protocol
 * @api private
 */
module.exports = function required(port, protocol) {
  protocol = protocol.split(':')[0];
  port = +port;

  if (!port) return false;

  switch (protocol) {
    case 'http':
    case 'ws':
    return port !== 80;

    case 'https':
    case 'wss':
    return port !== 443;

    case 'ftp':
    return port !== 21;

    case 'gopher':
    return port !== 70;

    case 'file':
    return false;
  }

  return port !== 0;
};

},
"xfg8l1wewzxd2AIDcJrc4dgDo7Vut/JqGz+Z+wlNYPA=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const Time = require("./queries/time");
const Health = require("./queries/health");
const Sorting = require("./queries/sorting");
class ConnQuery {
    constructor(db, hub, staging) {
        this.db = db;
        this.hub = hub;
        this.staging = staging;
    }
    _hubEntryToPeer([address, hubData]) {
        const stagingEntry = Array.from(this.staging.entries()).find(([addr]) => addr === address);
        const peer = this.db.has(address)
            ? [address, { pool: 'db', ...this.db.get(address) }]
            : !!stagingEntry
                ? [address, { pool: 'staging', ...stagingEntry[1] }]
                : [address, { pool: 'hub', ...hubData }];
        if (hubData.key && !peer[1].key) {
            peer[1].key = hubData.key;
        }
        return peer;
    }
    peersAll() {
        return this.peersConnectable('dbAndStaging').concat(this.peersInConnection());
    }
    peersConnected() {
        return Array.from(this.hub.entries())
            .filter(([_address, data]) => data.state === 'connected')
            .map((e) => this._hubEntryToPeer(e));
    }
    peersConnecting() {
        return Array.from(this.hub.entries())
            .filter(([_address, data]) => data.state === 'connecting')
            .map((e) => this._hubEntryToPeer(e));
    }
    peersInConnection() {
        return Array.from(this.hub.entries())
            .filter(([_address, data]) => data.state === 'connected' || data.state === 'connecting')
            .map((e) => this._hubEntryToPeer(e));
    }
    peersConnectable(pool = 'db') {
        const useDB = pool === 'db' || pool === 'dbAndStaging';
        const useStaging = pool === 'staging' || pool === 'dbAndStaging';
        const dbPool = useDB
            ? Array.from(this.db.entries()).map(([addr, data]) => [
                addr,
                { pool: 'db', ...data },
            ])
            : [];
        const stagingPool = useStaging
            ? Array.from(this.staging.entries()).map(([addr, data]) => [
                addr,
                { pool: 'staging', ...data },
            ])
            : [];
        return []
            .concat(dbPool)
            .concat(stagingPool)
            .filter(([address]) => {
            const state = this.hub.getState(address);
            return state !== 'connected' && state !== 'connecting';
        });
    }
}
ConnQuery.passesExpBackoff = Time.passesExpBackoff;
ConnQuery.passesGroupDebounce = Time.passesGroupDebounce;
ConnQuery.hasNoAttempts = Health.hasNoAttempts;
ConnQuery.hasOnlyFailedAttempts = Health.hasOnlyFailedAttempts;
ConnQuery.hasSuccessfulAttempts = Health.hasSuccessfulAttempts;
ConnQuery.hasPinged = Health.hasPinged;
ConnQuery.sortByStateChange = Sorting.sortByStateChange;
module.exports = ConnQuery;

},
"xm940DkNdL0yCuHb8fwDQElynxDLSoYE5b1heU2BmDU=":
function (require, module, exports, __dirname, __filename) {
'use strict'

function id (e) { return e }
var prop = require('../util/prop')

module.exports = function asyncMap (map) {
  if(!map) return id
  map = prop(map)
  var busy = false, abortCb, aborted
  return function (read) {
    return function next (abort, cb) {
      if(aborted) return cb(aborted)
      if(abort) {
        aborted = abort
        if(!busy) read(abort, cb)
        else read(abort, function () {
          //if we are still busy, wait for the mapper to complete.
          if(busy) abortCb = cb
          else cb(abort)
        })
      }
      else
        read(null, function (end, data) {
          if(end) cb(end)
          else if(aborted) cb(aborted)
          else {
            busy = true
            map(data, function (err, data) {
              busy = false
              if(aborted) {
                cb(aborted)
                abortCb(aborted)
              }
              else if(err) next (err, cb)
              else cb(null, data)
            })
          }
        })
    }
  }
}



},
"xpP1N1fOjbjoICaYJ+BoH31kSsQAyJ87MuwhMkqXQuc=":
function (require, module, exports, __dirname, __filename) {
'use strict'

module.exports = function (append) {

  var writing = false, queue = []

  function drain () {
    if(writing || !queue.length) return
    writing = true
    var _queue = queue
    queue = []

    var values = []
    _queue.forEach(function (e) {
      if(Array.isArray(e.value))
        e.value.forEach(function (e) { values.push(e) })
      else values.push(e.value)
    })

    append(values, function (err, max) {
      writing = false
      for(var i in _queue) _queue[i].cb(err, max)

      drain() //if there is more to write, write it.
    })
  }


  function write (value, cb) {
    queue.push({value: value, cb: cb}); drain()
  }

  return write

}



},
"xrVcBOieXCeK23taYVMumg1VSIA9t6/tHjZ/Gd2qRco=":
function (require, module, exports, __dirname, __filename) {
'use strict'
const Permissions = require('./permissions')
const u = require('./util')

module.exports = function createLocalCall (api, manifest, perms) {
  perms = Permissions(perms)

  function has (type, name) {
    return type === u.get(manifest, name)
  }

  function localCall (type, name, args) {
    if (name === 'emit') throw new Error('emit has been removed')

    // is there a way to know whether it's sync or async?
    if (type === 'async') {
      if (has('sync', name)) {
        const cb = args.pop()
        let value
        try {
          value = u.get(api, name).apply(this, args)
        } catch (err) {
          return cb(err)
        }
        return cb(null, value)
      }
    }

    if (!has(type, name)) {
      throw new Error(`no ${type}:${name}`)
    }

    return u.get(api, name).apply(this, args)
  }

  return function localCallWithPerms (type, name, args) {
    const err = perms.pre(name, args)
    if (err) throw err
    return localCall.call(this, type, name, args)
  }
}

},
"xwNbRxsZe6bUh5toA7bKJzoXr2yKI4Lcul6zunCkOsI=":
function (require, module, exports, __dirname, __filename) {
var path = require('path');
var fs = require('fs');
var _0777 = parseInt('0777', 8);

module.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;

function mkdirP (p, opts, f, made) {
    if (typeof opts === 'function') {
        f = opts;
        opts = {};
    }
    else if (!opts || typeof opts !== 'object') {
        opts = { mode: opts };
    }
    
    var mode = opts.mode;
    var xfs = opts.fs || fs;
    
    if (mode === undefined) {
        mode = _0777
    }
    if (!made) made = null;
    
    var cb = f || function () {};
    p = path.resolve(p);
    
    xfs.mkdir(p, mode, function (er) {
        if (!er) {
            made = made || p;
            return cb(null, made);
        }
        switch (er.code) {
            case 'ENOENT':
                if (path.dirname(p) === p) return cb(er);
                mkdirP(path.dirname(p), opts, function (er, made) {
                    if (er) cb(er, made);
                    else mkdirP(p, opts, cb, made);
                });
                break;

            // In the case of any other error, just see if there's a dir
            // there already.  If so, then hooray!  If not, then something
            // is borked.
            default:
                xfs.stat(p, function (er2, stat) {
                    // if the stat fails, then that's super weird.
                    // let the original error be the failure reason.
                    if (er2 || !stat.isDirectory()) cb(er, made)
                    else cb(null, made);
                });
                break;
        }
    });
}

mkdirP.sync = function sync (p, opts, made) {
    if (!opts || typeof opts !== 'object') {
        opts = { mode: opts };
    }
    
    var mode = opts.mode;
    var xfs = opts.fs || fs;
    
    if (mode === undefined) {
        mode = _0777
    }
    if (!made) made = null;

    p = path.resolve(p);

    try {
        xfs.mkdirSync(p, mode);
        made = made || p;
    }
    catch (err0) {
        switch (err0.code) {
            case 'ENOENT' :
                made = sync(path.dirname(p), opts, made);
                sync(p, opts, made);
                break;

            // In the case of any other error, just see if there's a dir
            // there already.  If so, then hooray!  If not, then something
            // is borked.
            default:
                var stat;
                try {
                    stat = xfs.statSync(p);
                }
                catch (err1) {
                    throw err0;
                }
                if (!stat.isDirectory()) throw err0;
                break;
        }
    }

    return made;
};

},
"y2y9xqfX2lCHfMmrhp/Xg0XdhImgLsNWlHJYh84rDi8=":
function (require, module, exports, __dirname, __filename) {
const thenable = require('pull-thenable');

module.exports = async function* awaitable(readable) {
  while (true) {
    try {
      yield await thenable(readable);
    } catch (err) {
      if (err === true) return;
      else throw err;
    }
  }
};

},
"y9bu6ooSJ4eTo3qLTOYHiygPQzsC5cIrHuZVk9FGhw4=":
function (require, module, exports, __dirname, __filename) {
module.exports = function series (continuables, callback) {
  if('function' === typeof continuables)
    return series([].slice.call(arguments))

  if (callback) {
    next(callback)
  } else {
    return next
  }

  function next (callback) {
    continuables.shift() (function (err, value) {
      if (err || !continuables.length)
        return callback(err, value)
      next (callback)
    })
  }
}

},
"yDf9yxVtQ1l4giJCYzfcu0PZTxFCSfqAwl1BMAlILFM=":
function (require, module, exports, __dirname, __filename) {
'use strict';

const object = {};
const hasOwnProperty = object.hasOwnProperty;
const forOwn = (object, callback) => {
	for (const key in object) {
		if (hasOwnProperty.call(object, key)) {
			callback(key, object[key]);
		}
	}
};

const extend = (destination, source) => {
	if (!source) {
		return destination;
	}
	forOwn(source, (key, value) => {
		destination[key] = value;
	});
	return destination;
};

const forEach = (array, callback) => {
	const length = array.length;
	let index = -1;
	while (++index < length) {
		callback(array[index]);
	}
};

const fourHexEscape = (hex) => {
	return '\\u' + ('0000' + hex).slice(-4);
}

const hexadecimal = (code, lowercase) => {
	let hexadecimal = code.toString(16);
	if (lowercase) return hexadecimal;
	return hexadecimal.toUpperCase();
};

const toString = object.toString;
const isArray = Array.isArray;
const isBuffer = (value) => {
	return typeof Buffer === 'function' && Buffer.isBuffer(value);
};
const isObject = (value) => {
	// This is a very simple check, but it’s good enough for what we need.
	return toString.call(value) == '[object Object]';
};
const isString = (value) => {
	return typeof value == 'string' ||
		toString.call(value) == '[object String]';
};
const isNumber = (value) => {
	return typeof value == 'number' ||
		toString.call(value) == '[object Number]';
};
const isFunction = (value) => {
	return typeof value == 'function';
};
const isMap = (value) => {
	return toString.call(value) == '[object Map]';
};
const isSet = (value) => {
	return toString.call(value) == '[object Set]';
};

/*--------------------------------------------------------------------------*/

// https://mathiasbynens.be/notes/javascript-escapes#single
const singleEscapes = {
	'\\': '\\\\',
	'\b': '\\b',
	'\f': '\\f',
	'\n': '\\n',
	'\r': '\\r',
	'\t': '\\t'
	// `\v` is omitted intentionally, because in IE < 9, '\v' == 'v'.
	// '\v': '\\x0B'
};
const regexSingleEscape = /[\\\b\f\n\r\t]/;

const regexDigit = /[0-9]/;
const regexWhitespace = /[\xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000]/;

const escapeEverythingRegex = /([\uD800-\uDBFF][\uDC00-\uDFFF])|([\uD800-\uDFFF])|(['"`])|[^]/g;
const escapeNonAsciiRegex = /([\uD800-\uDBFF][\uDC00-\uDFFF])|([\uD800-\uDFFF])|(['"`])|[^ !#-&\(-\[\]-_a-~]/g;

const jsesc = (argument, options) => {
	const increaseIndentation = () => {
		oldIndent = indent;
		++options.indentLevel;
		indent = options.indent.repeat(options.indentLevel)
	};
	// Handle options
	const defaults = {
		'escapeEverything': false,
		'minimal': false,
		'isScriptContext': false,
		'quotes': 'single',
		'wrap': false,
		'es6': false,
		'json': false,
		'compact': true,
		'lowercaseHex': false,
		'numbers': 'decimal',
		'indent': '\t',
		'indentLevel': 0,
		'__inline1__': false,
		'__inline2__': false
	};
	const json = options && options.json;
	if (json) {
		defaults.quotes = 'double';
		defaults.wrap = true;
	}
	options = extend(defaults, options);
	if (
		options.quotes != 'single' &&
		options.quotes != 'double' &&
		options.quotes != 'backtick'
	) {
		options.quotes = 'single';
	}
	const quote = options.quotes == 'double' ?
		'"' :
		(options.quotes == 'backtick' ?
			'`' :
			'\''
		);
	const compact = options.compact;
	const lowercaseHex = options.lowercaseHex;
	let indent = options.indent.repeat(options.indentLevel);
	let oldIndent = '';
	const inline1 = options.__inline1__;
	const inline2 = options.__inline2__;
	const newLine = compact ? '' : '\n';
	let result;
	let isEmpty = true;
	const useBinNumbers = options.numbers == 'binary';
	const useOctNumbers = options.numbers == 'octal';
	const useDecNumbers = options.numbers == 'decimal';
	const useHexNumbers = options.numbers == 'hexadecimal';

	if (json && argument && isFunction(argument.toJSON)) {
		argument = argument.toJSON();
	}

	if (!isString(argument)) {
		if (isMap(argument)) {
			if (argument.size == 0) {
				return 'new Map()';
			}
			if (!compact) {
				options.__inline1__ = true;
				options.__inline2__ = false;
			}
			return 'new Map(' + jsesc(Array.from(argument), options) + ')';
		}
		if (isSet(argument)) {
			if (argument.size == 0) {
				return 'new Set()';
			}
			return 'new Set(' + jsesc(Array.from(argument), options) + ')';
		}
		if (isBuffer(argument)) {
			if (argument.length == 0) {
				return 'Buffer.from([])';
			}
			return 'Buffer.from(' + jsesc(Array.from(argument), options) + ')';
		}
		if (isArray(argument)) {
			result = [];
			options.wrap = true;
			if (inline1) {
				options.__inline1__ = false;
				options.__inline2__ = true;
			}
			if (!inline2) {
				increaseIndentation();
			}
			forEach(argument, (value) => {
				isEmpty = false;
				if (inline2) {
					options.__inline2__ = false;
				}
				result.push(
					(compact || inline2 ? '' : indent) +
					jsesc(value, options)
				);
			});
			if (isEmpty) {
				return '[]';
			}
			if (inline2) {
				return '[' + result.join(', ') + ']';
			}
			return '[' + newLine + result.join(',' + newLine) + newLine +
				(compact ? '' : oldIndent) + ']';
		} else if (isNumber(argument)) {
			if (json) {
				// Some number values (e.g. `Infinity`) cannot be represented in JSON.
				return JSON.stringify(argument);
			}
			if (useDecNumbers) {
				return String(argument);
			}
			if (useHexNumbers) {
				let hexadecimal = argument.toString(16);
				if (!lowercaseHex) {
					hexadecimal = hexadecimal.toUpperCase();
				}
				return '0x' + hexadecimal;
			}
			if (useBinNumbers) {
				return '0b' + argument.toString(2);
			}
			if (useOctNumbers) {
				return '0o' + argument.toString(8);
			}
		} else if (!isObject(argument)) {
			if (json) {
				// For some values (e.g. `undefined`, `function` objects),
				// `JSON.stringify(value)` returns `undefined` (which isn’t valid
				// JSON) instead of `'null'`.
				return JSON.stringify(argument) || 'null';
			}
			return String(argument);
		} else { // it’s an object
			result = [];
			options.wrap = true;
			increaseIndentation();
			forOwn(argument, (key, value) => {
				isEmpty = false;
				result.push(
					(compact ? '' : indent) +
					jsesc(key, options) + ':' +
					(compact ? '' : ' ') +
					jsesc(value, options)
				);
			});
			if (isEmpty) {
				return '{}';
			}
			return '{' + newLine + result.join(',' + newLine) + newLine +
				(compact ? '' : oldIndent) + '}';
		}
	}

	const regex = options.escapeEverything ? escapeEverythingRegex : escapeNonAsciiRegex;
	result = argument.replace(regex, (char, pair, lone, quoteChar, index, string) => {
		if (pair) {
			if (options.minimal) return pair;
			const first = pair.charCodeAt(0);
			const second = pair.charCodeAt(1);
			if (options.es6) {
				// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae
				const codePoint = (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;
				const hex = hexadecimal(codePoint, lowercaseHex);
				return '\\u{' + hex + '}';
			}
			return fourHexEscape(hexadecimal(first, lowercaseHex)) + fourHexEscape(hexadecimal(second, lowercaseHex));
		}

		if (lone) {
			return fourHexEscape(hexadecimal(lone.charCodeAt(0), lowercaseHex));
		}

		if (
			char == '\0' &&
			!json &&
			!regexDigit.test(string.charAt(index + 1))
		) {
			return '\\0';
		}

		if (quoteChar) {
			if (quoteChar == quote || options.escapeEverything) {
				return '\\' + quoteChar;
			}
			return quoteChar;
		}

		if (regexSingleEscape.test(char)) {
			// no need for a `hasOwnProperty` check here
			return singleEscapes[char];
		}

		if (options.minimal && !regexWhitespace.test(char)) {
			return char;
		}

		const hex = hexadecimal(char.charCodeAt(0), lowercaseHex);
		if (json || hex.length > 2) {
			return fourHexEscape(hex);
		}

		return '\\x' + ('00' + hex).slice(-2);
	});

	if (quote == '`') {
		result = result.replace(/\$\{/g, '\\${');
	}
	if (options.isScriptContext) {
		// https://mathiasbynens.be/notes/etago
		result = result
			.replace(/<\/(script|style)/gi, '<\\/$1')
			.replace(/<!--/g, json ? '\\u003C!--' : '\\x3C!--');
	}
	if (options.wrap) {
		result = quote + result + quote;
	}
	return result;
};

jsesc.version = '3.0.2';

module.exports = jsesc;

},
"yFQ9igUdyeN0+gBEoIeUDBANrY3ZyD99nos/cwXw6+U=":
function (require, module, exports, __dirname, __filename) {
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.StreamReader = exports.EndOfStreamError = void 0;
const EndOfFileStream_1 = require("./EndOfFileStream");
var EndOfFileStream_2 = require("./EndOfFileStream");
Object.defineProperty(exports, "EndOfStreamError", { enumerable: true, get: function () { return EndOfFileStream_2.EndOfStreamError; } });
class Deferred {
    constructor() {
        this.resolve = () => null;
        this.reject = () => null;
        this.promise = new Promise((resolve, reject) => {
            this.reject = reject;
            this.resolve = resolve;
        });
    }
}
const maxStreamReadSize = 1 * 1024 * 1024; // Maximum request length on read-stream operation
class StreamReader {
    constructor(s) {
        this.s = s;
        /**
         * Deferred read request
         */
        this.request = null;
        this.endOfStream = false;
        /**
         * Store peeked data
         * @type {Array}
         */
        this.peekQueue = [];
        if (!s.read || !s.once) {
            throw new Error('Expected an instance of stream.Readable');
        }
        this.s.once('end', () => this.reject(new EndOfFileStream_1.EndOfStreamError()));
        this.s.once('error', err => this.reject(err));
        this.s.once('close', () => this.reject(new Error('Stream closed')));
    }
    /**
     * Read ahead (peek) from stream. Subsequent read or peeks will return the same data
     * @param uint8Array - Uint8Array (or Buffer) to store data read from stream in
     * @param offset - Offset target
     * @param length - Number of bytes to read
     * @returns Number of bytes peeked
     */
    async peek(uint8Array, offset, length) {
        const bytesRead = await this.read(uint8Array, offset, length);
        this.peekQueue.push(uint8Array.subarray(offset, offset + bytesRead)); // Put read data back to peek buffer
        return bytesRead;
    }
    /**
     * Read chunk from stream
     * @param buffer - Target Uint8Array (or Buffer) to store data read from stream in
     * @param offset - Offset target
     * @param length - Number of bytes to read
     * @returns Number of bytes read
     */
    async read(buffer, offset, length) {
        if (length === 0) {
            return 0;
        }
        if (this.peekQueue.length === 0 && this.endOfStream) {
            throw new EndOfFileStream_1.EndOfStreamError();
        }
        let remaining = length;
        let bytesRead = 0;
        // consume peeked data first
        while (this.peekQueue.length > 0 && remaining > 0) {
            const peekData = this.peekQueue.pop(); // Front of queue
            if (!peekData)
                throw new Error('peekData should be defined');
            const lenCopy = Math.min(peekData.length, remaining);
            buffer.set(peekData.subarray(0, lenCopy), offset + bytesRead);
            bytesRead += lenCopy;
            remaining -= lenCopy;
            if (lenCopy < peekData.length) {
                // remainder back to queue
                this.peekQueue.push(peekData.subarray(lenCopy));
            }
        }
        // continue reading from stream if required
        while (remaining > 0 && !this.endOfStream) {
            const reqLen = Math.min(remaining, maxStreamReadSize);
            const chunkLen = await this._read(buffer, offset + bytesRead, reqLen);
            bytesRead += chunkLen;
            if (chunkLen < reqLen)
                break;
            remaining -= chunkLen;
        }
        return bytesRead;
    }
    /**
     * Read chunk from stream
     * @param buffer Target Uint8Array (or Buffer) to store data read from stream in
     * @param offset Offset target
     * @param length Number of bytes to read
     * @returns Number of bytes read
     */
    async _read(buffer, offset, length) {
        if (this.request)
            throw new Error('Concurrent read operation?');
        const readBuffer = this.s.read(length);
        if (readBuffer) {
            buffer.set(readBuffer, offset);
            return readBuffer.length;
        }
        else {
            this.request = {
                buffer,
                offset,
                length,
                deferred: new Deferred()
            };
            this.s.once('readable', () => {
                this.tryRead();
            });
            return this.request.deferred.promise;
        }
    }
    tryRead() {
        if (!this.request)
            throw new Error('this.request should be defined');
        const readBuffer = this.s.read(this.request.length);
        if (readBuffer) {
            this.request.buffer.set(readBuffer, this.request.offset);
            this.request.deferred.resolve(readBuffer.length);
            this.request = null;
        }
        else {
            this.s.once('readable', () => {
                this.tryRead();
            });
        }
    }
    reject(err) {
        this.endOfStream = true;
        if (this.request) {
            this.request.deferred.reject(err);
            this.request = null;
        }
    }
}
exports.StreamReader = StreamReader;

},
"yT/gl3q/fLIpwi9YKoQILA9RbNRsI3yCPssV9NNyh9w=":
function (require, module, exports, __dirname, __filename) {
module.exports = function authGlue (sbot, layered, isBlocking) {
  // Whenever we create a new block, immediately disconnect from peers we just
  // blocked, if they are connected at all
  layered.onEdge((orig, dest, value) => {
    // if WE are BLOCKING a CONNECTED PEER
    if (orig === sbot.id && value === -1 && sbot.peers[dest]) {
      sbot.peers[dest].forEach(rpc => rpc.close(true))
      sbot.peers[dest] = []
    }
  })

  // Blocked peers also cannot *initiate* new connections
  sbot.auth.hook(function (fn, args) {
    const self = this
    const [feedId, cb] = args
    isBlocking({ source: sbot.id, dest: feedId }, (_err, blocked) => {
      if (blocked) cb(new Error('client is blocked'))
      else fn.apply(self, args)
    })
  })
}

},
"ybzGnP5/vfS9X8fXCDvjnVukKNGL25awUAYAXG1ITkc=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2020 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const ssbKeys = require('ssb-keys');
const Ref = require('ssb-ref');
module.exports = {
    name: 'publishUtilsBack',
    version: '1.0.0',
    manifest: {
        publish: 'async',
        publishAbout: 'async',
    },
    permissions: {
        master: {
            allow: ['publish', 'publishAbout'],
        },
    },
    init: function init(ssb) {
        var _a, _b;
        if (!((_a = ssb.blobs) === null || _a === void 0 ? void 0 : _a.push)) {
            throw new Error('"publishUtilsBack" is missing required plugin "ssb-blobs"');
        }
        if (!((_b = ssb.blobsUtils) === null || _b === void 0 ? void 0 : _b.addFromPath)) {
            throw new Error('"publishUtilsBack" is missing required plugin "blobsUtils"');
        }
        return {
            publish(content, cb) {
                if (content.mentions) {
                    for (const mention of content.mentions) {
                        if (Ref.isBlob(mention.link)) {
                            ssb.blobs.push(mention.link, (err) => {
                                if (err)
                                    console.error(err);
                            });
                        }
                    }
                }
                if (content.recps) {
                    try {
                        content = ssbKeys.box(content, content.recps
                            .map((e) => Ref.isFeed(e) ? e : Ref.isFeed(e.link) ? e.link : void 0)
                            .filter((x) => !!x));
                    }
                    catch (e) {
                        return cb(e);
                    }
                }
                ssb.publish(content, (err, msg) => {
                    if (err)
                        console.error(err);
                    if (cb)
                        cb(err, msg);
                });
            },
            publishAbout(content, cb) {
                if (content.image && !Ref.isBlobId(content.image[0])) {
                    ssb.blobsUtils.addFromPath(content.image, (err, hash) => {
                        if (err)
                            return console.error(err);
                        content.image = hash;
                        ssb.publish(content, (err2, msg) => {
                            if (err2)
                                console.error(err2);
                            if (cb)
                                cb(err2, msg);
                        });
                    });
                }
                else {
                    ssb.publish(content, (err, msg) => {
                        if (err)
                            console.error(err);
                        if (cb)
                            cb(err, msg);
                    });
                }
            },
        };
    },
};
//# sourceMappingURL=publishUtilsBack.js.map
},
"yds//vKsQ82TtChBR83Uv7Jk7sCtGj5pEJvANxsSjuc=":
function (require, module, exports, __dirname, __filename) {
const assert = require("assert")
const path = require("path")
const fs = require("fs")
let glob = undefined
try {
  glob = require("glob")
} catch (_err) {
  // treat glob as optional.
}

const defaultGlobOpts = {
  nosort: true,
  silent: true
}

// for EMFILE handling
let timeout = 0

const isWindows = (process.platform === "win32")

const defaults = options => {
  const methods = [
    'unlink',
    'chmod',
    'stat',
    'lstat',
    'rmdir',
    'readdir'
  ]
  methods.forEach(m => {
    options[m] = options[m] || fs[m]
    m = m + 'Sync'
    options[m] = options[m] || fs[m]
  })

  options.maxBusyTries = options.maxBusyTries || 3
  options.emfileWait = options.emfileWait || 1000
  if (options.glob === false) {
    options.disableGlob = true
  }
  if (options.disableGlob !== true && glob === undefined) {
    throw Error('glob dependency not found, set `options.disableGlob = true` if intentional')
  }
  options.disableGlob = options.disableGlob || false
  options.glob = options.glob || defaultGlobOpts
}

const rimraf = (p, options, cb) => {
  if (typeof options === 'function') {
    cb = options
    options = {}
  }

  assert(p, 'rimraf: missing path')
  assert.equal(typeof p, 'string', 'rimraf: path should be a string')
  assert.equal(typeof cb, 'function', 'rimraf: callback function required')
  assert(options, 'rimraf: invalid options argument provided')
  assert.equal(typeof options, 'object', 'rimraf: options should be object')

  defaults(options)

  let busyTries = 0
  let errState = null
  let n = 0

  const next = (er) => {
    errState = errState || er
    if (--n === 0)
      cb(errState)
  }

  const afterGlob = (er, results) => {
    if (er)
      return cb(er)

    n = results.length
    if (n === 0)
      return cb()

    results.forEach(p => {
      const CB = (er) => {
        if (er) {
          if ((er.code === "EBUSY" || er.code === "ENOTEMPTY" || er.code === "EPERM") &&
              busyTries < options.maxBusyTries) {
            busyTries ++
            // try again, with the same exact callback as this one.
            return setTimeout(() => rimraf_(p, options, CB), busyTries * 100)
          }

          // this one won't happen if graceful-fs is used.
          if (er.code === "EMFILE" && timeout < options.emfileWait) {
            return setTimeout(() => rimraf_(p, options, CB), timeout ++)
          }

          // already gone
          if (er.code === "ENOENT") er = null
        }

        timeout = 0
        next(er)
      }
      rimraf_(p, options, CB)
    })
  }

  if (options.disableGlob || !glob.hasMagic(p))
    return afterGlob(null, [p])

  options.lstat(p, (er, stat) => {
    if (!er)
      return afterGlob(null, [p])

    glob(p, options.glob, afterGlob)
  })

}

// Two possible strategies.
// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR
// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR
//
// Both result in an extra syscall when you guess wrong.  However, there
// are likely far more normal files in the world than directories.  This
// is based on the assumption that a the average number of files per
// directory is >= 1.
//
// If anyone ever complains about this, then I guess the strategy could
// be made configurable somehow.  But until then, YAGNI.
const rimraf_ = (p, options, cb) => {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')

  // sunos lets the root user unlink directories, which is... weird.
  // so we have to lstat here and make sure it's not a dir.
  options.lstat(p, (er, st) => {
    if (er && er.code === "ENOENT")
      return cb(null)

    // Windows can EPERM on stat.  Life is suffering.
    if (er && er.code === "EPERM" && isWindows)
      fixWinEPERM(p, options, er, cb)

    if (st && st.isDirectory())
      return rmdir(p, options, er, cb)

    options.unlink(p, er => {
      if (er) {
        if (er.code === "ENOENT")
          return cb(null)
        if (er.code === "EPERM")
          return (isWindows)
            ? fixWinEPERM(p, options, er, cb)
            : rmdir(p, options, er, cb)
        if (er.code === "EISDIR")
          return rmdir(p, options, er, cb)
      }
      return cb(er)
    })
  })
}

const fixWinEPERM = (p, options, er, cb) => {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')

  options.chmod(p, 0o666, er2 => {
    if (er2)
      cb(er2.code === "ENOENT" ? null : er)
    else
      options.stat(p, (er3, stats) => {
        if (er3)
          cb(er3.code === "ENOENT" ? null : er)
        else if (stats.isDirectory())
          rmdir(p, options, er, cb)
        else
          options.unlink(p, cb)
      })
  })
}

const fixWinEPERMSync = (p, options, er) => {
  assert(p)
  assert(options)

  try {
    options.chmodSync(p, 0o666)
  } catch (er2) {
    if (er2.code === "ENOENT")
      return
    else
      throw er
  }

  let stats
  try {
    stats = options.statSync(p)
  } catch (er3) {
    if (er3.code === "ENOENT")
      return
    else
      throw er
  }

  if (stats.isDirectory())
    rmdirSync(p, options, er)
  else
    options.unlinkSync(p)
}

const rmdir = (p, options, originalEr, cb) => {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')

  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)
  // if we guessed wrong, and it's not a directory, then
  // raise the original error.
  options.rmdir(p, er => {
    if (er && (er.code === "ENOTEMPTY" || er.code === "EEXIST" || er.code === "EPERM"))
      rmkids(p, options, cb)
    else if (er && er.code === "ENOTDIR")
      cb(originalEr)
    else
      cb(er)
  })
}

const rmkids = (p, options, cb) => {
  assert(p)
  assert(options)
  assert(typeof cb === 'function')

  options.readdir(p, (er, files) => {
    if (er)
      return cb(er)
    let n = files.length
    if (n === 0)
      return options.rmdir(p, cb)
    let errState
    files.forEach(f => {
      rimraf(path.join(p, f), options, er => {
        if (errState)
          return
        if (er)
          return cb(errState = er)
        if (--n === 0)
          options.rmdir(p, cb)
      })
    })
  })
}

// this looks simpler, and is strictly *faster*, but will
// tie up the JavaScript thread and fail on excessively
// deep directory trees.
const rimrafSync = (p, options) => {
  options = options || {}
  defaults(options)

  assert(p, 'rimraf: missing path')
  assert.equal(typeof p, 'string', 'rimraf: path should be a string')
  assert(options, 'rimraf: missing options')
  assert.equal(typeof options, 'object', 'rimraf: options should be object')

  let results

  if (options.disableGlob || !glob.hasMagic(p)) {
    results = [p]
  } else {
    try {
      options.lstatSync(p)
      results = [p]
    } catch (er) {
      results = glob.sync(p, options.glob)
    }
  }

  if (!results.length)
    return

  for (let i = 0; i < results.length; i++) {
    const p = results[i]

    let st
    try {
      st = options.lstatSync(p)
    } catch (er) {
      if (er.code === "ENOENT")
        return

      // Windows can EPERM on stat.  Life is suffering.
      if (er.code === "EPERM" && isWindows)
        fixWinEPERMSync(p, options, er)
    }

    try {
      // sunos lets the root user unlink directories, which is... weird.
      if (st && st.isDirectory())
        rmdirSync(p, options, null)
      else
        options.unlinkSync(p)
    } catch (er) {
      if (er.code === "ENOENT")
        return
      if (er.code === "EPERM")
        return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)
      if (er.code !== "EISDIR")
        throw er

      rmdirSync(p, options, er)
    }
  }
}

const rmdirSync = (p, options, originalEr) => {
  assert(p)
  assert(options)

  try {
    options.rmdirSync(p)
  } catch (er) {
    if (er.code === "ENOENT")
      return
    if (er.code === "ENOTDIR")
      throw originalEr
    if (er.code === "ENOTEMPTY" || er.code === "EEXIST" || er.code === "EPERM")
      rmkidsSync(p, options)
  }
}

const rmkidsSync = (p, options) => {
  assert(p)
  assert(options)
  options.readdirSync(p).forEach(f => rimrafSync(path.join(p, f), options))

  // We only end up here once we got ENOTEMPTY at least once, and
  // at this point, we are guaranteed to have removed all the kids.
  // So, we know that it won't be ENOENT or ENOTDIR or anything else.
  // try really hard to delete stuff on windows, because it has a
  // PROFOUNDLY annoying habit of not closing handles promptly when
  // files are deleted, resulting in spurious ENOTEMPTY errors.
  const retries = isWindows ? 100 : 1
  let i = 0
  do {
    let threw = true
    try {
      const ret = options.rmdirSync(p, options)
      threw = false
      return ret
    } finally {
      if (++i < retries && threw)
        continue
    }
  } while (true)
}

module.exports = rimraf
rimraf.sync = rimrafSync

},
"ye8f470QDZ1xvARx3PD3Ccn2+9EX/dg4ZTM7U9vwQi8=":
function (require, module, exports, __dirname, __filename) {
'use strict'

function id (e) { return e }
var prop = require('../util/prop')

module.exports = function asyncMap (map) {
  if(!map) return id
  map = prop(map)
  var busy = false, abortCb, aborted
  return function (read) {
    return function next (abort, cb) {
      if(aborted) return cb(aborted)
      if(abort) {
        aborted = abort
        if(!busy) read(abort, function (err) {
          //incase the source has already ended normally,
          //we should pass our own error.
          cb(abort)
        })
        else read(abort, function (err) {
          //if we are still busy, wait for the mapper to complete.
          if(busy) abortCb = cb
          else cb(abort)
        })
      }
      else
        read(null, function (end, data) {
          if(end) cb(end)
          else if(aborted) cb(aborted)
          else {
            busy = true
            map(data, function (err, data) {
              busy = false
              if(aborted) {
                cb(aborted)
                abortCb && abortCb(aborted)
              }
              else if(err) next (err, cb)
              else cb(null, data)
            })
          }
        })
    }
  }
}








},
"ygMPXluo7BBlYtJFSOCqOVbFDicUpzn7/tAxiQSfgmg=":
function (require, module, exports, __dirname, __filename) {
var fs = require('fs')

module.exports = function (path, opts, cb) {
  if('function' == typeof opts)
    cb = opts, opts = null
  var flags = opts && opts.flags || 'w'
  var mode = opts && opts.mode || 0666
  var pos = 0
  return function (read) {
    fs.open(path, flags, mode, function (err, fd) {
      if(err) return read(err, cb)
      read(null, function next (end, data) {
        if(end === true) fs.close(fd, cb)
        else if(end)     cb(end) //error!
        else {
          if(typeof data === 'string') data = Buffer.from(data) // convert strings to buffers
          fs.write(fd, data, 0, data.length, pos, function (err, bytes) {
            if(err) read(err, function () { fs.close(fd, cb) })
            else    pos += bytes, read(null, next)
          })
        }
      })
    })
  }
}







},
"yh3VqhoCEumEBxUpV/a7PfMJrn3HYirU3UQSOXjPUVA=":
function (require, module, exports, __dirname, __filename) {
"use strict";
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
const fromEvent = require('pull-stream-util/from-event');
module.exports = {
    name: 'syncing',
    version: '1.0.0',
    manifest: {
        migrating: 'source',
        indexing: 'source',
    },
    permissions: {
        master: {
            allow: ['migrating', 'indexing'],
        },
    },
    init: function init(ssb) {
        return {
            migrating() {
                return fromEvent('ssb:db2:migrate:progress', ssb);
            },
            indexing() {
                return fromEvent('ssb:db2:indexing:progress', ssb);
            },
        };
    },
};
//# sourceMappingURL=syncing.js.map
},
"yrRL0OQGG5Te23FPh+t2kFRORwqygkFAcmixlRWItCc=":
function (require, module, exports, __dirname, __filename) {
module.exports = function (op, done) {
  return new ThroughStream(op, done)
}

function noop () {}

function ThroughStream(op, done) {
  this._op = op || noop
  this._done = done || noop
  this.paused = true
  this.ended = false
  this.source = this.sink = null
}

ThroughStream.prototype.resume = function () {
  if(this.source && this.sink && !(this.paused = this.sink.paused)) this.source.resume()
}

ThroughStream.prototype.end = function (err) {
  this.ended = err || true
  this._done(err === true ? null : err)
  return this.sink.end(err)
}

ThroughStream.prototype.abort = function (err) {
  //should this check if the sink has already ended?
  this.ended = err
  return this.source.abort(err)
}

ThroughStream.prototype.write = function (data) {
  this._op(data)
  this.sink.write(data)
}

ThroughStream.prototype.pipe = require('../pipe')

//module.exports = ThroughStream

},
"yy3RxsYxK4WeCWIDyerJTQ1+zGvtvGQap8J2T2jW3I8=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2021 Anders Rune Jensen
//
// SPDX-License-Identifier: LGPL-3.0-only

const Obv = require('obz')
const Level = require('level')
const debounce = require('lodash.debounce')
const encodings = require('level-codec/lib/encodings')
const path = require('path')
const Debug = require('debug')
const DeferredPromise = require('p-defer')
const { indexesPath } = require('../defaults')

function thenMaybeReportError(err) {
  if (err) console.error(err)
}

module.exports = class Plugin {
  constructor(log, dir, name, version, keyEncoding, valueEncoding) {
    this.log = log
    this.name = name
    this._keyEncoding = keyEncoding
    this._valueEncoding = valueEncoding
    const debug = Debug('ssb:db2:' + name)

    const indexPath = path.join(indexesPath(dir), name)
    if (typeof window === 'undefined') {
      // outside browser
      const mkdirp = require('mkdirp')
      mkdirp.sync(indexPath)
    }
    this.level = Level(indexPath)

    const META = '\x00'
    const chunkSize = 2048
    let processedSeq = 0
    let processedOffset = -1
    this.offset = Obv() // persisted offset
    this._stateLoaded = DeferredPromise()
    this.batch = []

    this.flush = (cb) => {
      if (processedOffset === this.offset.value || this.level.isClosed()) return cb()
      if (!this.onFlush) this.onFlush = (cb2) => cb2()

      const processedOffsetAtFlush = processedOffset
      const processedSeqAtFlush = processedSeq

      this.onFlush((err) => {
        if (err) return cb(err)

        // 1st, persist the operations in the batch array
        this.level.batch(
          this.batch,
          { keyEncoding: this.keyEncoding, valueEncoding: this.valueEncoding },
          (err2) => {
            if (err2) return cb(err2)
            if (this.level.isClosed()) return cb()

            // 2nd, persist the META because it has its own valueEncoding
            this.level.put(
              META,
              { version, offset: processedOffsetAtFlush, processed: processedSeqAtFlush },
              { valueEncoding: 'json' },
              (err3) => {
                if (err3) cb(err3)
                else {
                  this.offset.set(processedOffsetAtFlush)
                  cb()
                }
              }
            )
          }
        )
        this.batch = []
      })
    }

    const liveFlush = debounce(this.flush, 250)

    this.onRecord = function onRecord(record, isLive) {
      let changes = 0
      if (record.offset > processedOffset) {
        if (record.value) this.processRecord(record, processedSeq)
        changes = this.batch.length
        processedSeq++
        processedOffset = record.offset
      }

      if (changes > chunkSize) this.flush(thenMaybeReportError)
      else if (isLive) liveFlush(thenMaybeReportError)
    }

    this.level.get(META, { valueEncoding: 'json' }, (err, status) => {
      debug(`got index status:`, status)

      if (status && status.version === version) {
        processedSeq = status.processed
        processedOffset = status.offset
        this.offset.set(status.offset)
        if (this.onLoaded) {
          this.onLoaded(() => {
            this._stateLoaded.resolve()
          })
        } else {
          this._stateLoaded.resolve()
        }
      } else {
        this.level.clear(() => {
          processedOffset = -1
          this.offset.set(-1)
          this._stateLoaded.resolve()
        })
      }
    })
  }

  get stateLoaded() {
    return this._stateLoaded.promise
  }

  // The reason why we need this is that `pull-level` (often used to read these
  // level indexes) only supports objects of shape {encode,decode,type,buffer}
  // for `keyEncoding` and `valueEncoding`. Actually, it's `level-post` that
  // doesn't support it, but `level-post` is a dependency in `pull-level`.
  // Note, this._keyEncoding and this._valueEncoding are strings.
  get keyEncoding() {
    if (encodings[this._keyEncoding]) return encodings[this._keyEncoding]
    else return undefined
  }

  get valueEncoding() {
    if (encodings[this._valueEncoding]) return encodings[this._valueEncoding]
    else return undefined
  }

  remove(...args) {
    this.level.clear(...args)
  }

  close(cb) {
    this.level.close(cb)
  }

  processRecord() {
    throw new Error('processRecord() is missing an implementation')
  }

  // used for reindexing encrypted content
  indexesContent() {
    return true
  }
}

},
"yz7aZ0O5ydhNxd4xn3Xmg/ZWLRZ7yqxW8C+3KSSdPwY=":
function (require, module, exports, __dirname, __filename) {
"use strict"

// (a, y, c, l, h) = (array, y[, cmp, lo, hi])

function ge(a, y, c, l, h) {
  var i = h + 1;
  while (l <= h) {
    var m = (l + h) >>> 1, x = a[m];
    var p = (c !== undefined) ? c(x, y) : (x - y);
    if (p >= 0) { i = m; h = m - 1 } else { l = m + 1 }
  }
  return i;
};

function gt(a, y, c, l, h) {
  var i = h + 1;
  while (l <= h) {
    var m = (l + h) >>> 1, x = a[m];
    var p = (c !== undefined) ? c(x, y) : (x - y);
    if (p > 0) { i = m; h = m - 1 } else { l = m + 1 }
  }
  return i;
};

function lt(a, y, c, l, h) {
  var i = l - 1;
  while (l <= h) {
    var m = (l + h) >>> 1, x = a[m];
    var p = (c !== undefined) ? c(x, y) : (x - y);
    if (p < 0) { i = m; l = m + 1 } else { h = m - 1 }
  }
  return i;
};

function le(a, y, c, l, h) {
  var i = l - 1;
  while (l <= h) {
    var m = (l + h) >>> 1, x = a[m];
    var p = (c !== undefined) ? c(x, y) : (x - y);
    if (p <= 0) { i = m; l = m + 1 } else { h = m - 1 }
  }
  return i;
};

function eq(a, y, c, l, h) {
  while (l <= h) {
    var m = (l + h) >>> 1, x = a[m];
    var p = (c !== undefined) ? c(x, y) : (x - y);
    if (p === 0) { return m }
    if (p <= 0) { l = m + 1 } else { h = m - 1 }
  }
  return -1;
};

function norm(a, y, c, l, h, f) {
  if (typeof c === 'function') {
    return f(a, y, c, (l === undefined) ? 0 : l | 0, (h === undefined) ? a.length - 1 : h | 0);
  }
  return f(a, y, undefined, (c === undefined) ? 0 : c | 0, (l === undefined) ? a.length - 1 : l | 0);
}

module.exports = {
  ge: function(a, y, c, l, h) { return norm(a, y, c, l, h, ge)},
  gt: function(a, y, c, l, h) { return norm(a, y, c, l, h, gt)},
  lt: function(a, y, c, l, h) { return norm(a, y, c, l, h, lt)},
  le: function(a, y, c, l, h) { return norm(a, y, c, l, h, le)},
  eq: function(a, y, c, l, h) { return norm(a, y, c, l, h, eq)}
}

},
"z8jXJHbYZVCxuRCMmoVkAGXw4Wms7d4nOEqwB4D0jIs=":
function (require, module, exports, __dirname, __filename) {
"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
const secret_stack_decorators_1 = require("secret-stack-decorators");
const path = require("path");
const run = require("promisify-tuple");
const Notify = require('pull-notify');
const pull = require('pull-stream');
const drainGently = require('pull-drain-gently');
const trammel = require('trammel');
const debug = require('debug')('ssb:blobs-purge');
function heuristic(blob) {
    const sizeInKb = blob.size * 9.7e-4;
    const ageInDays = (Date.now() - blob.ts) * 1.2e-8;
    return sizeInKb * ageInDays;
}
function bytesToMB(x) {
    return Math.round(x * 9.53e-7);
}
const DEFAULT_CPU_MAX = 50;
const DEFAULT_MAX_PAUSE = 15e3;
const DEFAULT_STORAGE_LIMIT = 10e9;
let blobsPurge = class blobsPurge {
    constructor(ssb, config) {
        this.isMyBlob = (blobId, cb) => {
            let isMine = false;
            pull(this.mentionsBlob(blobId), drainGently({ ceiling: this.cpuMax, wait: 60, maxPause: this.maxPause }, (msg) => {
                if (msg.value.author === this.ssb.id) {
                    isMine = true;
                    return false;
                }
                else
                    return;
            }, () => {
                cb(null, isMine);
            }));
        };
        this.resume = async () => {
            var _a;
            this.notifier({ event: 'resumed' });
            const [e1, used] = await run(trammel)(this.blobsPath, {
                type: 'raw',
            });
            if (e1)
                throw e1;
            if (used < this.storageLimit) {
                debug('Blobs directory already fits within our predetermined limit: %dMB < %dMB', bytesToMB(used), bytesToMB(this.storageLimit));
                debug('Paused the purge task');
                this.notifier({ event: 'paused' });
                this.scheduleNextResume();
                return;
            }
            const thresholds = pull.values([1e7, 1e6, 1e5, 1e4, 1e3, 0]);
            (_a = this.task) === null || _a === void 0 ? void 0 : _a.abort();
            this.task = pull(thresholds, pull.map((threshold) => pull(this.ssb.blobs.ls({ meta: true }), pull.filter((blob) => heuristic(blob) > threshold))), pull.flatten(), pull.asyncMap(this.maybeDelete), drainGently({ ceiling: this.cpuMax, wait: 60, maxPause: this.maxPause }, (done) => {
                if (!done)
                    return;
                debug('Paused the purge task');
                this.notifier({ event: 'paused' });
                return false;
            }, this.scheduleNextResume));
        };
        this.maybeDelete = async (blob, cb) => {
            const [e1, used] = await run(trammel)(this.blobsPath, {
                type: 'raw',
            });
            if (e1)
                return cb(e1);
            if (used > this.storageLimit) {
                const [e2, isMine] = await run(this.isMyBlob)(blob.id);
                if (e2)
                    return cb(e2);
                if (isMine)
                    return cb(null, false);
                debug('Blobs directory occupies too much space: %dMB', bytesToMB(used));
                debug('Delete blob %s which weighs %dMB', blob.id, bytesToMB(blob.size));
                const [e3] = await run(this.ssb.blobs.rm)(blob.id);
                if (e3)
                    return cb(e3);
                this.notifier({ event: 'deleted', blobId: blob.id });
                cb(null, false);
            }
            else {
                debug('Blobs directory now fits within our predetermined limit of %dMB', bytesToMB(this.storageLimit));
                cb(null, true);
            }
        };
        this.scheduleNextResume = () => {
            var _a, _b;
            let count = 0;
            (_a = this.task) === null || _a === void 0 ? void 0 : _a.abort();
            this.task = pull((_b = this.ssb.blobs) === null || _b === void 0 ? void 0 : _b.changes(), pull.drain(() => {
                count += 1;
                if (count < 10)
                    return;
                debug('Resuming the purge task because new blobs have been added');
                this.resume();
                return false;
            }));
        };
        this.start = (opts) => {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k;
            this.storageLimit =
                (_c = (_b = (_a = this.config.blobsPurge) === null || _a === void 0 ? void 0 : _a.storageLimit) !== null && _b !== void 0 ? _b : opts === null || opts === void 0 ? void 0 : opts.storageLimit) !== null && _c !== void 0 ? _c : DEFAULT_STORAGE_LIMIT;
            this.cpuMax =
                (_f = (_e = (_d = this.config.blobsPurge) === null || _d === void 0 ? void 0 : _d.cpuMax) !== null && _e !== void 0 ? _e : opts === null || opts === void 0 ? void 0 : opts.cpuMax) !== null && _f !== void 0 ? _f : DEFAULT_CPU_MAX;
            this.maxPause =
                (_j = (_h = (_g = this.config.blobsPurge) === null || _g === void 0 ? void 0 : _g.maxPause) !== null && _h !== void 0 ? _h : opts === null || opts === void 0 ? void 0 : opts.maxPause) !== null && _j !== void 0 ? _j : DEFAULT_MAX_PAUSE;
            (_k = this.task) === null || _k === void 0 ? void 0 : _k.abort();
            this.task = void 0;
            debug('Started the purge task ');
            this.resume();
        };
        this.stop = () => {
            var _a;
            (_a = this.task) === null || _a === void 0 ? void 0 : _a.abort();
            this.task = void 0;
            debug('Stopped the purge task ');
        };
        this.changes = () => {
            return this.notifier.listen();
        };
        this.ssb = ssb;
        this.config = config;
        this.blobsPath = path.join(config.path, 'blobs');
        this.notifier = Notify();
        this.init();
    }
    init() {
        var _a, _b, _c, _d, _e;
        if (!((_a = this.ssb.blobs) === null || _a === void 0 ? void 0 : _a.ls) || !((_b = this.ssb.blobs) === null || _b === void 0 ? void 0 : _b.rm)) {
            throw new Error('"ssb-blobs-purge" is missing required plugin "ssb-blobs"');
        }
        if (!((_c = this.ssb.db) === null || _c === void 0 ? void 0 : _c.query) && !((_d = this.ssb.backlinks) === null || _d === void 0 ? void 0 : _d.read)) {
            throw new Error('"ssb-blobs-purge" is missing required "ssb-db2" OR "ssb-backlinks"');
        }
        if (((_e = this.ssb.db) === null || _e === void 0 ? void 0 : _e.query) && !this.ssb.db.operators.fullMentions) {
            throw new Error('"ssb-blobs-purge" is missing required "ssb-db2/full-mentions" plugin');
        }
    }
    mentionsBlob(blobId) {
        var _a;
        if ((_a = this.ssb.db) === null || _a === void 0 ? void 0 : _a.query) {
            const { where, fullMentions, toPullStream } = this.ssb.db.operators;
            return this.ssb.db.query(where(fullMentions(blobId)), toPullStream());
        }
        else {
            return this.ssb.backlinks.read({
                query: [{ $filter: { dest: blobId } }],
                index: 'DTA',
            });
        }
    }
};
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], blobsPurge.prototype, "start", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('sync')
], blobsPurge.prototype, "stop", void 0);
__decorate([
    secret_stack_decorators_1.muxrpc('source')
], blobsPurge.prototype, "changes", void 0);
blobsPurge = __decorate([
    secret_stack_decorators_1.plugin('1.0.0')
], blobsPurge);
module.exports = blobsPurge;

},
"zAEO/pUSb4j/uRSuSXJn05UM7H7zNbwqGDa0998R79s=":
function (require, module, exports, __dirname, __filename) {

var udp = require('dgram')
var pipe = require('stream').prototype.pipe
var os = require('os')

module.exports = function (port, loopback) {

  var addresses = {}
  var socket = udp.createSocket({type: 'udp4', reuseAddr: true})

// disable to test if this fixes: https://github.com/dominictarr/broadcast-stream/issues/5
//  process.on('exit', function () {
//    socket.dropMembership('255.255.255.255')
//    socket.close()
//  })

  socket.readable = socket.writable = true

  socket.write = function (message) {
    if('string' === typeof message)
      message = new Buffer(message, 'utf8')
    socket.send(message, 0, message.length, port, '255.255.255.255')
    return true
  }

  socket.end = function () {
    socket.close()
  }

  socket.on('close', function () {
    socket.emit('end')
  })

  var latest = null

  socket.on('message', function (msg, other) {
    if(addresses[other.address] && other.port === port) {
      if(loopback === false) return
      msg.loopback = true
    }

    msg.port = other.port
    msg.address = other.address

    //if paused, remember the latest item.
    //otherwise just drop those messages.
    if(socket.paused)
      return latest = msg

    latest = null
    socket.emit('data', msg)
  })

  socket.pause = function () {
    socket.paused = true
    return this
  }

  socket.resume = function () {
    socket.paused = false
    if(latest) {
      var msg = latest
      latest = null
      socket.emit('data', msg)
    }
    return this
  }

  socket.bind(port)
  socket.on('listening', function () {
    var ifaces = os.networkInterfaces()
    for(var k in ifaces)
      ifaces[k].forEach(function (address) {
        addresses[address.address] = true
      })
    socket.setBroadcast(true)
  })

  socket.pipe = pipe

  return socket
}

},
"zAcLomqBPQ6rU1FGePAfIn5jgpJlHvFwNvMVKTNalcY=":
function (require, module, exports, __dirname, __filename) {
var pushable = require('pull-pushable')
var cat      = require('pull-cat')
var post     = require('level-post')

module.exports = function (db, opts) {
  opts = opts || {}

  var l = pushable(function (err) {
    if(opts.onAbort) opts.onAbort(err)
    cleanup()
  })

  var cleanup = post(db, opts, function (ch) {
    if(opts.keys === false)
      l.push(ch.value)
    else if(opts.values === false)
      l.push(ch.key)
    else
      l.push(ch)
  })

  return l

}


},
"zFwENznp0VlKGOUYw0UZkxqAiBy3wg7PWi8lMBIuBBE=":
function (require, module, exports, __dirname, __filename) {
var nextTick = require('./next-tick')

function AbstractIterator (db) {
  if (typeof db !== 'object' || db === null) {
    throw new TypeError('First argument must be an abstract-leveldown compliant store')
  }

  this.db = db
  this._ended = false
  this._nexting = false
}

AbstractIterator.prototype.next = function (callback) {
  var self = this

  if (typeof callback !== 'function') {
    throw new Error('next() requires a callback argument')
  }

  if (self._ended) {
    nextTick(callback, new Error('cannot call next() after end()'))
    return self
  }

  if (self._nexting) {
    nextTick(callback, new Error('cannot call next() before previous next() has completed'))
    return self
  }

  self._nexting = true
  self._next(function () {
    self._nexting = false
    callback.apply(null, arguments)
  })

  return self
}

AbstractIterator.prototype._next = function (callback) {
  nextTick(callback)
}

AbstractIterator.prototype.seek = function (target) {
  if (this._ended) {
    throw new Error('cannot call seek() after end()')
  }
  if (this._nexting) {
    throw new Error('cannot call seek() before next() has completed')
  }

  target = this.db._serializeKey(target)
  this._seek(target)
}

AbstractIterator.prototype._seek = function (target) {}

AbstractIterator.prototype.end = function (callback) {
  if (typeof callback !== 'function') {
    throw new Error('end() requires a callback argument')
  }

  if (this._ended) {
    return nextTick(callback, new Error('end() already called on iterator'))
  }

  this._ended = true
  this._end(callback)
}

AbstractIterator.prototype._end = function (callback) {
  nextTick(callback)
}

// Expose browser-compatible nextTick for dependents
AbstractIterator.prototype._nextTick = nextTick

module.exports = AbstractIterator

},
"zJmNEdN+8h26PsfDgO8yRVZG8VHEGuIDURz1yNRIwh8=":
function (require, module, exports, __dirname, __filename) {
"use strict";
const pull = require('pull-stream');
const cat = require('pull-cat');
const Notify = require('pull-notify');
const msAddress = require('multiserver-address');
const debug = require('debug')('ssb:conn-staging');
class ConnStaging {
    constructor() {
        this._peers = new Map();
        this._closed = false;
        this._notifyEvent = Notify();
        this._notifyEntries = Notify();
    }
    _assertNotClosed() {
        if (this._closed) {
            throw new Error('This ConnStaging instance is closed, create a new one.');
        }
    }
    _assertValidAddress(address) {
        if (!msAddress.check(address)) {
            throw new Error('The given address is not a valid multiserver-address');
        }
    }
    _updateLiveEntries() {
        this._notifyEntries(Array.from(this._peers.entries()));
    }
    stage(address, data) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        const now = Date.now();
        if (this._peers.has(address)) {
            const previous = this._peers.get(address);
            this._peers.set(address, { ...previous, stagingUpdated: now, ...data });
            this._updateLiveEntries();
            return false;
        }
        else {
            this._peers.set(address, {
                stagingBirth: now,
                stagingUpdated: now,
                ...data,
            });
            debug('staged peer %s', address);
            this._notifyEvent({ type: 'staged', address });
            this._updateLiveEntries();
            return true;
        }
    }
    unstage(address) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        if (!this._peers.has(address))
            return false;
        this._peers.delete(address);
        debug('unstaged peer %s', address);
        this._notifyEvent({ type: 'unstaged', address });
        this._updateLiveEntries();
        return true;
    }
    get(address) {
        this._assertNotClosed();
        this._assertValidAddress(address);
        return this._peers.get(address);
    }
    entries() {
        this._assertNotClosed();
        return this._peers.entries();
    }
    liveEntries() {
        this._assertNotClosed();
        return cat([
            pull.values([Array.from(this._peers.entries())]),
            this._notifyEntries.listen(),
        ]);
    }
    listen() {
        this._assertNotClosed();
        return this._notifyEvent.listen();
    }
    close() {
        this._closed = true;
        this._notifyEvent.end();
        this._peers.clear();
        debug('closed the ConnStaging instance');
    }
}
module.exports = ConnStaging;

},
"zKrPE75JMEROfV//FutcQKK2S5MFe4htKaYGvgJYnRE=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var implementation = require('./implementation');

module.exports = function getPolyfill() {
	return typeof Object.is === 'function' ? Object.is : implementation;
};

},
"zRr0kgMSWss1BTBetxewVXvLIxmN/x0IflBA1vg7lLU=":
function (require, module, exports, __dirname, __filename) {
// SPDX-FileCopyrightText: 2018-2021 The Manyverse Authors
//
// SPDX-License-Identifier: MPL-2.0
let channel;
// Setup Channel
if (process.env.MANYVERSE_PLATFORM === 'mobile') {
    const rnBridge = require('rn-bridge');
    channel = {
        addListener(type, fn) {
            rnBridge.channel.on(type, fn);
        },
        post(type, msg) {
            rnBridge.channel.post(type, msg);
        },
    };
}
else {
    const { ipcMain } = require('electron');
    const webContentsPromise = process.webContentsP;
    let webContents = null;
    channel = {
        addListener(type, fn) {
            ipcMain.addListener(type, (first, second) => {
                const msg = second !== null && second !== void 0 ? second : first;
                fn(msg);
            });
        },
        post(type, msg) {
            if (webContents) {
                webContents.send(type, msg);
            }
            else {
                webContentsPromise.then((wc) => {
                    webContents = wc;
                    webContents.send(type, msg);
                });
            }
        },
    };
}
// Setup initial communication with the frontend, to create or restore identity
channel.addListener('identity', (request) => {
    const startSSB = () => require('./ssb');
    let response;
    if (request === 'CREATE' || request === 'USE') {
        startSSB();
        response = 'IDENTITY_READY';
    }
    else if (request.startsWith('RESTORE:')) {
        const words = request.split('RESTORE: ')[1].trim();
        const restore = require('./restore');
        response = restore(words);
        if (response === 'IDENTITY_READY')
            startSSB();
    }
    channel.post('identity', response);
});
//# sourceMappingURL=index.js.map
},
"zTbsG31tVyqv98iql6Cr1WMujE6BnVgMUVMOf7ivdfw=":
function (require, module, exports, __dirname, __filename) {
var inherits = require('util').inherits
var RandomAccess = require('random-access-storage')
var fs = require('fs')
var mkdirp = require('mkdirp-classic')
var path = require('path')
var constants = fs.constants || require('constants') // eslint-disable-line

var READONLY = constants.O_RDONLY
var READWRITE = constants.O_RDWR | constants.O_CREAT

module.exports = RandomAccessFile

function RandomAccessFile (filename, opts) {
  if (!(this instanceof RandomAccessFile)) return new RandomAccessFile(filename, opts)
  RandomAccess.call(this)

  if (!opts) opts = {}
  if (opts.directory) filename = path.join(opts.directory, path.resolve('/', filename).replace(/^\w+:\\/, ''))

  this.directory = opts.directory || null
  this.filename = filename
  this.fd = 0

  // makes random-access-storage open in writable mode first
  if (opts.writable || opts.truncate) this.preferReadonly = false

  this._size = opts.size || opts.length || 0
  this._truncate = !!opts.truncate || this._size > 0
  this._rmdir = !!opts.rmdir
  this._lock = opts.lock || noLock
  this._sparse = opts.sparse || noLock
  this._alloc = opts.alloc || Buffer.allocUnsafe
}

inherits(RandomAccessFile, RandomAccess)

RandomAccessFile.prototype._open = function (req) {
  var self = this

  mkdirp(path.dirname(this.filename), ondir)

  function ondir (err) {
    if (err) return req.callback(err)
    open(self, READWRITE, req)
  }
}

RandomAccessFile.prototype._openReadonly = function (req) {
  open(this, READONLY, req)
}

RandomAccessFile.prototype._write = function (req) {
  var data = req.data
  var fd = this.fd

  fs.write(fd, data, 0, req.size, req.offset, onwrite)

  function onwrite (err, wrote) {
    if (err) return req.callback(err)

    req.size -= wrote
    req.offset += wrote

    if (!req.size) return req.callback(null)
    fs.write(fd, data, data.length - req.size, req.size, req.offset, onwrite)
  }
}

RandomAccessFile.prototype._read = function (req) {
  var data = req.data || this._alloc(req.size)
  var fd = this.fd

  if (!req.size) return process.nextTick(readEmpty, req)
  fs.read(fd, data, 0, req.size, req.offset, onread)

  function onread (err, read) {
    if (err) return req.callback(err)
    if (!read) return req.callback(new Error('Could not satisfy length'))

    req.size -= read
    req.offset += read

    if (!req.size) return req.callback(null, data)
    fs.read(fd, data, data.length - req.size, req.size, req.offset, onread)
  }
}

RandomAccessFile.prototype._del = function (req) {
  var fd = this.fd

  fs.fstat(fd, onstat)

  function onstat (err, st) {
    if (err) return req.callback(err)
    if (req.offset + req.size < st.size) return req.callback(null)
    fs.ftruncate(fd, req.offset, ontruncate)
  }

  function ontruncate (err) {
    req.callback(err)
  }
}

RandomAccessFile.prototype._stat = function (req) {
  fs.fstat(this.fd, onstat)

  function onstat (err, st) {
    req.callback(err, st)
  }
}

RandomAccessFile.prototype._close = function (req) {
  var self = this

  fs.close(this.fd, onclose)

  function onclose (err) {
    if (err) return req.callback(err)
    self.fd = 0
    req.callback(null)
  }
}

RandomAccessFile.prototype._destroy = function (req) {
  var self = this

  var root = this.directory && path.resolve(path.join(this.directory, '.'))
  var dir = path.resolve(path.dirname(this.filename))

  fs.unlink(this.filename, onunlink)

  function onunlink (err) {
    if (!self._rmdir || !root || dir === root) return req.callback(err)
    fs.rmdir(dir, onrmdir)
  }

  function onrmdir (err) {
    dir = path.join(dir, '..')
    if (err || dir === root) return req.callback(null)
    fs.rmdir(dir, onrmdir)
  }
}

function open (self, mode, req) {
  if (self.fd) fs.close(self.fd, oncloseold)
  else fs.open(self.filename, mode, onopen)

  function onopen (err, fd) {
    if (err) return req.callback(err)
    self.fd = fd
    if (!self._lock(self.fd)) return req.callback(createLockError(self.filename)) // TODO: fix fd leak here
    if (!self._sparse(self.fd)) return req.callback(createSparseError(self.filename))
    if (!self._truncate || mode === READONLY) return req.callback(null)
    fs.ftruncate(self.fd, self._size, ontruncate)
  }

  function oncloseold (err) {
    if (err) return onerrorafteropen(err)
    self.fd = 0
    fs.open(self.filename, mode, onopen)
  }

  function ontruncate (err) {
    if (err) return onerrorafteropen(err)
    req.callback(null)
  }

  function onerrorafteropen (err) {
    fs.close(self.fd, function () {
      self.fd = 0
      req.callback(err)
    })
  }
}

function readEmpty (req) {
  req.callback(null, Buffer.alloc(0))
}

function noLock (fd) {
  return true
}

function createSparseError (path) {
  var err = new Error('ENOTSPARSE: File could not be marked as sparse')
  err.code = 'ENOTSPARSE'
  err.path = path
  return err
}

function createLockError (path) {
  var err = new Error('ELOCKED: File is locked')
  err.code = 'ELOCKED'
  err.path = path
  return err
}

},
"zXiSEqjSjF1a8LhdARoR44gmjdICViuF8nex7tho8tY=":
function (require, module, exports, __dirname, __filename) {
// master plugin
// allows you to define "master" IDs in the config
// which are given the full rights of the local main ID
module.exports = function (api, opts) {
  var masters = [api.id].concat(opts.master).filter(Boolean)
  api.auth.hook(function (fn, args) {
    var id = args[0]
    var cb = args[1]
    cb(null, ~masters.indexOf(id) ? {allow: null, deny: null} : null)
  })
}

},
"zb7ZljS1I75lUiXfFUfNACleMEHLAoSMZS3a1eZ4fkk=":
function (require, module, exports, __dirname, __filename) {
'use strict';

var ERR_INVALID_OPT_VALUE = require('../../../errors').codes.ERR_INVALID_OPT_VALUE;

function highWaterMarkFrom(options, isDuplex, duplexKey) {
  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;
}

function getHighWaterMark(state, options, duplexKey, isDuplex) {
  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);

  if (hwm != null) {
    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {
      var name = isDuplex ? duplexKey : 'highWaterMark';
      throw new ERR_INVALID_OPT_VALUE(name, hwm);
    }

    return Math.floor(hwm);
  } // Default value


  return state.objectMode ? 16 : 16 * 1024;
}

module.exports = {
  getHighWaterMark: getHighWaterMark
};
},
"zhUf2HR4piU5RpEKm92vHQ4Hy72fokFcRP69u6azc7M=":
function (require, module, exports, __dirname, __filename) {
var sources = require('./sources')
var sinks = require('./sinks')
var throughs = require('./throughs')

function push () {
  var args = [].slice.call(arguments)
  var source = args[0]
  for(var i = 1; i < args.length; i++) {
    source = source.pipe(args[i])
  }
  return source
}

for(var k in sources)  push[k] =  sources[k]
for(var k in sinks)    push[k] =    sinks[k]
for(var k in throughs) push[k] = throughs[k]

module.exports = push

},
"zpieRmo/hlSe+0QSz36Buj8tmxxaGRbVlCGr8boXhsI=":
function (require, module, exports, __dirname, __filename) {
var toSource = require('./source')
var toSink = require('./sink')

module.exports = function (push, cb) {
  return {
    source: toSource(push, cb),
    sink: toSink(push)
  }
}

},

}
,
{
  "index.js": [
    "zRr0kgMSWss1BTBetxewVXvLIxmN/x0IflBA1vg7lLU=",
    {
      "./restore": "restore.js",
      "./ssb": "ssb.js"
    }
  ],
  "node_modules/@minireq/browser/build/bundle.cjs.js": [
    "Gxi6OFfjN4MMv2zODwnYfZkJeHsy8MSDWWhkxHv/DCY=",
    {
      "@minireq/common": "node_modules/@minireq/common/build/bundle.cjs.js"
    }
  ],
  "node_modules/@minireq/common/build/bundle.cjs.js": [
    "PvSh3VWqh6+Ionq3pEqT4x/SnbFEdKKj1+KEj1K7hfY=",
    {}
  ],
  "node_modules/@minireq/node/build/bundle.cjs.js": [
    "61r6Yx1OtPVKfCZEiHA76brp45pjKGL6lad+JCRlmug=",
    {
      "@minireq/common": "node_modules/@minireq/common/build/bundle.cjs.js"
    }
  ],
  "node_modules/abstract-leveldown/abstract-chained-batch.js": [
    "15Xpz9+kzWDcRjyolLaaUMvt+u1g3Tt9nuLZZmZYLTo=",
    {}
  ],
  "node_modules/abstract-leveldown/abstract-iterator.js": [
    "egOl/fDE75Wnpj5bapQSJLvp9M2hIv8gaHq2sbDicns=",
    {}
  ],
  "node_modules/abstract-leveldown/abstract-leveldown.js": [
    "C6qADXMOE7DHqXoeZbqzqpKXlk9us1wDsGTxetNAV68=",
    {
      "./abstract-chained-batch": "node_modules/abstract-leveldown/abstract-chained-batch.js",
      "./abstract-iterator": "node_modules/abstract-leveldown/abstract-iterator.js",
      "xtend": "node_modules/xtend/immutable.js"
    }
  ],
  "node_modules/abstract-leveldown/index.js": [
    "TZhD82oHTYdXvS5L6p4PGz8scF9rlqoYYWIXtimi4GY=",
    {
      "./abstract-chained-batch": "node_modules/abstract-leveldown/abstract-chained-batch.js",
      "./abstract-iterator": "node_modules/abstract-leveldown/abstract-iterator.js",
      "./abstract-leveldown": "node_modules/abstract-leveldown/abstract-leveldown.js"
    }
  ],
  "node_modules/aligned-block-file/blocks.js": [
    "JNpFV7Uxb5ZrEIrciRhj53M0aQzxKco8nXrzYkR8zhE=",
    {
      "hashlru": "node_modules/hashlru/index.js",
      "int53": "node_modules/int53/index.js",
      "uint48be": "node_modules/uint48be/index.js"
    }
  ],
  "node_modules/aligned-block-file/file.js": [
    "FHRdfMkgTG8UH99hmFIdkPoU3w+al9Ro6LYuMM0dNDY=",
    {
      "mkdirp": "node_modules/aligned-block-file/node_modules/mkdirp/index.js",
      "obv": "node_modules/obv/index.js",
      "rwlock": "node_modules/rwlock/lib/lock.js"
    }
  ],
  "node_modules/aligned-block-file/index.js": [
    "HTzTRZJMVe7DbKvuxjjJBmn+0XN45NxOWQjzBG/8kwQ=",
    {
      "./blocks": "node_modules/aligned-block-file/blocks.js",
      "./file": "node_modules/aligned-block-file/file.js"
    }
  ],
  "node_modules/aligned-block-file/node_modules/mkdirp/index.js": [
    "xwNbRxsZe6bUh5toA7bKJzoXr2yKI4Lcul6zunCkOsI=",
    {}
  ],
  "node_modules/append-batch/index.js": [
    "xpP1N1fOjbjoICaYJ+BoH31kSsQAyJ87MuwhMkqXQuc=",
    {}
  ],
  "node_modules/async-append-only-log/index.js": [
    "UggFUV0PxonAamVANWZjUucBPAR4EjlFkPAyZz+tqoo=",
    {
      "./stream": "node_modules/async-append-only-log/stream.js",
      "debug": "node_modules/debug/src/index.js",
      "hashlru": "node_modules/hashlru/index.js",
      "lodash.debounce": "node_modules/lodash.debounce/index.js",
      "mutexify": "node_modules/mutexify/index.js",
      "obz": "node_modules/obz/index.js",
      "polyraf": "node_modules/polyraf/index.js"
    }
  ],
  "node_modules/async-append-only-log/node_modules/looper/index.js": [
    "KricQafdcfK9V/7mcHaPDtDxPjqNg+ipAtIcKJI7Du4=",
    {}
  ],
  "node_modules/async-append-only-log/stream.js": [
    "/fx0fuCbDWUiM/LBcUrrmSiCNF1DXye+jQ1sgy47XeQ=",
    {
      "looper": "node_modules/async-append-only-log/node_modules/looper/index.js",
      "ltgt": "node_modules/ltgt/index.js",
      "push-stream/pipe": "node_modules/push-stream/pipe.js"
    }
  ],
  "node_modules/async-single/proto.js": [
    "OUSl51p34cFBP3IsJL6CccLd2j6LVCv9wboKpFQUmwA=",
    {}
  ],
  "node_modules/atomic-file-rw/browser.js": [
    "KTFBBqPJiD+ipt+uIZq+21hHyhbKzxOGf7LKfekqoMo=",
    {
      "idb-kv-store": "node_modules/idb-kv-store/index.js"
    }
  ],
  "node_modules/atomic-file-rw/fs.js": [
    "IagCdeY6WtvLC5DWqerY/wKlWsDUE07fzN8+KNoMG2w=",
    {
      "mutexify": "node_modules/mutexify/index.js"
    }
  ],
  "node_modules/atomic-file-rw/index.js": [
    "jyKM70FLOQpwcr/asR5ObYxwOtitTeL1RpczLyYXco8=",
    {
      "./browser": "node_modules/atomic-file-rw/browser.js",
      "./fs": "node_modules/atomic-file-rw/fs.js"
    }
  ],
  "node_modules/atomic-file/index.js": [
    "CJNsZUArFMqbpvNekePV8wrLiyXq7lpku1o2wuhOfkg=",
    {
      "./inject": "node_modules/atomic-file/inject.js",
      "./store/fs": "node_modules/atomic-file/store/fs.js"
    }
  ],
  "node_modules/atomic-file/inject.js": [
    "GNMWnP7cs2UL9sgR85SgiDUEhvn2CLMayZcND4cIDmg=",
    {
      "flumecodec/json": "node_modules/flumecodec/json.js",
      "mutexify": "node_modules/mutexify/index.js"
    }
  ],
  "node_modules/atomic-file/store/fs.js": [
    "ZdPm2t7pUKePjhZjN5q0oZY+S8+mSyOn1She1B8PMSg=",
    {}
  ],
  "node_modules/balanced-match/index.js": [
    "XDQV/oeWHP/FA+mh10/izUwMLsV7fqT+8KS2Y/U+UrQ=",
    {}
  ],
  "node_modules/base64-url/index.js": [
    "7K0UBOixDGPoRkf9omfHi5tsCtkcmWWCsNIb3lHsuhg=",
    {}
  ],
  "node_modules/bencode/lib/decode.js": [
    "LHlpxkX13FKDHbe7FdwU8SvWnU61CEaZbSiRKwgyNFA=",
    {}
  ],
  "node_modules/bencode/lib/encode.js": [
    "HHod+0xMVFBcp4b4clM0g0T/PKlL+xSWHrou2eEwI2s=",
    {
      "./util.js": "node_modules/bencode/lib/util.js"
    }
  ],
  "node_modules/bencode/lib/encoding-length.js": [
    "gz7IBtF0K9SDfQ8PyZ4H2+0CRzgct5aeaIavv4u7430=",
    {
      "./util.js": "node_modules/bencode/lib/util.js"
    }
  ],
  "node_modules/bencode/lib/index.js": [
    "3SuPvFPLYoUfRoj6Dxl7RevRZvTIPEBHkRVllexmQAA=",
    {
      "./decode.js": "node_modules/bencode/lib/decode.js",
      "./encode.js": "node_modules/bencode/lib/encode.js",
      "./encoding-length.js": "node_modules/bencode/lib/encoding-length.js"
    }
  ],
  "node_modules/bencode/lib/util.js": [
    "DQHE38gxJVYt4+XeWBYawsgpXXeHYeIUWDMVSjgMYF8=",
    {}
  ],
  "node_modules/binary-search-bounds/search-bounds.js": [
    "yz7aZ0O5ydhNxd4xn3Xmg/ZWLRZ7yqxW8C+3KSSdPwY=",
    {}
  ],
  "node_modules/bindings-noderify-nodejs-mobile/bindings.js": [
    "wcrwnTx0GBU4XGAxzPhRt4q5CLXY0M2GgN7m8YPVpQc=",
    {}
  ],
  "node_modules/bip39/src/_wordlists.js": [
    "c5vsbLOT8Bh1wlNBZu7WkHMoeU9MkAEeIxXyh6rNOtY=",
    {
      "./wordlists/chinese_simplified.json": "node_modules/bip39/src/wordlists/chinese_simplified.json",
      "./wordlists/chinese_traditional.json": "node_modules/bip39/src/wordlists/chinese_traditional.json",
      "./wordlists/czech.json": "node_modules/bip39/src/wordlists/czech.json",
      "./wordlists/english.json": "node_modules/bip39/src/wordlists/english.json",
      "./wordlists/french.json": "node_modules/bip39/src/wordlists/french.json",
      "./wordlists/italian.json": "node_modules/bip39/src/wordlists/italian.json",
      "./wordlists/japanese.json": "node_modules/bip39/src/wordlists/japanese.json",
      "./wordlists/korean.json": "node_modules/bip39/src/wordlists/korean.json",
      "./wordlists/spanish.json": "node_modules/bip39/src/wordlists/spanish.json"
    }
  ],
  "node_modules/bip39/src/index.js": [
    "omS13tMv0GjwKuOachD8YKC7sSFZdM+7IFEqxHBCIeo=",
    {
      "./_wordlists": "node_modules/bip39/src/_wordlists.js",
      "create-hash": "node_modules/create-hash/index.js",
      "pbkdf2": "node_modules/pbkdf2/index.js",
      "randombytes": "node_modules/randombytes/index.js"
    }
  ],
  "node_modules/bip39/src/wordlists/chinese_simplified.json": [
    "WnTlvJMMNqdemuhLQd96nqNpx/uankm2sZOa5NkSU1M=",
    {}
  ],
  "node_modules/bip39/src/wordlists/chinese_traditional.json": [
    "wD+3NzhAZwc5cdGOekVNfAL4ET9/i2BIUS2AA3XmUhM=",
    {}
  ],
  "node_modules/bip39/src/wordlists/czech.json": [
    "HNOwxrCMnZwenqSz+Qxx7JaQ4D1x2GnbwBWjUVJwh7U=",
    {}
  ],
  "node_modules/bip39/src/wordlists/english.json": [
    "SKDUqBxHSbRcpgTkh/aWxV6pcWp6Gx8e19/kk8OjzBU=",
    {}
  ],
  "node_modules/bip39/src/wordlists/french.json": [
    "5vFqCwpK2l4rGECYPd1b0hXUg9v0N3NaPCgTv770S8Y=",
    {}
  ],
  "node_modules/bip39/src/wordlists/italian.json": [
    "+1U1cNlSvfoFauoKg7QIMQYA6dPbPgxZIt+oQQlZlvA=",
    {}
  ],
  "node_modules/bip39/src/wordlists/japanese.json": [
    "sBIjpA5A4qWyBo1+qf1Idy87JZuRsOvpsp+1eY3taIA=",
    {}
  ],
  "node_modules/bip39/src/wordlists/korean.json": [
    "Xm5jw7EUMBMShiOuJuDQxLUIWMF5s/Yfyc+u/PzIV9s=",
    {}
  ],
  "node_modules/bip39/src/wordlists/spanish.json": [
    "fSZoQc1wVUnyySCVITovHGKvuKIhknPw3RgaKdbXh9s=",
    {}
  ],
  "node_modules/bipf/index.js": [
    "lqba57wshQ1ewL/FaQpvlzUvhJgj8qnhTopraWplcQw=",
    {
      "varint": "node_modules/varint/index.js"
    }
  ],
  "node_modules/blake2s/index.js": [
    "ugR+w4XZMN/3juELVikZ64t5T3QAEtcBtleh6bAHr/A=",
    {}
  ],
  "node_modules/brace-expansion/index.js": [
    "a/nu45IpqmisPmpxF3w4fIMh7/H4MkKjXz58Ncue7Bs=",
    {
      "balanced-match": "node_modules/balanced-match/index.js",
      "concat-map": "node_modules/concat-map/index.js"
    }
  ],
  "node_modules/broadcast-stream/index.js": [
    "zAEO/pUSb4j/uRSuSXJn05UM7H7zNbwqGDa0998R79s=",
    {}
  ],
  "node_modules/call-bind/callBound.js": [
    "Ky/OdiL91oAlbSi81ZwwkTVGqCW/addU0hodIczCkow=",
    {
      "./": "node_modules/call-bind/index.js",
      "get-intrinsic": "node_modules/get-intrinsic/index.js"
    }
  ],
  "node_modules/call-bind/index.js": [
    "UbK8nUV6P8NcfQQyrdo9nDAi1JDjxR2CvS5vvABAeTA=",
    {
      "function-bind": "node_modules/function-bind/index.js",
      "get-intrinsic": "node_modules/get-intrinsic/index.js"
    }
  ],
  "node_modules/concat-map/index.js": [
    "CRtl13gzdZnQFAs11TwDhgPRcy0nwzv+OeA4calpJrI=",
    {}
  ],
  "node_modules/cont/index.js": [
    "my3Mtk8msQFkFs5faZG4tS0EjwmtODFORzhSxcgleDM=",
    {
      "continuable": "node_modules/continuable/index.js",
      "continuable-para": "node_modules/continuable-para/index.js",
      "continuable-series": "node_modules/continuable-series/index.js"
    }
  ],
  "node_modules/continuable-hash/index.js": [
    "Ofp/3pHGnR/xhrB0q5TIvQrTtz5GW+A+PkWMdavBy0o=",
    {
      "continuable/maybe-callback": "node_modules/continuable-hash/node_modules/continuable/maybe-callback.js"
    }
  ],
  "node_modules/continuable-hash/node_modules/continuable/maybe-callback.js": [
    "pN128HmfxJd3AhJuZ6vuPPgWw3XLAKVTqj/gX8bFlno=",
    {}
  ],
  "node_modules/continuable-list/index.js": [
    "MZNAuf/Vk6btL7qAEyf1tKcUS0ojiXtWJ1bT9eyhPic=",
    {
      "continuable/maybe-callback": "node_modules/continuable-list/node_modules/continuable/maybe-callback.js"
    }
  ],
  "node_modules/continuable-list/node_modules/continuable/maybe-callback.js": [
    "pN128HmfxJd3AhJuZ6vuPPgWw3XLAKVTqj/gX8bFlno=",
    {}
  ],
  "node_modules/continuable-para/index.js": [
    "5cfvpgW0NF9XIpq727oLs8A9i4N5lZiBMtgMuvj2Ijk=",
    {
      "continuable-hash": "node_modules/continuable-hash/index.js",
      "continuable-list": "node_modules/continuable-list/index.js"
    }
  ],
  "node_modules/continuable-series/index.js": [
    "y9bu6ooSJ4eTo3qLTOYHiygPQzsC5cIrHuZVk9FGhw4=",
    {}
  ],
  "node_modules/continuable/both.js": [
    "MjvLr/xOseyqvTTmpIHI8bgRJsCpKTL5QuFJFStCwCs=",
    {}
  ],
  "node_modules/continuable/chain.js": [
    "Yu76t+DKfnA75RFAqcScJ3XCdzDeuPe8X0/wXqLI3ak=",
    {}
  ],
  "node_modules/continuable/either.js": [
    "Xz71w1g5FDlgcpQB1RsYHmnE9+BZfKrwfQyi9hcFlUM=",
    {
      "./of": "node_modules/continuable/of.js"
    }
  ],
  "node_modules/continuable/error.js": [
    "v1JJsvB84WMOaJeajnHp6rZ4y/7uHk4RMQQpWljccnM=",
    {}
  ],
  "node_modules/continuable/index.js": [
    "BPW+ohGOj+1TlKqaWFsfFn7zUbaW6USLAAF5Ln1+CLI=",
    {
      "./both.js": "node_modules/continuable/both.js",
      "./chain.js": "node_modules/continuable/chain.js",
      "./either.js": "node_modules/continuable/either.js",
      "./error.js": "node_modules/continuable/error.js",
      "./join.js": "node_modules/continuable/join.js",
      "./map-async.js": "node_modules/continuable/map-async.js",
      "./map.js": "node_modules/continuable/map.js",
      "./maybe-callback.js": "node_modules/continuable/maybe-callback.js",
      "./of.js": "node_modules/continuable/of.js",
      "./to.js": "node_modules/continuable/to.js"
    }
  ],
  "node_modules/continuable/join.js": [
    "D0nA59GBhKIX7Sc5Kwjc5GZ5UCdU/INt/J2cmRjCIAQ=",
    {}
  ],
  "node_modules/continuable/map-async.js": [
    "BAb8PtZjQg38fOfdP6kJel/Askmzk4LekGrQIq39Zbo=",
    {}
  ],
  "node_modules/continuable/map.js": [
    "8oVQAh3PHo5mQo4nNZARZxbXyIiufUbrNzi1vx0D53w=",
    {}
  ],
  "node_modules/continuable/maybe-callback.js": [
    "pN128HmfxJd3AhJuZ6vuPPgWw3XLAKVTqj/gX8bFlno=",
    {}
  ],
  "node_modules/continuable/of.js": [
    "AhGM13F38Ugmo+1/psfxxr/69gITlpyAFudfqUhCubg=",
    {}
  ],
  "node_modules/continuable/to.js": [
    "CYFjk0MA9cqunsqirN4JfopZp1rC3FTB21giVtLNJLQ=",
    {}
  ],
  "node_modules/cpu-percentage/index.js": [
    "YJqQ01wDN9jF/GrwCbS6vh2UN9TGTJiQnnpE6imE6NE=",
    {}
  ],
  "node_modules/crc/lib/crc32.js": [
    "Nj3ROjAbFi1qrgkmx5q/WWdY3lLCpXfDCBVJKuvY9sc=",
    {
      "./es6/crc32": "node_modules/crc/lib/es6/crc32.js"
    }
  ],
  "node_modules/crc/lib/es6/crc32.js": [
    "4kPe2IgUGNpjZZAqP9pMFZZXky9hiXPjeJhPYZ/bkLQ=",
    {
      "./create_buffer": "node_modules/crc/lib/es6/create_buffer.js",
      "./define_crc": "node_modules/crc/lib/es6/define_crc.js"
    }
  ],
  "node_modules/crc/lib/es6/create_buffer.js": [
    "2NZ17+yHfioBRKI1kM7M6cvf8v57kj63H+F/mYOth9M=",
    {}
  ],
  "node_modules/crc/lib/es6/define_crc.js": [
    "bOmx5DpyWdyV3euSt80OhJemBxqnjA32D+vFtO7fPGQ=",
    {}
  ],
  "node_modules/create-hash/index.js": [
    "S1YIYzrBJPak7W+hfc3pGalXWJaV8W25l4eY9v2Pcew=",
    {}
  ],
  "node_modules/create-hmac/index.js": [
    "7zjesWGed4jKtuDXva9K3esbuy9Xu86TIfVIovsi01E=",
    {}
  ],
  "node_modules/currify/lib/currify.js": [
    "NbCMBVfsi0jux2Xra6nge5X8Tj+gPSMhmiwmxC/Yli8=",
    {}
  ],
  "node_modules/debug/src/browser.js": [
    "Tj3G0OHbWKDXQga0Q/NVgtO3F75WoPbQMMNK9sKtn2I=",
    {
      "./common": "node_modules/debug/src/common.js"
    }
  ],
  "node_modules/debug/src/common.js": [
    "rmhV6fXvZoeqj3bmndGFTxuZmFFGQ02v8xAVAIPP3gI=",
    {
      "ms": "node_modules/ms/index.js"
    }
  ],
  "node_modules/debug/src/index.js": [
    "qhJ/8XUrfZx0FcXHu2mU2apyK4G8vKtL1IMWsBPSO/M=",
    {
      "./browser.js": "node_modules/debug/src/browser.js",
      "./node.js": "node_modules/debug/src/node.js"
    }
  ],
  "node_modules/debug/src/node.js": [
    "8jety1KEnefBKPV+BGi1I1PFKabINBgQR3wOcUQ1lVk=",
    {
      "./common": "node_modules/debug/src/common.js"
    }
  ],
  "node_modules/deep-equal/index.js": [
    "PA0rKtb47h3RL+1b/tkpJ1aYrM4wxnYp6aM84nJojzA=",
    {
      "is-arguments": "node_modules/is-arguments/index.js",
      "is-date-object": "node_modules/is-date-object/index.js",
      "is-regex": "node_modules/is-regex/index.js",
      "object-is": "node_modules/object-is/index.js",
      "object-keys": "node_modules/object-keys/index.js",
      "regexp.prototype.flags": "node_modules/regexp.prototype.flags/index.js"
    }
  ],
  "node_modules/deep-extend/lib/deep-extend.js": [
    "h6raxbPMgIG1cKJDwXxXXBlcSuZC6Yg0SVKR+mJu2dY=",
    {}
  ],
  "node_modules/deferred-leveldown/deferred-iterator.js": [
    "xY66vPoTm/ZFEhk7hnzUAtTkROIeaQGrZYqfhGacHuk=",
    {
      "abstract-leveldown": "node_modules/abstract-leveldown/index.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/deferred-leveldown/deferred-leveldown.js": [
    "EFyelVMiBsGQgnD2oWobg/BdPLIaM0NHbl1N1bXv/rI=",
    {
      "./deferred-iterator": "node_modules/deferred-leveldown/deferred-iterator.js",
      "abstract-leveldown": "node_modules/abstract-leveldown/index.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/define-properties/index.js": [
    "3Huaa8u+AMVeAEB3XNau1l9qkfu/XPnLSZkufQnuZGc=",
    {
      "object-keys": "node_modules/object-keys/index.js"
    }
  ],
  "node_modules/defined/index.js": [
    "Vb6mMU0vc4x3R8riil6ujf6QXdnLhd83zDfmivCKls8=",
    {}
  ],
  "node_modules/dynamic-dijkstra/index.js": [
    "F+Gv1QrpWW5VIU/ob1qFr8bkvWmgvJeOy7vapiycETM=",
    {
      "heap": "node_modules/heap/index.js"
    }
  ],
  "node_modules/dynamic-dijkstra/simple.js": [
    "kOY7mCKQFTpUGdM5qk1XnVaUR7u8E7uwENICOAnjVu8=",
    {}
  ],
  "node_modules/encoding-down/index.js": [
    "4/vtdCbL5dshSa2VbKM4ZGuYoUwj6oIAdXqNiip2TwM=",
    {
      "abstract-leveldown": "node_modules/abstract-leveldown/index.js",
      "inherits": "node_modules/inherits/inherits.js",
      "level-codec": "node_modules/encoding-down/node_modules/level-codec/index.js",
      "level-errors": "node_modules/level-errors/errors.js"
    }
  ],
  "node_modules/encoding-down/node_modules/level-codec/index.js": [
    "KeOe/kUQLqH0ZVsn667GMT/xNkS+X3KXhqwXVeL+564=",
    {
      "./lib/encodings": "node_modules/encoding-down/node_modules/level-codec/lib/encodings.js"
    }
  ],
  "node_modules/encoding-down/node_modules/level-codec/lib/encodings.js": [
    "DyIrMBtSdZUpgdkxj46x8WboxEO6lUAd6lVSQb6wefA=",
    {}
  ],
  "node_modules/epidemic-broadcast-trees/events.js": [
    "02mP/70TntdBmhroiQH3+OShqJkBlGFUqU1G4DOOvZQ=",
    {}
  ],
  "node_modules/epidemic-broadcast-trees/index.js": [
    "C6DEo8Hzu8WvthGYGces7M5RraPde/RtjiZwMV15HMs=",
    {
      "./events": "node_modules/epidemic-broadcast-trees/events.js",
      "./progress": "node_modules/epidemic-broadcast-trees/progress.js",
      "./stream": "node_modules/epidemic-broadcast-trees/stream.js",
      "./v3": "node_modules/epidemic-broadcast-trees/v3.js"
    }
  ],
  "node_modules/epidemic-broadcast-trees/progress.js": [
    "ijDe77uaZDBR5WxVfPWIas5CDn1d9ga0e143aW4TUBs=",
    {}
  ],
  "node_modules/epidemic-broadcast-trees/stream.js": [
    "aITDRdeWC8dzHMyx3Ae8V8JCuUZnIKb9O9CDUiymt/A=",
    {
      "./v3": "node_modules/epidemic-broadcast-trees/v3.js",
      "push-stream/pipe": "node_modules/push-stream/pipe.js"
    }
  ],
  "node_modules/epidemic-broadcast-trees/v3.js": [
    "d42LqRx3ZCwjTOY8vKjBWHMdJm/xdE0/q8yxWKohP5U=",
    {}
  ],
  "node_modules/errno/custom.js": [
    "LQrn+beMz9sSTqtT7mL/SXunAGHjhGQnZY0eip5XI+o=",
    {
      "prr": "node_modules/prr/prr.js"
    }
  ],
  "node_modules/errno/errno.js": [
    "Hk6T3FVpUObSr+tQzzuU3LOQ2HC4cqsuS+qI19rk5aI=",
    {
      "./custom": "node_modules/errno/custom.js"
    }
  ],
  "node_modules/explain-error/index.js": [
    "r7K2Ec87mTos7IN6ebWeulFVVA5l0tGjezcSIff0kEA=",
    {}
  ],
  "node_modules/fastintcompression/FastIntegerCompression.js": [
    "ITwob2+2DgxQU4os1EG+48uwEG3lL5vBuXCReCxT6ws=",
    {}
  ],
  "node_modules/fastpriorityqueue/FastPriorityQueue.js": [
    "U6nYZCDNxzQIeF2lKWe0N2R34WaQbuHvvYyYeU2Qe5c=",
    {}
  ],
  "node_modules/file-type/core.js": [
    "g/0pKxcFvD17UgSo6pY44/FmIQhzdkaV2qxj16I0psQ=",
    {
      "./supported": "node_modules/file-type/supported.js",
      "./util": "node_modules/file-type/util.js",
      "strtok3/lib/core": "node_modules/strtok3/lib/core.js",
      "token-types": "node_modules/token-types/lib/index.js"
    }
  ],
  "node_modules/file-type/index.js": [
    "7iEjpT3z0zbRKb98t87frdFy/JmB05tW8ZosMaFthtQ=",
    {
      "./core": "node_modules/file-type/core.js",
      "strtok3": "node_modules/strtok3/lib/index.js"
    }
  ],
  "node_modules/file-type/supported.js": [
    "0LRE9AZXeIuQjycmZQioBk33CRl8wVU1ATgXR5kzTvc=",
    {}
  ],
  "node_modules/file-type/util.js": [
    "hzCxsz+nDf0dyJJDPun/vULTAdbOd9PJq0maneo+4vc=",
    {}
  ],
  "node_modules/flumecodec/json.js": [
    "BUZhdKi5Zm9hvtj/jhsOtNkcFGMNoivpgyWgq5g5xS4=",
    {
      "level-codec/lib/encodings": "node_modules/level-codec/lib/encodings.js"
    }
  ],
  "node_modules/flumelog-offset/frame/offset-codecs.js": [
    "WBfMm1Uw5mOe+TPWn1xOQAiPJA9UKbNbdqgQCN2lBSs=",
    {
      "int53": "node_modules/int53/index.js",
      "uint48be": "node_modules/uint48be/index.js"
    }
  ],
  "node_modules/flumelog-offset/frame/recoverable.js": [
    "7SR4vSZ8a5HmkiCYF5CNYb7mrFRpRdck5miW0gqgjL4=",
    {
      "./offset-codecs": "node_modules/flumelog-offset/frame/offset-codecs.js",
      "looper": "node_modules/flumelog-offset/node_modules/looper/index.js"
    }
  ],
  "node_modules/flumelog-offset/index.js": [
    "5KnBJt9hi41Znz2CpbpdCEtdPcMbcsNjMCHI1RgKrow=",
    {
      "./frame/recoverable": "node_modules/flumelog-offset/frame/recoverable.js",
      "./inject": "node_modules/flumelog-offset/inject.js",
      "aligned-block-file": "node_modules/aligned-block-file/index.js",
      "hashlru": "node_modules/hashlru/index.js"
    }
  ],
  "node_modules/flumelog-offset/inject.js": [
    "/+L1Gp0bOTCBtcd9Np60dTtpg8m7r0j72hK7DQ8MC+A=",
    {
      "append-batch": "node_modules/append-batch/index.js",
      "hashlru": "node_modules/hashlru/index.js",
      "obv": "node_modules/obv/index.js",
      "pull-cursor": "node_modules/pull-cursor/index.js",
      "pull-looper": "node_modules/pull-looper/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "pull-stream/throughs/filter": "node_modules/pull-stream/throughs/filter.js"
    }
  ],
  "node_modules/flumelog-offset/node_modules/looper/index.js": [
    "KricQafdcfK9V/7mcHaPDtDxPjqNg+ipAtIcKJI7Du4=",
    {}
  ],
  "node_modules/flumeview-reduce/index.js": [
    "jhlhpZ0VEFx8CzyctLwC6i43SWm7KHJoRPbVJPefQi8=",
    {
      "./inject": "node_modules/flumeview-reduce/inject.js",
      "./store": "node_modules/flumeview-reduce/store/index.js"
    }
  ],
  "node_modules/flumeview-reduce/inject.js": [
    "YKLr15FMcHiQbeYbxK+mGPhQKx/vSknqkbaxIbn2uo0=",
    {
      "async-single": "node_modules/async-single/proto.js",
      "deep-equal": "node_modules/deep-equal/index.js",
      "obv": "node_modules/obv/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-stream/sinks/drain": "node_modules/pull-stream/sinks/drain.js",
      "pull-stream/sources/once": "node_modules/pull-stream/sources/once.js"
    }
  ],
  "node_modules/flumeview-reduce/node_modules/flumecodec/json.js": [
    "BUZhdKi5Zm9hvtj/jhsOtNkcFGMNoivpgyWgq5g5xS4=",
    {
      "level-codec/lib/encodings": "node_modules/level-codec/lib/encodings.js"
    }
  ],
  "node_modules/flumeview-reduce/store/fs.js": [
    "TOUXLCiaod6gCRkjK5KmIJP3+b1QDDs7BmP1pH5UhHc=",
    {
      "atomic-file": "node_modules/atomic-file/index.js",
      "flumecodec/json": "node_modules/flumeview-reduce/node_modules/flumecodec/json.js"
    }
  ],
  "node_modules/flumeview-reduce/store/index.js": [
    "Nxlk1SJ4gkCoR/Qq7WpBa1bj4fd6NwzTYJsWfveiWfs=",
    {
      "./fs": "node_modules/flumeview-reduce/store/fs.js"
    }
  ],
  "node_modules/format-io/lib/format.js": [
    "dB6plWSA+wZ+Wu8ZdK8m6fDoAxb21F0EnSh1rp6r444=",
    {
      "./mode": "node_modules/format-io/lib/mode.js"
    }
  ],
  "node_modules/format-io/lib/mode.js": [
    "XpAmElnGd0xgrvHyA0J6tXyfvC5SYVReo9axfzxLZy8=",
    {
      "currify": "node_modules/currify/lib/currify.js"
    }
  ],
  "node_modules/fs.realpath/index.js": [
    "LjNLpDzUhS96PtaBWQKRZ8Bdf6avU25u8XfrhozNG7g=",
    {
      "./old.js": "node_modules/fs.realpath/old.js"
    }
  ],
  "node_modules/fs.realpath/old.js": [
    "ByRagnF/m/oqY7l4QoSht/xD/1/LSvKpS85fg2EdSi8=",
    {}
  ],
  "node_modules/function-bind/implementation.js": [
    "h1KlfwWETsACybYDUptls1BwFpRIraumgRUPfJf3aJ0=",
    {}
  ],
  "node_modules/function-bind/index.js": [
    "EvobkkKdslWZ9v4RjLu4d/f2K4PLm/4vyJay1qgRBkc=",
    {
      "./implementation": "node_modules/function-bind/implementation.js"
    }
  ],
  "node_modules/get-intrinsic/index.js": [
    "Y7alFgoTddAX2MNgffGarBupf46LGYw+qR8Slbpn2mw=",
    {
      "function-bind": "node_modules/function-bind/index.js",
      "has": "node_modules/has/src/index.js",
      "has-symbols": "node_modules/get-intrinsic/node_modules/has-symbols/index.js"
    }
  ],
  "node_modules/get-intrinsic/node_modules/has-symbols/index.js": [
    "KHT2zwAwGOe0diYUS598siZKhRnHGqq4hWKBWyQW09I=",
    {
      "./shams": "node_modules/get-intrinsic/node_modules/has-symbols/shams.js"
    }
  ],
  "node_modules/get-intrinsic/node_modules/has-symbols/shams.js": [
    "W6Gkc1Dc5VviwZjHkd9S+gE7rCrY19zX1ncmwIpCMfE=",
    {}
  ],
  "node_modules/glob/common.js": [
    "6aXzeHgmb0QQaVVupBGmDWWL37FqqZ07KbU/1jmlqjo=",
    {
      "minimatch": "node_modules/minimatch/minimatch.js",
      "path-is-absolute": "node_modules/path-is-absolute/index.js"
    }
  ],
  "node_modules/glob/glob.js": [
    "4/PR/VSqJBM6PVGK5+rybVy8G5SWOJ4Y3SS6Y+p2PtM=",
    {
      "./common.js": "node_modules/glob/common.js",
      "./sync.js": "node_modules/glob/sync.js",
      "fs.realpath": "node_modules/fs.realpath/index.js",
      "inflight": "node_modules/inflight/inflight.js",
      "inherits": "node_modules/inherits/inherits.js",
      "minimatch": "node_modules/minimatch/minimatch.js",
      "once": "node_modules/once/once.js",
      "path-is-absolute": "node_modules/path-is-absolute/index.js"
    }
  ],
  "node_modules/glob/sync.js": [
    "8EwE6eQOoa2peh5BStJthx+qB3jjsfsNX8Zuxqy8JD8=",
    {
      "./common.js": "node_modules/glob/common.js",
      "./glob.js": "node_modules/glob/glob.js",
      "fs.realpath": "node_modules/fs.realpath/index.js",
      "minimatch": "node_modules/minimatch/minimatch.js",
      "path-is-absolute": "node_modules/path-is-absolute/index.js"
    }
  ],
  "node_modules/has-network2/index.js": [
    "d2Q3v8BAehsqunv/JOnTXkdnnDEqadfrGzfQYC3mokY=",
    {}
  ],
  "node_modules/has/src/index.js": [
    "1Po//hmkciAoo9NJgrderk1tLEXXN+eWf/upzhNRXEw=",
    {
      "function-bind": "node_modules/function-bind/index.js"
    }
  ],
  "node_modules/hashlru/index.js": [
    "ESLtdoCU2GYADhPMtZOF83EMRia+I9HVAV94JPwQlZA=",
    {}
  ],
  "node_modules/heap/index.js": [
    "phvOfVFFv8Xts/2HMFfcnDzhAJ/DebRZVKq2h/QyX9s=",
    {
      "./lib/heap": "node_modules/heap/lib/heap.js"
    }
  ],
  "node_modules/heap/lib/heap.js": [
    "0b/cE6EoTU+KEH+wyJv4TfPVA8ZShZK98xLQuog1vKE=",
    {}
  ],
  "node_modules/hoox/index.js": [
    "rw6wQdeShnSEjU8e/YNtOxUjBtvczz3KxnDJvn1GGAY=",
    {}
  ],
  "node_modules/idb-kv-store/index.js": [
    "sEVbgS2SVdiKblUzCYwGwg+DLmGgnGsI1AkpCzt+Ld4=",
    {
      "inherits": "node_modules/inherits/inherits.js",
      "promisize": "node_modules/promisize/index.js"
    }
  ],
  "node_modules/ieee754/index.js": [
    "/j4rIMHrtXw7OQyPaFrR4E5vSTUX+n5DL0NRu3ehpNA=",
    {}
  ],
  "node_modules/increment-buffer/index.js": [
    "TvkwrcolBlXf3iAG9u7v5JPPMp7w8L/ioeY+jniUqYw=",
    {}
  ],
  "node_modules/inflight/inflight.js": [
    "4z6gmKkdLEG+iG+7zsrLl5n+GD2KRG8TikeGyz2AmAI=",
    {
      "once": "node_modules/once/once.js",
      "wrappy": "node_modules/wrappy/wrappy.js"
    }
  ],
  "node_modules/inherits/inherits.js": [
    "uzgPMr71/rGGePD0X4gHP+1degBpowkTLLIIDNVT1cc=",
    {
      "./inherits_browser.js": "node_modules/inherits/inherits_browser.js"
    }
  ],
  "node_modules/inherits/inherits_browser.js": [
    "rTIqex3sYPPS69ogkYFkae+1W1Z9JBzzzw+kxaSv5QA=",
    {}
  ],
  "node_modules/ini/ini.js": [
    "VKsqB5mOnvwfeWZ+5SZQR58i5tbyvTu5ximxQm9bGQY=",
    {}
  ],
  "node_modules/int53/index.js": [
    "7ir8sinprP5XygFU50ay/O86Zn/b3DUHcPQ3ccIKFI4=",
    {}
  ],
  "node_modules/ip/lib/ip.js": [
    "5g9p49oc/65drSUpDWPyOm4FClhynavE9ZzCRG2W63U=",
    {}
  ],
  "node_modules/is-arguments/index.js": [
    "c/yWyBKxh4cbx8bANGSprF2IPO+vHX4nIQDOGVaDfaw=",
    {
      "call-bind/callBound": "node_modules/call-bind/callBound.js"
    }
  ],
  "node_modules/is-canonical-base64/index.js": [
    "OF65+WylOvlXjk1yJq4Rbgn2F/8X5KQBXU2B7MOMzlE=",
    {}
  ],
  "node_modules/is-date-object/index.js": [
    "U0JVStsh8WUeErhxvp+Nha2FHAoHxcPZOoCucg/Ivrk=",
    {}
  ],
  "node_modules/is-pull-stream/index.js": [
    "3GKP0QabXZg3mQoJ7x/raDTxNNhhg0bca9j8uUazKaM=",
    {}
  ],
  "node_modules/is-regex/index.js": [
    "G7KjyckHCop/vC6nJsQJHoGW/yQWNAeMeOJ5JGcKBg0=",
    {
      "call-bind/callBound": "node_modules/call-bind/callBound.js",
      "has-symbols/shams": "node_modules/is-regex/node_modules/has-symbols/shams.js"
    }
  ],
  "node_modules/is-regex/node_modules/has-symbols/shams.js": [
    "W6Gkc1Dc5VviwZjHkd9S+gE7rCrY19zX1ncmwIpCMfE=",
    {}
  ],
  "node_modules/is-valid-domain/domains/sld.js": [
    "ERhvJEVPubIZkxgc5IQr52HPWuFxZxnJOHg1aKejGoQ=",
    {}
  ],
  "node_modules/is-valid-domain/index.js": [
    "Pi7pp3AAuDKQ0CIj2zahLYspEqHEZEYrlGKbRKrMLIE=",
    {
      "./domains/sld": "node_modules/is-valid-domain/domains/sld.js"
    }
  ],
  "node_modules/jitdb/files.js": [
    "I6CkLO94rufcS9BY3wPo/nAqUrbH0vl6LBwlwkfuFAs=",
    {
      "atomic-file-rw": "node_modules/atomic-file-rw/index.js",
      "crc/lib/crc32": "node_modules/crc/lib/crc32.js",
      "idb-kv-store": "node_modules/idb-kv-store/index.js",
      "jsesc": "node_modules/jsesc/jsesc.js",
      "mkdirp": "node_modules/mkdirp/index.js",
      "sanitize-filename": "node_modules/sanitize-filename/index.js",
      "typedarray-to-buffer": "node_modules/jitdb/node_modules/typedarray-to-buffer/index.js",
      "typedfastbitset": "node_modules/typedfastbitset/TypedFastBitSet.js"
    }
  ],
  "node_modules/jitdb/index.js": [
    "JIegApdPUt0/wY9We7EikkVDnJlM/ZbTWj4HDvPpCPk=",
    {
      "./files": "node_modules/jitdb/files.js",
      "./status": "node_modules/jitdb/status.js",
      "binary-search-bounds": "node_modules/binary-search-bounds/search-bounds.js",
      "bipf": "node_modules/bipf/index.js",
      "debug": "node_modules/debug/src/index.js",
      "fastpriorityqueue": "node_modules/fastpriorityqueue/FastPriorityQueue.js",
      "multicb": "node_modules/multicb/index.js",
      "pull-async": "node_modules/pull-async/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "push-stream": "node_modules/push-stream/index.js",
      "push-stream-to-pull-stream": "node_modules/push-stream-to-pull-stream/index.js",
      "typedfastbitset": "node_modules/typedfastbitset/TypedFastBitSet.js"
    }
  ],
  "node_modules/jitdb/node_modules/typedarray-to-buffer/index.js": [
    "uL61TlttIPMJUhjfIE+mrAcTOzy7we9x83UbcC58j+U=",
    {}
  ],
  "node_modules/jitdb/operators.js": [
    "XuAW+tXD3JQOEIun7Wse5aJTjgCWFU7RezxH/G/6kpU=",
    {
      "./files": "node_modules/jitdb/files.js",
      "bipf": "node_modules/bipf/index.js",
      "multicb": "node_modules/multicb/index.js",
      "promisify-4loc": "node_modules/promisify-4loc/index.js",
      "pull-awaitable": "node_modules/pull-awaitable/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "traverse": "node_modules/traverse/index.js"
    }
  ],
  "node_modules/jitdb/status.js": [
    "K4U/gwpEILfX6/S+ODXPSq1xnOum4jqZ3Tzyy6eJoeE=",
    {
      "obz": "node_modules/obz/index.js"
    }
  ],
  "node_modules/jsesc/jsesc.js": [
    "yDf9yxVtQ1l4giJCYzfcu0PZTxFCSfqAwl1BMAlILFM=",
    {}
  ],
  "node_modules/key-value-file-store/index.js": [
    "0QsVYkCP3wzxfSvVSCLHXUCISRE0LgGpmfA3aNDYHs0=",
    {
      "./json": "node_modules/key-value-file-store/json.js",
      "./store": "node_modules/key-value-file-store/store.js",
      "atomic-file-rw": "node_modules/atomic-file-rw/index.js"
    }
  ],
  "node_modules/key-value-file-store/json.js": [
    "AWec1grcPLhUXRka4eduyljgIGlmFAHBkEsgrWrAsSk=",
    {}
  ],
  "node_modules/key-value-file-store/store.js": [
    "VEo9/bJDBkaCu4VkOSmU7ih/96nTK+a0IOAeIzWpJ9Q=",
    {}
  ],
  "node_modules/layered-graph/index.js": [
    "gNsXfsz+6ZOyf5FxpV8CoAbfvuRi8WdIThz7T0zJYUs=",
    {
      "dynamic-dijkstra": "node_modules/dynamic-dijkstra/index.js",
      "dynamic-dijkstra/simple": "node_modules/dynamic-dijkstra/simple.js",
      "pull-cont": "node_modules/pull-cont/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-stream/sources/once": "node_modules/pull-stream/sources/once.js"
    }
  ],
  "node_modules/level-codec/lib/encodings.js": [
    "Z2vAVtzqrB1GE1WJkJBbyiqQStPlUVHJPZyBuSu9YTI=",
    {}
  ],
  "node_modules/level-errors/errors.js": [
    "a6mujEb8qBzOC6yEE+qyF1FCbTGyqLm4GMFAFsaMsxM=",
    {
      "errno": "node_modules/errno/errno.js"
    }
  ],
  "node_modules/level-iterator-stream/index.js": [
    "9fd1k5ZkeTwPk3R00CrHjPFwfqfnoN2YXmDjJiyUzgE=",
    {
      "inherits": "node_modules/inherits/inherits.js",
      "readable-stream": "node_modules/level-iterator-stream/node_modules/readable-stream/readable.js",
      "xtend": "node_modules/xtend/immutable.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js": [
    "cCjMqVsvEkNFvVuBbg2BhOe30gj+Cqdus430PoZE/QM=",
    {}
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/experimentalWarning.js": [
    "X5vv9ZQ0e6Z2W4Buw24laZvhQHYn4u6Rvl1gnkC6rLg=",
    {}
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_duplex.js": [
    "w9l2Bit3C0qIyR0kRVe76agotV3C3h+ayFwtXpCTicQ=",
    {
      "./_stream_readable": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_readable.js",
      "./_stream_writable": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_writable.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_passthrough.js": [
    "FEdWQewdhdy/leJVX+2wS/AvhILgiCKloJsB3cY4n18=",
    {
      "./_stream_transform": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_transform.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_readable.js": [
    "h9jG45dN8gAQewtq7QjyOncdP2vLaROZh0+NvviciZ0=",
    {
      "../errors": "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js",
      "../experimentalWarning": "node_modules/level-iterator-stream/node_modules/readable-stream/experimentalWarning.js",
      "./_stream_duplex": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_duplex.js",
      "./internal/streams/async_iterator": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/async_iterator.js",
      "./internal/streams/buffer_list": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/buffer_list.js",
      "./internal/streams/destroy": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/destroy.js",
      "./internal/streams/state": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/state.js",
      "./internal/streams/stream": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/stream.js",
      "inherits": "node_modules/inherits/inherits.js",
      "string_decoder/": "node_modules/string_decoder/lib/string_decoder.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_transform.js": [
    "2FuyuMa6PPceaudZNC34ne6VmBxoVun03AuF1wz2C1k=",
    {
      "../errors": "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js",
      "./_stream_duplex": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_duplex.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_writable.js": [
    "YsRLNpaHVsekqDxmv6eFRmnmCsCseBfg5r2pRfJUDZk=",
    {
      "../errors": "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js",
      "./_stream_duplex": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_duplex.js",
      "./internal/streams/destroy": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/destroy.js",
      "./internal/streams/state": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/state.js",
      "./internal/streams/stream": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/stream.js",
      "inherits": "node_modules/inherits/inherits.js",
      "util-deprecate": "node_modules/util-deprecate/node.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/async_iterator.js": [
    "OnUvL8sN41MmXy1JKBJhg7WgjZyetqpPq3SAgobmmEQ=",
    {
      "./end-of-stream": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/end-of-stream.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/buffer_list.js": [
    "GR7qOXKw4G+SlbAoo+ThsHSQCZTrM+ED7k3wnsp8pMU=",
    {}
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/destroy.js": [
    "vezOi3+97in0OUM1iocZ1iMnRo0fKLIffm1VHVAkOCg=",
    {}
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/end-of-stream.js": [
    "ddprWwY0ASAXpiUsbhMDNd53deWgLxCBfQKvR6+ou40=",
    {
      "../../../errors": "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/pipeline.js": [
    "FldrIBHHjQxc7M3rp0Ueg+G9hvLD8xwF3n30zPsUnCo=",
    {
      "../../../errors": "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js",
      "./end-of-stream": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/end-of-stream.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/state.js": [
    "zb7ZljS1I75lUiXfFUfNACleMEHLAoSMZS3a1eZ4fkk=",
    {
      "../../../errors": "node_modules/level-iterator-stream/node_modules/readable-stream/errors.js"
    }
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/stream.js": [
    "HnkDkn3zOq2zZZ7M5VJmychR2mXObItyOmCjBcHFQiw=",
    {}
  ],
  "node_modules/level-iterator-stream/node_modules/readable-stream/readable.js": [
    "KUTx08jF1cXgfnww1svvX8N0QLfHPeR66zf6hCTwS/E=",
    {
      "./lib/_stream_duplex.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_duplex.js",
      "./lib/_stream_passthrough.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_passthrough.js",
      "./lib/_stream_readable.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_readable.js",
      "./lib/_stream_transform.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_transform.js",
      "./lib/_stream_writable.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/_stream_writable.js",
      "./lib/internal/streams/end-of-stream.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/end-of-stream.js",
      "./lib/internal/streams/pipeline.js": "node_modules/level-iterator-stream/node_modules/readable-stream/lib/internal/streams/pipeline.js"
    }
  ],
  "node_modules/level-packager/level-packager.js": [
    "tf5U14dxc7PYAAXmvBsky40qOlhjmF0r/85RTn79O8A=",
    {
      "encoding-down": "node_modules/encoding-down/index.js",
      "levelup": "node_modules/levelup/lib/levelup.js"
    }
  ],
  "node_modules/level-post/index.js": [
    "2uBTHH0mScjN6VwbN2yQcRtjLsMVQI2dw3Bz0+Oi0go=",
    {
      "ltgt": "node_modules/ltgt/index.js"
    }
  ],
  "node_modules/level-supports/index.js": [
    "wDldIgTWkq3WWCNiCxvD5kG+5npYBS8nTJk+tkylzvU=",
    {
      "xtend": "node_modules/level-supports/node_modules/xtend/immutable.js",
      "xtend/mutable": "node_modules/level-supports/node_modules/xtend/mutable.js"
    }
  ],
  "node_modules/level-supports/node_modules/xtend/immutable.js": [
    "BJhvFouPFvTyUjfQYIzfV7bKFPEA/tYsApW9olWasks=",
    {}
  ],
  "node_modules/level-supports/node_modules/xtend/mutable.js": [
    "caOGScd0CCF0g/gfVdruHWZG1sZw49A0pEgss0U4huk=",
    {}
  ],
  "node_modules/level/level.js": [
    "wCjG5RX/lhZqNW+n+TXsJsVIyG5nX7hngZgg5ESu9Go=",
    {
      "level-packager": "node_modules/level-packager/level-packager.js",
      "leveldown": "node_modules/leveldown-nodejs-mobile/leveldown.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/binding.js": [
    "xDHh0C6g2r9Qe+wYtDJqKLYbO2MUg2fZY/nndbP2QyY=",
    {
      "bindings": "node_modules/bindings-noderify-nodejs-mobile/bindings.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/chained-batch.js": [
    "vbdI62o94a9x5thTSnOwtqgzR/r+J89nsb8aKGRU/zw=",
    {
      "./binding": "node_modules/leveldown-nodejs-mobile/binding.js",
      "abstract-leveldown": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/index.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/iterator.js": [
    "v4J0FVF4WmGxbPDZEqMP0dXbZqcjBIrdbvjPDIZGVlg=",
    {
      "./binding": "node_modules/leveldown-nodejs-mobile/binding.js",
      "abstract-leveldown": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/index.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/leveldown.js": [
    "dV6WHoG7ZmVmFkGbVk+bl0e5LeFHSPGmlDOLWta/68s=",
    {
      "./binding": "node_modules/leveldown-nodejs-mobile/binding.js",
      "./chained-batch": "node_modules/leveldown-nodejs-mobile/chained-batch.js",
      "./iterator": "node_modules/leveldown-nodejs-mobile/iterator.js",
      "abstract-leveldown": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/index.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-chained-batch.js": [
    "Z8EKDfGEpOQukRahaYVq29rf5GC4NqI89BA8V8zLEjM=",
    {
      "./next-tick": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/next-tick.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-iterator.js": [
    "zFwENznp0VlKGOUYw0UZkxqAiBy3wg7PWi8lMBIuBBE=",
    {
      "./next-tick": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/next-tick.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-leveldown.js": [
    "x0iMaqNlst14z89o06Dn5qILdB4SVT1ZLCwHt7tYY3s=",
    {
      "./abstract-chained-batch": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-chained-batch.js",
      "./abstract-iterator": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-iterator.js",
      "./next-tick": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/next-tick.js",
      "level-supports": "node_modules/level-supports/index.js",
      "xtend": "node_modules/xtend/immutable.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/index.js": [
    "TZhD82oHTYdXvS5L6p4PGz8scF9rlqoYYWIXtimi4GY=",
    {
      "./abstract-chained-batch": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-chained-batch.js",
      "./abstract-iterator": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-iterator.js",
      "./abstract-leveldown": "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/abstract-leveldown.js"
    }
  ],
  "node_modules/leveldown-nodejs-mobile/node_modules/abstract-leveldown/next-tick.js": [
    "JczFU1xaSOlfDIj/bfki3cAkCh3PBIunWfLagGh0jBk=",
    {}
  ],
  "node_modules/levelup/lib/batch.js": [
    "5XU3E7VBT7wkB2QI49GA6vwf8P/E4Hvgd7C9wBJktKA=",
    {
      "./common": "node_modules/levelup/lib/common.js",
      "./promisify": "node_modules/levelup/lib/promisify.js",
      "level-errors": "node_modules/level-errors/errors.js"
    }
  ],
  "node_modules/levelup/lib/common.js": [
    "LOgJFiE4jDSnvlkw/xVoJGC16bPVePyumo/9xppTGXA=",
    {}
  ],
  "node_modules/levelup/lib/levelup.js": [
    "VdIW5uG3T5zrCyaC7sTb6OKb9zvW+ObUAQo0Tx6GfH4=",
    {
      "./batch": "node_modules/levelup/lib/batch.js",
      "./common": "node_modules/levelup/lib/common.js",
      "./promisify": "node_modules/levelup/lib/promisify.js",
      "deferred-leveldown": "node_modules/deferred-leveldown/deferred-leveldown.js",
      "level-errors": "node_modules/level-errors/errors.js",
      "level-iterator-stream": "node_modules/level-iterator-stream/index.js",
      "xtend": "node_modules/xtend/immutable.js"
    }
  ],
  "node_modules/levelup/lib/promisify.js": [
    "P4SmaY4k9IerC2UPiYhuHbO5MvGb9gN+MjKTVCtIdH4=",
    {}
  ],
  "node_modules/lodash.debounce/index.js": [
    "eLukxUXKuOUKah/SVw+FOlmqz5YPDl0mTBK7RvmqowI=",
    {}
  ],
  "node_modules/lodash.get/index.js": [
    "fm7agC5Aeb8jRfA/2BQwWV/IDEgg6Zg9esWkI3eBZkg=",
    {}
  ],
  "node_modules/looper/index.js": [
    "cmcRqa+IsEsc2DIUeGXoK+grYAXQPGL4p7ftDNw4G6g=",
    {}
  ],
  "node_modules/ltgt/index.js": [
    "RC0G4pXmjf4c8/Lyl7lseK6vKwAETWfBC2RSfyB7mR0=",
    {}
  ],
  "node_modules/map-merge/index.js": [
    "WbGGkbXE072ELwpIugZuNTPk/+pFO11qXzmSHyh8Vls=",
    {}
  ],
  "node_modules/minimatch/minimatch.js": [
    "wOsU2J+v8D5povtXnv2iaAG82fiQsfmMwudy5EjJN1w=",
    {
      "brace-expansion": "node_modules/brace-expansion/index.js"
    }
  ],
  "node_modules/minimist/index.js": [
    "VeEkjVfnqryqbxUNCx17+zBHU1JEsoDbTRoFhNgl6sM=",
    {}
  ],
  "node_modules/mkdirp-classic/index.js": [
    "bk9dbSa68ZTPS7tNghEARu1iFSBbQSxXp7UJfcFiPqw=",
    {}
  ],
  "node_modules/mkdirp/index.js": [
    "/XjQhkiFHi2xsZ4ScakK1VtkDQtq4rIK0RyUruyEezM=",
    {
      "./lib/mkdirp-manual.js": "node_modules/mkdirp/lib/mkdirp-manual.js",
      "./lib/mkdirp-native.js": "node_modules/mkdirp/lib/mkdirp-native.js",
      "./lib/opts-arg.js": "node_modules/mkdirp/lib/opts-arg.js",
      "./lib/path-arg.js": "node_modules/mkdirp/lib/path-arg.js",
      "./lib/use-native.js": "node_modules/mkdirp/lib/use-native.js"
    }
  ],
  "node_modules/mkdirp/lib/find-made.js": [
    "dDt/2P1ewR3WpxgAZQplB59b0/CMurtcjfrfBtE411U=",
    {}
  ],
  "node_modules/mkdirp/lib/mkdirp-manual.js": [
    "SSvtzZkQFGlYA6N4j2xSDfnJtG/DFckjfev9txPXWq8=",
    {}
  ],
  "node_modules/mkdirp/lib/mkdirp-native.js": [
    "uwGJS8pFXXzEfElXaHKT7w+nQPxQ6a8TUVF+etZn0Ao=",
    {
      "./find-made.js": "node_modules/mkdirp/lib/find-made.js",
      "./mkdirp-manual.js": "node_modules/mkdirp/lib/mkdirp-manual.js"
    }
  ],
  "node_modules/mkdirp/lib/opts-arg.js": [
    "qaPk8XACAcHssdXrsz1tpp7PPbI1RsTQd8cwrkKgpqk=",
    {}
  ],
  "node_modules/mkdirp/lib/path-arg.js": [
    "k6uvt6ifD+AMZizY9BAPSu731bCgaLipr4GzjwPSEyU=",
    {}
  ],
  "node_modules/mkdirp/lib/use-native.js": [
    "/tHhT006ZQSTZmaXiJ5367O+bMtgVOn1UZdWbRzw7qg=",
    {}
  ],
  "node_modules/monotonic-timestamp/index.js": [
    "0ctY+ep4+F5/Kvk7cLkYlpHMnljPFrV5iNuugfJJSU0=",
    {}
  ],
  "node_modules/ms/index.js": [
    "VZhpcvXzyURvh2xXbhzTD9TwTNJlJ++7Wtg0Y3x0Dkw=",
    {}
  ],
  "node_modules/multiblob-http/index.js": [
    "MLOcvdJDegn+WNAXrQHN4ksrhEr+RDmG6uEDAckfU/k=",
    {
      "pull-many": "node_modules/pull-many/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "range-parser": "node_modules/range-parser/index.js",
      "stream-to-pull-stream": "node_modules/stream-to-pull-stream/index.js",
      "url-parse": "node_modules/url-parse/index.js"
    }
  ],
  "node_modules/multiblob/index.js": [
    "SX4Koa9IgsQ5iVOz8Wb+hmYGHG0EDhBnFus2kWOtzUQ=",
    {
      "./util": "node_modules/multiblob/util.js",
      "cont": "node_modules/cont/index.js",
      "explain-error": "node_modules/explain-error/index.js",
      "mkdirp": "node_modules/multiblob/node_modules/mkdirp/index.js",
      "pull-defer": "node_modules/pull-defer/index.js",
      "pull-glob": "node_modules/pull-glob/index.js",
      "pull-live": "node_modules/pull-live/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-paramap": "node_modules/pull-paramap/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "pull-write-file": "node_modules/pull-write-file/index.js",
      "rimraf": "node_modules/multiblob/node_modules/rimraf/rimraf.js"
    }
  ],
  "node_modules/multiblob/node_modules/mkdirp/index.js": [
    "xwNbRxsZe6bUh5toA7bKJzoXr2yKI4Lcul6zunCkOsI=",
    {}
  ],
  "node_modules/multiblob/node_modules/rimraf/rimraf.js": [
    "ObijCKnT/swbgPsChLHJV0zC2amgKxjwlh4yPR1ctyw=",
    {
      "glob": "node_modules/glob/glob.js"
    }
  ],
  "node_modules/multiblob/util.js": [
    "d68VhD4qPjJCCjZV4iht/AQ3G9MJCPwVFEILLpteZw4=",
    {
      "blake2s": "node_modules/blake2s/index.js",
      "pull-catch": "node_modules/pull-catch/index.js",
      "pull-file": "node_modules/pull-file/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/multicb/index.js": [
    "E+Lg/sIylbaDQTsYgpLQb6VqQhci414hp0+Ok/Qtvg8=",
    {}
  ],
  "node_modules/multiserver-address/index.js": [
    "NBNR/F8atKw3gYuYtJtZKLDqCBTAhVt3SAJbeaVYNF8=",
    {
      "./multiserver": "node_modules/multiserver-address/multiserver.js",
      "nearley": "node_modules/nearley/lib/nearley.js"
    }
  ],
  "node_modules/multiserver-address/multiserver.js": [
    "TaQlRWsarAhCsgdA53CNohbTKeqfyqGyJ1PcxCBKISo=",
    {}
  ],
  "node_modules/multiserver-bluetooth/index.js": [
    "+lJor2dtqZ6C1+x3yE+qwPLsbqTdxLdv+1/Vbq/t2VY=",
    {}
  ],
  "node_modules/multiserver-rn-channel/index.js": [
    "q5bx/UTtkXlbC5JX0SxWtwzw/uUs9V7eftjsmve1IVE=",
    {
      "pull-rn-channel": "node_modules/pull-rn-channel/index.js"
    }
  ],
  "node_modules/multiserver-scopes/index.js": [
    "vrzqLIyoiY9n8Ux8m/+gpkaGs3T2/2ixQlvSfT+BXYQ=",
    {
      "non-private-ip": "node_modules/non-private-ip-android/index.js"
    }
  ],
  "node_modules/multiserver/compose.js": [
    "sLmiPjL2jm6TJh7NT1zi9RFhougdthD/RilkssESTwY=",
    {
      "separator-escape": "node_modules/multiserver/node_modules/separator-escape/index.js"
    }
  ],
  "node_modules/multiserver/index.js": [
    "oKxecXS+ExfxPnCAlaCsLAYOIJ3m/bKnF0qZ6fDcXok=",
    {
      "./compose": "node_modules/multiserver/compose.js",
      "multicb": "node_modules/multicb/index.js"
    }
  ],
  "node_modules/multiserver/node_modules/separator-escape/index.js": [
    "qhIwNTpyhDgj1BQ3p6RpDN7ODtzFIDCmou5BfVoQeNI=",
    {}
  ],
  "node_modules/multiserver/plugins/noauth.js": [
    "IE2TfAMT+iaqzlx89bUg2LLc/4d7G7cx4BjgL5dMB+A=",
    {}
  ],
  "node_modules/multiserver/plugins/shs.js": [
    "wo8eZ38QomU23+HuhoRiapqt6BWw19qBYJHtnuMpDQI=",
    {
      "pull-stream": "node_modules/pull-stream/index.js",
      "secret-handshake": "node_modules/secret-handshake/index.js"
    }
  ],
  "node_modules/multiserver/plugins/ws.js": [
    "AthTRY10OgBLAlaG/beXl4z5FCAlPocbMnJaqKLBJIw=",
    {
      "debug": "node_modules/debug/src/index.js",
      "multiserver-scopes": "node_modules/multiserver-scopes/index.js",
      "pull-stream/pull": "node_modules/pull-stream/pull.js",
      "pull-stream/throughs/map": "node_modules/pull-stream/throughs/map.js",
      "pull-websocket": "node_modules/pull-websocket/index.js"
    }
  ],
  "node_modules/mutexify/index.js": [
    "bys7gyuw7IkQA/zIhbOomEwqgmjqI0BfEI8jDozx2ao=",
    {}
  ],
  "node_modules/muxrpc/index.js": [
    "oxwx+EUZbcigI6wvnehb6W7UwGyO5S3/coTk3OTTQJ8=",
    {
      "./local-api": "node_modules/muxrpc/local-api.js",
      "./remote-api": "node_modules/muxrpc/remote-api.js",
      "./stream": "node_modules/muxrpc/stream.js",
      "packet-stream-codec": "node_modules/packet-stream-codec/index.js"
    }
  ],
  "node_modules/muxrpc/local-api.js": [
    "xrVcBOieXCeK23taYVMumg1VSIA9t6/tHjZ/Gd2qRco=",
    {
      "./permissions": "node_modules/muxrpc/permissions.js",
      "./util": "node_modules/muxrpc/util.js"
    }
  ],
  "node_modules/muxrpc/permissions.js": [
    "tH0U05KG/Q1gFRPPteSw/JwtU3lEkSy8wYmXX8GK2o4=",
    {
      "./util": "node_modules/muxrpc/util.js"
    }
  ],
  "node_modules/muxrpc/pull-weird.js": [
    "Jwj2rCfgJw0NHt3AvO4xbjvr7f5LsUZc5tTrf2iQ3Vo=",
    {
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/muxrpc/remote-api.js": [
    "hLfHheaBCA/u6FTNJvtvLUBUzn0KmM8b/BoYWPmXzkY=",
    {
      "./util": "node_modules/muxrpc/util.js",
      "explain-error": "node_modules/explain-error/index.js"
    }
  ],
  "node_modules/muxrpc/stream.js": [
    "23ExSkdQgwdR5Q2Nt84Ti7Y1BXJ1CPUdGKLqFtft8Pc=",
    {
      "./pull-weird": "node_modules/muxrpc/pull-weird.js",
      "./util": "node_modules/muxrpc/util.js",
      "explain-error": "node_modules/explain-error/index.js",
      "packet-stream": "node_modules/packet-stream/index.js",
      "pull-goodbye": "node_modules/pull-goodbye/index.js"
    }
  ],
  "node_modules/muxrpc/util.js": [
    "3PFOGJDDD5HnzobxKjYpLIqOmTcCYDinOmM/VKH+SoA=",
    {
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/nearley/lib/nearley.js": [
    "hFQKenIZaVQyuP6Hd5SjFa4atiqjB4h7WNbq/6qL8cM=",
    {}
  ],
  "node_modules/non-private-ip-android/index.js": [
    "/zFQoSDNfJ+hXgO0jFfy8uPR09vTZ4UxMBxW8yVrL3I=",
    {
      "ip": "node_modules/ip/lib/ip.js"
    }
  ],
  "node_modules/object-is/implementation.js": [
    "NRHFeNHC/84D/xoLT79B8HK/a17eF0B1K2LDGKUogok=",
    {}
  ],
  "node_modules/object-is/index.js": [
    "s0VA/WSn9Snw5iF0galXnEPUhSoS2pTt11wFpXW+RZc=",
    {
      "./implementation": "node_modules/object-is/implementation.js",
      "./polyfill": "node_modules/object-is/polyfill.js",
      "./shim": "node_modules/object-is/shim.js",
      "call-bind": "node_modules/call-bind/index.js",
      "define-properties": "node_modules/define-properties/index.js"
    }
  ],
  "node_modules/object-is/polyfill.js": [
    "zKrPE75JMEROfV//FutcQKK2S5MFe4htKaYGvgJYnRE=",
    {
      "./implementation": "node_modules/object-is/implementation.js"
    }
  ],
  "node_modules/object-is/shim.js": [
    "xPbNzdTI39I17WGLPy44fNIntC+JebKS/V60dQSirrE=",
    {
      "./polyfill": "node_modules/object-is/polyfill.js",
      "define-properties": "node_modules/define-properties/index.js"
    }
  ],
  "node_modules/object-keys/implementation.js": [
    "TdQ7+GuIb2rcFqo0svDTonuS7PZa3LhyJOVM05TSAkw=",
    {
      "./isArguments": "node_modules/object-keys/isArguments.js"
    }
  ],
  "node_modules/object-keys/index.js": [
    "QARYiqejdp2MNO+ag34WMiN0h+U+1XyuxRv8xmaPLCk=",
    {
      "./implementation": "node_modules/object-keys/implementation.js",
      "./isArguments": "node_modules/object-keys/isArguments.js"
    }
  ],
  "node_modules/object-keys/isArguments.js": [
    "MfNt7SeEFQt0gPVspC5/2m4RnUNF1YhKTV9V4T/mrDA=",
    {}
  ],
  "node_modules/obv/index.js": [
    "xSRq8n3FIcXzFSl9Byiz7J1D2CyiAtSlGAUztSy6ad8=",
    {}
  ],
  "node_modules/obz/index.js": [
    "PzqmH036YAvn8s/HIs/BtoJzKFyXkFW/tpzfv/YOWWI=",
    {}
  ],
  "node_modules/on-change-network-strict/index.js": [
    "fL5D0k4SZBTB3uNOuJrRc0PxkyYCr7Mlc2Yxf7Mnwtg=",
    {}
  ],
  "node_modules/on-wakeup/index.js": [
    "mJ1Mb97wyF/JYKHtacPJzv4XFtJkBvQS68qNva21Y08=",
    {}
  ],
  "node_modules/once/once.js": [
    "Pbc+NH7L26/fjQ24UUXId+Ez9TcudnNg75DAn3CsUQM=",
    {
      "wrappy": "node_modules/wrappy/wrappy.js"
    }
  ],
  "node_modules/os-homedir/index.js": [
    "6+0EJUY6cZ+zYs2V8FcjxPdpC0MQXyTWQqJ40hix9aU=",
    {}
  ],
  "node_modules/p-defer/index.js": [
    "DR0vy+NgqrmJOPJkI6Hw4SLB8ox2DZOJ9T1ygtpAMNw=",
    {}
  ],
  "node_modules/packet-stream-codec/index.js": [
    "hBy4BpDLhfBjslamYaN7SKNU00r5tz2pFNrSVFl+q5o=",
    {
      "pull-reader": "node_modules/pull-reader/index.js",
      "pull-through": "node_modules/pull-through/index.js"
    }
  ],
  "node_modules/packet-stream/index.js": [
    "26dye6s1OH2zki3bHmc/SGdSTEpBF1WswVtN4KJ2AB4=",
    {
      "./substream": "node_modules/packet-stream/substream.js",
      "./utils": "node_modules/packet-stream/utils.js"
    }
  ],
  "node_modules/packet-stream/substream.js": [
    "Q4bxXCqL1Ab2Xb/fdXqD8A0XLVWcCYDImaKNU7YGEMQ=",
    {
      "./utils": "node_modules/packet-stream/utils.js"
    }
  ],
  "node_modules/packet-stream/utils.js": [
    "UEa2KusXKPiwqCM8Ucgw1onALpA2a3nd+wzx931plQI=",
    {}
  ],
  "node_modules/path-is-absolute/index.js": [
    "TrERnD7szE2OiEG3fQYquvRXKzMoAfWxYXW8MxG12PE=",
    {}
  ],
  "node_modules/pbkdf2/index.js": [
    "e45PHnhDaGXDW35/LSAfzpkq3S3Qe/P9rnBeBkEIKIs=",
    {
      "./lib/async": "node_modules/pbkdf2/lib/async.js",
      "./lib/default-encoding": "node_modules/pbkdf2/lib/default-encoding.js",
      "./lib/precondition": "node_modules/pbkdf2/lib/precondition.js",
      "./lib/sync": "node_modules/pbkdf2/lib/sync.js",
      "./lib/to-buffer": "node_modules/pbkdf2/lib/to-buffer.js"
    }
  ],
  "node_modules/pbkdf2/lib/async.js": [
    "/xj/D2HNeAgc46GiRf1m5DmBFYlnsqX6oJ9W/FF0TEU=",
    {
      "./default-encoding": "node_modules/pbkdf2/lib/default-encoding.js",
      "./precondition": "node_modules/pbkdf2/lib/precondition.js",
      "./sync": "node_modules/pbkdf2/lib/sync.js",
      "./to-buffer": "node_modules/pbkdf2/lib/to-buffer.js",
      "safe-buffer": "node_modules/safe-buffer/index.js"
    }
  ],
  "node_modules/pbkdf2/lib/default-encoding.js": [
    "PGWYEYmYIgPUf88EuAnryg5Ac4vxRG7uvYuILVqpgGw=",
    {}
  ],
  "node_modules/pbkdf2/lib/precondition.js": [
    "L8Nn1TL1ypFEFXQDGSFGtOMVJgFtYUb4UaEFgq+4qpY=",
    {}
  ],
  "node_modules/pbkdf2/lib/sync.js": [
    "cdAjy5xVv/ggD4VyofSOVRaslZQ9sWo3Bfxvs1dxEUg=",
    {
      "./default-encoding": "node_modules/pbkdf2/lib/default-encoding.js",
      "./precondition": "node_modules/pbkdf2/lib/precondition.js",
      "./to-buffer": "node_modules/pbkdf2/lib/to-buffer.js",
      "create-hmac": "node_modules/create-hmac/index.js",
      "safe-buffer": "node_modules/safe-buffer/index.js"
    }
  ],
  "node_modules/pbkdf2/lib/to-buffer.js": [
    "jZcIkJxgPPvJUSn/GZwG+T7smUrcB25nczaGP1Fv/7Y=",
    {
      "safe-buffer": "node_modules/safe-buffer/index.js"
    }
  ],
  "node_modules/peek-readable/lib/EndOfFileStream.js": [
    "JTC/Fj0gcy4Hk7lDAtqjl5ZMxM7/P87Ec2+rcXG5sOM=",
    {}
  ],
  "node_modules/peek-readable/lib/index.js": [
    "yFQ9igUdyeN0+gBEoIeUDBANrY3ZyD99nos/cwXw6+U=",
    {
      "./EndOfFileStream": "node_modules/peek-readable/lib/EndOfFileStream.js"
    }
  ],
  "node_modules/polyraf/index.js": [
    "bPnKnRHY9Y1+/6jYdrKcxU1emBLzYFJiw4mTfEX3SLQ=",
    {
      "random-access-file": "node_modules/random-access-file/index.js"
    }
  ],
  "node_modules/private-box/index.js": [
    "TQAUexAH54IG+4QLpJseo/IuVTYWBRpcD0xFGxX05rE=",
    {
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/promisify-4loc/index.js": [
    "wlWpEMyyQXJHi0o8aS8IyFXgiv1if1amTRaJE1CjFwQ=",
    {}
  ],
  "node_modules/promisify-tuple/index.js": [
    "v4tcZrpwSGJnagS9urzPN03rp3UGiREWn5xfYhbbXUM=",
    {}
  ],
  "node_modules/promisize/index.js": [
    "Oc5R85kAunEsl9tmxVP0hyHzugCqnT53PX/JhoVOXXE=",
    {}
  ],
  "node_modules/prr/prr.js": [
    "M2waEw6vcov0DK2BRKoWlCliMH8ZJJjGMyHW/1nZqqw=",
    {}
  ],
  "node_modules/pull-abortable/index.js": [
    "8awuKc7pKqrk8gvE3q1Yl+IrB12AY+YJoKIyW9haNcI=",
    {}
  ],
  "node_modules/pull-async/index.js": [
    "Z3VmD9lJ5/XB3h2+m5IE1aSFTJQtfWQjZ1/v0+KDm/U=",
    {}
  ],
  "node_modules/pull-awaitable/index.js": [
    "y2y9xqfX2lCHfMmrhp/Xg0XdhImgLsNWlHJYh84rDi8=",
    {
      "pull-thenable": "node_modules/pull-thenable/index.js"
    }
  ],
  "node_modules/pull-box-stream/index.js": [
    "Hd42sxnEpaud2aKp5Kueybje9K86nee9rdK2HHTmBxE=",
    {
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js",
      "increment-buffer": "node_modules/increment-buffer/index.js",
      "pull-reader": "node_modules/pull-reader/index.js",
      "pull-through": "node_modules/pull-through/index.js",
      "split-buffer": "node_modules/split-buffer/index.js"
    }
  ],
  "node_modules/pull-cat/index.js": [
    "idd7qu25M925EN8jktnwp9Lp6QUaQ7d5lzrO+4WrzJ4=",
    {}
  ],
  "node_modules/pull-catch/index.js": [
    "0USpmsILuN6k9ei85R4WvKV4b7XOs8EQtm7X8xiHOmc=",
    {}
  ],
  "node_modules/pull-cont/duplex.js": [
    "/cvNxPM80iuWFV+jxhXBKmglbAPdCZKVGWELQeNLVog=",
    {
      "./": "node_modules/pull-cont/index.js",
      "./sink": "node_modules/pull-cont/sink.js"
    }
  ],
  "node_modules/pull-cont/index.js": [
    "UYSNoj9/0kgnXgUE5YtPc5OwTrs+QkgByb7sJCNsGzY=",
    {
      "./duplex": "node_modules/pull-cont/duplex.js",
      "./sink": "node_modules/pull-cont/sink.js",
      "./source": "node_modules/pull-cont/source.js"
    }
  ],
  "node_modules/pull-cont/sink.js": [
    "8vxRGsq1DtgN3QLXryHGZxIJZ7Et6C+dF1MYssntWsE=",
    {}
  ],
  "node_modules/pull-cont/source.js": [
    "rqwIhOjK14ppHLMhv6r7JKQ86nk8skJVNtKQIdyb/gs=",
    {}
  ],
  "node_modules/pull-cursor/cursor.js": [
    "w79prpAb+6NCPSE7aITlZyMi4X1+tQXmILfQfh0AXvU=",
    {}
  ],
  "node_modules/pull-cursor/index.js": [
    "1KZeGX3adyx7FFG+EWqY06bl4IWMm9hDXtEdAcP0Jm8=",
    {
      "./cursor": "node_modules/pull-cursor/cursor.js",
      "./range": "node_modules/pull-cursor/range.js",
      "./skip": "node_modules/pull-cursor/skip.js",
      "pull-stream/throughs/take": "node_modules/pull-stream/throughs/take.js"
    }
  ],
  "node_modules/pull-cursor/node_modules/looper/index.js": [
    "KricQafdcfK9V/7mcHaPDtDxPjqNg+ipAtIcKJI7Du4=",
    {}
  ],
  "node_modules/pull-cursor/range.js": [
    "0vwyYoswQgtCoEP6xFmarlTOtZIddwv7w6GLRb1Ewc4=",
    {
      "ltgt": "node_modules/ltgt/index.js"
    }
  ],
  "node_modules/pull-cursor/skip.js": [
    "SuebAfIKqQBB1uxEahV1WftDO2rU0Qt4teNgrjRwMeg=",
    {
      "looper": "node_modules/pull-cursor/node_modules/looper/index.js"
    }
  ],
  "node_modules/pull-defer/duplex.js": [
    "an9dxouVGOFt+pPYLCmIvQ3cMN+eGDewAEmBPGhlX6s=",
    {
      "./sink": "node_modules/pull-defer/sink.js",
      "./source": "node_modules/pull-defer/source.js"
    }
  ],
  "node_modules/pull-defer/index.js": [
    "Ec94syWZ8ZehXUFpWXfxPzgEuSAFW53cQ5rrsxA9vDg=",
    {
      "./duplex": "node_modules/pull-defer/duplex.js",
      "./sink": "node_modules/pull-defer/sink.js",
      "./source": "node_modules/pull-defer/source.js",
      "./through": "node_modules/pull-defer/through.js"
    }
  ],
  "node_modules/pull-defer/sink.js": [
    "iNFmWMaOW92q0y0KBbZ4lp23v+VKyzsbYGydLZaoAGI=",
    {}
  ],
  "node_modules/pull-defer/source.js": [
    "72XVPy+VsgaBUFvX4hmVSkng1lKVA5wGIBkU87syh+U=",
    {}
  ],
  "node_modules/pull-defer/through.js": [
    "bDJXRfHwQQgCZLXZdgjYSo4HwvJzGOortTI8nFRPCeA=",
    {}
  ],
  "node_modules/pull-drain-gently/index.js": [
    "lOD7p1oqL5sG3n2M87o/mW8Hfeb1TltKtfoBBhT0eWU=",
    {
      "cpu-percentage": "node_modules/cpu-percentage/index.js",
      "pull-pause": "node_modules/pull-pause/index.js"
    }
  ],
  "node_modules/pull-file/index.js": [
    "uMt0kvwcnRi+ULOk8HcWo6hfu8zIzqslNq+Oi9mMC6U=",
    {
      "pull-utf8-decoder": "node_modules/pull-utf8-decoder/index.js"
    }
  ],
  "node_modules/pull-fs/core.js": [
    "9+Nl4PO/Aeysg9Z/HWpXKn2CTtKNmBDCkgkl/lk0i3w=",
    {
      "pull-file": "node_modules/pull-fs/node_modules/pull-file/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "pull-write-file": "node_modules/pull-write-file/index.js"
    }
  ],
  "node_modules/pull-fs/index.js": [
    "ap3iIy8iwWqq+wjloxfLq1T76n5Jxge27khF9jPmU2s=",
    {
      "./core": "node_modules/pull-fs/core.js",
      "./util": "node_modules/pull-fs/util.js"
    }
  ],
  "node_modules/pull-fs/node_modules/pull-file/index.js": [
    "Lta3am9ceHN18sGtRfYsVM7JX7PYRPD85r4mnC6A61U=",
    {
      "pull-utf8-decoder": "node_modules/pull-utf8-decoder/index.js"
    }
  ],
  "node_modules/pull-fs/util.js": [
    "NPTQaqC0L+LL08vg469X8W8PG9i/6dnupB6Z8HZ13w4=",
    {
      "./core": "node_modules/pull-fs/core.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "pull-traverse": "node_modules/pull-traverse/index.js"
    }
  ],
  "node_modules/pull-glob/index.js": [
    "Il16G9zxx06MfUmseVn0fq/M8pBXAjmNMQUNkSV9zrI=",
    {
      "pull-fs": "node_modules/pull-fs/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/pull-goodbye/endable.js": [
    "MPt8C16/vEjBz4HvZWE4nL0TRrByiC2xv/wtHIxN044=",
    {}
  ],
  "node_modules/pull-goodbye/index.js": [
    "dJExb2QIXWVtCYEVjUZImSHXrDegUkHDIbJ8QrcZBWM=",
    {
      "./endable": "node_modules/pull-goodbye/endable.js",
      "pull-stream": "node_modules/pull-goodbye/node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/index.js": [
    "T3UqgRvH4bF+fXBGd8nMc1944LbajxvPEQKRdhx9vNs=",
    {
      "./pull": "node_modules/pull-goodbye/node_modules/pull-stream/pull.js",
      "./sinks": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/index.js",
      "./sources": "node_modules/pull-goodbye/node_modules/pull-stream/sources/index.js",
      "./throughs": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/index.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/pull.js": [
    "IcQfpQxyzQfjpUrE5UZsOmUXrjCPM4b2yiXwbu5wUOI=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/collect.js": [
    "gMHYP8b6vKRO61YoCyxW+3f1wgj+w4hadEXqdTRhitI=",
    {
      "./reduce": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/reduce.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/concat.js": [
    "7LceS+qAzU+tDOfC68RLs+EK6L2OcwVChem7Koha3+s=",
    {
      "./reduce": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/reduce.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/drain.js": [
    "MFvgRymxsxnD2IUCoCxMftlhI2mmRvOjePIYa43LPIc=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/find.js": [
    "vh1sso/6T5hxzkJ4j7B953lMLenDDUF3uPJQTTQXVMA=",
    {
      "../util/prop": "node_modules/pull-goodbye/node_modules/pull-stream/util/prop.js",
      "./drain": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/index.js": [
    "fu5736jRclYQ5bBIMvHbeZrVIn9Ge1vsNaC3nOHuE6g=",
    {
      "./collect": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/collect.js",
      "./concat": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/concat.js",
      "./drain": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/drain.js",
      "./find": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/find.js",
      "./log": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/log.js",
      "./on-end": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/on-end.js",
      "./reduce": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/reduce.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/log.js": [
    "sr4ZuI56+DGxLPSkbLiTDq4lQC4DEnbSXP5/4GyHlWU=",
    {
      "./drain": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/on-end.js": [
    "xA8pUYHbmyFv8yRIInUee/Papd2wIiHeL8KpOgUueLc=",
    {
      "./drain": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sinks/reduce.js": [
    "l2IwU6xsFEXan/x2xPS/h8CMhbIgsTxAXNU6urAAsCQ=",
    {
      "./drain": "node_modules/pull-goodbye/node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/count.js": [
    "D6nHxB06ZsH6a/+aiIBcTcmNMvDiLVScaxthn734INo=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/empty.js": [
    "2Y2ZC8CxBt7Bw3QLvjvOTALAHIlSzSRJfk9JOyNrpTs=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/error.js": [
    "icbkd+UFtlzcBH2FZL1S82H9g+EfjgiTDf75GwYy1gQ=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/index.js": [
    "N4AuyayS6B7XIgVGR+Mj/YZ/o0Y4aBgIy4yJRVAEFMw=",
    {
      "./count": "node_modules/pull-goodbye/node_modules/pull-stream/sources/count.js",
      "./empty": "node_modules/pull-goodbye/node_modules/pull-stream/sources/empty.js",
      "./error": "node_modules/pull-goodbye/node_modules/pull-stream/sources/error.js",
      "./infinite": "node_modules/pull-goodbye/node_modules/pull-stream/sources/infinite.js",
      "./keys": "node_modules/pull-goodbye/node_modules/pull-stream/sources/keys.js",
      "./once": "node_modules/pull-goodbye/node_modules/pull-stream/sources/once.js",
      "./values": "node_modules/pull-goodbye/node_modules/pull-stream/sources/values.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/infinite.js": [
    "uDwvQE69haX7Ha1KXpbIxpyqbRXpu8KQwRW/yHySsTw=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/keys.js": [
    "2AeMBMOSc/5k20IYF42HLOAJXiNOJGJoyb8U79p3Wc4=",
    {
      "./values": "node_modules/pull-goodbye/node_modules/pull-stream/sources/values.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/once.js": [
    "pHKD0YRdWAkLaR4mj/jjwLSo0oWPObv1rDQFtnBdbgQ=",
    {
      "../util/abort-cb": "node_modules/pull-goodbye/node_modules/pull-stream/util/abort-cb.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/sources/values.js": [
    "CCV/8KXzWyHw5p1xKk33zQBu1/gzi/adDMDZU27EUUw=",
    {
      "../util/abort-cb": "node_modules/pull-goodbye/node_modules/pull-stream/util/abort-cb.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/async-map.js": [
    "xm940DkNdL0yCuHb8fwDQElynxDLSoYE5b1heU2BmDU=",
    {
      "../util/prop": "node_modules/pull-goodbye/node_modules/pull-stream/util/prop.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/filter-not.js": [
    "JI5bMXQY9dKVqGD3OEE1aCjUp1viKEcQXFVJxofiPzE=",
    {
      "../util/tester": "node_modules/pull-goodbye/node_modules/pull-stream/util/tester.js",
      "./filter": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/filter.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/filter.js": [
    "iH0TcLTxRBPQ09mNvsmD4iv9MaMkB8ZNmder3XPFVwo=",
    {
      "../util/tester": "node_modules/pull-goodbye/node_modules/pull-stream/util/tester.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/flatten.js": [
    "g4zOVThIoKpKDOd5LclaDVQBHLrludnmLrPmtq5xUl0=",
    {
      "../sources/once": "node_modules/pull-goodbye/node_modules/pull-stream/sources/once.js",
      "../sources/values": "node_modules/pull-goodbye/node_modules/pull-stream/sources/values.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/index.js": [
    "QC13FnlczWnvX4IxreFGpKJod3GHol2Nh0MeFAx7rdg=",
    {
      "./async-map": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/async-map.js",
      "./filter": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/filter.js",
      "./filter-not": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/filter-not.js",
      "./flatten": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/flatten.js",
      "./map": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/map.js",
      "./non-unique": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/non-unique.js",
      "./take": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/take.js",
      "./through": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/through.js",
      "./unique": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/unique.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/map.js": [
    "AINTHrGMiW9dchJOHX1AoGEo7qDBiT1vE+EEgjZTTM8=",
    {
      "../util/prop": "node_modules/pull-goodbye/node_modules/pull-stream/util/prop.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/non-unique.js": [
    "du21y+8inJ/P4nQDRHX/EG89baNvBz9s/Df9yIAsdy4=",
    {
      "./unique": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/unique.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/take.js": [
    "AnlcEj/4pufJjUD4wN/HjKnYXqwoI6Nes7QmANhf9lo=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/through.js": [
    "qRbKwEJSKJyVjIDhbQ80030gZD5fwou1JipZ80ksCEk=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/throughs/unique.js": [
    "UmPkJSHiu8xxCj90vud+nsZcf3NuTOu0M/ZLtxMfiE8=",
    {
      "../util/prop": "node_modules/pull-goodbye/node_modules/pull-stream/util/prop.js",
      "./filter": "node_modules/pull-goodbye/node_modules/pull-stream/throughs/filter.js"
    }
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/util/abort-cb.js": [
    "Yfjgf9nNTJ9CcTEHyc6w417HHM0GOBsjZOOC/ojsBVA=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/util/prop.js": [
    "bdLIeMr12r3Y6t1FkL3yngdaHzmbPIQdtI/UzAK1ffw=",
    {}
  ],
  "node_modules/pull-goodbye/node_modules/pull-stream/util/tester.js": [
    "N6CE39E4absFwePI6bRfr43tXN4FV3L3mxO/OdUpmEg=",
    {
      "./prop": "node_modules/pull-goodbye/node_modules/pull-stream/util/prop.js"
    }
  ],
  "node_modules/pull-handshake/index.js": [
    "6+BxrYHbhymYY1ZogfZ7psXyJBTFvc4LnvHwuYIFAWE=",
    {
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-pair": "node_modules/pull-pair/index.js",
      "pull-pushable": "node_modules/pull-pushable/index.js",
      "pull-reader": "node_modules/pull-reader/index.js"
    }
  ],
  "node_modules/pull-inactivity/index.js": [
    "6Guyk+kvFKXes2B5gVa1V2Ss2ATwgx5FVJBKUPHx1yk=",
    {
      "./rate": "node_modules/pull-inactivity/rate.js",
      "pull-abortable": "node_modules/pull-abortable/index.js",
      "pull-stream/pull": "node_modules/pull-stream/pull.js",
      "pull-stream/throughs/through": "node_modules/pull-stream/throughs/through.js"
    }
  ],
  "node_modules/pull-inactivity/rate.js": [
    "i7hs1ROQ5c8UpROCVPsG/HxeXhdrV8iusVB8W5UPuvk=",
    {
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/pull-json-doubleline/index.js": [
    "6ervpJovy46ChznRJlGQkYDZQCGIHufyCMecluGBgWY=",
    {
      "is-pull-stream": "node_modules/is-pull-stream/index.js",
      "pull-split": "node_modules/pull-split/index.js",
      "pull-stream/pull": "node_modules/pull-stream/pull.js",
      "pull-stream/throughs/filter": "node_modules/pull-stream/throughs/filter.js",
      "pull-stream/throughs/map": "node_modules/pull-stream/throughs/map.js",
      "pull-stringify": "node_modules/pull-stringify/index.js"
    }
  ],
  "node_modules/pull-level/index.js": [
    "/uTEjzzH3brhfJ65dBWMQ9ZokSzxbWV7FTgbybBkRL8=",
    {
      "./live": "node_modules/pull-level/live.js",
      "./old": "node_modules/pull-level/old.js",
      "./read": "node_modules/pull-level/read.js",
      "./write": "node_modules/pull-level/write.js",
      "pull-live": "node_modules/pull-live/index.js"
    }
  ],
  "node_modules/pull-level/live.js": [
    "zAcLomqBPQ6rU1FGePAfIn5jgpJlHvFwNvMVKTNalcY=",
    {
      "level-post": "node_modules/level-post/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-pushable": "node_modules/pull-pushable/index.js"
    }
  ],
  "node_modules/pull-level/old.js": [
    "O77Ee49dvz+Zr5xnNk3T8kIxIBbIbMX3dTMVDQBXvoU=",
    {
      "stream-to-pull-stream": "node_modules/stream-to-pull-stream/index.js"
    }
  ],
  "node_modules/pull-level/read.js": [
    "rwNYsCS+A6tOLsNoqukwlgE/+tgudzpFMF5kNadc528=",
    {
      "./live": "node_modules/pull-level/live.js",
      "./old": "node_modules/pull-level/old.js",
      "pull-live": "node_modules/pull-live/index.js"
    }
  ],
  "node_modules/pull-level/write.js": [
    "3p6myKHUlW9PdND2YLlWi/MgrVPUa1t7YVRNrgd8nXE=",
    {
      "pull-stream/pull": "node_modules/pull-stream/pull.js",
      "pull-stream/sinks/drain": "node_modules/pull-stream/sinks/drain.js",
      "pull-stream/throughs/async-map": "node_modules/pull-stream/throughs/async-map.js",
      "pull-stream/throughs/map": "node_modules/pull-stream/throughs/map.js",
      "pull-window": "node_modules/pull-window/index.js"
    }
  ],
  "node_modules/pull-live/index.js": [
    "JZKVVZFwolTe6of+EmBC7QR4zbX38nI6VWeZwpZxj3U=",
    {
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream/pull": "node_modules/pull-stream/pull.js",
      "pull-stream/sources/once": "node_modules/pull-stream/sources/once.js"
    }
  ],
  "node_modules/pull-looper/index.js": [
    "unnOKzF5Ubb6CRwfvBY0tfhGPLN2FeveP9BOFVEdvNQ=",
    {
      "looper": "node_modules/pull-looper/node_modules/looper/index.js"
    }
  ],
  "node_modules/pull-looper/node_modules/looper/index.js": [
    "KricQafdcfK9V/7mcHaPDtDxPjqNg+ipAtIcKJI7Du4=",
    {}
  ],
  "node_modules/pull-many/index.js": [
    "pypnDHT31dfog1AFrqXz8xOQHgBglbiMO10JsdrAXi0=",
    {}
  ],
  "node_modules/pull-notify/index.js": [
    "vHm/pcwRyBehzxEtphC1pDh+OUrUB4NLdjVQ02UJToY=",
    {
      "pull-pushable": "node_modules/pull-pushable/index.js"
    }
  ],
  "node_modules/pull-pair/duplex.js": [
    "S2rBVEZMo4/ty/rY/enQ5WJaFapBlW5050ajj0i1i4s=",
    {
      "./": "node_modules/pull-pair/index.js"
    }
  ],
  "node_modules/pull-pair/index.js": [
    "8It9l0trLHjLwFy+Qv3oPWTAEoErwSDL9wH5UIDmgGE=",
    {}
  ],
  "node_modules/pull-paramap/index.js": [
    "KTuLg9BprAdeeu1VSnlH1oabcpcDJWgLTe3Zc/+2Mlc=",
    {
      "looper": "node_modules/pull-paramap/node_modules/looper/index.js"
    }
  ],
  "node_modules/pull-paramap/node_modules/looper/index.js": [
    "KricQafdcfK9V/7mcHaPDtDxPjqNg+ipAtIcKJI7Du4=",
    {}
  ],
  "node_modules/pull-pause/index.js": [
    "JdmrN6fAzt50f1H7c9iV5a4yNrlFGCj2h+jn6RgK9aw=",
    {}
  ],
  "node_modules/pull-ping/index.js": [
    "gP3g9VLKEJyQWuiNQ78ib7+rKUW8f84N8Dcxp3qR3Yc=",
    {
      "pull-pushable": "node_modules/pull-pushable/index.js",
      "pull-stream/sinks/drain": "node_modules/pull-stream/sinks/drain.js",
      "statistics/mutate": "node_modules/statistics/mutate.js"
    }
  ],
  "node_modules/pull-promise/index.js": [
    "1wSZ5U01FYlmrtFORry+hgFMXPPFEOmZpuJTspxVStg=",
    {
      "./source": "node_modules/pull-promise/source.js",
      "./through": "node_modules/pull-promise/through.js"
    }
  ],
  "node_modules/pull-promise/source.js": [
    "lOsxLWvDh9oFvVCijNGrR2iC+dtdL8ipsbKaPsjzyvw=",
    {
      "pull-stream/util/abort-cb": "node_modules/pull-stream/util/abort-cb.js"
    }
  ],
  "node_modules/pull-promise/through.js": [
    "uPQ41FZx81sDszYzXDS7+9JihCfkNL0TmQouJWRj900=",
    {
      "pull-stream/throughs/async-map": "node_modules/pull-stream/throughs/async-map.js"
    }
  ],
  "node_modules/pull-pushable/index.js": [
    "CHLIk0Y1f6e8W0C/NVOxpVzjwwrZJZAsw4dZtWW3PQM=",
    {}
  ],
  "node_modules/pull-reader/index.js": [
    "RtJfR0T1FNWmtbehnPBLchbGZ16wg/GW6tq6tYHH2Xk=",
    {
      "./state": "node_modules/pull-reader/state.js"
    }
  ],
  "node_modules/pull-reader/state.js": [
    "WLbVp5KKu/6DuSzVUw9IqoqvaxRknrerO3lh6mcu+sU=",
    {}
  ],
  "node_modules/pull-rn-channel/index.js": [
    "7nx6M/8jYI/tPQVAOIMyQPi7B7tMpUSziHghUjPfKMA=",
    {
      "quick-insert": "node_modules/quick-insert/index.js"
    }
  ],
  "node_modules/pull-split/index.js": [
    "LNMmQ887D8pIaPCl9mWvS7Lwx2T3qk+TcUnyxU0yfQY=",
    {
      "pull-through": "node_modules/pull-through/index.js"
    }
  ],
  "node_modules/pull-stream-util/from-event.js": [
    "UlklLaXNgUZVmkgH4euWOojpke4AOCm639HrKUHDTjM=",
    {
      "pull-pushable": "node_modules/pull-pushable/index.js"
    }
  ],
  "node_modules/pull-stream/index.js": [
    "18Fc7E2hFtjB+iI+xuiQwSfH+/wRydXt0qUqjhgOUd8=",
    {
      "./pull": "node_modules/pull-stream/pull.js",
      "./sinks": "node_modules/pull-stream/sinks/index.js",
      "./sources": "node_modules/pull-stream/sources/index.js",
      "./throughs": "node_modules/pull-stream/throughs/index.js"
    }
  ],
  "node_modules/pull-stream/pull.js": [
    "IcQfpQxyzQfjpUrE5UZsOmUXrjCPM4b2yiXwbu5wUOI=",
    {}
  ],
  "node_modules/pull-stream/sinks/collect.js": [
    "gMHYP8b6vKRO61YoCyxW+3f1wgj+w4hadEXqdTRhitI=",
    {
      "./reduce": "node_modules/pull-stream/sinks/reduce.js"
    }
  ],
  "node_modules/pull-stream/sinks/concat.js": [
    "7LceS+qAzU+tDOfC68RLs+EK6L2OcwVChem7Koha3+s=",
    {
      "./reduce": "node_modules/pull-stream/sinks/reduce.js"
    }
  ],
  "node_modules/pull-stream/sinks/drain.js": [
    "MFvgRymxsxnD2IUCoCxMftlhI2mmRvOjePIYa43LPIc=",
    {}
  ],
  "node_modules/pull-stream/sinks/find.js": [
    "vh1sso/6T5hxzkJ4j7B953lMLenDDUF3uPJQTTQXVMA=",
    {
      "../util/prop": "node_modules/pull-stream/util/prop.js",
      "./drain": "node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-stream/sinks/index.js": [
    "fu5736jRclYQ5bBIMvHbeZrVIn9Ge1vsNaC3nOHuE6g=",
    {
      "./collect": "node_modules/pull-stream/sinks/collect.js",
      "./concat": "node_modules/pull-stream/sinks/concat.js",
      "./drain": "node_modules/pull-stream/sinks/drain.js",
      "./find": "node_modules/pull-stream/sinks/find.js",
      "./log": "node_modules/pull-stream/sinks/log.js",
      "./on-end": "node_modules/pull-stream/sinks/on-end.js",
      "./reduce": "node_modules/pull-stream/sinks/reduce.js"
    }
  ],
  "node_modules/pull-stream/sinks/log.js": [
    "sr4ZuI56+DGxLPSkbLiTDq4lQC4DEnbSXP5/4GyHlWU=",
    {
      "./drain": "node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-stream/sinks/on-end.js": [
    "xA8pUYHbmyFv8yRIInUee/Papd2wIiHeL8KpOgUueLc=",
    {
      "./drain": "node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-stream/sinks/reduce.js": [
    "l2IwU6xsFEXan/x2xPS/h8CMhbIgsTxAXNU6urAAsCQ=",
    {
      "./drain": "node_modules/pull-stream/sinks/drain.js"
    }
  ],
  "node_modules/pull-stream/sources/count.js": [
    "D6nHxB06ZsH6a/+aiIBcTcmNMvDiLVScaxthn734INo=",
    {}
  ],
  "node_modules/pull-stream/sources/empty.js": [
    "2Y2ZC8CxBt7Bw3QLvjvOTALAHIlSzSRJfk9JOyNrpTs=",
    {}
  ],
  "node_modules/pull-stream/sources/error.js": [
    "icbkd+UFtlzcBH2FZL1S82H9g+EfjgiTDf75GwYy1gQ=",
    {}
  ],
  "node_modules/pull-stream/sources/index.js": [
    "N4AuyayS6B7XIgVGR+Mj/YZ/o0Y4aBgIy4yJRVAEFMw=",
    {
      "./count": "node_modules/pull-stream/sources/count.js",
      "./empty": "node_modules/pull-stream/sources/empty.js",
      "./error": "node_modules/pull-stream/sources/error.js",
      "./infinite": "node_modules/pull-stream/sources/infinite.js",
      "./keys": "node_modules/pull-stream/sources/keys.js",
      "./once": "node_modules/pull-stream/sources/once.js",
      "./values": "node_modules/pull-stream/sources/values.js"
    }
  ],
  "node_modules/pull-stream/sources/infinite.js": [
    "uDwvQE69haX7Ha1KXpbIxpyqbRXpu8KQwRW/yHySsTw=",
    {}
  ],
  "node_modules/pull-stream/sources/keys.js": [
    "2AeMBMOSc/5k20IYF42HLOAJXiNOJGJoyb8U79p3Wc4=",
    {
      "./values": "node_modules/pull-stream/sources/values.js"
    }
  ],
  "node_modules/pull-stream/sources/once.js": [
    "pHKD0YRdWAkLaR4mj/jjwLSo0oWPObv1rDQFtnBdbgQ=",
    {
      "../util/abort-cb": "node_modules/pull-stream/util/abort-cb.js"
    }
  ],
  "node_modules/pull-stream/sources/values.js": [
    "CCV/8KXzWyHw5p1xKk33zQBu1/gzi/adDMDZU27EUUw=",
    {
      "../util/abort-cb": "node_modules/pull-stream/util/abort-cb.js"
    }
  ],
  "node_modules/pull-stream/throughs/async-map.js": [
    "ye8f470QDZ1xvARx3PD3Ccn2+9EX/dg4ZTM7U9vwQi8=",
    {
      "../util/prop": "node_modules/pull-stream/util/prop.js"
    }
  ],
  "node_modules/pull-stream/throughs/filter-not.js": [
    "JI5bMXQY9dKVqGD3OEE1aCjUp1viKEcQXFVJxofiPzE=",
    {
      "../util/tester": "node_modules/pull-stream/util/tester.js",
      "./filter": "node_modules/pull-stream/throughs/filter.js"
    }
  ],
  "node_modules/pull-stream/throughs/filter.js": [
    "iH0TcLTxRBPQ09mNvsmD4iv9MaMkB8ZNmder3XPFVwo=",
    {
      "../util/tester": "node_modules/pull-stream/util/tester.js"
    }
  ],
  "node_modules/pull-stream/throughs/flatten.js": [
    "g4zOVThIoKpKDOd5LclaDVQBHLrludnmLrPmtq5xUl0=",
    {
      "../sources/once": "node_modules/pull-stream/sources/once.js",
      "../sources/values": "node_modules/pull-stream/sources/values.js"
    }
  ],
  "node_modules/pull-stream/throughs/index.js": [
    "QC13FnlczWnvX4IxreFGpKJod3GHol2Nh0MeFAx7rdg=",
    {
      "./async-map": "node_modules/pull-stream/throughs/async-map.js",
      "./filter": "node_modules/pull-stream/throughs/filter.js",
      "./filter-not": "node_modules/pull-stream/throughs/filter-not.js",
      "./flatten": "node_modules/pull-stream/throughs/flatten.js",
      "./map": "node_modules/pull-stream/throughs/map.js",
      "./non-unique": "node_modules/pull-stream/throughs/non-unique.js",
      "./take": "node_modules/pull-stream/throughs/take.js",
      "./through": "node_modules/pull-stream/throughs/through.js",
      "./unique": "node_modules/pull-stream/throughs/unique.js"
    }
  ],
  "node_modules/pull-stream/throughs/map.js": [
    "AINTHrGMiW9dchJOHX1AoGEo7qDBiT1vE+EEgjZTTM8=",
    {
      "../util/prop": "node_modules/pull-stream/util/prop.js"
    }
  ],
  "node_modules/pull-stream/throughs/non-unique.js": [
    "du21y+8inJ/P4nQDRHX/EG89baNvBz9s/Df9yIAsdy4=",
    {
      "./unique": "node_modules/pull-stream/throughs/unique.js"
    }
  ],
  "node_modules/pull-stream/throughs/take.js": [
    "7ZoUb78Dv5MKH2Uj9+R+WkT9kcIKCYC8jN3ihAKB390=",
    {}
  ],
  "node_modules/pull-stream/throughs/through.js": [
    "qRbKwEJSKJyVjIDhbQ80030gZD5fwou1JipZ80ksCEk=",
    {}
  ],
  "node_modules/pull-stream/throughs/unique.js": [
    "UmPkJSHiu8xxCj90vud+nsZcf3NuTOu0M/ZLtxMfiE8=",
    {
      "../util/prop": "node_modules/pull-stream/util/prop.js",
      "./filter": "node_modules/pull-stream/throughs/filter.js"
    }
  ],
  "node_modules/pull-stream/util/abort-cb.js": [
    "Yfjgf9nNTJ9CcTEHyc6w417HHM0GOBsjZOOC/ojsBVA=",
    {}
  ],
  "node_modules/pull-stream/util/prop.js": [
    "bdLIeMr12r3Y6t1FkL3yngdaHzmbPIQdtI/UzAK1ffw=",
    {}
  ],
  "node_modules/pull-stream/util/tester.js": [
    "N6CE39E4absFwePI6bRfr43tXN4FV3L3mxO/OdUpmEg=",
    {
      "./prop": "node_modules/pull-stream/util/prop.js"
    }
  ],
  "node_modules/pull-stringify/index.js": [
    "dpVWLXaRZ5A76CpYthU7h0fHQUSYHmoVilwIzah524E=",
    {
      "defined": "node_modules/defined/index.js"
    }
  ],
  "node_modules/pull-thenable/index.js": [
    "kLNE+2h2M6nSj5bQygkmpHV8JjSUIbzQgYr/aXCsmm0=",
    {
      "quicktask": "node_modules/quicktask/index.js"
    }
  ],
  "node_modules/pull-through/index.js": [
    "nE3FfVy09zeoqtOb2QPPhqMDmYweZPnssE1SJZU42xk=",
    {
      "looper": "node_modules/looper/index.js"
    }
  ],
  "node_modules/pull-traverse/index.js": [
    "dVGMHXGHr0+GxeFblHAQzROahkySucGyG/RAHLAwgH8=",
    {}
  ],
  "node_modules/pull-utf8-decoder/index.js": [
    "vXr06kAjV1uxhCmbeWEi2J2oQtJSPqHkTD6Vf5NMgus=",
    {}
  ],
  "node_modules/pull-websocket/client.js": [
    "5t3rfA/2J7Ac6pY5J2pu4blMNng8RNnmy3rJwK75f/I=",
    {
      "./duplex": "node_modules/pull-websocket/duplex.js",
      "./web-socket": "node_modules/pull-websocket/web-socket.js",
      "./ws-url": "node_modules/pull-websocket/ws-url.js"
    }
  ],
  "node_modules/pull-websocket/duplex.js": [
    "9JSqMrDasmeWQ3N9YmglujCqV6TIYmGSCyKSBd0vl3k=",
    {
      "./sink": "node_modules/pull-websocket/sink.js",
      "./source": "node_modules/pull-websocket/source.js"
    }
  ],
  "node_modules/pull-websocket/index.js": [
    "u6cUVLTSQT2T15LdiO8t/iLDApfzU2vGoBCouTtwntU=",
    {
      "./client": "node_modules/pull-websocket/client.js",
      "./duplex": "node_modules/pull-websocket/duplex.js",
      "./server": "node_modules/pull-websocket/server.js",
      "./sink": "node_modules/pull-websocket/sink.js",
      "./source": "node_modules/pull-websocket/source.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/index.js": [
    "wrDJkFVApRrLJ2UjuwJO88Eb0RiwOpDZKWIIDr0H/sk=",
    {
      "./lib/receiver": "node_modules/pull-websocket/node_modules/ws/lib/receiver.js",
      "./lib/sender": "node_modules/pull-websocket/node_modules/ws/lib/sender.js",
      "./lib/stream": "node_modules/pull-websocket/node_modules/ws/lib/stream.js",
      "./lib/websocket": "node_modules/pull-websocket/node_modules/ws/lib/websocket.js",
      "./lib/websocket-server": "node_modules/pull-websocket/node_modules/ws/lib/websocket-server.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/buffer-util.js": [
    "2iCI3PqEe+KyagxP1GSA4qeHsxILys65hVVlS7ulNjE=",
    {
      "./constants": "node_modules/pull-websocket/node_modules/ws/lib/constants.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/constants.js": [
    "LC6Paru3wjFNVzbvCo0R8E3cPPT68ccQ3111xBcOk34=",
    {}
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/event-target.js": [
    "a60+g8So8RPPxA7ydX7LxyfmfF4W6oRHzcbhKvKxVUo=",
    {}
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/extension.js": [
    "E7IoqS0trZ0b/9Cfqq5rZL/B9xPdlmAQrUeakBwkOoY=",
    {}
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/limiter.js": [
    "4EadS4P2unZLFfgOF2a3XBNvv/aPBI9MBQ8LHH8GX2k=",
    {}
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/permessage-deflate.js": [
    "QzzVVDyj80I8Dq8ntLH+CSESdr8WCQqDnXP1/oCXJ7o=",
    {
      "./buffer-util": "node_modules/pull-websocket/node_modules/ws/lib/buffer-util.js",
      "./constants": "node_modules/pull-websocket/node_modules/ws/lib/constants.js",
      "./limiter": "node_modules/pull-websocket/node_modules/ws/lib/limiter.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/receiver.js": [
    "96b9o3I74bYOFfyHfwhgHPvBjrjbvnmYPHRT+QJ0Ktw=",
    {
      "./buffer-util": "node_modules/pull-websocket/node_modules/ws/lib/buffer-util.js",
      "./constants": "node_modules/pull-websocket/node_modules/ws/lib/constants.js",
      "./permessage-deflate": "node_modules/pull-websocket/node_modules/ws/lib/permessage-deflate.js",
      "./validation": "node_modules/pull-websocket/node_modules/ws/lib/validation.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/sender.js": [
    "P3Um8oE0K7rBaONmz4AY7ZGfkojbO1Lzb2nWN/IL1pE=",
    {
      "./buffer-util": "node_modules/pull-websocket/node_modules/ws/lib/buffer-util.js",
      "./constants": "node_modules/pull-websocket/node_modules/ws/lib/constants.js",
      "./permessage-deflate": "node_modules/pull-websocket/node_modules/ws/lib/permessage-deflate.js",
      "./validation": "node_modules/pull-websocket/node_modules/ws/lib/validation.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/stream.js": [
    "UD5nc/WKn9BayHvna4+oiEjbyYAPCRVPUZGmdou2h/g=",
    {}
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/validation.js": [
    "eT7gjeeuK+zTNhibZxQIfCYr/egK+GKqP9GX3OI2mUY=",
    {}
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/websocket-server.js": [
    "ZQGeyoGWehJ+sTnQlD8XmfkV8Z0qWHZuiH0HCNvlwvU=",
    {
      "./constants": "node_modules/pull-websocket/node_modules/ws/lib/constants.js",
      "./extension": "node_modules/pull-websocket/node_modules/ws/lib/extension.js",
      "./permessage-deflate": "node_modules/pull-websocket/node_modules/ws/lib/permessage-deflate.js",
      "./websocket": "node_modules/pull-websocket/node_modules/ws/lib/websocket.js"
    }
  ],
  "node_modules/pull-websocket/node_modules/ws/lib/websocket.js": [
    "tab6gtDtlrOnF2IWtyMQI5uctUIXu5/7QqAfWC72lSI=",
    {
      "./buffer-util": "node_modules/pull-websocket/node_modules/ws/lib/buffer-util.js",
      "./constants": "node_modules/pull-websocket/node_modules/ws/lib/constants.js",
      "./event-target": "node_modules/pull-websocket/node_modules/ws/lib/event-target.js",
      "./extension": "node_modules/pull-websocket/node_modules/ws/lib/extension.js",
      "./permessage-deflate": "node_modules/pull-websocket/node_modules/ws/lib/permessage-deflate.js",
      "./receiver": "node_modules/pull-websocket/node_modules/ws/lib/receiver.js",
      "./sender": "node_modules/pull-websocket/node_modules/ws/lib/sender.js"
    }
  ],
  "node_modules/pull-websocket/ready.js": [
    "8a51bL3pVppKr5W1HMFs1nx8iryH6TaqPNjZNwiFcaI=",
    {}
  ],
  "node_modules/pull-websocket/server.js": [
    "tq7oTpkr4LkzfLPQwnEXkKky6zNNCUVf47lfR3Ed7Vc=",
    {
      "./": "node_modules/pull-websocket/index.js",
      "ws": "node_modules/pull-websocket/node_modules/ws/index.js"
    }
  ],
  "node_modules/pull-websocket/sink.js": [
    "uiS7pqqXD1yZqgN/avrOI/OfYpp1iUKKoM1/SCx4A8s=",
    {
      "./ready": "node_modules/pull-websocket/ready.js"
    }
  ],
  "node_modules/pull-websocket/source.js": [
    "KID55Erb5JNu50aaP7V7PIxQcAyvG1EUFfmvEmafO6g=",
    {
      "safe-buffer": "node_modules/safe-buffer/index.js"
    }
  ],
  "node_modules/pull-websocket/web-socket.js": [
    "kyY0pema5Lmak0gYmGaTDoLGVKnsVW712hHlvXK9Ev0=",
    {
      "ws": "node_modules/pull-websocket/node_modules/ws/index.js"
    }
  ],
  "node_modules/pull-websocket/ws-url.js": [
    "cPKgI7c06cC2sPF+pkS7aV1xs7hZBRBui9WWBSdSJpg=",
    {
      "relative-url": "node_modules/relative-url/index.js"
    }
  ],
  "node_modules/pull-window/index.js": [
    "vJ76/FgQ+IqOSfnX3bm9Dg8+HblwxfflyX7SWhNHpWY=",
    {
      "looper": "node_modules/pull-window/node_modules/looper/index.js"
    }
  ],
  "node_modules/pull-window/node_modules/looper/index.js": [
    "h1jrjtl3Kl6vXLm4kjf4kzLRRNPkpgIukEUI+VqJagE=",
    {}
  ],
  "node_modules/pull-write-file/index.js": [
    "ygMPXluo7BBlYtJFSOCqOVbFDicUpzn7/tAxiQSfgmg=",
    {}
  ],
  "node_modules/pull-zip/index.js": [
    "Y/mK/q7HVIcAcgijekW/+GtvjwUHdEMkHs05wj09wd0=",
    {}
  ],
  "node_modules/push-stream-to-pull-stream/duplex.js": [
    "zpieRmo/hlSe+0QSz36Buj8tmxxaGRbVlCGr8boXhsI=",
    {
      "./sink": "node_modules/push-stream-to-pull-stream/sink.js",
      "./source": "node_modules/push-stream-to-pull-stream/source.js"
    }
  ],
  "node_modules/push-stream-to-pull-stream/index.js": [
    "WQemjJngdxdOE8GpYenbA59hGEMDR2UCBcRusVYXHXo=",
    {
      "./duplex": "node_modules/push-stream-to-pull-stream/duplex.js",
      "./sink": "node_modules/push-stream-to-pull-stream/sink.js",
      "./source": "node_modules/push-stream-to-pull-stream/source.js"
    }
  ],
  "node_modules/push-stream-to-pull-stream/sink.js": [
    "RD33PvzBdB9vjmR0whP8kFyH+s8oYunkaCAcv75Hhf0=",
    {
      "pull-looper": "node_modules/pull-looper/index.js"
    }
  ],
  "node_modules/push-stream-to-pull-stream/source.js": [
    "R2J3cRqemhtoXodLUPWZ3x6GpeIWFb5CYpk7ZO7AgjY=",
    {
      "pull-looper": "node_modules/pull-looper/index.js"
    }
  ],
  "node_modules/push-stream/index.js": [
    "zhUf2HR4piU5RpEKm92vHQ4Hy72fokFcRP69u6azc7M=",
    {
      "./sinks": "node_modules/push-stream/sinks/index.js",
      "./sources": "node_modules/push-stream/sources/index.js",
      "./throughs": "node_modules/push-stream/throughs/index.js"
    }
  ],
  "node_modules/push-stream/pipe.js": [
    "hRDMkQ2i0TTb2zJwx88UQkQmM7bedmkKApHibXXsH5Q=",
    {}
  ],
  "node_modules/push-stream/sinks/collect.js": [
    "DC/O0jJuWWfpbmSs/ShGBs4vh0OHZnFLFFTPmI1cXW0=",
    {}
  ],
  "node_modules/push-stream/sinks/drain.js": [
    "1vWcuCm2V7HDbRtKIl7+f67gDyhuQpcXu2md8vRAW0I=",
    {}
  ],
  "node_modules/push-stream/sinks/index.js": [
    "T60KyaOFdTt6P3sFlqayBcT4CMcG5+lsJKiByZOZTgM=",
    {
      "./collect": "node_modules/push-stream/sinks/collect.js",
      "./drain": "node_modules/push-stream/sinks/drain.js",
      "./reduce": "node_modules/push-stream/sinks/reduce.js"
    }
  ],
  "node_modules/push-stream/sinks/reduce.js": [
    "jp9lOh+ob7kYCzYhOaWELxf1731oXTuDJctH/xjwJmE=",
    {
      "./drain": "node_modules/push-stream/sinks/drain.js"
    }
  ],
  "node_modules/push-stream/sources/empty.js": [
    "3Wto9YvbeST2Hedm2a3EJGeF/aOc+5dkJqygwHeYuYs=",
    {
      "../pipe": "node_modules/push-stream/pipe.js"
    }
  ],
  "node_modules/push-stream/sources/index.js": [
    "iNs+m8tgrtDQ9g9ihUsrslFd5iDUv/Hx/brMXDbjo6U=",
    {
      "./empty": "node_modules/push-stream/sources/empty.js",
      "./infinite": "node_modules/push-stream/sources/infinite.js",
      "./values": "node_modules/push-stream/sources/values.js"
    }
  ],
  "node_modules/push-stream/sources/infinite.js": [
    "TwkPhV9hSeGwbG7PtMFw4BiSVDnbnhbpxSVJGo6dtDI=",
    {
      "../pipe": "node_modules/push-stream/pipe.js"
    }
  ],
  "node_modules/push-stream/sources/values.js": [
    "45XtBV6cxlTt8Muqcbwg3PeklxoRKZBXz3VXbZNnATs=",
    {
      "../pipe": "node_modules/push-stream/pipe.js"
    }
  ],
  "node_modules/push-stream/throughs/async-map.js": [
    "BbJ+AHGSnoS13OpDSkWGHhM+CJATmn9px1+2E8kOdtg=",
    {
      "./through": "node_modules/push-stream/throughs/through.js"
    }
  ],
  "node_modules/push-stream/throughs/filter.js": [
    "4NofZKFbc2vMn7lZ0/YC8QunKMECU0DsGy7LKBDXfA0=",
    {
      "./through": "node_modules/push-stream/throughs/through.js"
    }
  ],
  "node_modules/push-stream/throughs/index.js": [
    "SPMiGnBLYmi33rld2nIMoA5gBeSZlQWJFsyFJOTNTuA=",
    {
      "./async-map": "node_modules/push-stream/throughs/async-map.js",
      "./filter": "node_modules/push-stream/throughs/filter.js",
      "./map": "node_modules/push-stream/throughs/map.js",
      "./take": "node_modules/push-stream/throughs/take.js",
      "./through": "node_modules/push-stream/throughs/through.js"
    }
  ],
  "node_modules/push-stream/throughs/map.js": [
    "xLi/JLFBZ7UsaNkZ0Tp7DoQPUnAAp520pqEH7pxZ3r8=",
    {
      "./through": "node_modules/push-stream/throughs/through.js"
    }
  ],
  "node_modules/push-stream/throughs/take.js": [
    "0FoMFq6AS2Z3T/RGdsPOqRbwcie/Sg7VUr5FURaBI1k=",
    {
      "./through": "node_modules/push-stream/throughs/through.js"
    }
  ],
  "node_modules/push-stream/throughs/through.js": [
    "yrRL0OQGG5Te23FPh+t2kFRORwqygkFAcmixlRWItCc=",
    {
      "../pipe": "node_modules/push-stream/pipe.js"
    }
  ],
  "node_modules/querystringify/index.js": [
    "9xVP90iyBmMd1dXKEgWfEDdwvjIeAWxI5nXFe3ucaRg=",
    {}
  ],
  "node_modules/quick-insert/index.js": [
    "ey7OPvS1eLJkRyIib+2QnlKv5zFO5XmNMwghcUhmKZI=",
    {}
  ],
  "node_modules/quicktask/index.js": [
    "Gaaxa5sEElP72u1VUGK+FoI2p+EAMoMgrNYQElse3k4=",
    {}
  ],
  "node_modules/random-access-file/index.js": [
    "zTbsG31tVyqv98iql6Cr1WMujE6BnVgMUVMOf7ivdfw=",
    {
      "mkdirp-classic": "node_modules/mkdirp-classic/index.js",
      "random-access-storage": "node_modules/random-access-storage/index.js"
    }
  ],
  "node_modules/random-access-storage/index.js": [
    "Trwq+KqeWzxsbUet+Omb+wC9uH2QMBcZNBUiXOCqCv4=",
    {
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/randombytes/index.js": [
    "7Xs21mvB3jBFa6LdigPzqD5mo3en4/fpZ7gtqwY3GZQ=",
    {}
  ],
  "node_modules/range-parser/index.js": [
    "OHhlJtAAR1MAco2wdFWqIdHjew8k5I+8TLMBNq4wsHs=",
    {}
  ],
  "node_modules/rc/index.js": [
    "ekwZ0QJdJmlyPdKpOc7X1VbYFe7f/2K/KIlwNluLJtw=",
    {
      "./lib/utils": "node_modules/rc/lib/utils.js",
      "deep-extend": "node_modules/deep-extend/lib/deep-extend.js",
      "minimist": "node_modules/minimist/index.js"
    }
  ],
  "node_modules/rc/lib/utils.js": [
    "Pro16v0HiixIQ6EQAMBkQ7XYsv6jtoKq4g2u6lvmbNI=",
    {
      "ini": "node_modules/ini/ini.js",
      "strip-json-comments": "node_modules/strip-json-comments/index.js"
    }
  ],
  "node_modules/regexp.prototype.flags/implementation.js": [
    "nJL/dqbqreskZ1hfmziKpRGw7JzGShFX7hpYB0bica8=",
    {}
  ],
  "node_modules/regexp.prototype.flags/index.js": [
    "FW/xh7nWutA0GJjxC2igK9GSk2i7dnXDATFrGGztQ6A=",
    {
      "./implementation": "node_modules/regexp.prototype.flags/implementation.js",
      "./polyfill": "node_modules/regexp.prototype.flags/polyfill.js",
      "./shim": "node_modules/regexp.prototype.flags/shim.js",
      "call-bind": "node_modules/call-bind/index.js",
      "define-properties": "node_modules/define-properties/index.js"
    }
  ],
  "node_modules/regexp.prototype.flags/polyfill.js": [
    "6K/6q6UGvfzIGStk02e5qR/h+jzFMOeSEtL0nRJkq/k=",
    {
      "./implementation": "node_modules/regexp.prototype.flags/implementation.js",
      "define-properties": "node_modules/define-properties/index.js"
    }
  ],
  "node_modules/regexp.prototype.flags/shim.js": [
    "PzOz7rfDJGtBCy6Ul16dAVoxSjTPHYn2SJum6kU2C+8=",
    {
      "./polyfill": "node_modules/regexp.prototype.flags/polyfill.js",
      "define-properties": "node_modules/define-properties/index.js"
    }
  ],
  "node_modules/relative-url/index.js": [
    "jlYk3dkZh74NvvWycIVRL655poF0Tuy+mQdFjJCZbNI=",
    {}
  ],
  "node_modules/requires-port/index.js": [
    "xcdD0oBlUhcQEiSfz18Nr9LzrQTiltGSnIbIxx/micM=",
    {}
  ],
  "node_modules/rimraf/rimraf.js": [
    "yds//vKsQ82TtChBR83Uv7Jk7sCtGj5pEJvANxsSjuc=",
    {
      "glob": "node_modules/glob/glob.js"
    }
  ],
  "node_modules/rwlock/lib/lock.js": [
    "HVnKb+KWE30tj/D3xqwlFsBi5qsM5FfmM7BPj3BBBYI=",
    {}
  ],
  "node_modules/safe-buffer/index.js": [
    "tpdn/6R1cMVMtxMP9vbiO7gcDf21nsi96QKevLmZ/RU=",
    {}
  ],
  "node_modules/sanitize-filename/index.js": [
    "Gyxb1O+ZxazmoR3fJJ3GrHX1UxrNcxmqjSderytY4VQ=",
    {
      "truncate-utf8-bytes": "node_modules/truncate-utf8-bytes/index.js"
    }
  ],
  "node_modules/secret-handshake/crypto.js": [
    "3mbElOEt6wnYkLfQf1uSbWPx+Nn5pCsTpToNmPWHr8s=",
    {
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/secret-handshake/errors.js": [
    "bI0k9SzCVzz5dVL+uB02I/IWuLjMRUMnD7lcERIsmxw=",
    {}
  ],
  "node_modules/secret-handshake/index.js": [
    "w6X69DnJuxqXA5+vnqOFa6YQtgcc1FPf+aHhW7MjSmE=",
    {
      "./crypto": "node_modules/secret-handshake/crypto.js",
      "./protocol": "node_modules/secret-handshake/protocol.js"
    }
  ],
  "node_modules/secret-handshake/protocol.js": [
    "AhjxB+Xjyxkt9RjYoBCkWAsmHOG+2xx1Y8YxsWNSsWU=",
    {
      "./errors": "node_modules/secret-handshake/errors.js",
      "./random": "node_modules/secret-handshake/random.js",
      "explain-error": "node_modules/explain-error/index.js",
      "pull-box-stream": "node_modules/pull-box-stream/index.js",
      "pull-handshake": "node_modules/pull-handshake/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/secret-handshake/random.js": [
    "r4M+MkdrPeknGkMqLH50etmG6hXXz6HrwbMI8zjG1Ok=",
    {
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/secret-stack-decorators/lib/index.js": [
    "XEvlqTbwXBglNY9cRC3ZKqi62LfeapH9XI6oSQQ2tFI=",
    {}
  ],
  "node_modules/secret-stack/lib/api.js": [
    "IjMweMFBqwnpwblY1xD5UwkrhiTTc2HgwSlLDFiwG1o=",
    {
      "./util": "node_modules/secret-stack/lib/util.js",
      "hoox": "node_modules/hoox/index.js"
    }
  ],
  "node_modules/secret-stack/lib/core.js": [
    "uEm695RlEddYSb7pPT2euxFceGvlMIwUb0AfFuicQms=",
    {
      "./util": "node_modules/secret-stack/lib/util.js",
      "debug": "node_modules/debug/src/index.js",
      "multiserver": "node_modules/multiserver/index.js",
      "muxrpc": "node_modules/muxrpc/index.js",
      "pull-inactivity": "node_modules/pull-inactivity/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/secret-stack/lib/index.js": [
    "CJRzKtw/9vxtqI98BQn7AfADtTsseF5YuNPb45fea3E=",
    {
      "./api": "node_modules/secret-stack/lib/api.js",
      "./core": "node_modules/secret-stack/lib/core.js",
      "./plugins/net": "node_modules/secret-stack/lib/plugins/net.js",
      "./plugins/shs": "node_modules/secret-stack/lib/plugins/shs.js"
    }
  ],
  "node_modules/secret-stack/lib/plugins/net.js": [
    "DTehFUDCbxaSJgY9TgwKyCicaKundCfJ9Wu7vuSsqKI=",
    {
      "debug": "node_modules/debug/src/index.js",
      "multiserver/plugins/net": "node_modules/staltz-multiserver/plugins/net.js"
    }
  ],
  "node_modules/secret-stack/lib/plugins/shs.js": [
    "nP40HJesq/zYmYY9CtXsQPha934F3omdk4vyEHx/6DY=",
    {
      "../util": "node_modules/secret-stack/lib/util.js",
      "multiserver/plugins/shs": "node_modules/multiserver/plugins/shs.js"
    }
  ],
  "node_modules/secret-stack/lib/util.js": [
    "hcDFJjsYaT2bXTd+DVrmrGpO6LJFYxkNxzD8/5cKXZs=",
    {
      "map-merge": "node_modules/map-merge/index.js",
      "to-camel-case": "node_modules/to-camel-case/index.js"
    }
  ],
  "node_modules/sodium-chloride-native-nodejs-mobile/index.js": [
    "txXy8KMSq0OQ5jAkMlDRgkXCGtxzWojt7TDHa4tFxWw=",
    {
      "sodium-chloride": "node_modules/sodium-chloride/index.js",
      "sodium-native-nodejs-mobile": "node_modules/sodium-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/sodium-chloride/index.js": [
    "76efcC3urfDlCDz3IT0NFLojITm6bvPREC7kd0vrCqk=",
    {}
  ],
  "node_modules/sodium-native-nodejs-mobile/index.js": [
    "84wOzamum2jP+/5fIqg6RNZF+/nib1rh845LX3EpSg8=",
    {
      "bindings": "node_modules/bindings-noderify-nodejs-mobile/bindings.js"
    }
  ],
  "node_modules/split-buffer/index.js": [
    "5X5j7KPAcgFaVohmaU/64/2n+E9hM1rokDb3tZfWKxQ=",
    {}
  ],
  "node_modules/ssb-bendy-butt/index.js": [
    "1HfbeL4+90mEuhzQNZEUE/rMuqjoxhtcKqVdCCdqszA=",
    {
      "bencode": "node_modules/bencode/lib/index.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "ssb-bfe": "node_modules/ssb-bfe/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-uri2": "node_modules/ssb-uri2/lib/index.js"
    }
  ],
  "node_modules/ssb-bfe-spec/bfe.json": [
    "S+3liXlUHl7GifvxI0J9bDoAPmlOkR0CpQbNmeW3Vfg=",
    {}
  ],
  "node_modules/ssb-bfe/index.js": [
    "+2zkD8kJfHO0kznqc9yjyAnu03W+fuY8Vri1j+vLgFY=",
    {
      "./util": "node_modules/ssb-bfe/util.js",
      "ssb-bfe-spec": "node_modules/ssb-bfe-spec/bfe.json",
      "ssb-uri2": "node_modules/ssb-uri2/lib/index.js"
    }
  ],
  "node_modules/ssb-bfe/node_modules/ssb-ref/index.js": [
    "t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-bfe/util.js": [
    "8evRgp8A3qK9k7z9EwZDTCw7zH/85Fz16c9sAsXDMg0=",
    {
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "ssb-ref": "node_modules/ssb-bfe/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-blobs-purge/lib/index.js": [
    "z8jXJHbYZVCxuRCMmoVkAGXw4Wms7d4nOEqwB4D0jIs=",
    {
      "debug": "node_modules/debug/src/index.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "pull-drain-gently": "node_modules/pull-drain-gently/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "trammel": "node_modules/trammel/lib/trammel.js"
    }
  ],
  "node_modules/ssb-blobs/create.js": [
    "VVxKYk0CPjdV6fWNP3XafEyJmhI7gOTkfgAlYGWx7bY=",
    {
      "multiblob": "node_modules/multiblob/index.js",
      "multiblob/util": "node_modules/multiblob/util.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-blobs/help.js": [
    "nVJ+N1U99iiq9YmyakUHVN/k7LAk2VQPq2nEmud3gGE=",
    {}
  ],
  "node_modules/ssb-blobs/index.js": [
    "8SYPXAO0L6iNyK/xgwoUh2bxaiMc3UUxydqVS903fHY=",
    {
      "./create": "node_modules/ssb-blobs/create.js",
      "./inject": "node_modules/ssb-blobs/inject.js",
      "./package.json": "node_modules/ssb-blobs/package.json",
      "./set": "node_modules/ssb-blobs/set.js",
      "level": "node_modules/level/level.js"
    }
  ],
  "node_modules/ssb-blobs/inject.js": [
    "r77I/UpUX6QrJvmkqR1wQOWxv7nv8h5DHVc+ncT2DVg=",
    {
      "./help": "node_modules/ssb-blobs/help.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-blobs/package.json": [
    "iEHVV2tV4tL4wu+KJx29RNWO9GblFOmSYf9anyFqp8c=",
    {}
  ],
  "node_modules/ssb-blobs/set.js": [
    "Lf3FXjpfE9rGl2M4iHXcaMHf6OFB1AM88FgQ3CkKRyM=",
    {
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-bluetooth/index.js": [
    "qFCsWoiBRAd3oPgvj8EWwVVhlnFzpzxOEnet7B/KAQ4=",
    {
      "multiserver-bluetooth": "node_modules/multiserver-bluetooth/index.js"
    }
  ],
  "node_modules/ssb-caps/caps.json": [
    "ig/61bj+prdFkzKhs5YFZsxSmf+2jvKFpUBfxY4g8A8=",
    {}
  ],
  "node_modules/ssb-config/default-ports.js": [
    "ffAsZA0UzzXnpBCz6JHYLNbJUHO6CIF2K44IDyjJN+o=",
    {}
  ],
  "node_modules/ssb-config/defaults.js": [
    "6HUpfuflJtR37rsR5RKgn9k38g1B7cxcNVretSlbeVw=",
    {
      "./util/fix-connections": "node_modules/ssb-config/util/fix-connections.js",
      "./util/incoming-connections": "node_modules/ssb-config/util/incoming-connections.js",
      "deep-extend": "node_modules/deep-extend/lib/deep-extend.js",
      "os-homedir": "node_modules/os-homedir/index.js",
      "ssb-caps": "node_modules/ssb-caps/caps.json",
      "ssb-keys": "node_modules/ssb-keys/index.js"
    }
  ],
  "node_modules/ssb-config/inject.js": [
    "3nAqcqzkBNDPu9t2hcW10UP2hB9qCJRS/8Zz+5ZDqd4=",
    {
      "./defaults": "node_modules/ssb-config/defaults.js",
      "rc": "node_modules/rc/index.js"
    }
  ],
  "node_modules/ssb-config/util/fix-connections.js": [
    "m6a2DG/HlwoJKhEG4Gt3lmhodGzghRbD2liCnEWLyOQ=",
    {
      "../default-ports": "node_modules/ssb-config/default-ports.js",
      "./get-net": "node_modules/ssb-config/util/get-net.js",
      "./get-ws": "node_modules/ssb-config/util/get-ws.js"
    }
  ],
  "node_modules/ssb-config/util/get-net.js": [
    "Qg1CsWWNepr40cYFYD6RaalQweqmyGedX0o07WLYU5w=",
    {
      "lodash.get": "node_modules/lodash.get/index.js"
    }
  ],
  "node_modules/ssb-config/util/get-ws.js": [
    "kjarMDG4fOFPkE0j1ksTmuUxzv+ss31VwYKWWR4IU2g=",
    {
      "lodash.get": "node_modules/lodash.get/index.js"
    }
  ],
  "node_modules/ssb-config/util/incoming-connections.js": [
    "LQ3/9ZCyjrFzcGWZYv38oAimQKrnHM/xg9ytYOazV5I=",
    {
      "../default-ports": "node_modules/ssb-config/default-ports.js",
      "ip": "node_modules/ip/lib/ip.js",
      "lodash.get": "node_modules/lodash.get/index.js"
    }
  ],
  "node_modules/ssb-conn-db/lib/atomic-file-codecs.js": [
    "FvVL6bsXckM6GcPE/NkK2CKbrlAulfyCyQNAjsSRhew=",
    {}
  ],
  "node_modules/ssb-conn-db/lib/index.js": [
    "Y733ooKNRRAcMO7Z0Cip/iPeOfyYjt1YlNR5Gp1KlIg=",
    {
      "./atomic-file-codecs": "node_modules/ssb-conn-db/lib/atomic-file-codecs.js",
      "./migration": "node_modules/ssb-conn-db/lib/migration.js",
      "atomic-file-rw": "node_modules/atomic-file-rw/index.js",
      "debug": "node_modules/debug/src/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js",
      "pull-notify": "node_modules/pull-notify/index.js"
    }
  ],
  "node_modules/ssb-conn-db/lib/migration.js": [
    "fvBu1HImzrrY++SCWSsqYqf7grsD4+VmOTogJBTBdu8=",
    {
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-conn-firewall/lib/index.js": [
    "+KjVs0WEmtTxrU6jegu5hZNYifjsLOhkIVRNmTKKXeo=",
    {
      "atomic-file-rw": "node_modules/atomic-file-rw/index.js",
      "debug": "node_modules/debug/src/index.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-promise": "node_modules/pull-promise/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-conn-hub/lib/index.js": [
    "cUcDZGydcEeG7OZbDlZ9NHMSXmFv72yWPwbfK+vil60=",
    {
      "debug": "node_modules/debug/src/index.js",
      "ip": "node_modules/ip/lib/ip.js",
      "multiserver-address": "node_modules/multiserver-address/index.js",
      "multiserver/plugins/net": "node_modules/staltz-multiserver/plugins/net.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-ref": "node_modules/ssb-conn-hub/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-conn-hub/node_modules/ssb-ref/index.js": [
    "t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-conn-query/lib/index.js": [
    "xfg8l1wewzxd2AIDcJrc4dgDo7Vut/JqGz+Z+wlNYPA=",
    {
      "./queries/health": "node_modules/ssb-conn-query/lib/queries/health.js",
      "./queries/sorting": "node_modules/ssb-conn-query/lib/queries/sorting.js",
      "./queries/time": "node_modules/ssb-conn-query/lib/queries/time.js"
    }
  ],
  "node_modules/ssb-conn-query/lib/queries/health.js": [
    "7q7LlTQEks9Myg/SZIMnoEC0HgzjCqoRDBnyrs8gCSc=",
    {}
  ],
  "node_modules/ssb-conn-query/lib/queries/sorting.js": [
    "W2QzrBcmZMMApQOfZWHTSIHxffcHacJGjk+rEC6QzbE=",
    {}
  ],
  "node_modules/ssb-conn-query/lib/queries/time.js": [
    "dsoOmx/gqDWsu7fYZl9qony5UFjn7F+z67O5wbOIMGo=",
    {}
  ],
  "node_modules/ssb-conn-staging/lib/index.js": [
    "zJmNEdN+8h26PsfDgO8yRVZG8VHEGuIDURz1yNRIwh8=",
    {
      "debug": "node_modules/debug/src/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-conn/lib/conn-scheduler.js": [
    "kX3/dabPNkkX8aoya4k75CrGE9M4nWwp35tb9KdglsA=",
    {
      "debug": "node_modules/debug/src/index.js",
      "has-network2": "node_modules/has-network2/index.js",
      "ip": "node_modules/ip/lib/ip.js",
      "on-change-network-strict": "node_modules/on-change-network-strict/index.js",
      "on-wakeup": "node_modules/on-wakeup/index.js",
      "pull-pause": "node_modules/pull-pause/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-conn-query": "node_modules/ssb-conn-query/lib/index.js",
      "ssb-ref": "node_modules/ssb-conn/node_modules/ssb-ref/index.js",
      "ziii": "node_modules/ziii/index.js"
    }
  ],
  "node_modules/ssb-conn/lib/conn.js": [
    "byhOw55nanqCNv+PSJd65soXJsKlCG/12A/L8eaXGdI=",
    {
      "./interpool-glue": "node_modules/ssb-conn/lib/interpool-glue.js",
      "pull-ping": "node_modules/pull-ping/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-conn-db": "node_modules/ssb-conn-db/lib/index.js",
      "ssb-conn-hub": "node_modules/ssb-conn-hub/lib/index.js",
      "ssb-conn-query": "node_modules/ssb-conn-query/lib/index.js",
      "ssb-conn-staging": "node_modules/ssb-conn-staging/lib/index.js"
    }
  ],
  "node_modules/ssb-conn/lib/gossip.js": [
    "uWOt3+QAzT8LY/cURWwIaprSiVt/LX81hmLTEf7gniU=",
    {
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js"
    }
  ],
  "node_modules/ssb-conn/lib/index.js": [
    "V9biW5ejxgsBFYsweKD8cefoeL/9TUDncU9OpUflsbs=",
    {
      "./conn": "node_modules/ssb-conn/lib/conn.js",
      "./conn-scheduler": "node_modules/ssb-conn/lib/conn-scheduler.js",
      "./gossip": "node_modules/ssb-conn/lib/gossip.js"
    }
  ],
  "node_modules/ssb-conn/lib/interpool-glue.js": [
    "9aC+WkcEkgFYz8gxKzAfRc7bicX7LCnDHZVHQ5JpUdw=",
    {
      "pull-ping": "node_modules/pull-ping/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "statistics": "node_modules/statistics/index.js"
    }
  ],
  "node_modules/ssb-conn/node_modules/ssb-ref/index.js": [
    "t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-db2/about-self.js": [
    "J4rGzEdrgNsaSB4+u4V/fvZ0vLlKQ9mFheYKQFQ2XBA=",
    {
      "./indexes/about-self": "node_modules/ssb-db2/indexes/about-self.js"
    }
  ],
  "node_modules/ssb-db2/compat/db.js": [
    "wnpUVC5FDGsUfwBvb8IBrsGkVCXo1cnR52yWi7EBjGg=",
    {
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-db2/compat/ebt.js": [
    "Y+2gkwdLlIBxgdH77po/jb0qOji4zCh4KcQRf87J2Mw=",
    {
      "../indexes/ebt": "node_modules/ssb-db2/indexes/ebt.js",
      "../utils": "node_modules/ssb-db2/utils.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-db2/compat/history-stream.js": [
    "IxgLJt3/NF+dNRtoJCfb+Gqr8MYrbsMFV87Z356gB2w=",
    {
      "../indexes/private": "node_modules/ssb-db2/indexes/private.js",
      "../operators": "node_modules/ssb-db2/operators/index.js",
      "hoox": "node_modules/hoox/index.js",
      "pull-cont": "node_modules/pull-cont/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-ref": "node_modules/ssb-db2/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-db2/compat/log-stream.js": [
    "12maJ3l0vAfBsxjeIoAkoSVt8+jdCUQMjBftutRwb1I=",
    {
      "../operators": "node_modules/ssb-db2/operators/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-db2/db.js": [
    "aOTU69E8jG8wUt0LNSy+XontoUma4esbabwnky9IjBw=",
    {
      "./debounce-batch": "node_modules/ssb-db2/debounce-batch.js",
      "./defaults": "node_modules/ssb-db2/defaults.js",
      "./indexes/base": "node_modules/ssb-db2/indexes/base.js",
      "./indexes/keys": "node_modules/ssb-db2/indexes/keys.js",
      "./indexes/private": "node_modules/ssb-db2/indexes/private.js",
      "./log": "node_modules/ssb-db2/log.js",
      "./operators": "node_modules/ssb-db2/operators/index.js",
      "./status": "node_modules/ssb-db2/status.js",
      "./utils": "node_modules/ssb-db2/utils.js",
      "bipf": "node_modules/bipf/index.js",
      "debug": "node_modules/debug/src/index.js",
      "jitdb": "node_modules/jitdb/index.js",
      "jitdb/operators": "node_modules/jitdb/operators.js",
      "multicb": "node_modules/multicb/index.js",
      "mutexify": "node_modules/mutexify/index.js",
      "obz": "node_modules/obz/index.js",
      "promisify-4loc": "node_modules/promisify-4loc/index.js",
      "pull-paramap": "node_modules/pull-paramap/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "push-stream": "node_modules/push-stream/index.js",
      "ssb-bendy-butt": "node_modules/ssb-bendy-butt/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-ref": "node_modules/ssb-db2/node_modules/ssb-ref/index.js",
      "ssb-uri2": "node_modules/ssb-uri2/lib/index.js",
      "ssb-validate": "node_modules/ssb-validate/index.js",
      "ssb-validate2": "node_modules/ssb-validate2/index.js",
      "ssb-validate2-rsjs-node": "node_modules/ssb-validate2/index.js"
    }
  ],
  "node_modules/ssb-db2/debounce-batch.js": [
    "Y6njsb3hYiFuo65OiDuJsxZxHsViNUW9zbNVD9KiL5U=",
    {}
  ],
  "node_modules/ssb-db2/defaults.js": [
    "ClhFVOW3yaObcO/tfOvOKabbzPMcJozDwU/wXT1kJ3A=",
    {}
  ],
  "node_modules/ssb-db2/full-mentions.js": [
    "KlqkCRk/B0PV38it7aKYg0A8huEk9IuWX7SBHN50lNQ=",
    {
      "./indexes/full-mentions": "node_modules/ssb-db2/indexes/full-mentions.js",
      "./operators/full-mentions": "node_modules/ssb-db2/operators/full-mentions.js"
    }
  ],
  "node_modules/ssb-db2/index.js": [
    "PGOrAEx6yT+O2u4PPKx2aE/za+5eJjh/yw1SCj5dM5k=",
    {
      "./db": "node_modules/ssb-db2/db.js",
      "./migrate": "node_modules/ssb-db2/migrate.js"
    }
  ],
  "node_modules/ssb-db2/indexes/about-self.js": [
    "kqkTySq5HILtVHAgmi6fmLuKEBmoX7tVEoz9t26YJ38=",
    {
      "./plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "bipf": "node_modules/bipf/index.js",
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-db2/indexes/base.js": [
    "EMLFOaIW0fk53cnh5aOxEIB47HIMSEbYDvwicWIDHO0=",
    {
      "./plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "bipf": "node_modules/bipf/index.js",
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-db2/indexes/ebt.js": [
    "fqL4U2M6/E/gay4qfbjlINV7hpWvEWytY+di/LoO5PE=",
    {
      "./plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "./private": "node_modules/ssb-db2/indexes/private.js",
      "bipf": "node_modules/bipf/index.js"
    }
  ],
  "node_modules/ssb-db2/indexes/full-mentions.js": [
    "QrRfUuyA/i3GFdhBNRafl+L/COPbuRemdgn5J6I2vsU=",
    {
      "../operators": "node_modules/ssb-db2/operators/index.js",
      "./plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "bipf": "node_modules/bipf/index.js",
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-db2/indexes/keys.js": [
    "wT7PotLvX9d6oTqh/VVsMDb+dKwVQSs7lC0xkNiQghU=",
    {
      "../operators": "node_modules/ssb-db2/operators/index.js",
      "./plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "bipf": "node_modules/bipf/index.js"
    }
  ],
  "node_modules/ssb-db2/indexes/plugin.js": [
    "yy3RxsYxK4WeCWIDyerJTQ1+zGvtvGQap8J2T2jW3I8=",
    {
      "../defaults": "node_modules/ssb-db2/defaults.js",
      "debug": "node_modules/debug/src/index.js",
      "level": "node_modules/ssb-db2/node_modules/level/level.js",
      "level-codec/lib/encodings": "node_modules/ssb-db2/node_modules/level-codec/lib/encodings.js",
      "lodash.debounce": "node_modules/lodash.debounce/index.js",
      "mkdirp": "node_modules/mkdirp/index.js",
      "obz": "node_modules/obz/index.js",
      "p-defer": "node_modules/p-defer/index.js"
    }
  ],
  "node_modules/ssb-db2/indexes/private.js": [
    "Lg2mVZsGiq5Wiye6kgSPZsLMHEXpvpP7b5teWzEUECQ=",
    {
      "../defaults": "node_modules/ssb-db2/defaults.js",
      "atomic-file-rw": "node_modules/atomic-file-rw/index.js",
      "binary-search-bounds": "node_modules/binary-search-bounds/search-bounds.js",
      "bipf": "node_modules/bipf/index.js",
      "debug": "node_modules/debug/src/index.js",
      "fastintcompression": "node_modules/fastintcompression/FastIntegerCompression.js",
      "obz": "node_modules/obz/index.js",
      "p-defer": "node_modules/p-defer/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-uri2": "node_modules/ssb-uri2/lib/index.js",
      "typedarray-to-buffer": "node_modules/ssb-db2/node_modules/typedarray-to-buffer/index.js"
    }
  ],
  "node_modules/ssb-db2/log.js": [
    "VxLGQbDfv8iToKc7T3UZLO4UYh0A9WqJ8LE0LcxC1y4=",
    {
      "./defaults": "node_modules/ssb-db2/defaults.js",
      "async-append-only-log": "node_modules/async-append-only-log/index.js",
      "bipf": "node_modules/bipf/index.js",
      "too-hot": "node_modules/too-hot/index.js"
    }
  ],
  "node_modules/ssb-db2/migrate.js": [
    "KcAdw1Y02Jmq/A95ch7hazXdngoAqwNcmjwsovDiIwY=",
    {
      "./defaults": "node_modules/ssb-db2/defaults.js",
      "./seekers": "node_modules/ssb-db2/seekers.js",
      "async-append-only-log": "node_modules/async-append-only-log/index.js",
      "bipf": "node_modules/bipf/index.js",
      "debug": "node_modules/debug/src/index.js",
      "flumecodec/json": "node_modules/flumecodec/json.js",
      "flumelog-offset": "node_modules/flumelog-offset/index.js",
      "obz": "node_modules/obz/index.js",
      "pull-drain-gently": "node_modules/pull-drain-gently/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "rimraf": "node_modules/rimraf/rimraf.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-chained-batch.js": [
    "Z8EKDfGEpOQukRahaYVq29rf5GC4NqI89BA8V8zLEjM=",
    {
      "./next-tick": "node_modules/ssb-db2/node_modules/abstract-leveldown/next-tick.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-iterator.js": [
    "zFwENznp0VlKGOUYw0UZkxqAiBy3wg7PWi8lMBIuBBE=",
    {
      "./next-tick": "node_modules/ssb-db2/node_modules/abstract-leveldown/next-tick.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-leveldown.js": [
    "x0iMaqNlst14z89o06Dn5qILdB4SVT1ZLCwHt7tYY3s=",
    {
      "./abstract-chained-batch": "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-chained-batch.js",
      "./abstract-iterator": "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-iterator.js",
      "./next-tick": "node_modules/ssb-db2/node_modules/abstract-leveldown/next-tick.js",
      "level-supports": "node_modules/level-supports/index.js",
      "xtend": "node_modules/xtend/immutable.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/abstract-leveldown/index.js": [
    "TZhD82oHTYdXvS5L6p4PGz8scF9rlqoYYWIXtimi4GY=",
    {
      "./abstract-chained-batch": "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-chained-batch.js",
      "./abstract-iterator": "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-iterator.js",
      "./abstract-leveldown": "node_modules/ssb-db2/node_modules/abstract-leveldown/abstract-leveldown.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/abstract-leveldown/next-tick.js": [
    "JczFU1xaSOlfDIj/bfki3cAkCh3PBIunWfLagGh0jBk=",
    {}
  ],
  "node_modules/ssb-db2/node_modules/deferred-leveldown/deferred-iterator.js": [
    "n4CGggNJyMn+JKT8JsASRAWx0CF5ZzurUGes9wLMyTM=",
    {
      "abstract-leveldown": "node_modules/ssb-db2/node_modules/abstract-leveldown/index.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/deferred-leveldown/deferred-leveldown.js": [
    "umkKKpEGau7k61gQBI0wq42O3weWyfCzB1xBb1fTMqY=",
    {
      "./deferred-iterator": "node_modules/ssb-db2/node_modules/deferred-leveldown/deferred-iterator.js",
      "abstract-leveldown": "node_modules/ssb-db2/node_modules/abstract-leveldown/index.js",
      "inherits": "node_modules/inherits/inherits.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/encoding-down/index.js": [
    "K1cNFqtlGOBiwNIxcnqMaT1oKNvJUTxlHDxw61tnn6I=",
    {
      "abstract-leveldown": "node_modules/ssb-db2/node_modules/abstract-leveldown/index.js",
      "inherits": "node_modules/inherits/inherits.js",
      "level-codec": "node_modules/ssb-db2/node_modules/level-codec/index.js",
      "level-errors": "node_modules/level-errors/errors.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/level-codec/index.js": [
    "KeOe/kUQLqH0ZVsn667GMT/xNkS+X3KXhqwXVeL+564=",
    {
      "./lib/encodings": "node_modules/ssb-db2/node_modules/level-codec/lib/encodings.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/level-codec/lib/encodings.js": [
    "ZKFfBH8Bf9Oof9cEuVd6bgdILtilMIjs4TK3LNLl0aY=",
    {}
  ],
  "node_modules/ssb-db2/node_modules/level-packager/level-packager.js": [
    "d0TtirgBvf3UcVRMDZWucNtL5cixueBZ6tNutLDnxsE=",
    {
      "encoding-down": "node_modules/ssb-db2/node_modules/encoding-down/index.js",
      "levelup": "node_modules/ssb-db2/node_modules/levelup/lib/levelup.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/level/level.js": [
    "wCjG5RX/lhZqNW+n+TXsJsVIyG5nX7hngZgg5ESu9Go=",
    {
      "level-packager": "node_modules/ssb-db2/node_modules/level-packager/level-packager.js",
      "leveldown": "node_modules/leveldown-nodejs-mobile/leveldown.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/levelup/lib/batch.js": [
    "6wjlMgmCb9E/v0dWOkSxeO7dnLftUJ1f1O3fPpL8vhI=",
    {
      "./common": "node_modules/ssb-db2/node_modules/levelup/lib/common.js",
      "./promisify": "node_modules/ssb-db2/node_modules/levelup/lib/promisify.js",
      "level-errors": "node_modules/level-errors/errors.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/levelup/lib/common.js": [
    "LOgJFiE4jDSnvlkw/xVoJGC16bPVePyumo/9xppTGXA=",
    {}
  ],
  "node_modules/ssb-db2/node_modules/levelup/lib/levelup.js": [
    "5ZjD3xAHNQn+H09e2ZrAmPZ1341nHZB7BUQ9fTz7bTg=",
    {
      "./batch": "node_modules/ssb-db2/node_modules/levelup/lib/batch.js",
      "./common": "node_modules/ssb-db2/node_modules/levelup/lib/common.js",
      "./promisify": "node_modules/ssb-db2/node_modules/levelup/lib/promisify.js",
      "deferred-leveldown": "node_modules/ssb-db2/node_modules/deferred-leveldown/deferred-leveldown.js",
      "level-errors": "node_modules/level-errors/errors.js",
      "level-iterator-stream": "node_modules/level-iterator-stream/index.js",
      "level-supports": "node_modules/level-supports/index.js",
      "xtend": "node_modules/xtend/immutable.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/levelup/lib/promisify.js": [
    "P4SmaY4k9IerC2UPiYhuHbO5MvGb9gN+MjKTVCtIdH4=",
    {}
  ],
  "node_modules/ssb-db2/node_modules/ssb-ref/index.js": [
    "t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-db2/node_modules/typedarray-to-buffer/index.js": [
    "uL61TlttIPMJUhjfIE+mrAcTOzy7we9x83UbcC58j+U=",
    {}
  ],
  "node_modules/ssb-db2/operators/full-mentions.js": [
    "vWGPEPruisJL6vrBmo/JgkQSHMKXhCHdSGs4HmDoNbM=",
    {
      "jitdb/operators": "node_modules/jitdb/operators.js"
    }
  ],
  "node_modules/ssb-db2/operators/index.js": [
    "EomJ7TjYLyjhbkdm05GMX7Egp9A2wWiVQzzf04E6QWI=",
    {
      "../seekers": "node_modules/ssb-db2/seekers.js",
      "jitdb/operators": "node_modules/jitdb/operators.js",
      "ssb-uri2": "node_modules/ssb-uri2/lib/index.js"
    }
  ],
  "node_modules/ssb-db2/seekers.js": [
    "9TNsQDI3nqQdPgb/sKQvU1f79rlQ5SyTo695X3SivaE=",
    {
      "bipf": "node_modules/bipf/index.js"
    }
  ],
  "node_modules/ssb-db2/status.js": [
    "PLjBxlVJaOPqbLzJb1o7ySXTwuRANZRpg2f4OXSYyU0=",
    {
      "obz": "node_modules/obz/index.js"
    }
  ],
  "node_modules/ssb-db2/utils.js": [
    "U+88cowEiM0rItWht3CR5K1FAforq1rFjy84GAJiddM=",
    {}
  ],
  "node_modules/ssb-deweird/producer.js": [
    "sg1kBY7bVcevi2VujDzDW8qpP0xgeUbr52YgmTFSOH4=",
    {
      "debug": "node_modules/debug/src/index.js"
    }
  ],
  "node_modules/ssb-ebt/formats/classic.js": [
    "s2GmZ2ZSShDi54xGGLJaMSX93aDQhunBlMbiZOlPmvc=",
    {
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-ebt/index.js": [
    "M2s7N+UQG1+EifxUtcNvRoOZabc7NGGGELYEZsq+F+k=",
    {
      "./formats/classic": "node_modules/ssb-ebt/formats/classic.js",
      "base64-url": "node_modules/base64-url/index.js",
      "epidemic-broadcast-trees": "node_modules/epidemic-broadcast-trees/index.js",
      "key-value-file-store": "node_modules/key-value-file-store/index.js",
      "pull-defer": "node_modules/pull-defer/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "push-stream-to-pull-stream": "node_modules/push-stream-to-pull-stream/index.js",
      "ssb-network-errors": "node_modules/ssb-network-errors/index.js"
    }
  ],
  "node_modules/ssb-friends/auth-glue.js": [
    "yT/gl3q/fLIpwi9YKoQILA9RbNRsI3yCPssV9NNyh9w=",
    {}
  ],
  "node_modules/ssb-friends/contacts.js": [
    "FIYopa/BrX7/XSovHppXiydkcqV9t64IWW6WREHXwwI=",
    {
      "flumeview-reduce": "node_modules/flumeview-reduce/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-friends/db2-contacts.js": [
    "/tH2HBDaFwSUvnskFV/HP5643XTWb3uGPICxxMnWb94=",
    {
      "bipf": "node_modules/bipf/index.js",
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-db2/indexes/plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-friends/help.js": [
    "mv08HRBnnsICLk0zCcodkRt8u9Hmsh2jmrS0b2QVvvg=",
    {}
  ],
  "node_modules/ssb-friends/index.js": [
    "Rms3M4gDfsKdRDioD3XNrGHVcubF/mm51QWSAvpRRT4=",
    {
      "./auth-glue": "node_modules/ssb-friends/auth-glue.js",
      "./contacts": "node_modules/ssb-friends/contacts.js",
      "./db2-contacts": "node_modules/ssb-friends/db2-contacts.js",
      "./help": "node_modules/ssb-friends/help.js",
      "layered-graph": "node_modules/layered-graph/index.js",
      "pull-cont": "node_modules/pull-cont/index.js",
      "pull-pushable": "node_modules/pull-pushable/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-http-auth-client/lib/constants.js": [
    "22sklfka1IsRm6XzsoQA3EILAS58dJfXfWfNV3KfF1I=",
    {}
  ],
  "node_modules/ssb-http-auth-client/lib/index.js": [
    "SRR26D+P2KAM1tEuK5udvEj+qVVrS36Kj9kuuE0Vug0=",
    {
      "./plugin-http-auth": "node_modules/ssb-http-auth-client/lib/plugin-http-auth.js",
      "./plugin-http-auth-client": "node_modules/ssb-http-auth-client/lib/plugin-http-auth-client.js",
      "./plugin-http-auth-client-tokens": "node_modules/ssb-http-auth-client/lib/plugin-http-auth-client-tokens.js"
    }
  ],
  "node_modules/ssb-http-auth-client/lib/plugin-http-auth-client-tokens.js": [
    "kUBbIgYLAvRSup7tX8ogxgGnWC85fZEvFlBsZLHOl8Y=",
    {
      "./constants": "node_modules/ssb-http-auth-client/lib/constants.js"
    }
  ],
  "node_modules/ssb-http-auth-client/lib/plugin-http-auth-client.js": [
    "Hi1NqZ474PNLZlkr7jSNN+wTYA4W9nMY+B6BcVDdhaM=",
    {
      "./constants": "node_modules/ssb-http-auth-client/lib/constants.js",
      "./solution": "node_modules/ssb-http-auth-client/lib/solution.js",
      "debug": "node_modules/debug/src/index.js",
      "ssb-ref": "node_modules/ssb-http-auth-client/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-http-auth-client/lib/plugin-http-auth.js": [
    "ikAOguEfEN2DC6+EuZVI5oOYmN2HnlETDh8Rn/xQ4C8=",
    {
      "./constants": "node_modules/ssb-http-auth-client/lib/constants.js",
      "./solution": "node_modules/ssb-http-auth-client/lib/solution.js",
      "debug": "node_modules/debug/src/index.js"
    }
  ],
  "node_modules/ssb-http-auth-client/lib/solution.js": [
    "1s7gNWL9bv3u1Jt8UO9OkwtwLbkbS3pXzZDOUI2E6Xw=",
    {
      "ssb-keys": "node_modules/ssb-keys/index.js"
    }
  ],
  "node_modules/ssb-http-auth-client/node_modules/ssb-ref/index.js": [
    "i3ZecsskmJPA4FlkZFhpDz9h4J/vS4YwfHM48haowDU=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-http-invite-client/lib/index.js": [
    "A8vg/dLVpwCJt5YxfoftVupQufIBkasQ8k2vyxQHJLI=",
    {
      "@minireq/browser": "node_modules/@minireq/browser/build/bundle.cjs.js",
      "@minireq/node": "node_modules/@minireq/node/build/bundle.cjs.js",
      "ssb-ref": "node_modules/ssb-http-invite-client/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-http-invite-client/node_modules/ssb-ref/index.js": [
    "i3ZecsskmJPA4FlkZFhpDz9h4J/vS4YwfHM48haowDU=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-invite-client/lib/index.js": [
    "AkufsqbhzOeEcKg5R0EcaYJpQ2QkC8Xk7XasY0Nl0Ew=",
    {
      "explain-error": "node_modules/explain-error/index.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-keys-mnemonic/lib/index.js": [
    "Jz6VhAuWsvtxE+LasoUSSdn52Ibbx7Z0NYFJtuHv76g=",
    {
      "bip39": "node_modules/bip39/src/index.js",
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/ssb-keys/index.js": [
    "HmhoBUNx528KX6oeQOYdonZP2HwDl8zLntuBhy/Jl9M=",
    {
      "./sodium": "node_modules/ssb-keys/sodium.js",
      "./storage": "node_modules/ssb-keys/storage.js",
      "./util": "node_modules/ssb-keys/util.js",
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js",
      "private-box": "node_modules/private-box/index.js"
    }
  ],
  "node_modules/ssb-keys/local-storage.js": [
    "SuH9xO3Rm8LEqlsnebPcb0XKI0O52FtK1EQ8Zea6z4I=",
    {}
  ],
  "node_modules/ssb-keys/node_modules/mkdirp/index.js": [
    "xwNbRxsZe6bUh5toA7bKJzoXr2yKI4Lcul6zunCkOsI=",
    {}
  ],
  "node_modules/ssb-keys/sodium.js": [
    "niN9ewvht3fE9moc8XWMebNBifnM/0WKOAdoePiTIk4=",
    {
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/ssb-keys/storage.js": [
    "g3Vx1n8DasPpnlH2ssn6Bk/hvwTrnt6KVea8psN2VRc=",
    {
      "./local-storage": "node_modules/ssb-keys/local-storage.js",
      "./util": "node_modules/ssb-keys/util.js",
      "mkdirp": "node_modules/ssb-keys/node_modules/mkdirp/index.js"
    }
  ],
  "node_modules/ssb-keys/util.js": [
    "oSONbch8b+vRQVX4roPYOvFuj3bSvkH7oL4ImqhBafM=",
    {
      "chloride": "node_modules/sodium-chloride-native-nodejs-mobile/index.js"
    }
  ],
  "node_modules/ssb-lan/lib/index.js": [
    "Jipyk9wcme+vGp+ggtaUWfkrlQCNoaN9cZ0KQwDd/wQ=",
    {
      "../port": "node_modules/ssb-lan/port.js",
      "broadcast-stream": "node_modules/broadcast-stream/index.js",
      "debug": "node_modules/debug/src/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-ref": "node_modules/ssb-lan/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-lan/node_modules/ssb-ref/index.js": [
    "t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-lan/port.js": [
    "ipAeMUD7gTZ/UJ5ca9uKT2OR95ebbUzcr8EGj0N2eOY=",
    {}
  ],
  "node_modules/ssb-master/index.js": [
    "zXiSEqjSjF1a8LhdARoR44gmjdICViuF8nex7tho8tY=",
    {}
  ],
  "node_modules/ssb-mobile-bluetooth-manager/index.js": [
    "AoZLaFBvqQ0x+URmYcRwzEkGuDdK92Uwpbsup93AdOs=",
    {
      "debug": "node_modules/debug/src/index.js",
      "pull-defer": "node_modules/pull-defer/index.js",
      "pull-json-doubleline": "node_modules/pull-json-doubleline/index.js",
      "pull-pushable": "node_modules/pull-pushable/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "pull-zip": "node_modules/pull-zip/index.js",
      "stream-to-pull-stream": "node_modules/stream-to-pull-stream/index.js",
      "uuid/v4": "node_modules/uuid/v4.js"
    }
  ],
  "node_modules/ssb-network-errors/index.js": [
    "HlRhYmikJ/Hw88F2T7kYdCAM6NW+vFJDcRQf/jkGOXY=",
    {}
  ],
  "node_modules/ssb-ref/index.js": [
    "qZ4HR5CmlpLbPLk1+d1LqqW1rFhXcWDxdD7g9IgIB+M=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-replication-scheduler/index.js": [
    "+w3zC48+bmTsIfQxXg5tmXkKa8aEA9GPzIKmhuhTd8c=",
    {
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-room-client/lib/error-duplex.js": [
    "dIH/Ywl/qcXqdU37HimxIzdK3MCVuYWRAIZXx1HUZHI=",
    {}
  ],
  "node_modules/ssb-room-client/lib/index.js": [
    "vHqmQ8fMMsT4AexObfLXsD7uE3ZeB4tGqJUC+NWK7Sk=",
    {
      "./plugin-room": "node_modules/ssb-room-client/lib/plugin-room.js",
      "./plugin-room-client": "node_modules/ssb-room-client/lib/plugin-room-client.js",
      "./plugin-tunnel": "node_modules/ssb-room-client/lib/plugin-tunnel.js"
    }
  ],
  "node_modules/ssb-room-client/lib/ms-tunnel.js": [
    "CyqPv4HVo4ehT+I/WLEF1D9l1H38iVlGBNvEwM/p508=",
    {
      "./room-observer": "node_modules/ssb-room-client/lib/room-observer.js",
      "./utils": "node_modules/ssb-room-client/lib/utils.js",
      "debug": "node_modules/ssb-room-client/node_modules/debug/src/index.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-ref": "node_modules/ssb-room-client/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-room-client/lib/plugin-room-client.js": [
    "1gi2b2zi1u8J8RnO+JeLS7H3zsegip+j9MtKgSBwWaw=",
    {
      "@minireq/browser": "node_modules/@minireq/browser/build/bundle.cjs.js",
      "@minireq/node": "node_modules/@minireq/node/build/bundle.cjs.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "pull-notify": "node_modules/pull-notify/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-ref": "node_modules/ssb-room-client/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-room-client/lib/plugin-room.js": [
    "vu5k+583N6JkAv3Qh2k5aHhsEis/lIiDj57B09nXFuw=",
    {
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "node_modules/ssb-room-client/lib/plugin-tunnel.js": [
    "V8LPVP6Dlm454X8QoU3/l04e5WR24JU3cf2+HlLflzE=",
    {
      "./error-duplex": "node_modules/ssb-room-client/lib/error-duplex.js",
      "./ms-tunnel": "node_modules/ssb-room-client/lib/ms-tunnel.js",
      "debug": "node_modules/ssb-room-client/node_modules/debug/src/index.js",
      "pull-pair/duplex": "node_modules/pull-pair/duplex.js"
    }
  ],
  "node_modules/ssb-room-client/lib/room-observer.js": [
    "VBd1fS+Iw8csaOw42aFWcU7x9+pn01qAvyerePYw8vw=",
    {
      "./utils": "node_modules/ssb-room-client/lib/utils.js",
      "debug": "node_modules/ssb-room-client/node_modules/debug/src/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-network-errors": "node_modules/ssb-network-errors/index.js"
    }
  ],
  "node_modules/ssb-room-client/lib/utils.js": [
    "0wFt4B8du4P4lVQyBzAOtjT62+VD7f6bbqGhJRwUMFA=",
    {
      "ssb-ref": "node_modules/ssb-room-client/node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-room-client/node_modules/debug/src/browser.js": [
    "Tj3G0OHbWKDXQga0Q/NVgtO3F75WoPbQMMNK9sKtn2I=",
    {
      "./common": "node_modules/ssb-room-client/node_modules/debug/src/common.js"
    }
  ],
  "node_modules/ssb-room-client/node_modules/debug/src/common.js": [
    "WOWZfRqweYHJ1ub617U6ZmC/iTQqnmHa1jBQyCJIS5I=",
    {
      "ms": "node_modules/ms/index.js"
    }
  ],
  "node_modules/ssb-room-client/node_modules/debug/src/index.js": [
    "qhJ/8XUrfZx0FcXHu2mU2apyK4G8vKtL1IMWsBPSO/M=",
    {
      "./browser.js": "node_modules/ssb-room-client/node_modules/debug/src/browser.js",
      "./node.js": "node_modules/ssb-room-client/node_modules/debug/src/node.js"
    }
  ],
  "node_modules/ssb-room-client/node_modules/debug/src/node.js": [
    "8jety1KEnefBKPV+BGi1I1PFKabINBgQR3wOcUQ1lVk=",
    {
      "./common": "node_modules/ssb-room-client/node_modules/debug/src/common.js"
    }
  ],
  "node_modules/ssb-room-client/node_modules/ssb-ref/index.js": [
    "t9FnZwPicKCLRp5P2BU7PoG1scLsBPjwmfKhacICRko=",
    {
      "ip": "node_modules/ip/lib/ip.js",
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "is-valid-domain": "node_modules/is-valid-domain/index.js",
      "multiserver-address": "node_modules/multiserver-address/index.js"
    }
  ],
  "node_modules/ssb-search2/lib/index.js": [
    "ImbZbki9SHk612auyf0MzhjQ/wGqu0Q2IE83/XMkrWE=",
    {
      "./plugin": "node_modules/ssb-search2/lib/plugin.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js"
    }
  ],
  "node_modules/ssb-search2/lib/plugin.js": [
    "jW4NYfy5IT7F/a/OMmCnVccFAro2P6EYPbke77c0xpo=",
    {
      "./stop-words": "node_modules/ssb-search2/lib/stop-words.js",
      "./unicode-word-regex": "node_modules/ssb-search2/lib/unicode-word-regex.js",
      "bipf": "node_modules/bipf/index.js",
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-db2/indexes/plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-search2/lib/stop-words.js": [
    "kukEw2ejQrFQSyLoq/mQZIyVXu5nX3HQgP+iQbU8T8E=",
    {}
  ],
  "node_modules/ssb-search2/lib/unicode-word-regex.js": [
    "je0s82rvO4qSmFDi+lj3VDr97Ad+B249AVdxkBptbag=",
    {}
  ],
  "node_modules/ssb-serve-blobs/id-to-url.js": [
    "xFswaLS+LEcypI3weUYW9sI8wzQNMsVE/jUOa+NfKrk=",
    {
      "./port": "node_modules/ssb-serve-blobs/port.js"
    }
  ],
  "node_modules/ssb-serve-blobs/index.js": [
    "AotSg8OFi+45XXQYOo3BG6J46u4PQvjSv8Syr5ga4p4=",
    {
      "./port": "node_modules/ssb-serve-blobs/port.js",
      "file-type": "node_modules/file-type/index.js",
      "multiblob-http": "node_modules/multiblob-http/index.js",
      "pull-box-stream": "node_modules/pull-box-stream/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "url-parse": "node_modules/url-parse/index.js"
    }
  ],
  "node_modules/ssb-serve-blobs/port.js": [
    "GCqC0Z1TFuAA+NbEVWgs0y6Xmyi1oMU9tnzKnEbcYz0=",
    {}
  ],
  "node_modules/ssb-sort/index.js": [
    "tBXb0zrw8npG9LgueIj3oBYWctXQJAlPteS0BOt/WfU=",
    {
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-suggest-lite/lib/index.js": [
    "fqrJBQcVRwgEz7qsHCeTnM1dneca74nTAK2jFJDFN4g=",
    {
      "p-defer": "node_modules/p-defer/index.js",
      "promisify-tuple": "node_modules/promisify-tuple/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-db2/utils": "node_modules/ssb-db2/utils.js"
    }
  ],
  "node_modules/ssb-threads/lib/hashtags.js": [
    "qTPbn8TDQgcxQj5aib9JU8JN/XRJr217ks5Skf/uOUs=",
    {
      "bipf": "node_modules/bipf/index.js",
      "pull-level": "node_modules/pull-level/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-db2/indexes/plugin": "node_modules/ssb-db2/indexes/plugin.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js"
    }
  ],
  "node_modules/ssb-threads/lib/index.js": [
    "sj1iJvVfF9fDiUSmoEZ0UkMJsNoYS7h79awiz1fegVw=",
    {
      "./hashtags": "node_modules/ssb-threads/lib/hashtags.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "secret-stack-decorators": "node_modules/secret-stack-decorators/lib/index.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js",
      "ssb-sort": "node_modules/ssb-sort/index.js",
      "ssb-typescript/utils": "node_modules/ssb-typescript/utils.js"
    }
  ],
  "node_modules/ssb-typescript/utils.js": [
    "w9J85IsmhUO/SCkzmKVEl6BaPW1P/Asp3WBG+DrBvYE=",
    {}
  ],
  "node_modules/ssb-uri2/lib/index.js": [
    "gCvs4gFsotcr+uMgZq2qK8X5EJQv6JI8otkGnZW7VLc=",
    {
      "url-parse": "node_modules/url-parse/index.js"
    }
  ],
  "node_modules/ssb-validate/index.js": [
    "X0uP+gxlB5CIVd6xBy1LxTe9b2hoZAqKp0rYk670Hmg=",
    {
      "is-canonical-base64": "node_modules/is-canonical-base64/index.js",
      "monotonic-timestamp": "node_modules/monotonic-timestamp/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "node_modules/ssb-validate2/index.js": [
    "BV2kG6VEVFcyNv+HpxDyLhk0Rs8wmuHW234wYy8pcjg=",
    {
      "ssb-validate": "node_modules/ssb-validate/index.js"
    }
  ],
  "node_modules/staltz-multiserver/plugins/net.js": [
    "Qtq0Zi1h5w+31kHBhWxZ18CIVEQ1XWTjrqNLMRMfh3Y=",
    {
      "debug": "node_modules/debug/src/index.js",
      "multiserver-scopes": "node_modules/multiserver-scopes/index.js",
      "stream-to-pull-stream": "node_modules/stream-to-pull-stream/index.js"
    }
  ],
  "node_modules/statistics/index.js": [
    "3CkTk26fOLUi82dbSnycCyGuWbLHMkto77jsauPEcCg=",
    {
      "./initial": "node_modules/statistics/initial.js"
    }
  ],
  "node_modules/statistics/initial.js": [
    "EUYfxyAHlH65uL4RrUnkstYjV7itgf8+PmpAXT33jnM=",
    {}
  ],
  "node_modules/statistics/mutate.js": [
    "bbXxctzqyJ5s8kKXUtlW3DmtqpGRJC7Hl1slGC0p3lA=",
    {
      "./initial": "node_modules/statistics/initial.js"
    }
  ],
  "node_modules/stream-to-pull-stream/index.js": [
    "bS4BElfJ23YQoMLX1jW0G0bQjV6BBWZxV0dwKr4wOfQ=",
    {
      "looper": "node_modules/looper/index.js",
      "pull-stream/pull": "node_modules/pull-stream/pull.js"
    }
  ],
  "node_modules/string_decoder/lib/string_decoder.js": [
    "8dNtR7LFeQYzksGmiWNGfy1PUaBprwnrBo2XTGPuOzc=",
    {
      "safe-buffer": "node_modules/string_decoder/node_modules/safe-buffer/index.js"
    }
  ],
  "node_modules/string_decoder/node_modules/safe-buffer/index.js": [
    "1YryHLBRiGTQxQV0LRr3HlteHxQvTA8nNTqg9DGmFtQ=",
    {}
  ],
  "node_modules/strip-json-comments/index.js": [
    "P+jANL/GScjoBFL0xwUhU6SciaV58/h6Tfavi6tc4rk=",
    {}
  ],
  "node_modules/strtok3/lib/AbstractTokenizer.js": [
    "JIiAvBspwjfdfeQG9aYaxD+5xVceD3JArLLS2pqM0I8=",
    {
      "peek-readable": "node_modules/peek-readable/lib/index.js"
    }
  ],
  "node_modules/strtok3/lib/BufferTokenizer.js": [
    "VU+1WBMeN1j/WKmx0ycNlhOeh0AXVNh2+kF4NmPAPAI=",
    {
      "./AbstractTokenizer": "node_modules/strtok3/lib/AbstractTokenizer.js",
      "peek-readable": "node_modules/peek-readable/lib/index.js"
    }
  ],
  "node_modules/strtok3/lib/FileTokenizer.js": [
    "ET16jD2WhTMT06Kw15vXP1DBSGm9iwDnkfq4R3EFxKI=",
    {
      "./AbstractTokenizer": "node_modules/strtok3/lib/AbstractTokenizer.js",
      "./FsPromise": "node_modules/strtok3/lib/FsPromise.js",
      "peek-readable": "node_modules/peek-readable/lib/index.js"
    }
  ],
  "node_modules/strtok3/lib/FsPromise.js": [
    "uxR9z+4gBSzxWxqRy5/zeTtiI+77Mk8mXN9xGbEXEGk=",
    {}
  ],
  "node_modules/strtok3/lib/ReadStreamTokenizer.js": [
    "QQQAILjqxIlVNE7ftJTfhXmUZcvNV/Z14NAv7EgrKxw=",
    {
      "./AbstractTokenizer": "node_modules/strtok3/lib/AbstractTokenizer.js",
      "peek-readable": "node_modules/peek-readable/lib/index.js"
    }
  ],
  "node_modules/strtok3/lib/core.js": [
    "5Izx0x/zPg453t8XlxmL0E8Igqu+NUJLgaMFp3rVBEI=",
    {
      "./BufferTokenizer": "node_modules/strtok3/lib/BufferTokenizer.js",
      "./ReadStreamTokenizer": "node_modules/strtok3/lib/ReadStreamTokenizer.js",
      "peek-readable": "node_modules/peek-readable/lib/index.js"
    }
  ],
  "node_modules/strtok3/lib/index.js": [
    "KPtuL0Xd6xLgTpL0WOseyTJ5g3IUh8NC7yadL+Apq2Y=",
    {
      "./FileTokenizer": "node_modules/strtok3/lib/FileTokenizer.js",
      "./FsPromise": "node_modules/strtok3/lib/FsPromise.js",
      "./core": "node_modules/strtok3/lib/core.js"
    }
  ],
  "node_modules/to-camel-case/index.js": [
    "ozyIVscu19VKjALanqYmscOQ6YeyyveCY+pQetRrmpw=",
    {
      "to-space-case": "node_modules/to-space-case/index.js"
    }
  ],
  "node_modules/to-no-case/index.js": [
    "DIlVPZ6OdBPO6pHIGw/Wsf1kH4kl4ZS+p0rVyffyut8=",
    {}
  ],
  "node_modules/to-space-case/index.js": [
    "TkIiVGduanukayVt0UICnsqUxsxMJtLRz4fzVxkRQfY=",
    {
      "to-no-case": "node_modules/to-no-case/index.js"
    }
  ],
  "node_modules/token-types/lib/index.js": [
    "IH0m90wB0IOj5Amv6VG+cxD6xxtdt9sAbjB3YonTijY=",
    {
      "ieee754": "node_modules/ieee754/index.js"
    }
  ],
  "node_modules/too-hot/index.js": [
    "cWiRHqXeVRvq+fEtoyMhLslo+0Lo+LSr6dipuR/xuy8=",
    {
      "cpu-percentage": "node_modules/cpu-percentage/index.js"
    }
  ],
  "node_modules/trammel/lib/trammel.js": [
    "a4dQTVAat0MdbsRjIcZTnAYaw7p1Z2s+IjRNF1moctk=",
    {
      "format-io": "node_modules/format-io/lib/format.js",
      "try-to-catch": "node_modules/try-to-catch/lib/try-to-catch.js"
    }
  ],
  "node_modules/traverse/index.js": [
    "VkDj/t9A1iltFCn2XW8+NX9qu1tBksktxzBCUwWnZ6U=",
    {}
  ],
  "node_modules/truncate-utf8-bytes/index.js": [
    "K3OiX0hdGM37TALUd22PFuE3iR3ful7ryRkaTyMDD/c=",
    {
      "./lib/truncate": "node_modules/truncate-utf8-bytes/lib/truncate.js"
    }
  ],
  "node_modules/truncate-utf8-bytes/lib/truncate.js": [
    "JZPGDHJrp9d7qlcUmyXIpEwjjmizZCwL61YgfUu6FEo=",
    {}
  ],
  "node_modules/try-to-catch/lib/try-to-catch.js": [
    "v8QBy1kW50yvZsdyrwAo5hCAdx0uGV5haJuf+4/ronM=",
    {}
  ],
  "node_modules/typedfastbitset/TypedFastBitSet.js": [
    "Zun2enq2ObP2KBPIWHJ6YL3JFIc7ICDOqYlmTNn4kWI=",
    {}
  ],
  "node_modules/uint48be/index.js": [
    "V40Est4Tyde8PXipRJ0Lhj33IOy+qf0d6LstY4y3TAU=",
    {}
  ],
  "node_modules/url-parse/index.js": [
    "u31cfWGdWCm6oJyY0157VZbLMYDWViuTy7rw7tV1xsI=",
    {
      "querystringify": "node_modules/querystringify/index.js",
      "requires-port": "node_modules/requires-port/index.js"
    }
  ],
  "node_modules/util-deprecate/node.js": [
    "moain6NKmbhh5wc0X7HR4uVabCPtuPmSvtV8xgf0LY4=",
    {}
  ],
  "node_modules/uuid/lib/bytesToUuid.js": [
    "bKeiwBPcHhuAkoiYhf8ZZ5xBOLX8kYKqzCBsJjRU+dY=",
    {}
  ],
  "node_modules/uuid/lib/rng.js": [
    "W/Rc8J/ztYuBMQPCdVlUyu/nbqIy/zpUblr1JVUR7JE=",
    {}
  ],
  "node_modules/uuid/v4.js": [
    "ZKX6Qcb3mXNjf+WN4k2IR1RbvXXvHr7UAvLJdvzySis=",
    {
      "./lib/bytesToUuid": "node_modules/uuid/lib/bytesToUuid.js",
      "./lib/rng": "node_modules/uuid/lib/rng.js"
    }
  ],
  "node_modules/varint/decode.js": [
    "fsejwzyU5jrjbqFHK+d/77RRRc4UHfP3BFH1DLMLkM8=",
    {}
  ],
  "node_modules/varint/encode.js": [
    "MOaFSzZeJ/pFf1bOYLzmtaAS2kSjjg2M11K5mzCm/hc=",
    {}
  ],
  "node_modules/varint/index.js": [
    "VVUHV3nLLb95odzcH12MZg9hHpE4e0UwHt9yLqgzvok=",
    {
      "./decode.js": "node_modules/varint/decode.js",
      "./encode.js": "node_modules/varint/encode.js",
      "./length.js": "node_modules/varint/length.js"
    }
  ],
  "node_modules/varint/length.js": [
    "0g4TXknmIVjmOwJNN4VBXhU+HE4pkx8bTCijb5TR4RI=",
    {}
  ],
  "node_modules/wrappy/wrappy.js": [
    "FTRTxNhKPC8TWJw3BVp9r/YdSEddzOVU9+7a0V/Hs+U=",
    {}
  ],
  "node_modules/xtend/immutable.js": [
    "BJhvFouPFvTyUjfQYIzfV7bKFPEA/tYsApW9olWasks=",
    {}
  ],
  "node_modules/ziii/index.js": [
    "Wa4og6G+jxcCWRTrlcuAb1r4ZfO5vm0oEaTcKtvHoU0=",
    {}
  ],
  "one-time-fixes.js": [
    "wDUddFoUUfikwogs68Z2pOEFmTJpppgiAcPj6Xt0U5I=",
    {
      "async-append-only-log": "node_modules/async-append-only-log/index.js",
      "bipf": "node_modules/bipf/index.js",
      "rimraf": "node_modules/rimraf/rimraf.js",
      "ssb-db2/defaults": "node_modules/ssb-db2/defaults.js"
    }
  ],
  "plugins/aboutSelf.js": [
    "ri2iJYfd1hM101FVpLsSCXGjhg5rx9jF3AKh+LwFcIk=",
    {
      "pull-async": "node_modules/pull-async/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "plugins/aliasUtils.js": [
    "SMmQWmiQ5Q+ptcXBccp9IbX7AzbT063HbpFOXbNDIH4=",
    {
      "pull-async": "node_modules/pull-async/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "plugins/blobsUtils.js": [
    "29Jh0EJBivwEt5btjv67KcmQxSvDgWBHRR98xIc+p/Q=",
    {
      "pull-file": "node_modules/pull-file/index.js",
      "pull-stream": "node_modules/pull-stream/index.js"
    }
  ],
  "plugins/bluetooth.js": [
    "+T7sQ04aU28GLFEBOj2FrWUH//Kh3I0/8/KMos/Nh4E=",
    {
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-bluetooth": "node_modules/ssb-bluetooth/index.js",
      "ssb-mobile-bluetooth-manager": "node_modules/ssb-mobile-bluetooth-manager/index.js"
    }
  ],
  "plugins/connUtils.js": [
    "HT/pJIWUIo+8yEwhsq6Do+C/gZeI0Vm0ZxOw/ruRWzY=",
    {
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-serve-blobs/id-to-url": "node_modules/ssb-serve-blobs/id-to-url.js"
    }
  ],
  "plugins/dbUtils.js": [
    "Hxyl99f9NK77cObdWj3oIbcx3nPOPiXE1FO+lkvBkfg=",
    {
      "mkdirp": "node_modules/mkdirp/index.js",
      "pull-async": "node_modules/pull-async/index.js",
      "pull-cat": "node_modules/pull-cat/index.js",
      "pull-stream": "node_modules/pull-stream/index.js",
      "rimraf": "node_modules/rimraf/rimraf.js"
    }
  ],
  "plugins/keysUtils.js": [
    "2+GLHn3KBKlfSWUQjnzwKa1WgDYtjV6aVR48BzwmwVs=",
    {
      "ssb-keys-mnemonic": "node_modules/ssb-keys-mnemonic/lib/index.js"
    }
  ],
  "plugins/multiserver-addons.js": [
    "88chY/ziKx3yfC1mhfx/HLAvhyOFSFmvaTQG9QACJMw=",
    {
      "multiserver-rn-channel": "node_modules/multiserver-rn-channel/index.js",
      "multiserver/plugins/noauth": "node_modules/multiserver/plugins/noauth.js",
      "multiserver/plugins/ws": "node_modules/multiserver/plugins/ws.js"
    }
  ],
  "plugins/publishUtilsBack.js": [
    "ybzGnP5/vfS9X8fXCDvjnVukKNGL25awUAYAXG1ITkc=",
    {
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "plugins/resyncUtils.js": [
    "pOnCRFSzp+kJnH5MSNe9WnblM1oX8MZ9asmcDPKQb5o=",
    {}
  ],
  "plugins/searchUtils.js": [
    "elrpliqmrOwGvUbADflkmicUu1ThW0xWsL4t6rHibOM=",
    {
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js"
    }
  ],
  "plugins/settingsUtils.js": [
    "flo5MMVYKgCxO3FuYOvvWdbilzNArrLpIOYYD97C4hg=",
    {
      "mkdirp": "node_modules/mkdirp/index.js"
    }
  ],
  "plugins/syncing.js": [
    "yh3VqhoCEumEBxUpV/a7PfMJrn3HYirU3UQSOXjPUVA=",
    {
      "pull-stream-util/from-event": "node_modules/pull-stream-util/from-event.js"
    }
  ],
  "plugins/votes.js": [
    "4ZQIBPA8MEvS5nlNTbzX9lMWLK5xzfIamk/MRkI9EfU=",
    {
      "pull-stream": "node_modules/pull-stream/index.js",
      "ssb-db2/operators": "node_modules/ssb-db2/operators/index.js",
      "ssb-ref": "node_modules/ssb-ref/index.js"
    }
  ],
  "restore.js": [
    "2CeEp9hcJXbTazlXf+iMgZjGlVj8fIgTlqAAn6ZauOg=",
    {
      "mkdirp": "node_modules/mkdirp/index.js",
      "ssb-keys-mnemonic": "node_modules/ssb-keys-mnemonic/lib/index.js"
    }
  ],
  "ssb.js": [
    "6MXKYXv2yybhg7BqMk6aetUaL8ARfB5rRb2GcXRRWQg=",
    {
      "./one-time-fixes": "one-time-fixes.js",
      "./plugins/aboutSelf": "plugins/aboutSelf.js",
      "./plugins/aliasUtils": "plugins/aliasUtils.js",
      "./plugins/blobsUtils": "plugins/blobsUtils.js",
      "./plugins/bluetooth": "plugins/bluetooth.js",
      "./plugins/connUtils": "plugins/connUtils.js",
      "./plugins/dbUtils": "plugins/dbUtils.js",
      "./plugins/keysUtils": "plugins/keysUtils.js",
      "./plugins/multiserver-addons": "plugins/multiserver-addons.js",
      "./plugins/publishUtilsBack": "plugins/publishUtilsBack.js",
      "./plugins/resyncUtils": "plugins/resyncUtils.js",
      "./plugins/searchUtils": "plugins/searchUtils.js",
      "./plugins/settingsUtils": "plugins/settingsUtils.js",
      "./plugins/syncing": "plugins/syncing.js",
      "./plugins/votes": "plugins/votes.js",
      "mkdirp": "node_modules/mkdirp/index.js",
      "secret-stack": "node_modules/secret-stack/lib/index.js",
      "ssb-blobs": "node_modules/ssb-blobs/index.js",
      "ssb-blobs-purge": "node_modules/ssb-blobs-purge/lib/index.js",
      "ssb-caps": "node_modules/ssb-caps/caps.json",
      "ssb-config/inject": "node_modules/ssb-config/inject.js",
      "ssb-conn": "node_modules/ssb-conn/lib/index.js",
      "ssb-conn-firewall": "node_modules/ssb-conn-firewall/lib/index.js",
      "ssb-db2": "node_modules/ssb-db2/index.js",
      "ssb-db2/about-self": "node_modules/ssb-db2/about-self.js",
      "ssb-db2/compat/db": "node_modules/ssb-db2/compat/db.js",
      "ssb-db2/compat/ebt": "node_modules/ssb-db2/compat/ebt.js",
      "ssb-db2/compat/history-stream": "node_modules/ssb-db2/compat/history-stream.js",
      "ssb-db2/compat/log-stream": "node_modules/ssb-db2/compat/log-stream.js",
      "ssb-db2/full-mentions": "node_modules/ssb-db2/full-mentions.js",
      "ssb-deweird/producer": "node_modules/ssb-deweird/producer.js",
      "ssb-ebt": "node_modules/ssb-ebt/index.js",
      "ssb-friends": "node_modules/ssb-friends/index.js",
      "ssb-http-auth-client": "node_modules/ssb-http-auth-client/lib/index.js",
      "ssb-http-invite-client": "node_modules/ssb-http-invite-client/lib/index.js",
      "ssb-invite-client": "node_modules/ssb-invite-client/lib/index.js",
      "ssb-keys": "node_modules/ssb-keys/index.js",
      "ssb-lan": "node_modules/ssb-lan/lib/index.js",
      "ssb-master": "node_modules/ssb-master/index.js",
      "ssb-replication-scheduler": "node_modules/ssb-replication-scheduler/index.js",
      "ssb-room-client": "node_modules/ssb-room-client/lib/index.js",
      "ssb-search2": "node_modules/ssb-search2/lib/index.js",
      "ssb-serve-blobs": "node_modules/ssb-serve-blobs/index.js",
      "ssb-suggest-lite": "node_modules/ssb-suggest-lite/lib/index.js",
      "ssb-threads": "node_modules/ssb-threads/lib/index.js"
    }
  ]
},
"index.js")
